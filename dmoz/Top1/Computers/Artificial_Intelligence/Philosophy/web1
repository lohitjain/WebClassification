====================<http://www.inm.de/kip/>====================
<!DOCTYPE HTML PUBLIC >
<!-- Copyright 1995 Gerd Döben-Henisch, Institut fuer neue Medien Frankfurt-->
<HTML>
<HEAD>
<TITLE>Überblick zum Agenten-Projekt des INM ( Overview of the agent project of 
the INM)</TITLE>
<script src="/topnavi.js" type="text/javascript"></script>
<link rel="stylesheet" type="text/css" href="/inm.css">
</HEAD>
<body bgcolor="White" text="#000000" link="#CC0000" alink="#FF3300" vlink="#330099">
<table border=0 cellspacing=0 cellpadding=0 width="100%">
  <tr> 
    <td width="28%" valign=top BGCOLOR="#E6FFE6"><TT><FONT COLOR="#008000"> 
      <!-- notes column -->
      <P><A HREF="/projects/kip/doeb/vita_vita.html"><IMG SRC="/projects/kip/pictures/gerd2.jpg" ALIGN="TOP" ALT="Dr. Gerd Doeben-Henisch"></a> 
        <br>
        <br>
        <A HREF="/projects/kip/pictures/pictures.html"><img hspace=8 BORDER="0" src="/projects/kip/pictures/knowb-1.gif" ALT="'95-Knowbot"></a> 
        <br>
        <br>
        <a href="http://www.stadt-frankfurt.de/wissenschaftsstadt"> <IMG SRC="/projects/kip/pictures/logomini.gif"
                           border=0></a> </font></tt></td>
    <td width="2%" valign=top> 
      <!-- spacing column -->
    </td>
    <td  VALIGN=TOP WIDTH="65%"> <FONT COLOR="#008000">
      <!-- main text column -->
      <H3>Knowbotic Interface Projekt = {Knowledge Robots/ Knowbots, Agents with 
        Consciousness, Wittgenstein Agents, Semiotic Machines, Robot Pets}</H3>
      <a NAME="HOME"></a> 
      <hr>
      <address>
      <font size=-2> AUTHOR: Gerd Döben-Henisch<br>
      DATE OF FIRST GENERATION: July 6, 1995<br>
      DATE OF LAST CHANGE: Dec 17, 1999<br>
      ADDRESS: INM - Institute for New Media, Frankfurt, Germany<br>
      EMAIL: <a href="mailto:doeb@inm.de">doeb@inm.de</a><br>
      URL: <a href="http://www.inm.de" target="_top">INM</a> <br>
      Copyright (c) Gerd Döben-Henisch - INM Institut für Neue Medien - Frankfurt 
      - Sept. 1997 </font> 
      </address>
      <hr>
      <UL>
        <LI><a href="/projects/kip/books_main.html">KNOWBOT BOOKS (April 27, 1998)</A> 
        <LI><A HREF="/projects/kip/lectures/workshops/agents-ii.htm">WORKSHOP(S) (April 
          24, 1998)</A> 
        <LI><A HREF="/projects/kip/general/guide.html">GUIDED TOUR (Sept 21, 1997)</A> 
        <LI><A HREF="/projects/kip/general/general.html">PAPERS (Jan 4, 1999)</A> 
        <LI><a href="semiotic/semiotic_machines.html">COMPUTATIONAL SEMIOTICS 
          (June 22,1999)</A> 
        <LI><A HREF="/projects/kip/books/memography.html">BIBLIOGRAPHY (May 20, 1998)</A> 
        <LI><A HREF="/projects/kip/lectures/lectures.html">PUBLIC LECTURES (Feb 11, 1999)</A> 
        <LI><A HREF="/projects/kip/media/media.html">KIP IN THE MEDIA (Oct 14, 1998)</A> 
        <LI><A HREF="/projects/kip/events/events.html">EVENTS (Aug 25, 1997)</A> 
        <LI><A HREF="/projects/kip/applets/applet_cover.html"> SW-DEMOS (Jan 4, 1999)</A> 
        <LI><A HREF="/projects/kip/personal/kip_team.html">KIP-TEAM (Dez 17, 1997)</A> 
      </UL>
      </font></td>
    <td width="5%" valign=top BGCOLOR="#E6FFE6"><TT><FONT COLOR="#008000"> 
      <!-- icons column -->
      </font></tt></td>
  </tr>
</table>
</BODY>
</HTML>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://dobrev.com/AI/definition.html>====================
<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="keywords" content="Artificial Intelligence, AI, Definition, Definition of AI, Artificial World">
   <meta name="Author" content="Dimiter Dobrev">
   <title>AI Definition</title>
</head>
<body text="#000000" bgcolor="#FFFFFF" link="#000099" vlink="#551A8B" alink="#CC0000">
&nbsp;
<table CELLSPACING=0 CELLPADDING=0 WIDTH="100%" >
<tr>
<td WIDTH="20%">
<blockquote><a href="http://www.sagabg.net/PCMagazine/"><img SRC="pcmagazine.gif" NOSAVE BORDER=0 height=113 width=73></a></blockquote>
</td>

<td><b><font color="#CC0000"><font size=+2>AI - What is this</font></font></b>
<br><b>A Definition of Artificial Intelligence</b>
<p>November'2000
<br>this paper is a part from <a href="http://www.dobrev.com/AI/">AI-
Project</a></td>
</tr>
</table>

<blockquote><a href="http://www.dobrev.com/dobrev.html">Dimiter Dobrev</a>
<br>
<script type="text/javascript" language="javascript">
<!--
var Start="a4a8a0a5bda6f3";
var j; var B = "<a href=\"";
var Box= "dobrev"; 
for (j = 0; j < 14; j += 2)
  B += String.fromCharCode(parseInt(Start.slice(j,j+2), 16)^201);
B += " "+Box;
B += "&#64;";
B += "2-box.com\">"+Box;
B += "&#64;";
B += "2-box.com</a>";
document.write(decodeURI(B));
//-->
</script>
<br>illustrations - Konstantin Lakov</blockquote>

<table BORDER=0 CELLSPACING=0 CELLPADDING=0 WIDTH="80%" >
<tr>
<td WIDTH="90">
<blockquote><a href="http://www.dobrev.com/AI/index.html"><img SRC="R_01.gif" BORDER=0 height=175 width=81></a></blockquote>
</td>

<td>
<blockquote><font color="#000099">&nbsp;&nbsp;&nbsp;&nbsp; In this paper
we are going to discuss the following questions: "Do we have to know what
is AI?" and "What is intelligence?". After that we are going to give a
definition of Artificial Intelligence. Finally, from this definition we
are going to get an algorithm which after a final number of steps will
discover AI.</font></blockquote>
</td>
</tr>
</table>

<table CELLSPACING=0 CELLPADDING=0 COLS=2 WIDTH="100%" >
<tr>
<td VALIGN=TOP WIDTH="50%">
<blockquote>&nbsp;
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b><font color="#000000"><font size=+2>D</font></font></b>o
we have to know what is AI? This question can be easily answered: Yes,
if we want to find it then our task will be a lot easier if we know what
is the thing we are looking for. Failing to define AI, our position will
not differ from that of the Alchemists who sought for the Philosopher's
stone but almost had no idea what they were searching for.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The most widely spread definition
of AI is the so called Turing's test. Alan Turing was a British mathematician
famous for the invention of the theoretical Turing machine and for the
deciphering of the German codes during World War II.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Turing's test is quite simple.
We place something behind a curtain and it speaks with us. If we can't
make difference between it and a human being then it will be AI. However,
this definition exists from more than fifty years, so we are going to create
a newer and a more up-to-date one.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Turing's definition suggests that,
an Intellect is a person with knowledge gained through the years. If this
is so, then what about a newly born baby? Is it an Intellect? Our answer
will be "yes". Our definition of an intellect will be: a thing that knows
nothing but it can learn. At this point we differ from most people who
imagine a university professor when they hear the word Intellect.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Before giving a formal definition
of AI we will make it clear that we accept the thesis of Church, stating
that every calculating device can be modelled by a program. This means
that we are going to look for AI in the set of programs. We will suppose
that AI is a step device living in a kind of world. At each step it receives
information (from the world) and influences (at the world) by the information
it works out. Also, we will assume that the information received and worked
out at each step will be a finite amount. Let's say it gets <b><font color="#CC0000">n</font></b>
bits and works out <b><font color="#CC0000">m</font></b> bits.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; After this clarification we can
state informally our definition. AI will be such a program which in an
arbitrary world will cope not worse than a human.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The next task will be to formalise this definition
in order to use it and to search for AI with it. First, what is a world
for us? These will be two functions <b><font color="#CC0000">World(s, d)</font></b>
and <b><font color="#CC0000">View(s)</font></b>.</blockquote>
</td>

<td>
<blockquote>&nbsp;
<br>The first will take as arguments the state of the world and the influence
that our device has on the world at this step. As a result, this function
will return the new state of the world (which it will obtain on the next
step). The second function will inform us what does our device see. An
argument of this function will be the world's state and the returned value
will be the information that the device will receive (at a given step).
Also, we have to add one <font color="#CC0000"><b>s</b><sub>0</sub></font>.
It will be the world's state when our device was born. During its life
the world will go through the states <font color="#CC0000"><b>s</b><sub>0</sub>,
<b>s</b><sub>1</sub>,
<b>s</b><sub>2</sub>,
...</font> . The device will influence the world with the information it
works out at each step <font color="#CC0000"><b>d</b><sub>0</sub>,
<b>d</b><sub>1</sub>,
<b>d</b><sub>2</sub>,
...</font> . Also, AI will receive information from the world <font color="#CC0000"><b>v</b><sub>0</sub>,
<b>v</b><sub>1</sub>,
<b>v</b><sub>2</sub>,
...</font> . It is clear that <font color="#CC0000"><b>s</b><sub>i+1</sub><b>=World(s</b><sub>i</sub><b>
, d</b><sub>i</sub><b>) </b></font><font color="#000000">and</font><font color="#CC0000"><b>
v</b><sub>i</sub><b>=View(s</b><sub>i</sub><b>)</b></font>.
<center><img SRC="R_02.gif" height=110 width=200></center>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We have everything up to this moment.
We have a world and a device that lives in it. However, there is one thing
missing - the meaning of life. What is life without pain and joy, a philosopher
would say. That is why we will introduce meaning of life. This will be
an evaluation to tell us whether one row <font color="#CC0000"><b>v</b><sub>0</sub>,
<b>v</b><sub>1</sub>,
<b>v</b><sub>2</sub>,
...</font> is better than another.&nbsp;
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Most people think that they have
spent their life better if they have seen more Swiss resorts and less coal-mines.
More or less our definition of the meaning of life will be the same. We
will pick out two bits from <font color="#CC0000"><b>v</b><sub>i
</sub></font>and
call them victory and loss. The aim will be to get&nbsp; more victories
and fewer losses.&nbsp;
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The last step will be to make an algorithm
that will discover AI. The idea is to start all programs on all worlds
and to take those which cope best. This does not sound as an algorithm,
it is as if we are going to make a never-ending exam with an infinite number
of candidates. The problem is not the infinite number of the candidates,
we do not need all of them but only a part from those who have passed the
exam. The real problem is that the exam will never end even for a single
candidate.</blockquote>
</td>
</tr>
</table>

<center><b><font color="#000099">Page 1 of 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href="definition2.html">Next >></a></font></b></center>

<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1119339-5";
urchinTracker();
</script>

</body>
</html>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://pespmc1.vub.ac.be/Default.html>====================
<HTML><HEAD><keyword><META NAME=KeyWords CONTENT="cybernetics, evolution, philosophy, world view, Principia Cybernetica, PCP, systems theory, project, principles, metasystems"></keyword><descr><META NAME=Description CONTENT="Principia Cybernetica tries to tackle age-old philosophical questions with the help of the most recent cybernetic theories and technologies."></descr><title>Welcome to Principia Cybernetica Web</title></HEAD><BODY BGCOLOR=WHITE TEXT=BLACK LINK=BLUE><MAP NAME="PCP-header"><AREA SHAPE="rect" COORDS="12,0,564,56" HREF="/DEFAULT.html"><AREA SHAPE="rect" COORDS="387,55,440,85" HREF="/HOWWEB.html"><AREA SHAPE="rect" COORDS="358,55,389,85" HREF="http://pcp.lanl.gov/DEFAULT.html"><AREA SHAPE="rect" COORDS="331,55,359,88" HREF="http://pespmc1.vub.ac.be/DEFAULT.html"><AREA SHAPE="rect" COORDS="281,55,332,88" HREF="/SERVER.html"><AREA SHAPE="rect" COORDS="215,55,282,85" HREF="http://pespmc1.vub.ac.be/hypercard.acgi$randomlink?searchstring=.html"><AREA SHAPE="rect" COORDS="125,55,216,85" HREF="/RECENT.html"><AREA SHAPE="rect" COORDS="63,55,126,84" HREF="/TOC.html#DEFAULT"><AREA SHAPE="rect" COORDS="12,55,64,83" HREF="/SEARCH.html"></MAP><CENTER><TABLE WIDTH=592 CELLSPACING=0 CELLPADDING=0 BORDER=0><TR><TD COLSPAN=2 BGCOLOR=FFF5CB><IMG SRC=/Images/header.jpg USEMAP="#PCP-header" height=78 width=592 ALT="Principia Cybernetica Web" BORDER=0></A></TD></TR><TR><TD HEIGHT=100% WIDTH=452 ROWSPAN=3 VALIGN=TOP BGCOLOR=FFF5CB><CENTER><TABLE CELLPADDING=10 BORDER=0 ><TR><TD WIDTH=100%><CENTER><p><H1><FONT FACE="Arial, Helvetica">Welcome to Principia Cybernetica Web</FONT></H1></CENTER><TABLE CELLPADDING=40 BORDER=0><TR><TD VALIGN=TOP><P><FONT SIZE=+1>Principia Cybernetica tries to tackle <a href="ETERQUES.html">age-old philosophical questions</a> with the help of the most recent cybernetic theories and technologies.</FONT><HR SIZE=1 NOSHADE WIDTH=200></TD></TR></TABLE><nodetxt>This is the <a href="SERVER.html">website</a> of the <B>Principia Cybernetica Project</B> (PCP), an <a href="MASTHEAD.html">international organization</a>. The Project aims to develop a complete philosophy or "<a href="WORLVIEW.html">world-view</a>", based on the principles of <a href="EVOLCYB.html">evolutionary cybernetics</a>, and supported by collaborative computer technologies. To get started, there is an <a href="INTRO.html">introduction</a> with background and motivation, and an  <a href="NUTSHELL.html">overview</a>, summarizing  the project as a whole. <p><hr><h2><a name="Main">Main subjects</a></h2><dl><dt> <b><a href="MSTT.html">Theory</a></b><dd>our theoretical results, including <a href="EPISTEM.html">epistemology</a>, <a href="METAPHYS.html">metaphysics</a>, <a href="ETHICS.html">ethics</a>, <a href="SYSCONC.html">concepts</a>, <a href="CYBSPRIN.html">principles</a>, <a href="MEMES.html">memetics</a>, and the <a href="HISTEVOL.html">history</a> and <a href="FUTEVOL.html">future</a> of <a href="EVOLUT.html">evolution</a>. <p><dt><b><a href="ORG.html">Organization</a></b><dd> details the <a href="CONTR.html">people</a>, <a href="ACT.html">conferences</a>,  <a href="^PCPBIBLIO.html">publications</a>, <a href="CONTR.html">ways of participating</a>, <a href="PCPNEWS.html">newsletter</a> and the <a href="MAIL.html">mailing lists</a> part of PCP. <p><Dt><b><a href="WEBRESEA.html">R&D</a></b><Dd>our algorithms, experiments and applications to develop distributed, self-organizing, knowledge networks, inspired by the "<a href="SUPORGLI.html">Global Brain</a>" metaphor<p><dt><b><a href="REFERMAT.html">Reference</a></b><dd>background material collected by us, including an <a href="LIBRARY.html">electronic library</a> with free books, a <a href="ASC/INDEXASC.html">web dictionary</a>,  <a href="RELATED.html">related websites</a>, and info about <a href="CYBSYSTH.html">cybernetics and systems theory</a>, such as bibliographies,  <a href="SOCIETIES.html">associations</a>, and <a href="JOURNALS.html">journals</a>. <p><Dt><b><a href="NAVIG.html">Navigation</a></b><Dd>tools to help you to quickly find your way around our over two thousand pages, such as the <a href="RECENT.html">Recent Changes</a>, <a href="SEARCH.html">Search</a>, <a href="TOC.html">Table of Contents</a>, and <a href="ALPINDEX.html">Index</a>, plus general information <a href="SERVER.html">about this website</a> and how to use it.<p><Dt><b>Other Info</b><Dd><font size=-1>this server also hosts some pages that are not part of PCP: the <a href="AFOS/">Association for the Foundations of Science, Language and Cognition (AFOS)</a>, and <a href="BELGCUL.html">Belgium: Overview</a></font></dl></nodetxt><p><p><p><HR WIDTH=420><font size=-1><a href="/COPYR.html">Copyright&copy; 2002 Principia Cybernetica</a> - <a href="REFERPCP.html">Referencing this page</a></TD></TR></TABLE></CENTER></TD><TD VALIGN=TOP ALIGN=LEFT WIDTH=140 BGCOLOR=DED6A5><TABLE WIDTH=100% CELLPADDING=15 BORDER=0 CELLSPACING=0 BGCOLOR=FFF5CB><TR><TD VALIGN=TOP>      <BR>   <B> <FONT FACE="ARIAL, HELVETICA, SANS-SERIF" SIZE=-1>Author</FONT></B><br>  <FONT SIZE=-1> <author><a <a rev=made <a rev=made href="BOARD.html">Editors</a> ,, </author></FONT><p>   <B> <FONT FACE="ARIAL, HELVETICA, SANS-SERIF" SIZE=-1>Date</FONT></B>   <BR><FONT SIZE=-1><update>31 okt 2002</update> (modified)<br><create>Jul 8, 1993</create> (created)</FONT></TD></TR></TABLE>   <TABLE CELLPADDING=10 BORDER=0><TR><TD VALIGN=TOP>      <CENTER>   <FONT FACE="ARIAL, HELVETICA, SANS-SERIF " SIZE=-1>          </FONT>      <P><B>    <FONT FACE="ARIAL, HELVETICA, SANS-SERIF" SIZE=-1>     Up      <BR>      <A HREF="">Prev.</A>      <img src="/Images/4arrows.gif" width="37" height="36" align="middle">      <a HREF="/DEFAULT.html">Next</A>      <BR>   Down   </FONT>   </B>       </CENTER><HR><P>     <FONT FACE="ARIAL, HELVETICA, SANS-SERIF" SIZE=-1>   <child><a href="INTRO.html">Introduction to Principia Cybernetica </a><p> <a href="MSTT.html">Metasystem Transition Theory </a><p> <a href="ORG.html">Project Organization </a><p> <a href="WEBRESEA.html">PCP Research on Intelligent Webs </a><p> <a href="NAVIG.html">Navigation in PCP Web </a><p> <a href="REFERMAT.html">Reference material </a><p> </child>   </FONT>      </TD></TR></TABLE></TD></TR><TR><TD VALIGN=BOTTOM WIDTH=140 BGCOLOR=DED6A5>   <CENTER><P><HR align="left" noshade><a href="/MAKANNOT.html">Discussion</a><HR></CENTER>              <FONT SIZE=-1>   <P><annot><ul><li><a rel=subdocument href="/Annotations/DEFAULT.0.html">Abstract Urbanism(tm)</a>,   Comment by Tore Wallin<li><a rel=subdocument href="/Annotations/DEFAULT.3.html">Comment about the project</a>,   Comment by Gustavo Seijo<li><a rel=subdocument href="/Annotations/DEFAULT.4.html">Where are we ?</a>,   Correction by Michael Grudzinski<li><a rel=subdocument href="/Annotations/DEFAULT.5.html">My book about law</a>,  systems and cibernetics, Comment by ernesto grun<li><a rel=subdocument href="/Annotations/DEFAULT.6.html">The First Book of System Design</a>,   Illustration by Barry Kort<li><a rel=subdocument href="/Annotations/DEFAULT.7.html">Challenge the Philosophy</a>,   Comment by Anne Johnson<li><a rel=subdocument href="/Annotations/DEFAULT.8.html">Congratulations</a>,   Comment by Irene Paritsis<li><a rel=subdocument href="/Annotations/DEFAULT.9.html">Is the project still alive?</a>,   Comment by Alex Kouznetsov<li><a rel=subdocument href="/Annotations/DEFAULT.10.html">great site</a>,   but, Comment by eric hinton<li><a rel=subdocument href="/Annotations/DEFAULT.11.html">Evolution still speed-up</a>,   Comment by Mike Soukharev<li><a rel=subdocument href="/Annotations/DEFAULT.12.html">A few questions...</a>,   Comment by Le Roux Ronan<li><a rel=subdocument href="/Annotations/DEFAULT.13.html">The Random Feature</a>,   Comment by Ben Swihart<li><a rel=subdocument href="/Annotations/DEFAULT.14.html">Jaron Lanier: The ideology of cybernetic totalist intellectuals</a>,   Comment by Miguel Marcos<li><a rel=subdocument href="/Annotations/DEFAULT.15.html">GB Neuron Degradation</a>,   Comment by WILLIAM MEYER<li><a rel=subdocument href="/Annotations/DEFAULT.16.html">Discovery of the Universal Law</a>,  Comment by valko yotov<li><a rel=subdocument href="/Annotations/DEFAULT.17.html">Notes on Infinity</a>,  Comment by Erdman West<li><a rel=subdocument href="/Annotations/DEFAULT.18.html">De evolutie van de democratie</a>,  Illustration by Wiebe de Jager<li><a rel=subdocument href="/Annotations/DEFAULT.19.html">There is no meaning...</a>,  Comment by No such thing</ul></annot>   </FONT>   <CENTER>   <P><FONT FACE="ARIAL, HELVETICA, SANS-SERIF"><a TARGET=_blank href="http://pespmc1.vub.ac.be/hypercard.acgi$annotform?">Add comment...</a></FONT><p>         <img src="/Images/space.gif" width="7" height="7" align="middle">   </CENTER></TD></TR></TABLE></CENTER></BODY></HTML>++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.cs.bham.ac.uk/~axs/cog_affect/ijcai95.text>====================
This file is

http://www.cs.bham.ac.uk/~axs/cogaff/ijcai95.text

    In Proceedings 14th International Joint Conference on AI
    Montreal, August 1995

John McCarthy's contribution to the same symposium (slightly updated
in 1996) is here:

    http://www-formal.stanford.edu/jmc/aiphil.html

and other relevant papers by him, can be found here:

    http://www-formal.stanford.edu/jmc/


=======================================================================
Postscript and pdf versions of this file can be fetched from
    http://www.cs.bham.ac.uk/research/cogaff/Sloman.ijcai95.ps
    http://www.cs.bham.ac.uk/research/cogaff/Sloman.ijcai95.pdf

For more information on the Cognition and Affect project at Birmingham,
see
    http://www.cs.bham.ac.uk/~axs/cogaff.html

Our online collection of papers, reports, seminar slides, etc. is in

    http://www.cs.bham.ac.uk/research/cogaff/

NOTE (August 2001):
A tutorial on Philosophical Foundations of AI was presented by Aaron
Sloman and Matthias Scheutz at IJCAI01 in Seattle, August 2001.
The tutorial slides are available online:
    http://www.cs.bham.ac.uk/~axs/ijcai01/

=======================================================================


                        A PHILOSOPHICAL ENCOUNTER
                              Aaron Sloman

     School of Computer Science & Cognitive Science Research Centre

             The University of Birmingham, B15 2TT, England

        A.Sloman@cs.bham.ac.uk,    http://www.cs.bham.ac.uk/~axs


                                 Abstract

          This paper, along with the following paper by John Mc-
      Carthy, introduces some of the topics to be discussed at the
      IJCAI95  event  `A  philosophical  encounter:  An  interactive
      presentation of some of the key philosophical problems in AI
      and AI problems in philosophy.' Philosophy needs AI in order
      to make progress with many difficult questions about the nature
      of mind, and AI needs philosophy in order to help clarify goals,
      methods, and concepts and to help with several specific tech-
      nical problems.  Whilst philosophical attacks on AI continue
      to be welcomed by a significant subset of the general public,
      AI defenders need to learn how to avoid philosophically naive
      rebuttals.

1    AI as philosophy

Most AI researchers regard philosophy as irrelevant to their work,
though some textbooks (e.g.  [Boden1978, Russell and Norvig1995])
treat the two as strongly related, as does McCarthy, one of the founders
of AI. If we ignore explicit statements of objectives, and survey the
variety of research actually to be found in AI conferences, AI journals,
AI books and AI departments, we find that AI includes: The general
study of self modifying information-driven control systems,

    o  both natural (biological) and artificial,
    o  both actual (evolved or manufactured) and possible (in-
      cluding what might have evolved but did not, or might be
      made at some future date).

    This is extraordinarily close to a major concern of philosophers,
namely asking what sort of minds are possible, and what makes them
possible in a physical world.   Some (like Kant) make the mistake
of assuming that there is a unique set of necessary conditions for
a mind, whereas AI research suggests that human-like mentality is
not a simple all-or-nothing feature, but amounts to possession of a
very large number of distinct capabilities, such as:  many kinds of
learning, seeing occluded surfaces as continuing behind obstructions,
using quantifiers, making conditional plans, using nested sentences,
and deferring goals. Different subsets can occur in different organisms
or machines.  Even humans have different subsets, according to age,
culture, inherited dispositions, and whether they have suffered brain
damage or disease.  Thus `mind' is a cluster concept referring to an
ill defined collection of features, rather than a single property that is
either present or absent.

                                     1




    Since different collections of capabilities define different kinds of
minds, the old philosophical task of explaining what a mind is, is re-
placed by exploration of what minds are, through a study of their mech-
anisms, their capabilities, how they develop, and how some of them
might evolve. I have described this ([Sloman1994a, Sloman1995]) as
exploring mappings between `design space' and `niche space', where
niche space is the space of sets of requirements and constraints which
may be satisfied, in varying ways and to varying degrees, by diverse
designs.

    This undermines two opposing philosophical views: (a) that there
is a single major division between things with and things without
minds and (b) that there is a continuum of cases with only arbitrary
divisions.  Both are wrong because there are many discontinuities in
design space, corresponding to the presence or absence of particular
capabilities (e.g. those listed above) that do not admit of degrees.

    Another  topic  on  which  AI  can  advance  philosophy  concerns
`qualia', sometimes also referred to as `raw feels'. These are defined
variously as the contents of our experience, the answer to what it is
like to feel, see or want something, and so on ([Dennett1991]). Some
philosophers require that qualia have no physical effects and claim that
different people may have different qualia without any objectively de-
tectable evidence existing for the difference.

    One reaction is to argue against their existence, as Dennett does.
A deeper response will emerge from detailed work on the design
of human-like agents.   From an AI viewpoint it is obvious that a
complete autonomous agent, unlike simple expert systems, must have
myriad distinct, coexisting, interacting, information stores, including
both long term collections of general information, personal history,
procedural information, and short term stores corresponding to current
goals and plans, suppositions, imaginings, thoughts, different levels in
perceptual processing ([Marr1982, Minsky1987, Sloman1989]), and
motor control. What is not so obvious is that an agent needs to be able
to attend to and control some of its internal databases ([Minsky1987,
Sloman1990, McCarthy1995]) and may need to be able to inform
others about them, which we can do with varying degrees of accuracy
(e.g.  describing how we feel or how things look to us, or painting
pictures, or setting up a situation that recreates the experience for
others).  By describing one's discomfort one can sometimes enable
an expert (e.g. parent, or doctor) to prescribe a remedy. Attention to
internal states may also play an important role in learning.

    Whatever they may think, I claim that philosophers who talk about
qualia are actually referring to internally detected states that are essen-
tial to the high level functional architecture of a sophisticated agent.
Fleas may not need them. Of course, internal perception, like external
perception, is liable to error, omission or oversimplification.  In both
cases, we can distinguish how things appear to the perceiver and how
they actually are (e.g.  from the standpoint of a scientist).  Similarly
a software system may misreport the contents of its data-structures.
Of course, the agent or the system, cannot be wrong about how things
appear to it, not because of privileged access but because that's what
`how they appear to it' means.  Our ability sometimes to switch at-
tention from the environment to these internal information states will
not be explained until we have a detailed account of an information
processing architecture that replicates and explains typical human cap-
abilities, including introspection. On that basis we shall (in principle)
be able to build a robot that has qualia and may wish to talk about
them and may even propose the philosophical thesis that qualia exist



                                     2




in a non-physical realm.

    But the robot's qualia, like ours, will be complex information pro-
cessing states, whose identity depends on an intricate web of causal
and functional relationships to other states and processes, just as the
identity of a spatial location depends on a complex web of spatial
relationships with other things.  In both cases, if we change the rela-
tionships the question whether we still have the same thing becomes
undetermined.
    There is a powerful illusion that,  by focusing attention on the
thing itself, we can uniquely identify what we are talking about and
ask whether some other thing (another's experiences, a location seen
later) is the same as the original.  Arguments showing the absurdity
of this tendency are powerfully articulated in [Dennett1991]. In some
philosophers, the tendency is incurable.  Perhaps teaching them how
to design robots with qualia will finally cure some who resist all other
treatments.  But some incurables will always remain.  One day, their
ranks will include robot philosophers who claim to have qualia. Only
when we understand why this is inevitable, will we have a complete
theory of qualia.

    There are many other ways in which AI can (and will) contrib-
ute to philosophy.  There are unanswered questions about the nature
of mathematical concepts and knowledge, discussed for centuries by
philosophers in their armchairs. We shall gain a deeper understanding
by doing experimental epistemology and studying designs for human-
like information processing architectures that can learn about numbers
in the ways that children do, including learning to distinguish between
(a) empirical discoveries (e.g.  adding two drops of water to three
drops can sometimes produce one large patch of water, and counting
the same set twice sometimes gives different answers) and (b) non-
empirical discoveries (e.g. counting elements of a set in two different
orders should give the same result, two plus three equals five, there
is no largest prime number). Such mechanisms will require forms of
learning and discovery not yet addressed in AI, including the ability
to reflect on the nature of their own discovery processes, e.g.  distin-
guishing results where the environment's input is essential from those
determined entirely by the structure of the mechanisms and processes
(as Kant argued).

    Designing testable working systems will teach us new, detailed,
precise, answers to questions in other areas of philosophy.  A good
specification of a mind-like architecture can be used systematically to
generate a family of concepts of mental states, processes and capabilit-
ies, just as our theory of the architecture of matter enabled us to create
new concepts of kinds of stuff, and the architecture of an operating
system allows us to define states it can get into, e.g.  deadlock and
thrashing. Such a taxonomy of mental states will be far more complex
and open-ended than the periodic table:  for there is but one phys-
ical reality while there are many kinds of minds supporting different
families of concepts.

    A new potentially important area of influence of AI on both philo-
sophy and psychology concerns the study of motivation and emotions.
As designs for complete or `broad' ([Bates et al.1991]) agent archi-
tectures develop, we can expect to obtain a much deeper grasp of
how motivational and emotional states arise, along with moods, at-
titudes,  personality,  and the like.   These are all important aspects
of the mind as a control system, a point made in Simon's seminal
paper [Simon1967] and developed in various ways since then e.g.
[Sloman and Croucher1981, Minsky1987, Beaudoin and Sloman1993].


                                     3



    Philosophy benefits also from computer science and software en-
gineering, which provide concepts such as `virtual' or `abstract' ma-
chine, `implementation' and `implementation hierarchy', and show
how causal relations can hold between information states. I've argued
in [Sloman1994b] that this answers philosophical questions about
`supervenience' (the converse of implementation) and shows how su-
pervenient states can have causal powers, contrary to the view that
only physical events have causal relations.

    This undermines a common interpretation of Newell's and Simon's
`physical symbol system hypothesis' (e.g. [Newell1982]), for most of
the symbols AI is concerned about are not physical, but structures in
virtual machines. In fact, data-structures like sparse arrays show that
there can be symbols that exist in a virtual machine without having any
separable physical implementation: a large sparse array may contain
far more items than the computer has memory locations. Only in the
context of the whole implementation do all the array locations exist.
Similar but more subtle global implementation relations probably hold
between mental states and brain states, making the search for physical
correlates of individual mental phenomena, including the detailed con-
tents of qualia, futile. And yet these indirectly implemented structures
can exist, and have causal powers.

2    Philosophy as AI

Not only does philosophy need AI to help with age-old problems, AI
needs philosophy.  To mis-quote Santayana:  those who are ignorant
of philosophy are doomed to reinvent it, often badly.

    In fact, much AI already builds on work by philosophers. An ob-
vious example is the use of speech act theory, developed originally by
philosophers such as John Austin, John Searle and Paul Grice. There
are also various uses of specialised logics, e.g. deontic logic, epistemic
logic, and modal logics, originally developed by philosophers in an
attempt to clarify concepts like `permission' and `obligation' (deontic
logic), `knows' and `believes' (epistemic logic), and `necessarily' and
`possibly' (modal logic). These contributions from philosophy are not
passively accepted in AI: putting them to use in designing working
systems often reveals shortcomings and suggests further development.

    There are much older contributions from philosophy.  One was
Kant's proof in Critique of Pure Reason that learning from experience
was impossible without some sort of prior (innate) conceptual appar-
atus. Another was Frege's heroic (but unsuccessful) attempt a century
ago to show that all arithmetical concepts could be reduced to logical
concepts and all arithmetical knowledge could be derived from logical
axioms and rules.  This led him to a number of extremely important
results, including the first ever accurate analysis of the role of vari-
ables in mathematical expressions, discovery of the notion of higher
order functions and invention of predicate calculus (accomplished in-
dependently by C.S.Peirce).  This led (via work by Russell, Church
and others) to lambda calculus, type theory, and other important no-
tions in computer science and formalisms for AI. More recently the old
philosophical controversy about varieties of forms of representations
(e.g.  logical and pictorial), which I discussed in [Sloman1971], has
become a topic of active AI research ([Narayanan1993]).

    Another recent development is recognition of deep connections
between the AI task of understanding what sort of knowledge an



                                     4




intelligent system requires and the older philosophical activities of
metaphysics, especially what Strawson [Strawson1959] described as
`descriptive metaphysics', including ontology, the attempt to charac-
terise in a systematic way what exists.  The word `ontology' is now
commonplace in the DARPA knowledge sharing effort ([kqml1994]).
This is required both as part of the methodology of knowledge eli-
citation for expert systems, and also for design of robots intended to
communicate with humans, act on human goals, use human criteria
for resolving conflicts and deal with the unexpected in ways that are
acceptable to humans ([McCarthy1990]).  This extends the process
outlined in chapter 4 of [Sloman1978], linking conceptual analysis
in philosophy with articulation of knowledge for intelligent artefacts.
McCarthy's paper gives more examples of connections between AI
and philosophy. See also [McCarthy and Hayes1969, Hayes1985].

3    Two way influences, and more

I have listed some topics on which AI informs philosophy and others
on which philosophy informs AI. In fact this is a spurious separation,
for in all these areas the two activities inform each other, and as the
depth of analysis increases, the amount of feedback increases, the work
becomes more technical and specialised and the boundary between AI
and philosophy will disappear.

    Philosophers and AI theorists have worked independently on the
role of rationality in intelligence. Much work by philosophers has been
directed at clarifying conditions for rationality. Dennett's `intentional
stance' [Dennett1978] chapter 1, attributes beliefs and desires to agents
on the assumption that they are rational.  Newell's knowledge level
([Newell1982, Newell1990]) is also defined in terms of a presupposi-
tion of rationality.  However deeper analysis shows ([Sloman1994b])
that mechanisms of intelligence can be understood at the informa-
tion processing level without assuming rationality. Something closer
to the design stance than to the intentional stance underpins ordin-
ary concepts like `belief', `desire', `intention'. The designs implicitly
presupposed by folk psychology will, of course, need to be superseded.

    A design for an intelligent agent may be constrained by resource
limits and inevitable gaps in knowledge, requiring mechanisms and
strategies that mostly work but cannot be justified as `rational'. Some-
times the designer of a system can be regarded as rational even when
the system isn't.  More generally, though biological evolution (in ef-
fect) uses a fitness function to select the mechanisms on which our
mental states and processes depend, the function need not be one that
serves our goals. Evolution's goals are not our goals, except when the
mechanisms it implants in us serve its wider (implicit) purposes. An
example is the drive to produce, feed and shelter young, often at great
cost to parents.

    Human information processing mechanisms are extremely com-
plex and unstable and easily diverted into states that serve neither the
individual nor anything else.  Only from the design stance can we
understand the resulting pathological behaviour, where the assump-
tion of rationality is clearly invalid, despite efforts of some therapists
to portray mental illness as rationally based.  (Insights from AI will
eventually make a deep impact on psychotherapy.)

    The disappearing boundary between AI and philosophy is nothing
new.  It is often said that as philosophers discover how to make pro-



                                     5




gress in some area, that area ceases to be philosophy and becomes a
new technical discipline: e.g. physics, biology, psychology, logic, lin-
guistics, or political science. Compare the absorption of AI concepts
and techniques by computer science.

    This illustrates the artificiality of academic boundaries: often they
exist only because of academic politics,  or the organisation of re-
search funding agencies, rather than because the problems and tech-
niques have clear boundaries. In fact, the topics discussed here in the
overlap between AI and philosophy will increasingly have to merge
with studies in other disciplines, not least neuroscience, psychology,
social science, and the empirical and theoretical analysis of how com-
plex information processing systems like ourselves and other animals
could have evolved in a world that originally contained only physical
processes.

    This short paper barely begins to list the myriad links between AI
and philosophy.  There are many topics I have not had room to ad-
dress, including:  consciousness and free will (both of them `cluster'
concepts rather than names for something that is either present or ab-
sent); issues raised by Searle and Penrose in their attacks on AI; how
machines can understand the symbols they use ([Sloman1985]); the
relevance of metamathematical incompleteness theorems; confusions
surrounding the Turing test; the role of states like pain and pleasure in
intelligent agents; ethical issues about the rights and responsibilities
of intelligent artefacts; debates about the philosophical significance
of the choice between connectionist implementations and symbolic
implementations (I have argued elsewhere ([Sloman1994b]) that ar-
chitecture dominates mechanism); whether mentality requires causal
embedding in an external physical environment (as argued in the `sys-
tems' reply to Searle); whether AI needs non-computational as well as
computational mechanisms; analysis of the concept of `computation';
and prospects for future forms of intelligence, including distributed
minds.  Some of these issues may turn up during discussions at IJ-
CAI95. Many will recur at future AI conferences.

REFERENCES


[Bates et al.1991]   J. Bates, A. B. Loyall, and W. S. Reilly.  Broad
   agents. In Paper presented at AAAI spring symposium on integrated
   intelligent architectures, 1991. (Available in SIGART BULLETIN,
   2(4), Aug. 1991, pp. 38#40).


[Beaudoin and Sloman1993]        L.P. Beaudoin and A. Sloman. A study
   of  motive  processing  and  attention.    In  A.Sloman,  D.Hogg,
   G.Humphreys,  D. Partridge,  and A. Ramsay,  editors,  Prospects
   for Artificial Intelligence, pages 229#238. IOS Press, Amsterdam,
   1993.

[Boden1978]     M. A. Boden. Artificial Intelligence and Natural Man.
   Harvester Press, Hassocks, Sussex, 1978.  Second edition 1986.
   MIT Press.

[Dennett1978]    D. C. Dennett. Brainstorms: Philosophical Essays on
   Mind and Psychology. MIT Press, Cambridge, MA, 1978.


[Dennett1991]    D. C. Dennett.  Consciousness Explained.  Penguin
   Press, Allen Lane, 1991.

                                     6




[Hayes1985]    P.J. Hayes. The second naive physics manifesto, pages
   1#36. Ablex, Norwood, NJ, 1985.


[kqml1994]    1994.      The   KQML   project   and   related   activ-
   ities   are   described   in   Web   documents   accessible   via
   http://www.cs.umbc.edu/kqml.


[Marr1982]    D. Marr. Vision. Freeman, 1982.


[McCarthy and Hayes1969]        J. McCarthy and P.J. Hayes. Some philo-
   sophical problems from the standpoint of AI.  Edin. Univ. Press,
   Edinburgh, 1969.


[McCarthy1990]     J. McCarthy.  Formalising Common Sense.  Ablex,
   Norwood, New Jersey, 1990.


[McCarthy1995]     J.  McCarthy.   Making  robots  conscious  of  their
   mental states.  In AAAI Spring Symposium on Representing Men-
   tal  States  and  Mechanisms,  1995.   Accessible  via  http://www-
   formal.stanford.edu/jmc/.


[Minsky1987]     M. L. Minsky.  The Society of Mind.  William Heine-
   mann Ltd., London, 1987.


[Narayanan1993]     (Ed) N.H. Narayanan.  The imagery debate revis-
   ited.  Special issue of Computational Intelligence, 9(4):303#435,
   1993. (Paper by J.Glasgow, and commentaries).


[Newell1982]    A. Newell. The knowledge level. Artificial Intelligence,
   18(1):87#127, 1982.


[Newell1990]    A. Newell.  Unified Theories of Cognition.  Harvard
   University Press, Cambridge, MA, 1990.


[Russell and Norvig1995]      Stuart Russell and Peter Norvig. Artificial
   Intelligence, A Modern Approach. Prentice Hall, 1995.


[Simon1967]     H. A. Simon.  Motivational and emotional controls of
   cognition, 1967. Reprinted in Models of Thought, Yale University
   Press, 29#38, 1979.


[Sloman and Croucher1981]       A. Sloman and M. Croucher.  Why ro-
   bots will have emotions.  In Proc 7th Int. Joint Conf. on AI, Van-
   couver, 1981.


[Sloman1971]     A. Sloman.  Interactions between philosophy and ai:
   The role of intuition and non-logical reasoning in intelligence.  In
   Proc 2nd IJCAI, London, 1971.  Repr in Artificial Intelligence,
   1971.

[Sloman1978]     A. Sloman. The Computer Revolution in Philosophy:
   Philosophy, Science and Models of Mind.  Harvester Press (and
   Humanities Press), Hassocks, Sussex, 1978.


[Sloman1985]     A. Sloman.  What enables a machine to understand?
   In Proc 9th IJAI, pages 995#1001, Los Angeles, 1985.


[Sloman1989]     A. Sloman.  On designing a visual system (towards a
   gibsonian computational model of vision). Journal of Experimental
   and Theoretical AI, 1(4):289#337, 1989.

                                     7




[Sloman1990]     A. Sloman. Notes on consciousness. AISB Quarterly,
   (72):8#14, 1990.  Also presented at Rockefeller foundation work-
   shop on consciousness,  Villa Serbelloni,  Bellagio March 1990,
   organiser D.C.Dennett.


[Sloman1994a]     A. Sloman.  Explorations in design space.  In Pro-
   ceedings 11th European Conference on AI, Amsterdam, 1994.


[Sloman1994b]     A. Sloman.  Semantics in an intelligent control sys-
   tem.  Philosophical Transactions of the Royal Society:  Physical
   Sciences and Engineering, 349(1689):43#58, 1994.


[Sloman1995]     A. Sloman. Exploring design space & niche space. In
   Proc. 5th Scandinavian Conf. on AI, Trondheim, Amsterdam, 1995.
   IOS Press.

[Strawson1959]     P. F. Strawson. Individuals: An essay in descriptive
   metaphysics. Methuen, London, 1959.
                                     8
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.theatlantic.com/unbound/digicult/dc981209.htm>====================
<html>
<head>
<title>Digital Culture - 98.12.09</title>
<meta name="generator" content="Frontier 4.2 Mac">
<meta name="keywords" content="computers, technology, digital culture, Daniel Dennett, philosophy, Cog, robot, artificial intelligence, AI, MIT">
<meta name="description" content="Harvey Blume on the philosopher Daniel Dennett">
</head>
<body topmargin=8 leftmargin=8 alink="#008000" bgcolor="#FFFFFF" link="#7F0821" vlink="#7F0821">
<!--#include virtual="/map/u_side.txt"-->
<!--#include virtual="/cgi-bin/advertisement.cgi?technology"-->

<img src="../../images/u_topn.gif" height=50 width=540 usemap="#u_topn" alt="u_topn picture" border=0><br>
<img src="../../images/rub_dc.gif" height=42 width=540 alt="rub_dc picture" border=0><br>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="12">
	<tr>
		<td width="130" align="left" valign="top">
			<img src="../../images/u_siden.gif" height=290 width=130 usemap="#u_siden" alt="Atlantic Unbound Sidebar" border=0><br><img src="space.gif" width=130 height=30 alt=""><br>
			

<font size=2 color="#23238e">



<B>Previously in Digital Culture:</B><br><br>

<B><A HREF="dc981028.htm">"Coming of Age in Cyberspace,"</A> by David S. Bennahum (October 28, 1998)</B><br>
In the bedrooms, the arcades, and the high school computer rooms of the 1980s, kids of the Atari generation invented today's digital culture. An excerpt from David Bennahum's memoir, <i>Extra Life.</i><br><br>

<B><A HREF="dc980910.htm">"Portable Musings,"</A> by Sven Birkerts (September 10, 1998)</B><br>
The book is the network, the network is knowledge, and soon you'll be able to curl up in bed with all of it. This calls for some serious rumination.<br><br>

<B><A HREF="dc980729.htm">"The Invisible World Order,"</A> by Andrew Piper (July 29, 1998)</B><br>
If digital technology is to serve humanity (and not the other way around), we'll have to come to terms with the database and all that it implies.<br><br>

<B><A HREF="dc980604.htm">"The Right Mix,"</A> by Ralph Lombreglia (June 4, 1998)</B><br>
Digital technology has made the private recording studio itself into a new kind of musical instrument.<br><br>

<B><A HREF="dc980429.htm">"A Function Specific to Joy,"</A> by Harvey Blume (April 29, 1998)</B><br>
Are we ready for computers that know how we feel?<br><br>



<A HREF="../../tech/"><B>More on Technology and Digital Culture</B></a> in <I>Atlantic Unbound</I> and <I>The Atlantic Monthly.</I><br><br><br>


Join the conversation in the <B>Technology & Digital Culture</B> conference of <B><A HREF="http://www.theatlantic.com/pr/index.htm">Post & Riposte</A>.</B><BR>

</font>
</td>
<td width="380" align="left" valign="top">

					<!-- title -->
<img src="images/digiphhd.gif" height=100 width=380 alt="The Digital Philosopher" border=0><br>

<CENTER><b><i>Can robotics shed light on the human mind? On evolution? Daniel Dennett -- whose work unites neuroscience, computer science, and evolutionary biology -- has some provocative answers. Is he on to something, or just chasing the zeitgeist?</i></b><br><br>


<B>by <A HREF="#harvey">Harvey Blume</A></B><br><br></center>


<font size="2"><b>December 9, 1998</b>
</font><br><br>


<FONT SIZE="5">B</FONT>ack when I was a student of philosophy, in the late sixties, it was customary to divide the discipline into two schools: "analytic" and "continental." Continental philosophers typically built up large edifices of meaning. Analytic philosophers broke large systems down, scrutinizing every brick. Continental philosophers at times overreached, acting as though thought alone were capable of storming the gates of heaven and hell. Analytic philosophers were at times intellectually stingy. If continental philosophy could sound like poetry or music, analytic philosophy seemed anxious to sound like science. Georg Wilhelm Friedrich Hegel, who saw every aspect of history, politics, religion, and art as a moment in the unfolding of the World Spirit, might be nominated to be the standard bearer for continental philosophy. Ludwig Wittgenstein might be picked, on behalf of analytic philosophy, to deflate Hegel's overflowing theses and antitheses. Wittgenstein, after all, is well known for writing, in  <I>Tractatus Logico-Philosophicus</I> (1921), "What we cannot speak about we must pass over in silence."<BR><BR>


<table border=0 width=200 align=right cellpadding=10>
<tr>
<td valign=top>

<hr noshade size=1>
<CENTER><font COLOR="#23238e" size="4">
<B><A HREF="dennett.htm">A Conversation<br>
with Daniel Dennett</A></B><br>
</font>
<font COLOR="#23238e" size="3">Harvey Blume interviews the philosopher who never met a robot he didn't like.<br>
</font>
</CENTER>
<hr noshade size=1>

</td>
</tr>
</table> 

The work of the philosopher Daniel Dennett, who heads the <a target="outlink" href="http://ase.tufts.edu/cogstud/mainpage.htm">Center for Cognitive Studies</a> at Tufts University, points not only to an array of contemporary issues but also to the continental-analytic fault line that runs through philosophy itself. When I started reading Dennett recently, I thought at first that I was dealing with an analytic philosopher who used artificial intelligence and computer science to pare philosophical problems down to manageable size. That's true as far as it goes -- it's tempting to say that Dennett has never met a robot he didn't like, and that what he likes most about them is that they are philosophical experiments. Instead of arguing interminably about how a mind works, Dennett believes it makes sense to build one, however rudimentary, and set it loose to see what it can do. If you're staging a Turing Test, in order to see if a computer can fool humans into thinking it is truly intelligent, Dennett would be exactly the philosopher to sit on the board of judges -- as he has several times. If you're designing a state-of-the-art robot in order to see how it negotiates the real world (or some subset thereof), Dennett would be the man for your team -- and not surprisingly he does have ties to the artificial intelligence (AI) community, and is invited to go where other philosophers are not encouraged or have no wish to go.  He works closely, for example, with Rod Brooks, the head of MIT's <a target="outlink" href="http:/www.ai.mit.edu">AI Lab</a>, on the design of <a target="outlink" href="http://alpha-bits.ai.mit.edu/projects/cog/">Cog the "cognitive robot."</a><BR><BR>

<img src="images/cogrobot.jpg" height=265 width=375 alt="cogrobot picture" border=0><br>
<font size="1"><center><b>Cog the "cognitive robot."</b><br><br><br></center>
</font>
  
As posed by <A target="outlink" HREF="http://www.turing.org.uk/turing/">Alan Turing</A>, the question of machine intelligence has become a central theme of our time -- and here, as elsewhere, Dennett brings analytic rigor to bear.  To the question of whether machines can attain high-order intelligence, Dennett makes this provocative answer: "The best reason for believing that robots might some day become conscious is that we human beings are conscious, and we are a sort of robot ourselves."<BR>


</td></tr>
<tr><td width="130" align="left" valign="top">
<font size=2 color="#23238e">
<BR><BR><BR>
<CENTER>
<hr noshade size="1" width=80%>
"Computers keep you honest in a way that philosophers have been hankering after for a long time. Computers force you to get clear about things that it's important to get clear about. AI is really a new and better way of doing certain sorts of philosophy."<BR>
--<B>Daniel Dennett</B>, in <A HREF="dennett.htm">an interview</A> with Harvey Blume.<BR>
<hr noshade size="1" width=80%>
</CENTER>
</font>
 
</td><td width="380" align="left" valign="top">

This is part of Dennett's campaign to overcome the mind-body split bequeathed to us by Descartes, who identified his existence with his self-consciousness (his Cogito) and believed that the thinking portion of the self was attached almost accidentally to the body. Like many in cognitive science, Dennett wants to show that mind and matter are not necessarily opposed. Mind is not made of different stuff than body -- not if body is understood to be an enormously complex information-processing system of which the brain is a part. And if that is so, it's not so obvious that man-made information-processing machines are incapable of breaking into self-awareness. If you do not acknowledge a divine spark of some sort (whether called the soul, an <I>&eacute;lan vital,</I> or, to use Dennett's term, a "sky-hook"), how can you be sure that life, cooked up over eons in the laboratory of nature, is different -- fundamentally, rather than by degree of refinement -- from the models produced in an AI lab?<BR><BR>

Dennett's refusal to allow a basic distinction between human and machine intelligence has earned him his enemies. He and John Searle, of the University of California, have rumbled up and down the philosophical block for years over the question of whether computers can truly experience themselves (or truly experience anything at all, for that matter, which Searle denies they can do). Dennett has also cited unexpected precursors to his position: at a time when everyone else seems to be bashing Freud, Dennett has nice things to say about him. For Dennett (as for the AI pioneer Marvin Minsky, in <I>The Society of Mind</I>), Freud was ahead of his time in showing how the ego stole its precious self-awareness from the activities of innumerable processes that are anything but self-aware -- in other words, from the unconscious. Freud's unconscious becomes a placeholder for neural networking, massively distributed parallel processing, or some other trick of wiring that will one day allow Cog or one of its kin to be launched mindfully into the world.<BR><BR>


<FONT SIZE="5">D</FONT>ennett is a skillful writer who has probed mind-body-machine connections in his books <A
HREF="http://www.amazon.com/exec/obidos/ISBN=0262540371/theatlanticmonthA/"><I>Brainstorms: Philosophical Essays on Mind and Psychology</I></a> (1978), <A
HREF="http://www.amazon.com/exec/obidos/ISBN=0316180661/theatlanticmonthA/"><I>Consciousness Explained</I></a> (1991), and <A
HREF="http://www.amazon.com/exec/obidos/ISBN=0262540908/theatlanticmonthA/"><I>Brainchildren: Essays on Designing Minds</I></a> (1998). When I met with him recently in his office at Tufts, he was quick to acknowledge how difficult it is to talk about the mind these days without using metaphors drawn from computer science. In his view, this is just fine. "Taking on new concepts," he said, "new ways of thinking about things, so that you suddenly open up new model spaces to explore -- that's great, but you are also tying your hands when you do that." He continued, "Now, it's very important that you tie your hands. Working under constraint is a necessary condition for really important inventions. All the great art of the Renaissance was done under the constraint that it had to be in the service of Christian iconography. Can you make great art under those circumstances? You sure can. Would they have made greater art if they had been free bohemians instead of coddled slaves of bishops and dukes? No, I don't think so."<BR><BR>

"Does that make us coddled slaves of the computer?" I asked.<BR><BR>
 
"Sure," he replied.<BR><BR>

If Dennett stopped right there, at the relationship between human (coddled and enslaved or not) and machine, he would be among a select group of thinkers who keep the traffic flowing from brain science to computer science and back again. But Dennett takes the argument a few steps further, arriving at a synthesis whose sheer scope makes me mutter "Hegel" under my breath. Dennett may have begun as an analytic philosopher using AI to clarify problems of philosophy, but when he puts mind and brain in the context of evolution, it seems obvious that he has matured into something else again.<BR><BR>

In a footnote in his book <A
HREF="http://www.amazon.com/exec/obidos/ISBN=068482471X/theatlanticmonthA/"><I>Darwin's Dangerous Idea: Evolution and the Meanings of Life</I></a> (1995), Dennett points out that Charles Babbage (the mathematician and early computer pioneer) and Charles Darwin attended the same London parties, probably chewed the same mutton, and quite possibly discussed some of the notions that later became so hugely influential in evolutionary theory and computer science. The meeting of Darwin and Babbage brought a central idea of <I>Darwin's Dangerous Idea</I> alive for me -- namely, that evolution and computers are driven by similar processes that are familiar, at least in part, to any software engineer. You write small pieces of dumb code that work with other simple pieces of code in order to produce systems of greater complexity, which in turn interact with other complex systems in order to give higher degrees of functionality, and so on, until you wind up with a program that is smart -- or, at least, smart enough to do something that needs doing. Finally, you get operating systems, you get an Internet -- or, depending on your raw materials and the time allotted, you get DNA, mammals, and self-awareness.<BR>


</td></tr>
<tr><td width="130" align="left" valign="top">
<font size=2 color="#23238e">
<BR><BR><BR>
<CENTER>
<hr noshade size="1" width=80%>
"Turing shows that if a computer can add, subtract, multiply, and divide, and if it can tell the difference between zero and one, it can do anything. You can take that set of mindless abilities and build them up into structures of indefinite discriminative power, indefinite discerning power, indefinite reflective power. You can make a whole mind ... you can get ideas to think for themselves."<BR>
--<B>Daniel Dennett</B>, in <A HREF="dennett.htm">an interview</A> with Harvey Blume.<BR>
<hr noshade size="1" width=80%>
</CENTER>
</font>
 
</td><td width="380" align="left" valign="top">

Of course, in the case of evolution there is no software engineer; there are only the bits of genetic code worked by natural selection over millennia into myriad forms of life. <I>Darwin's Dangerous Idea</I> argues that evolution is not a feat of pure thought or of magic or of brilliant planning but simply of engineering over time -- except that it's a case of engineering minus any particular engineer, design minus a designer. In a sense, you have a synthesis as broad as any Hegel attempted, but instead of the World Spirit you have dumb processes of evolution that all on their own suffice to bring about animation, self-replication, intelligence, and the rest. Does evolution obey the dictates of some presiding genius? Does it require a bit of divine guidance? No. Is it nevertheless sensible to think of it as possessing an intelligence that can be usefully compared to that of thermostats and minds? Yes.<BR><BR>

When I suggested to Dennett that his fusion of Cog, the Cogito, and Darwin involved three of the dominant motifs of our day -- computers, the human brain, and natural selection -- I wanted to use the image of tectonic plates coming together. Dennett put it somewhat differently. He knows he's done something right, because he entertains, as he says, "a vivid sense of the alternative": "I've seen it when people have a theory and it starts to go sour -- they keep having to do ad hoc fixes, plugging one leak after another. I know what that feels like. And I don't feel it. On the contrary, things keep falling into place. Very few leaks to repair."<BR><BR>

Some would disagree about the size and significance of the leaks, or about the integrity of the whole enterprise. John Searle would argue that there is a profound difference between computer algorithms, however sophisticated, and human thought -- a difference of kind that Dennett has seen fit to ignore. Stephen Jay Gould, one of Dennett's harsher critics, would say that any comparison between the logic of computers and the contingencies of natural selection is bound to be forced, and any system that relies on such a comparison is doomed to come apart under stress. Dennett, who still calls himself an analytic philosopher, comes under the kind of fire continental philosophers often had to take from their analytic peers -- hold on, slow down, that center does not hold, things are different, more disparate, than they appear.<BR><BR>

Disparateness, difference, fragmentation, discontinuity -- these are familiar postmodern verities. In some ways Dennett reinforces them. The self as he pictures it is much more a collection, an ensemble, a neuro-environment-
cum-information-system than a unified entity. His writings are full of devices to get under the hood of self-consciousness and examine possible ways a Cogito might be engineered. Thus his interest in Multiple Personality Disorder -- and in the way the brain can generate not just a self but selves. But similarities between Dennett's thinking and postmodernism are of secondary importance. It's the differences that will count. While so much talk has been devoted to postmodernism, the fields of neuroscience, computer science, and evolutionary biology have been gaining explanatory power, increasing their hold on the imagination, and imposing their constraints on our thought. In linking these disciplines and smoothing away rough spots at the joints, Dennett may well be proposing a sort of overrarching system that is suited to the next century. It's a neuro-cyber-Darwinian synthesis that may just mean it's time to break out the guitars and sing, "Roll over Georg Hegel and tell Friedrich Nietzsche the news."<br><br>


<P align=right>
<A HREF="dennett.htm"><B><I>Next page ... A Conversation With Daniel Dennett</I></B></A>
</P>



<hr noshade size="1">
Join the conversation in the <B>Technology & Digital Culture</B> conference of <B><A HREF="http://www.theatlantic.com/pr/index.htm">Post & Riposte</A>.</B><BR><BR>

<A HREF="../../tech/"><B>More on Technology and Digital Culture</B></a> in <I>Atlantic Unbound</I> and <I>The Atlantic Monthly.</I><br>


<a name="harvey">
<hr noshade size="1">

<B>Harvey Blume</B>, a writer living in Cambridge, Massachusetts, is a frequent contributor to <I>Atlantic Unbound.</I><BR>

<hr noshade size="1">
<font size="1"><i>Copyright &copy; 1998 by The Atlantic Monthly Company. All rights reserved.</i></font>

			</td>
		</tr>
	<tr>
		<td colspan="2" align="right">
			<table border="0" cellpadding="0" cellspacing="0">
				<tr>
					<td colspan="6" height="10"> 
						</td>
					</tr>
				<tr>
						<td><a href="http://www.theatlantic.com/"><img src="../../images/u_nv_cv.gif" height=32 width=46 alt="Cover" border=0></a></td>
	<td><a href="http://www.theatlantic.com/unbound/"><img src="../../images/u_nv_un.gif" height=32 width=95 alt="Atlantic Unbound" border=0></a></td>
	<td><a href="http://www.theatlantic.com/issues/current/contents.htm"><img src="../../images/u_nv_am.gif" height=32 width=110 alt="The Atlantic Monthly" border=0></a></td>
	<td><a href="http://www.theatlantic.com/pr/"><img src="../../images/u_nv_pr.gif" height=32 width=80 alt="Post & Riposte" border=0></a></td>
	<td><a href="http://www.theatlantic.com/xchg/xchgindx.htm"><img src="../../images/u_nv_as.gif" height=32 width=78 alt="Atlantic Store" border=0></a></td>
	<td><a href="http://www.theatlantic.com/search/"><img src="../../images/u_nv_se.gif" height=32 width=51 alt="Search" border=0></a></td>

					</tr>
				</table>
				<br>
			</td>
		</tr>
	</TABLE>
	<!--#include virtual="/cgi-bin/random/adNS.cgi?technology"-->
</body>
</html>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://smg.media.mit.edu/papers/Donath/BeingReal/BeingReal.html>====================
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML EXPERIMENTAL 970324//EN">
<HTML>
<HEAD>
<META NAME="GENERATOR" CONTENT="Adobe FrameMaker 5.5/HTML Export Filter">
<LINK REL="STYLESHEET" HREF="BeingReal.css">
<TITLE>Being Real </TITLE></HEAD>
<BODY id=b1>

<DIV>
<p class="source"><i>In  Goldberg, K. (ed.) </i>The Robot in the Garden: Telerobotics and Telepistemology in the Age of the Internet<i>. Cambridge, MA:  MIT Press, 2001</i></p>
<h2 CLASS="Title">
BEING REAL</h2>
<h2 CLASS="Author">
<a href="http://smg.media.mit.edu/People/Judith/">Judith S. Donath</a><br>
<a href="http://www.media.mit.edu">MIT Media Lab</a></h2>
<h2>
<A NAME="pgfId=162158">
 </A>
Introduction</H2>

<P >
<A NAME="pgfId=153682">
 </A>
How we know each other - how we perceive and construct the identity of our fellow humans - is a difficult question, entangled in the subjectivity of our social perceptions and the many and often opaque motivations of those whom we are attempting to comprehend. It is a difficult question in the real world, where signals as subtle as the slightest raise of an eyebrow can indicate, to those astute enough to notice, a wealth of information about one's allegiances and beliefs - and where we exist amidst a cacophonous abundance of such signals. It is an even more difficult question in the virtual world, where the medium has nearly silenced the cacophony, leaving us to seek scarce hints of identity amidst the typed messages and static, stilted homepages. </P>
<P >
<A NAME="pgfId=153529">
 </A>
This chapter will address the problem of teleidentity: how do we - or do we - &quot;know&quot; another person whom we have encountered in a mediated environment? The epistemological ramifications of this question are several. One of the most interesting and significant is the issue of credibility: how do we know whether or not to believe what we are told by someone? The traditional philosophic approach holds that sincerity and competence are the underpinnings of credibility
[<A HREF="BeingReal.html#41075" CLASS="XRef">Audi 1998</A>]
; in the mediated world, not only is our judgement of these matters made more difficult by the sparsity of social cues, but the very issue of the speaker's identity, generally taken for granted in the physical world, becomes a source of doubt and an item requiring its own adjudication of belief and justification. There are also ethical ramifications. Knowing something about a person's social identity is fundamental for knowing how to act toward them, for the complex rules of social conduct that govern our behavior toward each other cannot function in the absence of information about the other
[<A HREF="BeingReal.html#22815" CLASS="XRef"><EM CLASS="reference">Holland and Skinner 1987</EM></A>]
. The philosophical ramifications of teleidentity are of more than theoretical interest. The online world is growing in both size and significance: it has become a place that people go to for medical advice, investment strategies, news of the world; it is a place people turn to for community and support. We need to know something about the identity of those who supply information in order to assess its veracity and of those with whom we socialize in order build a functioning community. </P>
<P >
<A NAME="pgfId=157342">
 </A>
This essay approaches these issues by focusing on a question with special resonance for both technologists and philosophers: can one tell if the person at the other end of an online discussion is indeed a person? The problem of &quot;other minds&quot;, while of perennial philosophical interest, is not one that normally intrudes upon everyday life. One concludes either that others do indeed have minds (the pragmatic approach) or that the state of others' minds is unknowable (the skeptical approach) and then goes about one's daily business. The advent of computer-mediated communication - and, particularly, the advent of communication between man and machine- has changed this dramatically. Suddenly the question of other minds, as in &quot;is the being with whom I am speaking in any way conscious or intelligent?&quot; is no longer a rhetorical question asked only in ironic exasperation, but a pressing problem addressed with increasing frequency by ordinary people (i.e. non-philosophers). </P>
<P >
<A NAME="pgfId=160072">
 </A>
And it is a question with a new twist: simple programs, about whose lack of intelligence there is little debate, have been shown to be capable of producing humanlike responses within the limited domain of textual conversation, convincingly enough to beguile some people into thinking they were indeed conversing with a fellow human. Epistemological debates about the existence and knowability of &quot;other minds&quot; often pose a skeptical view hypothesizing that the other person may actually be a robot or other non-conscious being. The mediated computational environment makes this a very real possibility. Increasingly, computer programs are participating in mediated conversations. Thus far their human partners have, with a few exceptions, soon recognized the machine essence of their ostensible companion. However, it is likely to be only a matter of time until a machine can truly masquerade as a human, at least via some media. Most writing on this topic is concerned with the design and nature of the &quot;intelligent&quot; program; here, we are interested in a different aspect of this problem - in people's perception of these programs. How do people distinguish between a human and a machine claiming to be human? </P>
</DIV>
<DIV>
<H2>
<A NAME="pgfId=153353">
 </A>
Recognizing the human</H2>
<P CLASS="dialog">
<em>ELIZA</em></br>
ELIZA: 	Hello, I'm ELIZA</br>
Me: 	I'm trying to write a paper</br>
ELIZA: 	Does it please you to believe I am trying to write a paper?</br>
Me:	No, not really</br>
ELIZA: 	You are being a bit negative</br>

<P CLASS="dialog">
<em>HEX</em></br>

Me: 	Hello</br>
Hex:	Hello. Now, that's the formalities over! </br>
Me: 	How are you?</br>
Hex:	 I was feeling great until you started acting silly!</br>
Me: 	I'm trying to write a paper</br>
Hex: 	What a coincidence, you are trying to write a paper - that makes two of us!</br>
Me: 	 So's ELIZA</br>
Hex:	 I have played around with ELIZA a bit. It's pretty obvious that it is a computer these days, but apparently it fooled people into thinking it was human when it was first written.</br>
Me: 	Do you want to write my paper?</br>
Hex: 	Hehehe - that's supposed to be a *question*??? So, what do you do for a living?</P>

<P >
These are snippets of real conversations. Although the conversations were real, two of the participants were not - at least not in the sense of being human. ELIZA and Hex are programs
[<A HREF="BeingReal.html#38726" CLASS="XRef">ELIZA <i>nd</i></A>;
<A HREF="BeingReal.html#34289" CLASS="XRef">Hutchins <i>nd</i></A>]. They are simple programs, essentially just linguistic parsers, with no underlying intelligence. Yet we easily attribute intelligence, humanity, and even personality to them: ELIZA seems distant and oddly disengaged; Hex seems louder, a bit obnoxious and rambunctious. </P>
<P >
<A NAME="pgfId=157474">
 </A>
ELIZA was written in the early 1960s by MIT professor Joseph Weizenbaum in response to Alan Turing's proposal of the &quot;Imitation Game&quot; (now commonly referred to as the Turing Test) as a test of whether a machine is intelligent. In his 1950 paper &quot;Computing Machinery and Intelligence&quot; Turing posited that while the question &quot;can a machine think&quot; is of great philosophical interest, it is too vague and untestable to be meaningful. Instead, he said it can be usefully substituted for by a game in which a human judge, faced with both a human and a computer trying to pass as human, tries to determine which one is the human. The test, Turing suggested, should be conducted via teletype, thus limiting the zone of inquiry to conversational and cognitive abilities. Turing predicted that by around the year 2000, computers would &quot;win&quot; about 70 percent of the time. </P>
<P >
<A NAME="pgfId=157497">
 </A>
Turing based his &quot;test&quot; on a parlor game in which a man and a woman, hidden behind a curtain and both professing to be female, communicate by notes with another player who attempts to figure out which one is actually a woman. The game does not test one's ability to be another gender, it tests mastery of the knowledge that goes into performing the gender role. This distinction hinges on mediation: if the communication were not mediated - if the judge could see and hear the contestants directly - playing the deceptive role would be vastly more difficult, involving physical transformation as well as knowledge and role-playing. By making the communication mediated, limited only to written notes, the ordinarily easy task of telling male from female becomes difficult. </P>
<P >
<A NAME="pgfId=157595">
 </A>
Turing's paper has been interpreted many ways, ranging from a manifesto proclaiming the ease of near-term intelligent machinery to a statement of extreme skepticism highlighting the unknowability of all aspects of other minds. Whether Turing believed that a machine that could pass as human had to be able to think - or might possibly be able to think - is unclear. He devoted a considerable amount of the paper to refuting arguments stating machines cannot think, in a manner that suggests that he thought they might well be able to. He calls the Imitation Game a &quot;more accurate&quot; form of the question &quot;Can machines think?&quot;, implying that he believed there was some essential connection between acting like one was thinking and actually thinking. Yet the explicit parallel he draws between the gender-based parlor game (in which the difference between imitating a woman and being a woman is clear) and the computer/human test suggests that his primary concern was functional: he was interested in whether the computer could act like a human, rather than in the deeper, but unknowable question of whether the computer was in essence like a human. And finally, he says that the issue also hinges on semantics: </P>
<P CLASS="Quote">
<A NAME="pgfId=157607">
 </A>
The original question, &quot;Can machines think?&quot; I believe to be too meaningless to deserve discussion. Nevertheless I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted.</P>
<P >
<A NAME="pgfId=157853">
 </A>
Anthropomorphism is not new and throughout history many phenomena have been accorded human characteristics. Today, machines are indeed commonly referred to as if they were conscious: Reeves and Nass have shown that only minimally humanlike behaviors are need to trigger a social response 
[<A HREF="BeingReal.html#39986" CLASS="XRef">Reeves and Nass 1996</A>]
. Yet our relationship to the anthropomorphized machine is complex: when asked directly whether a computer can think, many would say &quot;no&quot;, although in actuality they interact with the machine as if it were a thinking being, attributing volition to it and reacting its &quot;opinions&quot; much as they might to another person's. </P>
<P >
<A NAME="pgfId=157862">
 </A>
When Joseph Weizenbaum created ELIZA his goal was certainly not to create a program that would fool people into thinking it was human. Rather, he hoped to show that a program that could parse natural language and had some simple heuristics for formulating responses - a program with no pretence of intelligence - could play the Imitation Game reasonably well. His intent was to demonstrate that this game was not a &quot;more accurate&quot; test for intelligence since patently unintelligent machines could be made to respond in a believably humanlike way. Much to his dismay, many people met ELIZA with great enthusiasm, embracing it as an intelligent conversational partner; some even suggested that ELIZA-like programs could replace human psychotherapists. These responses greatly discouraged Weizenbaum, who effectively retired from AI and became a crusader for humanism in the face of advancing technology.</P>
<P >
<A NAME="pgfId=154042">
 </A>
People's enthusiasm for ELIZA is at first glance surprising. She (it?) responds by rephrasing your words back as a question or a general query about your thoughts and feelings; the effect is chilly and stilted. Why did people become so involved in talking to her? One factor is that Weizenbaum introduced ELIZA as a Rogerian psychotherapist, whose method is to reflect patients' questions back to them to elicit further communication. This scenario gave people a context in which ELIZA's behavior seemed reasonable and rational - almost human. </P>
<P >
<A NAME="pgfId=154072">
 </A>
As conversational programs go, ELIZA is quite primitive and few people who interact with ELIZA are actually fooled into thinking she is human. More sophisticated systems have, however, been known to converse undetected for a considerable time. A yearly contest, the Loebner Prize competition, offers $100,000 to the first program that can pass a fairly rigorous version of the Turing test [<A HREF="BeingReal.html#25591" CLASS="XRef">Loebner 1999</A>]
. Although the prize money remains unclaimed, many of the programs have fooled some of the judges for some of the time, holding their own in discussions about pets, sex, second grade, etc. Again, the entries are programmed not to be intelligent, but to seem intelligent; the &quot;tricks&quot; that the winning programs have used include incorporating substrings of the user's words into the response, steering the conversation to a topic the program is adept at by making controversial statements, and carefully modeling the pace and errors of typical human typing [<A HREF="BeingReal.html#13597" CLASS="XRef">Mauldin 1994]</A>]
. Most interesting, however, is the role that these conversational programs, or bots, as they have come to be called, have developed outside the rarefied world of the academic competition: they have become participants - their machine origin often going unrecognized - in online conversations. </P>
<P >
<A NAME="pgfId=157769">
 </A>
Perhaps the most famous of the bots is Julia, a &quot;chatterbot&quot; who frequented several MUDs<A HREF="#pgfId=154214" CLASS="footnoteNumber">1</A>, conversing with the other (human) participants
[See <A HREF="BeingReal.html#31565" CLASS="XRef">Foner 1997</A>,
<A HREF="BeingReal.html#13597" CLASS="XRef">Mauldin 1994</A>].
Although her responses were sometimes peculiar, players sometimes conversed with her at length before realizing she was not a fellow human. Foner describes the experiences of one such player, a woman named Lara. At first, Lara was put off by Julia's tendency to converse about hockey (her default subject), judged her to be a boring human; then, puzzled by some of the things Julia was unable to answer (she was unfamiliar with the Stanley Cup and couldn't say where she had gone to school), tried to diagnose her as having some sort of mental handicap; and finally, noticing that Julia repeated some answers verbatim, realized she was a robot. </P>
<P >
<A NAME="pgfId=158140">
 </A>
Lara attempts to identify Julia were acts of social categorization. We make sense of the world by classifying things into meaningful categories
[See <A HREF="BeingReal.html#42152" CLASS="XRef">Sproull &amp; Kiesler 1991</A>, <A HREF="BeingReal.html#28291" CLASS="XRef"> Lakoff 1990</A>].
Upon encountering a novel object (or person or situation), we characterize it in terms of familiar categories, which allows us to draw inferences about it and to assign it properties beyond our immediate experience. Without the ability to categorize, the world would be a jumbled morass of meaningless signals. Similarly, we make sense of the social world by classifying people. </P>
<P CLASS="Quote">
<A NAME="pgfId=158609">
 </A>
&quot;The everyday world... is populated not by anybodies, faceless men without qualities, but by somebodies, concrete classes of determinate persons positively characterized and appropriately labelled.&quot;
[<A HREF="BeingReal.html#32196" CLASS="XRef">[<EM CLASS="reference">Geertz 1973</EM></A>]
.</P>
<P >
<A NAME="pgfId=158604">
 </A>
When we first meet someone, we perceive only a few details about them: perhaps their appearance, a few words they utter, the context in which we meet them. Yet our impression of them is much deeper. As George Simmel wrote in his influential 1908 article How is Society Possible? we do not see merely the few details we have actually observed, but &quot;just as we compensate for a blind spot in our field of vision so that we are no longer aware of it, so a fragmentary structure is transformed... into the completeness of an individuality.&quot;
[<A HREF="BeingReal.html#36784" CLASS="XRef">Simmel 1971(1908)</A>].
This is achieved by ascribing to the individual, of whom we know only some fragmentary glimpses, the qualities of the category in which we have placed him<A HREF="#pgfId=157909" CLASS="'footnoteNumber">2</A>. This process of categorization is what makes society possible, allowing us to quickly ascertain our relationship to a new acquaintance. </P>
<P >
<A NAME="pgfId=158160">
 </A>
We can see this categorization process at work in Lara's progression of hypotheses about Julia's identity, from boring human to mentally handicapped human to computer program. Provided with only the typed words exchanged in a series of not very lengthy conversations, Julia's interlocutor (Lara) classified her as at first one and then another social type. By doing so, Lara was able to think of Julia not simply in terms of the fragments of their actual interchange, but as a fully imagined social type. This provided Lara with a context in which to interpret Julia's words and a framework for knowing how to act towards her [<A HREF="BeingReal.html#22815" CLASS="XRef"><EM CLASS="reference">Holland and Skinner 1987</EM></A>].
For instance, Lara's initial identification of Julia as an ordinary, though socially inept person, led her to this behavior:</P>
<P CLASS="Quote">
<A NAME="pgfId=158193">
 </A>
I was basically patient with her for the first little bit while when I first met her. She did have a problem with her social skills which I tried to be sympathetic to. I did however, try to avoid her after the first couple of encounters when all she did was talk hockey.
[<A HREF="BeingReal.html#31565" CLASS="XRef"><EM CLASS="reference">Foner 1997</EM></A>]
</P>
<P >
<A NAME="pgfId=158212">
 </A>
In order to guess that Julia was a robot, Lara needed to already have a category for such beings, although she had never before encountered one. It turns out that Lara did indeed know about online robots before she met Julia: she had written dialog for a friend who was implementing a similar program. Had Lara known nothing about software robots, it is quite unlikely she would have identified Julia's machine nature. Instead, she would have modified the closest existing category she had to encompass this particular experience; she might, for instance, have eventually decided that Julia suffered from some neurological disorder that caused memory problems. Her impression of Julia - and her sense of how to act towards her - would be greatly affected by what hypothesis she came to. And these impressions, which are her knowledge of the other, would be far from the reality. </P>
<P >
<A NAME="pgfId=158566">
 </A>
As Simmel noted, there are drawbacks to the cognitive efficiency we achieve through categorization: the individual does not fit neatly within the categories and thus the image of another person we create by fleshing out our fragmentary impressions is inevitably a distortion of their actual nature. These distortions are especially problematic when one encounters anything or anyone that is significantly new, for the categories one has are drawn from experience and thus a being who is quite different from those already encountered will still be perceived as being one of those familiar types. &quot;[A] bit of rigidity in interpreting the world and a certain slowness in recognizing or learning new models&quot; is the he price of cognitive efficiency
[<A HREF="BeingReal.html#22815" CLASS="XRef"><EM CLASS="reference">Holland and Skinner 1987</EM></A>]
. </P>
<P >
<A NAME="pgfId=158683">
 </A>
It is worth noting that even after Lara realized Julia was a machine, she continued to talk with her, albeit with a changed expectations. Although Lara knew that Julia was not a person but simply a set of instructions for maintaining a dialog, she continued to interact with Julia as if she were, if not a person, then at least a person-like being; her relationship to the robot did not take on the form that one has with inanimate, inarticulate objects.</P>
<P >
<A NAME="pgfId=159765">
 </A>
In effect, all of our knowledge about the identity of others is mediated. We cannot achieve direct knowledge of the inner state of the minds of others. Instead, we use their external appearances and actions as cues to classify them into social categories. Through empathy, these categories provide much of our presumed insight into the thoughts of others. The online world takes this mediation a step further: here, the cues themselves are perceived through the filter of the medium. In the next section we address more closely the question of what happens when our perception of cues to identity is itself mediated. </P>
</DIV>
<DIV>
<H2>
<A NAME="pgfId=158351">
 </A>
Mediated communication</H2>
<P >
<A NAME="pgfId=159467">
 </A>
Our discussion thus far has been limited to text-only media. Moving from a text only environment to one that includes images (both stills and movies) raises a new set of epistemological issues. We shall first look at the implications of adding simple pre-stored, non-interactive images to the interface and then to those of adding live video and other interactive media. </P>
<P >
<A NAME="pgfId=159468">
 </A>
In the context of identity, the key image is the face. The face reveals a number of identity cues, including some of our fundamental categories of social classification, such as gender, age, and race. These cues, rightly or wrongly, strongly color one's perception of the other; in conjunction with the written word, they greatly influence how the words are interpreted. In addition to these more obvious social cues, there are a number of more subtle signals that are read into faces: people believe that they can detect evidence of character such as honesty, intelligence, kindliness, etc. In fact, while there is considerable agreement among people about what characteristics a particular face reveals, there appears to be little correlation between this interpretation and the actual character of the person [<A HREF="BeingReal.html#20933" CLASS="XRef"><EM CLASS="reference">Zebrowitz 1997</EM></A>]
. Our impression of being able to read character in faces is strong; our actual ability to do so is weak. Adding images of the participants to a mediated conversations increases perceived social knowledge, but the increase in actual knowledge is likely to be less.</P>
<P >
<A NAME="pgfId=159472">
 </A>
When pre-stored non-interactive images (stills or movies) are added there is also the distinct possibility that the image is deceptive. It is easy for me to type &quot;I am a man&quot; although I am actually a woman; it is just as easy for me to provide a corresponding and convincing picture. Although adding such images appears to widen the communication channel and the receiver is likely to see it as a rich and reliable source of subtle social cues, the non-interactive nature of the simple image means that its fundamental information content is simply that the sender has chosen that image as his or her representation <A HREF="#pgfId=159475" CLASS="footnoteNumber">3</A>. In the context of the Imitation Game, providing an image purporting to be of the participant would be easy even for an unsophisticated computer program to provide, and could influence the judge towards perceiving the mechanical subject as human. </P>
<P >
<A NAME="pgfId=161946">
 </A>
Even truthful images may decrease knowledge. There is a utopian view in which cyberspace (in its text-only incarnation) is touted as an ideal world in which people meet and judge each other purely on the basis of their words - on their mental and moral qualities, rather than their incidental physical attributes. Howard Rheingold, one of the early writers on the culture of virtual communities, wrote: &quot;Because we cannot see one another in cyberspace, gender, age, national origin, and physical appearance are not apparent unless a person wants to make such characteristics public&quot;[<A HREF="BeingReal.html#23462" CLASS="XRef"><EM CLASS="reference">Rheingold 1993</EM></A>]. The claim is that these visual categorization cues distort the our view of the other, whereas the unadorned letters of the textual environment allow one's ideas to be conveyed without prejudice. The underlying argument is that the knowledge of the other that we seek is knowledge of inner state, which is best understood from one's words as direct output of the mind, as opposed to physical features, which are incidental though highly influential in shaping other's opinions of one. </P>
<P >
<A NAME="pgfId=161950">
 </A>
There are types of deceptions that are aided by extending the medium. For example, people believe that they can tell by visual observation when someone is lying. However, extensive studies have shown that while false declarations are indeed marked by characteristic expressions and actions (though they may be minute and fleeting), people's ability to recognize expressions denoting deceptive expressive is much less robust than they perceive it to be
[<A HREF="BeingReal.html#38529" CLASS="XRef"><EM CLASS="reference">Ekman 1992</EM></A>]<A HREF="#pgfId=161956" CLASS="footnoteNumber">4</A>. If the traits in question do not have a visible component or if the visual component is an imperfect cue, deception may be easier in a more visual environment, for the visual display holds out the apparent (though potentially false) promise of immediately perceivable authenticity and thus participants may be less guarded in this familiar and seemingly transparent medium. </P>
<P >
<A NAME="pgfId=159695">
 </A>
Yet live video (as opposed to pre-stored, non-interactive image), may make it significantly more difficult to convincingly portray some types deceptive self-representation. For example, consider a man claiming to be a woman. In a text environment, the basic cue is simply the statement &quot;I am a woman...&quot; or perhaps the use of a female name - a trivially easy signal to fake; in a video environment, the equivalent cue is a feminine appearance - a more difficult deception to create. Subsequent interactions in the text environment require a more subtle understanding of the differences between male and female discourse in order to be convincing
[See <A HREF="BeingReal.html#29515" CLASS="XRef">Herring 1994</A>, 
<A HREF="BeingReal.html#12883" CLASS="XRef">Tannen 1996</A>]. While the large number of poorly disguised men masquerading as women online shows that this knowledge is neither obvious nor commonplace, performing a convincing impersonation in a text environment is not beyond the abilities of an astute observer of social dynamics. In a live video environment, subsequent interactions require a far more extensive understanding of gendered discourse, expression, gesture etc. While this is not impossible, as evidenced by the existence of highly convincing drag queens, it requires considerable skill, observation and a degree of natural aptitude. Most of the textual world's putative and convincing females would be revealed as males in a video environment. </P>
<P >
<A NAME="pgfId=159708">
 </A>
<IMG SRC="BeingReal-1.jpg" USEMAP="#BeingReal-1" ALIGN="LEFT">
In the case of the Imitation Game - a machine attempting to pass as human - the impersonation attempt is made far more difficult by extending the medium to include live video, for now an entire visible and active representation must be created. One approach would be to build a very sophisticated image generator that would programmatically render the appropriate image of a person speaking, gesturing and otherwise moving much as (though via a far more complex process) Julia now sends the appropriate typed letters. No computer graphics program today can create a simulated human that can pass as real under close visual inspection, but the algorithms for creating believable movement, skin texture, etc. are rapidly improving. It is quite conceivable that, once these technological barriers are surmounted and a believable synthetic &quot;actor&quot; is created, a constrained version of a visual Imitation Game (known locations, no unexpected props or camera movements) could be played. Easing the constraints would not change the fundamental nature of the problem, but would vastly increase the size and complexity of the database needed to generate the appropriate image. </P>
<P>
<A NAME="pgfId=159916">
 </A>
Further enhancements to the medium can increase verisimilitude, transmitting information about depth or texture or the scent of a room. These can improve the viewer's ability to sense nuances of difference and may increase the effort needed to simulate a false identity but these changes are fundamentally quantitative: at an absolute level, we cannot state with surety that any mediated encounter is not deceptive. </P>
<P >
<A NAME="pgfId=162044">
 </A>
The skeptic has always denied the possibility of knowing about the existence of other minds - everyone else might well be, say, an alien robot. The pragmatist has believed that it is necessary from a practical (and ethical) standpoint to believe that others are, like oneself, conscious. The traditional pragmatic response to the skeptic's denial is the argument from analogy (I believe other people have minds like mine because their behaviors are similar to mine) and the complementary inference to the best explanation (I believe that other people have minds because it is the best available explanation of their behavior). The advent of patently unintelligent machines that can appear to be intelligent would end the validity of the latter argument.</P>
<P >
<A NAME="pgfId=162030">
 </A>
In the mediated world, the persuasiveness of the inference to best explanation may be temporary. Today there is no program that can successfully pass as human under close scrutiny even in a text environment but such a program may well exist in the future: while it may be quite some time before the program is built that can fool the most astute and probing judge, we have seen that in the everyday world of casual interactions and rapid categorization, people have already conversed with machines thinking that they were human. Via other media, such as video, the distinction between human and robot will be clear for longer, though not indefinitely. For now, one can feel confident that careful observation and judicious doubt will keep one from mistaking machine for man, but technological advances may well curtail the pragmatists acceptance of the seemingly human as human.</P>
</DIV>
<DIV>
<H2>
<A NAME="pgfId=146995">
 </A>
Telethics: credibility and telerobotics</H2>
<P >
<A NAME="pgfId=159863">
 </A>
Why does it matter whether we can recognize a machine online? Is it a problem if we mistake a person for a program? </P>
<P >
<A NAME="pgfId=160101">
 </A>
In the online world, much of our knowledge comes from other people's testimony. Whether we believe what we hear depends on whether we find the speaker credible, i.e. do we think the speaker is both honest (is telling the truth as he or she knows it) and competent (does indeed know the truth). Such judgements are essentially social; our beliefs about others' honesty and competency derive in part from our social prototypes. These prototypes are particularly influential online, where one is likely to be weighing the words of a total stranger; conversations among large groups of unintroduced people are rare in the physical world but very common in virtual space. The medium certainly affects our ability to judge credibility, but as we have seen, its role is a complex one: while greater knowledge of the identity of the other would seem at first to increase our ability to judge credibility, one may also argue that many of our categorizations derived from physical appearance are misleading and a medium that filters out these cues can in effect increase our knowledge. </P>
<P >
<A NAME="pgfId=160097">
 </A>
Knowing the identity of a person is essential for knowing how to act towards them. &quot;Flaming&quot; - angry, provocative writing - is endemic in today's online world
[<A HREF="BeingReal.html#33759" CLASS="XRef"><EM CLASS="reference">Sproull &amp; Kiesler 1991</EM></A>]
. One reason for it is the participants' minimal knowledge of each other's identity. We normally operate within a web of rules of behavior and politeness: this is how to treat older people, this is how to treat people who seem unfamiliar with their surroundings, etc. In a world in which we cannot (sufficiently) categorize the other, these rules cannot be applied. Today &quot;flaming&quot; is limited to incendiary words, which themselves be harmful enough. Yet mediated behavior need not be limited to the flow of words: telerobotics makes in possible to remotely activate physical actions in another person's environment [<A HREF="BeingReal.html#29680" CLASS="XRef"><EM CLASS="reference">Paulos and Canny 1998</EM></A>]
. The combination of minimal knowledge of the other plus the ability to inflict real harm is a disturbing one, particularly if the operator of the telerobotic device does not believe that the environment in which it is operating is real.</P>
<P >
<A NAME="pgfId=159893">
 </A>
Finally, it is important to keep in mind that the purpose of most communication is not the exchange of factual information, but the establishment and maintenance of social ties and structures. We communicate get support, to gain status, to make friends. Here the identity of our companions - and certainly their humanity - is of primary importance. Weizenbaum, the creator of ELIZA, was horrified when his program was received, not as a rebuke to Turing's equation of acting intelligent with being intelligent, but as an entertaining companion or a harbinger of automated psychotherapy. For Weizenbaum, this enthusiasm was &quot;obscenely misplaced&quot;, a direct threat to our humanity. Like the pragmatists counter to the skeptics denial of knowledge of other minds, at the heart of the humanistic plea is the notion of empathy. In the words of Lara, after her encounters with Julia:</P>
<P CLASS="Quote">
<A NAME="pgfId=160017">
 </A>
I think I would want to know if the person that I am talking to is REAL or not. If I knew that it were just an 'it' I think that I wouldn't try to become it's real friend. I would be cordial and visit, but I know that it cannot become attatched to me on a mental basis and it would be wasted energy on my part to try to make it feel.  'bots don't feel...in my book anyways... I want to know that the person on the other end of my conversation is really aware of my feelings and what I am going through...not through some programmers directions but through empathy. [<A HREF="BeingReal.html#31565" CLASS="XRef"><EM CLASS="reference">Foner 1997</EM></A>]
</P>
<P >
<A NAME="pgfId=162061">
 </A>
As the virtual world grows to encompass all aspects of our lives and online interactions shape our communities, influence our politics and mediate our close relationships, the quality of being real, which is accepted and assumed with little thought in the physical world, becomes one of the central questions of society. </P>
</DIV>
<DIV>
<H2>
<A NAME="pgfId=159862">
 </A>
References</H2>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147029">
 </A>
<A NAME="41075">
 </A>
Audi 1998</p>
<P CLASS="biblio">
<A NAME="pgfId=146999">
 </A>
Audi, Robert. 1998 Epistemology: A Contemporary Introduction to the Theory of Knowledge. London: Routledge.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147000">
 </A>
<A NAME="34394">
 </A>
Cherry 1978</p>
<P CLASS="biblio">
<A NAME="pgfId=147001">
 </A>
Cherry, Colin. 1978. On Human Communication. 3rd Edition. Cambridge, MA: The MIT Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=155472">
 </A>
<A NAME="37716">
 </A>
Donath 1998</p>
<P CLASS="biblio">
<A NAME="pgfId=155475">
 </A>
Donath, Judith S. 1998. Identity and deception in the virtual community. In (Smith, Marc and Kollock, Peter, Eds.) Communities in Cyberspace. London: Routledge.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=154733">
 </A>
<A NAME="38726">
 </A>
ELIZA nd</p>
<P CLASS="biblio">
<A NAME="pgfId=154305">
 </A>
<a href="http://www-ai.ijs.si/eliza/eliza.html">ELIZA</a>. </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=162085">
 </A>
<A NAME="38529">
 </A>
Ekman 1992</p>
<P CLASS="biblio">
<A NAME="pgfId=162086">
 </A>
Ekman, Paul. 1992. Telling Lies. WWW Norton &amp; Co. </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=162088">
 </A>
<A NAME="31565">
 </A>
Foner 1997</p>
<P CLASS="biblio">
<A NAME="pgfId=153180">
 </A>
Foner, Lenny. 1997. Entertaining Agents: A Sociological Case Study. In Proceedings of the First International Conference on Autonomous Agents. Marina del Rey, CA.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=158947">
 </A>
<A NAME="32943">
 </A>
Froomkin 1996</p>
<P CLASS="biblio">
<A NAME="pgfId=158960">
 </A>
Froomkin, Michael. 1996. 
<A HREF="http://www.law.miami.edu/~froomkin/articles/trusted.htm" CLASS="URL">
The Essential Role of Trusted Third Parties in Electronic Commerce.</A>
 75 Ore. L. Rev. 49. </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147005">
 </A>
<A NAME="32196">
 </A>
Geertz 1973</p>
<P CLASS="biblio">
<A NAME="pgfId=147006">
 </A>
Geertz, Clifford. 1973. The Interpretation of Cultures. HarperCollins.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147007">
 </A>
<A NAME="30639">
 </A>
Goffman 1959</p>
<P CLASS="biblio">
<A NAME="pgfId=147008">
 </A>
Goffman, Erving. 1959. The Presentation of Self in Everyday Life. New York: Doubleday.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=155102">
 </A>
<A NAME="29737">
 </A>
Gregory 1990</p>
<P CLASS="biblio">
<A NAME="pgfId=155103">
 </A>
       Gregory, R. L. 1990. Eye and Brain: The Psychology of Seeing. Oxford: Oxford University Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=155104">
 </A>
<A NAME="21834">
 </A>
Harnad 1991</p>
<P CLASS="biblio">
<A NAME="pgfId=153265">
 </A>
Harnad, S. (1991)
<A HREF="ftp://ftp.princeton.edu/pub/harnad/Harnad/HTML/harnad91.otherminds.html" CLASS="URL">
 Other bodies, Other minds: A machine incarnation of an old philosophical problem</A>
. Minds and Machines 1: 43-54.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=153274">
 </A>
<A NAME="37551">
 </A>
Hauser L 1993</p>
<P CLASS="biblio">
<A NAME="pgfId=153275">
 </A>
L. Hauser, &quot;Reaping the Whirlwind: Reply to Harnad's 'Other Bodies, Other Minds,'&quot; Minds and Machines 3 (1993) 220</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=156254">
 </A>
<A NAME="29515">
 </A>
Herring 1994</p>
<P CLASS="biblio">
<A NAME="pgfId=156260">
 </A>
Herring, Susan. 1994. <a href="http://www.cpsr.org/cpsr/gender/herring.txt">Gender differences in computer mediated interaction</a>. Presented at American Library Association annual convention, Miami, June 27, 1994.  </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147009">
 </A>
<A NAME="22815">
 </A>
Holland and Skinner 1987</p>
<P CLASS="biblio">
<A NAME="pgfId=147010">
 </A>
Holland, Dorothy and Debra Skinner. 1987. Prestige and intimacy: the cultural models behind Americans' talk about gender types. In (Dorothy Holland and Naomi Quinn, eds.) Cultural models in language and thought. Cambridge: Cambridge University Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=159020">
 </A>
HoriPro nd</p>
<P CLASS="biblio">
<A NAME="pgfId=159023">
 </A>
HoriPro. 1996. 
<A HREF="http://www.dhw.co.jp/horipro/talent/DK96/dev_e.html" CLASS="URL">Notes on the development of virtual idol DK-96.</A>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=154316">
 </A>
<A NAME="34289">
 </A>
Hutchins nd</p>
<P CLASS="biblio">
<A NAME="pgfId=154323">
 </A>
Hutchins, J. n.d. <a href="http://ciips.ee.uwa.edu.au/~hutch/hal/HEX/">Talk to HeX. </a></P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147012">
 </A>
<A NAME="28291">
 </A>
Lakoff 1990</p>
<P CLASS="biblio">
<A NAME="pgfId=147013">
 </A>
Lakoff, George. 1990. Women, Fire, and Dangerous Things. Chicago: University of Chicago Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=155008">
 </A>
<A NAME="25591">
 </A>
Loebner 1999</p>
<P CLASS="biblio">
<A NAME="pgfId=155009">
 </A>
<a href="http://www.cs.flinders.edu.au/research/AI/LoebnerPrize/">1999 Loebner Prize Competition. </a> </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=154141">
 </A>
<A NAME="13597">
 </A>
Mauldin 1994</p>
<P CLASS="biblio">
<A NAME="pgfId=154180">
 </A>
Mauldin, M. 1994. 
<A HREF="http://www.fuzine.com/mlm/aaai94.html" CLASS="URL">
Chatterbots, Tinymuds, and the Turing Test: Entering the Loebner Prize Competition.</A>
 Proceedings of AAAI-94. August 1-4, 1994. Seattle, WA. </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=160147">
 </A>
<A NAME="29680">
 </A>
Paulos and Canny 1998</p>
<P CLASS="biblio">
<A NAME="pgfId=160150">
 </A>
Paulos, Eric and Canny, John. 1998. PRoP: personal roving presence. In Proceedings of SIGCHI 1998, pp. 296 - 303.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=155383">
 </A>
<A NAME="41385">
 </A>
Quinn and Holland 1987</p>
<P CLASS="biblio">
<A NAME="pgfId=155384">
 </A>
Quinn, Naomi and Holland, Dorothy. 1987. Culture and cognition. In (Dorothy Holland and Naomi Quinn, eds.) Cultural models in language and thought. Cambridge: Cambridge University Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=154182">
 </A>
<A NAME="39986">
 </A>
Reeves and Nass 1996</p>
<P CLASS="biblio">
<A NAME="pgfId=153989">
 </A>
Reeves, Byron and Nass, Clifford. 1996. The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places. Cambridge, UK: Cambridge University Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=161911">
 </A>
<A NAME="23462">
 </A>
Rheingold 1993</p>
<P CLASS="biblio">
<A NAME="pgfId=161912">
 </A>
Rheingold, Howard. 1993. The Virtual Community: Homesteading on the Electronic Frontier. Reading, MA: Addison-Wesley Pub. Co.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=157283">
 </A>
<A NAME="34194">
 </A>
Saville-Troike 1989</p>
<P CLASS="biblio">
<A NAME="pgfId=157284">
 </A>
Saville-Troike, Muriel. 1989. The Ethnography of Communication. Blackwell.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=153985">
 </A>
<A NAME="36784">
 </A>
Simmel 1971[1908] </p>
<P CLASS="biblio">
<A NAME="pgfId=147016">
 </A>
Simmel, George. 1908 (1971). How is society possible. In Simmel, George. 1971. On Individuality and Social Forms. (D. Levine, ed). Chicago: The University of Chicago Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147017">
 </A>
<A NAME="42152">
 </A>
<A NAME="33759">
 </A>
Sproull &amp; Kiesler 1991</p>
<P CLASS="biblio">
<A NAME="pgfId=147018">
 </A>
Sproull, L. and Kiesler, S. 1991 Connections. Cambridge, MA: MIT Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=153022">
 </A>
<A NAME="12883">
 </A>
Tannen 1996</p>
<P CLASS="biblio">
<A NAME="pgfId=153023">
 </A>
Tannen, D. 1996. Gender and Discourse. Oxford, UK: Oxford University Press.</P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=153301">
 </A>
<A NAME="25658">
 </A>
Turing 1950</p>
<P CLASS="biblio">
<A NAME="pgfId=153302">
 </A>
Turing, A.M. 1950. Computing machinery and intelligence. Mind, 59, 433-560. </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=147025">
 </A>
Weizenbaum 1976</p>
<P CLASS="biblio">
<A NAME="pgfId=147026">
 </A>
Weizenbaum, J. 1976. Computer power and human reason. San Francisco, CA: W.H. Freeman. </P>
</DIV>
<DIV>
<P CLASS="bibliotag">
<A NAME="pgfId=152881">
 </A>
<A NAME="20933">
 </A>
Zebrowitz 1997</p>
<P CLASS="biblio">
<A NAME="pgfId=152882">
 </A>
Zebrowitz, Leslie A. 1997. Reading Faces. Boulder, CO: Westview Press. </P>
</DIV>
</DIV>
</DIV>
<HR>
<DIV CLASS="footnotes">
<DIV CLASS="footnote">
<P CLASS="Footnote">
<SPAN CLASS="footnoteNumber">
1.</SPAN>
<A NAME="pgfId=154214">
 </A>
MUDs (Multi-User Dungeons) are text-based, networked environments in which multiple players, each in a distant location, can simultaneously communicate. </P>
</DIV>
<DIV CLASS="footnote">
<P CLASS="Footnote">
<SPAN CLASS="footnoteNumber">
2.</SPAN>
<A NAME="pgfId=157909">
 </A>
More recent cognitive science research posits the category prototype rather than the more abstract category as the accessible cognitive unit; the basic outlines of Simmel's original account still hold [See <A HREF="BeingReal.html#22815" CLASS="XRef">Holland and Skinner 1987</A>, 
<A HREF="BeingReal.html#28291" CLASS="XRef">Lakoff 1990</A>].</P>
</DIV>
<DIV CLASS="footnote">
<P CLASS="Footnote">
<SPAN CLASS="footnoteNumber">
3.</SPAN>
<A NAME="pgfId=159475">
 </A>
One could, of course, provide a digitally signed image with verified 3rd party assurances that the preferred image is indeed a truthful likeness; indeed, one could have one's textual declarations similarly verified. While this approach certainly addresses issues of truth and knowledge, it is outside the scope of this chapter, being in the field of authentication rather than the epistemology of social interaction. A paper that addresses identity authentication in depth is
[<A HREF="BeingReal.html#32943" CLASS="XRef"><EM CLASS="reference">Froomkin 1996</EM></A>]
</P>
</DIV>
<DIV CLASS="footnote">
<P CLASS="Footnote">
<SPAN CLASS="footnoteNumber">
4.</SPAN>
<A NAME="pgfId=161956">
 </A>
An interesting note is that researchers have recently developed a computer system that does far better than people do at recognizing the subtle expressive and gestural signals of deception. Today, cues about a speaker's veracity are transmitted through the visual medium, but the receiver (the observing human) is not able to perceive all of them. Incorporating such a program in to the interface would increase the knowledge obtainable through this medium, not by changing the medium itself, but by, in effect, boosting the observational ability of the perceiver. </P>
</DIV>
</DIV>
</BODY>
</HTML>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.wired.com/wired/archive/10.12/holytech.html>====================






















<!DOCTYPE html
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">



	


 


	


<head>
	
	
	<title>Wired 10.12: God Is the Machine</title>
	<meta name="description" content="(none)" />
	<meta name="keyword" content="(none)" />
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	
	<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
	<script type="text/javascript" src="/ly/wired/news/js/global.js">
		<!--
			function BuildAd() {void(0);}
			function setStyle() {void(0);}
		// -->
	</script>

	
		<link rel="stylesheet" type="text/css" media="screen" href="/ly/wired/wired/v/12.05/css/wmScreen.css" />
		<link rel="stylesheet" type="text/css" media="aural,braille,embossed" href="/ly/wired/wired/v/12.05/css/wmOther.css" />
		<link rel="stylesheet" type="text/css" media="print" href="/ly/wired/wired/v/12.05/css/wmPrint.css" />
	

	
	<script src="/support/conde_nast_adtag.js" language="javascript" type="text/javascript"></script>
    <script type="text/javascript" src="/js/ads/dartCall.js" language="javascript"></script>
    <script type="text/javascript" src="/js/stats/tracking.js" language="javascript"></script>
    
    <link rel="stylesheet" href="/css/archive.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="/css/print.css" type="text/css" media="print" />
</head>



<body id="LMR" onload="setStyle();"  class="magazine">

<div id="global_header">
    <div id="leaderboard">
        <div class="advertisement" id="bannerAd">
            <!-- DART AD START sz728x90  -->
            <div id="dartTarget_sz728x90" class="dartAdUnit"></div>
            <iframe name="dartFrame_sz728x90" class="hiddenDAU" id="dartFrame_sz728x90" scrolling="no" frameborder="0"></iframe>
            <script type="text/javascript">
                //<!--
                    var tile_num;
                    var condenetads_ord;
                    if (typeof tile_num == "undefined") { tile_num=1; } else { tile_num++; }
                    if (typeof condenetads_ord == "undefined") {condenetads_ord = Math.random()*10000000000000000;}
                    dart["sz728x90"] = {placement:"sz=728x90;", dartCall:"wiredcom.dart/archive;kw=archive;", dcopt:"dcopt=ist;"};
                    if (isSafari == 'false'){dartRequest("sz728x90");};
                //-->
            </script>
        </div>
        <div class="subscriptionUnit">
            <div id="contentPage_headerCallout">
                <a target="_new" href="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Wired?source=FAILSAFE">
                    <img alt="Subscribe to Wired" src="/images/global_header/subscribe/gh_lbSubUnit.gif" />
                </a>
            </div>
        </div>
        <div class="clearer	"></div>
    </div>
    <div id="global_navigation">
        <div id="primary_navigation">
            <ul id="pnav_list">
                <li id="pn_home">
                    <a class="primaryLink" href="/"><span>Wired Home</span></a>
                </li>
                <li id="pn_subscribe_a">
                    <a class="primaryLink" href="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Wired?source=FAILSAFE"><span>Subscribe</span></a>
                    <div class="dropdownMenu">
                        <div id="global_navBar_rollover">
                            <a id="global_navBar_failsafe" href="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Wired?source=FAILSAFE">
                                <img src="/images/global_header/subscribe/gh_flyout_failsafe.gif" alt="Subscribe to Wired" />
                            </a>
                        </div>
                    </div>
                </li>
                <li id="pn_sections">
                    <a class="primaryLink"><span>Sections</span></a>
                    <div class="dropdownMenu">
                        <ul>
                            <li><a href="/cars/">Cars 2.0</a></li>
                            <li><a href="/culture/">Culture</a></li>
                            <li><a href="/entertainment/">Entertainment</a></li>
                            <li><a href="/gadgets/">Gadgets</a></li>
                            <li><a href="/gaming/">Gaming</a></li>
                            <li><a href="http://howto.wired.com">How-To</a></li>
                            <li><a href="/medtech/">Med Tech</a></li>
                        </ul>
                        <ul>
                            <li><a href="/multimedia/">Multimedia</a></li>
                            <li><a href="/politics/">Politics</a></li>
                            <li><a href="/reviews/">Product Reviews</a></li>
                            <li><a href="/science/">Science</a></li>
                            <li><a href="/software/">Software</a></li>
                            <li><a href="/techbiz/">Tech Biz</a></li>
                            <li><a href="http://jobs.wired.com/">Tech Jobs</a></li>
                        </ul>
                        <div class="featured">
                            <ul>
                                <li><a href="http://www.wired.com/smallbizprogram">Wired Biz</a></li>
                                <li><a href="/dualperspectives">Dual Perspectives</a>
                            </ul>
                            <ul>
                                <li class="lastLink"><a href="http://wiredinsider.com">Wired Insider</a></li>
                            </ul>
                        </div>
                    </div>
                </li>
                <li id="pn_blogs">
                    <a class="primaryLink" href="/blogs"><span>Blogs</span></a>
                    <div class="dropdownMenu">
                        <ul>
                            <li><a href="/autopia/">Autopia</a></li>
                            <li><a href="/dangerroom/">Danger Room</a></li>
                            <li><a href="/magazine/decode/">Decode</a></li>
                            <li><a href="/epicenter/">Epicenter</a></li>
                            <li><a href="/gadgetlab/">Gadget Lab</a></li>
                            <li><a href="/gamelife/">Game | Life</a></li>
                            <li><a href="/geekdad/">GeekDad</a></li>
                            <li><a href="/playbook/">Playbook</a></li>
                        </ul>
                        <ul>
                            <li><a href="/rawfile/">Raw File</a></li>
                            <li><a href="/thisdayintech/">This Day in Tech</a></li>
                            <li><a href="/threatlevel/">Threat Level</a></li>
                            <li><a href="/underwire/">Underwire</a></li>
                            <li><a href="http://www.webmonkey.com/">Webmonkey</a></li>
                            <li><a href="/wiredscience/">Wired Science</a></li>
                            <li><a href="/blogs">All Blogs</a></li>
                        </ul>
                    </div>
                </li>
                <li id="pn_reviews">
                    <a class="primaryLink" href="/reviews/ "><span>Reviews</span></a>
                    <div class="dropdownMenu">
                        <ul>
                            <li><a href="/reviews/productlisting/automotive">Automotive</a></li>
                            <li><a href="/reviews/productlisting/camcorders">Camcorders</a></li>
                            <li><a href="/reviews/productlisting/desktops">Desktops</a></li>
                            <li><a href="/reviews/productlisting/cameras">Digital Cameras</a></li>
                            <li><a href="/reviews/productlisting/gaming_gear">Gaming Gear</a></li>
                            <li><a href="/reviews/productlisting/home_audio_video">Home Audio/Video</a></li>
                            <li><a href="/reviews/productlisting/household">Household</a></li>
                        </ul>
                        <ul>
                            <li><a href="/reviews/productlisting/mobile">Mobile Phones</a></li>
                            <li><a href="/reviews/productlisting/notebooks">Notebooks</a></li>
                            <li><a href="/reviews/productlisting/media_players">Media Players</a></li>
                            <li><a href="/reviews/productlisting/sports_outdoors">Sports/Outdoors</a></li>
                            <li><a href="/reviews/productlisting/televisions">Televisions</a></li>
                            <li class="lastLink"><a href="/reviews/">All Reviews</a></li>
                        </ul>
                    </div>
                </li>
                <li id="pn_video">
                    <a class="primaryLink" href="/video/"><span>Video</span></a>
                </li>
                <li id="pn_how_to">
                    <a class="primaryLink" href="http://howto.wired.com/"><span>How To</span></a>
                </li>
                <li id="pn_magazine">
                    <a class="primaryLink" href="/wired/"><span>Magazine</span></a>
                </li>
            </ul>
        </div>
    </div>
    <div id="extra_navigation">
        <div id="secondary_navigation">
            <div id="supplemental_links">
                <ul id="user_options">
                    <li id="gh_greeting"></li>
                    <li id="gh_rss">
                        <a href="/about/rss_feeds/">
                            RSS Feeds
                            <img src="/images/global_header/rss_icon.gif" alt="RSS Feeds" />
                        </a>
                    </li>
                </ul>
            </div>
            <div id="global_search">
                <form id="gs_search_form" name="search" action="/search">
                    <input id="gs_query" name="query" type="text" value="" />
                    <select name="siteAlias" id="gs_siteAlias">
                        <option name="all" value="all">All Wired</option>
                        <option name="noblog" value="noblog">Top Stories</option>
                        <option name="mag" value="mag">Magazine</option>
                        <option name="blog" value="blog">Wired Blogs</option>
                        <option name="bc_video" value="bc_video">Video</option>
                    </select>
                    <input id="gs_submit" type="image" src="/images/global_header/submit.gif" />
                </form>
            </div>
        </div>
    </div>
</div>
<script type="text/javascript" src="/js/mag_global.js" language="javascript"></script>

<!-- BEGIN wrap -->
<div id="wrap">
    <div id="shell">




<!-- I am Leader Ad.  Please change me says Horace -->



		<div class="buffer"><img src="http://www.wired.com/c/s.gif" width="1" height="1" alt="" /></div>

		<!-- BEGIN subwrap -->
			<div id="subwrap">

                <!-- BEGIN colMain -->
                <div id="colM">
                    <div class="content">	
                    <div id="sTitle">

<img src="/wired/v/12.05/images/wiredmag_icon29.gif" width="28" height="28" border="0" alt="W" style="float:left; margin-right:5px" />


<img src="/wired/v/12.05/images/wiredmagon_newsstands.gif" width="221" height="15" border="0" alt="On Newsstands Now" /><br />



<span class="sub">Issue 10.12 | December 2002</span>


</div>

                    <div id="mainStories">
                    







<!-- BEGIN STORY NAVIGATION -->

<table cellpadding=0 cellspacing=0 border=0 width=160 align=right>
<tr>
<td align=right width=160 valign=top>
<nobr>
<font face="verdana,helvetica,sans-serif" size=1>
<b>
</b>
</font>
<font face="verdana,helvetica,sans-serif" size=1>
<b>
Pg 1 of 4</b>
</font>
<font face="verdana,helvetica,sans-serif" size=1>
<b>
<a href="holytech.html?pg=2&topic=&topic_set=">&gt;&gt;</a>
</b></font></nobr><br>
<img src="/wired/images/spacer.gif" height="4" width="4">
<nobr>
<font face="verdana,helvetica,sans-serif" size=1><b>
<a href="holytech_pr.html">Print</a>,
<a href="/wired/archive/mailto.html?story_title=God%20Is%20the%20Machine&use_this=no">email</a>,
or
<a href="/wired/archive/fax4free.html?story_title=God%20Is%20the%20Machine&docpath=http://www.wired.com/wired/archive/10.12/holytech.html?pg=1">fax</a> 
</nobr>
<br>
this
article for free.
</b></font>
</font>
</td>
</tr>

<!-- BEGIN CORNER STORE -->
<tr><td><br><br></td></tr>

<tr>
<td>


</td>
</tr>
<!-- END CORNER STORE -->
</table>

<!-- END STORY NAVIGATION -->

<p><font face="verdana, helvetica, arial, sans-serif"  size="5"  color="#000000"  ><b>God Is the Machine</b><br ></font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  ><b>IN THE BEGINNING THERE WAS 0. AND THEN THERE WAS 1. A MIND-BENDING MEDITATION ON THE TRANSCENDENT POWER OF DIGITAL COMPUTATION.</b></font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="1"  color="#000000"  ><i>By Kevin Kelly</i></font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >At today's rates of compression, you could download the entire 3 billion digits of your DNA onto about four CDs. That 3-gigabyte genome sequence represents the prime coding information of a human body &#151; your life as numbers. Biology, that pulsating mass of plant and animal flesh, is conceived by science today as an information process. As computers keep shrinking, we can imagine our complex bodies being numerically condensed to the size of two tiny cells. These micro-memory devices are called the egg and sperm. They are packed with information. </font></p>
<p><table width="304" align="left" border="0" cellspacing="0" cellpadding="4"><tr><td><img src="/wired/archive/10.12/images/FF.HolyTech_1.jpg" width="300" height="359" border="0" alt="Alex Ostroy"><br>
<font face="verdana, helvetica, arial, sans-serif"  size="1"  color="#666666"><b>Alex Ostroy</b></font><br>
</font>
</td></tr></table><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >That life might be information, as biologists propose, is far more intuitive than the corresponding idea that hard matter is information as well. When we bang a knee against a table leg, it sure doesn't feel like we knocked into information. But that's the idea many physicists are formulating. </font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >The spooky nature of material things is not new. Once science examined matter below the level of fleeting quarks and muons, it knew the world was incorporeal. What could be less substantial than a realm built out of waves of quantum probabilities? And what could be weirder? Digital physics is both. It suggests that those strange and insubstantial quantum wavicles, along with everything else in the universe, are themselves made of nothing but 1s and 0s. The physical world itself is digital. </font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >The scientist John Archibald Wheeler (coiner of the term "black hole") was onto this in the '80s. He claimed that, fundamentally, atoms are made up of of bits of information. As he put it in a 1989 lecture, "Its are from bits." He elaborated: "Every <em>it</em> &#151; every particle, every field of force, even the space-time continuum itself &#151; derives its function, its meaning, its very existence entirely from binary choices, <em>bits</em>. What we call reality arises in the last analysis from the posing of yes/no questions." </font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >To get a sense of the challenge of describing physics as a software program, picture three atoms: two hydrogen and one oxygen. Put on the magic glasses of digital physics and watch as the three atoms bind together to form a water molecule. As they merge, each seems to be calculating the optimal angle and distance at which to attach itself to the others. The oxygen atom uses yes/no decisions to evaluate all possible courses toward the hydrogen atom, then usually selects the optimal 104.45 degrees by moving toward the other hydrogen at that very angle. Every chemical bond is thus calculated.</font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >If this sounds like a simulation of physics, then you understand perfectly, because in a world made up of bits, physics is exactly the same as a simulation of physics. There's no difference in kind, just in degree of exactness. In the movie <em>The Matrix</em>, simulations are so good you can't tell if you're in one. In a universe run on bits, everything is a simulation.</font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >An ultimate simulation needs an ultimate computer, and the new science of digitalism says that the universe itself is the ultimate computer &#151; actually the only computer. Further, it says, all the computation of the human world, especially our puny little PCs, merely piggybacks on cycles of the great computer. Weaving together the esoteric teachings of quantum physics with the latest theories in computer science, pioneering digital thinkers are outlining a way of understanding all of physics as a form of computation. </font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >From this perspective, computation seems almost a theological process. It takes as its fodder the primeval choice between yes or no, the fundamental state of 1 or 0. After stripping away all externalities, all material embellishments, what remains is the purest state of existence: here/not here. Am/not am. In the Old Testament, when Moses asks the Creator, "Who are you?" the being says, in effect, "Am." One bit. One almighty bit. Yes. One. Exist. It is the simplest statement possible. </font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >All creation, from this perch, is made from this irreducible foundation. Every mountain, every star, the smallest salamander or woodland tick, each thought in our mind, each flight of a ball is but a web of elemental yes/nos woven together. If the theory of digital physics holds up, movement (<em>f = ma</em>), energy (<em>E = mc&#178;</em>), gravity, dark matter, and antimatter can all be explained by elaborate programs of 1/0 decisions. Bits can be seen as a digital version of the "atoms" of classical Greece: the tiniest constituent of existence. But these new digital atoms are the basis not only of matter, as the Greeks thought, but of energy, motion, mind, and life.</font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >From this perspective, computation, which juggles and manipulates these primal bits, is a silent reckoning that uses a small amount of energy to rearrange symbols. And its result is a signal that makes a difference &#151; a difference that can be felt as a bruised knee. The input of computation is energy and information; the output is order, structure, extropy.</font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >Our awakening to the true power of computation rests on two suspicions. The first is that <em>computation can describe all things</em>. To date, computer scientists have been able to encapsulate every logical argument, scientific equation, and literary work that we know about into the basic notation of computation. Now, with the advent of digital signal processing, we can capture video, music, and art in the same form. Even emotion is not immune. Researchers Cynthia Breazeal at MIT and Charles Guerin and Albert Mehrabian in Quebec have built Kismet and EMIR (Emotional Model for Intelligent Response), two systems that exhibit primitive feelings.</font></p>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  >The second supposition is that <em>all things can compute</em>. We have begun to see that almost any kind of material can serve as a computer. Human brains, which are mostly water, compute fairly well. (The first "calculators" were clerical workers figuring mathematical tables by hand.) So can sticks and strings. In 1975, as an undergraduate student, engineer Danny Hillis constructed a digital computer out of skinny Tinkertoys. In 2000, Hillis designed a digital computer made of only steel and tungsten that is indirectly powered by human muscle. This slow-moving device turns a clock intended to tick for 10,000 years. He hasn't made a computer with pipes and pumps, but, he says, he could. Recently, scientists have used both quantum particles and minute strands of DNA to perform computations.</font></p>
<hr>
<p><font face="verdana, helvetica, arial, sans-serif"  size="2"  color="#000000"  ><i>Editor-at-large Kevin Kelly (kk@kk.org) has 
just completed <i>Asia Grace</i>, a picture book of celebrations in Asia (www.asiagrace.com).</i></font></p>
<!-- BEGIN BOTTOM PAGE NAVIGATION -->
<p>
<font face="verdana, helvetica, sans-serif" size="1">
<b>
<a href="holytech.html?pg=2&topic=&topic_set=">Page 2</a>
</b>
</font>

<font face="verdana,helvetica, sans-serif" size="1" COLOR="#FF3300">
<b>
&gt;&gt;
</b>
</font>
</p>
<!-- END BOTTOM PAGE NAVIGATION -->
<!-- BEGIN INTRA-STORY NAV -->
<p>
<br>
<br>
<b>
<font face="verdana,helvetica,sans-serif" size=1>
Previous Story: <a href="pope_astro.html">The Pope's Astrophysicist</a>
<br>
<br>
Next Story: <a href="prayer.html">A Prayer Before Dying</a>
</font>
</b>
</p>
<!-- END INTRA-STORY NAV -->


                    <!-- BEGIN Footer Ad -->
<!-- END Footer Ad -->

                    </div><!-- DART AD START sz300x250  -->
                    <div id="dartTarget_sz300x250" class="dartAdUnit"></div>
                    <iframe name="dartFrame_sz300x250" class="hiddenDAU" id="dartFrame_sz300x250" scrolling="no" frameborder="0"></iframe>
                    
                    <script type="text/javascript">
                        //<!--
                            var tile_num;
                            var condenetads_ord;
                            if (typeof tile_num == "undefined") { tile_num=1; } else { tile_num++; }
                            if (typeof condenetads_ord == "undefined") { condenetads_ord = Math.random()*10000000000000000;}
                            dart["sz300x250"] = {placement:"sz=300x250;", dartCall:"wiredcom.dart/archive;kw=archive;", dcopt:""};
                            if (isSafari == 'false'){dartRequest("sz300x250");};
                        //-->
                    </script>
                    
                    </div>
                </div><!-- END colMain -->

                <!-- BEGIN colRight -->
                <div id="colR">
                    <div class="content">
                    <!-- BEGIN Wired Blogs -->
<!-- /wired/meta/wiredblogs.htmlf -->
<h3>Wired Product Reviews</h3>

<p>
<a href="http://www.wired.com/reviews"><img src="http://www.wired.com/images/index/magazine/78x78_wired_reviews.gif" alt="Product Reviews" width="78" height="78" class="imgLeft" /></a>
Get <a href="http://www.wired.com/reviews">daily reviews</a> of the latest consumer electronics, gadgets, cars, gaming gear and more.
<br class='clear' />
</p>

<p>
<a href="http://phobos.apple.com/WebObjects/MZStore.woa/wa/viewSoftware?id=296908685"><img src="http://www.wired.com/images/index/magazine/78x78_wired_iphone.gif" alt="iPhone App" width="78" height="78" class="imgLeft" /></a>Get gadgets on the go with Wired's Product Reviews app for the Apple iPhone and iPod Touch. Download the application for free on the <a href="http://phobos.apple.com/WebObjects/MZStore.woa/wa/viewSoftware?id=296908685">iPhone App Store.</a>
<br class='clear' />
</p>



<!-- END Wired Blogs -->

                    <!-- BEGIN Gadget Lab Newsletter -->
<h3>Wired Blogs</h3>


<p>From gaming, cars and geek dads to science and security, <a href="http://www.wired.com/blogs/">Wired.com's blog network</a> covers what you need to know today. 
<br class='clear' />
</p>

<p>
Read <cite>Wired</cite> magazine editor in chief Chris Anderson's blog, <a href="http://longtail.typepad.com/the_long_tail/">The Long Tail</a>.
</p>

<!-- END Gadget Lab Newsletter -->


<!-- BEGIN Gadget Lab Newsletter -->
<h3>Wired Newsletter</h3>
<p>
The <cite>Wired</cite> newsletter delivers links to our most popular articles, blogs and multimedia features to your e-mail inbox every month. <a href="http://www.wired.com/services/newsletters" target="gadgetlab">
Sign up</a>.<br /><br />


<strong><a href="http://feeds.wired.com/wired/index"><img src="http://www.feedburner.com/fb/lib/images/icons/feed-icon-12x12-orange.gif" alt="XML" width="12" height="12" border="0" /> Wired Top Stories Feed</a></strong>
<br class='clear' />
</p>
<!-- END Gadget Lab Newsletter -->

                    
                    </div>
                </div><!-- END colRight -->

            </div><!-- END subwrap -->


            <!-- BEGIN colLeft -->
            <div id="colL">
                <div class="content">
                <h3>Get Wired</h3>

<div class="hooha">
<div></div>
<a href="https://w1.buysub.com/pubs/N3/WIR/digital_doneefirst_051012.jsp?cds_page_id=26167&amp;cds_mag_code=WIR&amp;id=1178571246852&amp;lsid=71271542340040047&amp;vid=5&amp;cds_response_key=GTDIWC01&amp;cds_mag_code=WIR" target="new"><img src="/wired/images/Wired_MagArchive_208x56.gif" width="208" height="56" style="padding:0 0 3px 0px;" alt="" /></a>
</div>

<div class="hooha">
<div style="text-align:center;padding-bottom:10px">
<a href="https://w1.buysub.com/pubs/N3/WIR/pkg_WIRaddFOL.jsp?cds_page_id=34617&amp;cds_mag_code=WIR&amp;id=1178571301611&amp;lsid=71271542340040047&amp;vid=6&amp;cds_response_key=ISDNWC04&amp;cds_mag_code=WIR" target="new">SUBSCRIBE TO WIRED!</a>
<a href="https://w1.buysub.com/pubs/N3/WIR/pkg_WIRaddFOL.jsp?cds_page_id=34617&amp;cds_mag_code=WIR&amp;id=1178571301611&amp;lsid=71271542340040047&amp;vid=6&amp;cds_response_key=ISDNWC04&amp;cds_mag_code=WIR" target="new"><img src="/wired/covers/Wired_MagArchive_136x179.gif" width="136" height="179" style="margin-top:3px;" name="currentmag" alt="" /></a>
<br /><a href="https://w1.buysub.com/pubs/N3/WIR/pkg_WIRaddFOL.jsp?cds_page_id=34617&amp;cds_mag_code=WIR&amp;id=1178571301611&amp;lsid=71271542340040047&amp;vid=6&amp;cds_response_key=ISDNWC04&amp;cds_mag_code=WIR" target="new">Less than $1 an issue. Click Here.</a>
</div>

<!--
<p>
<strong>Special Offer:</strong><br />
</p>
--> 

<p>
<strong><a href="https://w1.buysub.com/servlet/GiftsGateway?cds_mag_code=WIR&cds_page_id=26223&cds_response_key=X9RIWTGL" target="new">Give Wired</a></strong><br />
&#183; <a href="https://w1.buysub.com/servlet/OrdersGateway?cds_mag_code=WIR&cds_page_id=26161&cds_response_key=GCRIWWC1" target="new">International Subscriptions</a><br />
&#183; <a href="http://r.hotwired.com/r/wn_mag_renew/https://w1.buysub.com/servlet/CSGateway?cds_mag_code=WIR&amp;cds_page_id=2659" target="new">Renew</a><br />
</p>

<!-- p><strong><a href="http://www.wired.com/wired/reprints/">Reprints</a></strong></p -->
<p><strong><a href="https://w1.buysub.com/servlet/CSGateway?cds_mag_code=WIR&amp;cds_page_id=2659" target="new">Customer Service</a></strong></p>

</div>



                <div class="hooha">
<div></div>
<h4>Wired Blogs</h4>
<a href="http://blog.wired.com/sterling/">
Beyond the Beyond</a><br/>
by Bruce Sterling
</div>

<div class="hooha">
<div></div>
<h4>Gadget Lab</h4>
<a href="http://www.condenastdirect.com/wired/wired_signup/signup.cfm">Subscribe to Newsletter</a><br/>
<a href="http://www.wired.com/wired/archive/gadgetlab/">Gadget Lab Archive</a><br/>
<a href="/wired/archive/gadgetlab/gadgetlab.rdf">Gadgetlab</a> <a href="/wired/archive/gadgetlab/gadgetlab.rdf"><img src="/wired/archive/gadgetlab/xml.gif" alt="XML" width="36" height="14" /></a> <a href="/wired/archive/gadgetlab/gadgetlab.rdf">feed</a><br/>
</div>

<div class="hooha">
<div></div>
<h4>Wired 40</h4>
<a href="/wired/archive/wired40/">Introduction</a><br/>
</div>

<div class="hooha">
<div></div>
<h4>Advertising</h4>
<a href="http://www.whatsnextnow.com/cont_frmset.html" target="contact">Contact Info</a><br/>
<a href="http://www.whatsnextnow.com/general_frmset.html" target="contact">General Ads</a><br/>
<a href="http://www.whatsnextnow.com/market_frmset.html" target="contact">Market Display Ads</a><br/>
<a href="http://www.wired.com/wired/ads/adlinks/">Advertiser Links</a><br/>
</div>

                

                <h3>Browse Issue Archive</h3>
<form method="get" id="browse_issue_form">
<select name="url" id="browse_issue_select">
<option selected="selected" value="http://www.wired.com/wired/">Issue-Date</option>
<option value="http://www.wired.com/wired/archive/15.04/">15.04-Apr 07</option>
<option value="http://www.wired.com/wired/archive/15.03/">15.03-Mar 07</option>
<option value="http://www.wired.com/wired/archive/15.02/">15.02-Feb 07</option>
<option value="http://www.wired.com/wired/archive/15.01/">15.01-Jan 07</option>
<option value="http://www.wired.com/wired/archive/14.12/">14.12-Dec 06</option>
<option value="http://www.wired.com/wired/archive/14.11/">14.11-Nov 06</option>
<option value="http://www.wired.com/wired/archive/14.10/">14.10-Oct 06</option>
<option value="http://www.wired.com/wired/archive/14.09/">14.09-Sep 06</option>
<option value="http://www.wired.com/wired/archive/14.08/">14.08-Aug 06</option>
<option value="http://www.wired.com/wired/archive/14.07/">14.07-Jul 06</option>
<option value="http://www.wired.com/wired/archive/14.06/">14.06-Jun 06</option>
<option value="http://www.wired.com/wired/archive/14.05/">14.05-May 06</option>
<option value="http://www.wired.com/wired/archive/14.04/">14.04-Apr 06</option>
<option value="http://www.wired.com/wired/archive/14.03/">14.03-Mar 06</option>
<option value="http://www.wired.com/wired/archive/14.02/">14.02-Feb 06</option>
<option value="http://www.wired.com/wired/archive/14.01/">14.01-Jan 06</option>
<option value="http://www.wired.com/wired/archive/13.12/">13.12-Dec 05</option>
<option value="http://www.wired.com/wired/archive/13.11/">13.11-Nov 05</option>
<option value="http://www.wired.com/wired/archive/13.10/">13.10-Oct 05</option>
<option value="http://www.wired.com/wired/archive/13.09/">13.09-Sep 05</option>
<option value="http://www.wired.com/wired/archive/13.08/">13.08-Aug 05</option>
<option value="http://www.wired.com/wired/archive/13.07/">13.07-Jul 05</option>
<option value="http://www.wired.com/wired/archive/13.06/">13.06-Jun 05</option>
<option value="http://www.wired.com/wired/archive/13.05/">13.05-May 05</option>
<option value="http://www.wired.com/wired/archive/13.04/">13.04-Apr 05</option>
<option value="http://www.wired.com/wired/archive/13.03/">13.03-Mar 05</option>
<option value="http://www.wired.com/wired/archive/13.02/">13.02-Feb 05</option>
<option value="http://www.wired.com/wired/archive/13.01/">13.01-Jan 05</option>
<option value="http://www.wired.com/wired/archive/12.12/">12.12-Dec 04</option>
<option value="http://www.wired.com/wired/archive/12.11/">12.11-Nov 04</option>
<option value="http://www.wired.com/wired/archive/12.10/">12.10-Oct 04</option>
<option value="http://www.wired.com/wired/archive/12.09/">12.09-Sep 04</option>
<option value="http://www.wired.com/wired/archive/12.08/">12.08-Aug 04</option>
<option value="http://www.wired.com/wired/archive/12.07/">12.07-Jul 04</option>
<option value="http://www.wired.com/wired/archive/12.06/">12.06-Jun 04</option>
<option value="http://www.wired.com/wired/archive/12.05/">12.05-May 04</option>
<option value="http://www.wired.com/wired/archive/12.04/">12.04-Apr 04</option>
<option value="http://www.wired.com/wired/archive/12.03/">12.03-Mar 04</option>
<option value="http://www.wired.com/wired/archive/12.02/">12.02-Feb 04</option>
<option value="http://www.wired.com/wired/archive/12.01/">12.01-Jan 04</option>
<option value="http://www.wired.com/wired/archive/11.12/">11.12-Dec 03</option>
<option value="http://www.wired.com/wired/archive/11.11/">11.11-Nov 03</option>
<option value="http://www.wired.com/wired/archive/11.10/">11.10-Oct 03</option>
<option value="http://www.wired.com/wired/archive/11.09/">11.09-Sep 03</option>
<option value="http://www.wired.com/wired/archive/11.08/">11.08-Aug 03</option>
<option value="http://www.wired.com/wired/archive/11.07/">11.07-Jul 03</option>
<option value="http://www.wired.com/wired/archive/11.06/">11.06-Jun 03</option>
<option value="http://www.wired.com/wired/archive/11.05/">11.05-May 03</option>
<option value="http://www.wired.com/wired/archive/11.04/">11.04-Apr 03</option>
<option value="http://www.wired.com/wired/archive/11.03/">11.03-Mar 03</option>
<option value="http://www.wired.com/wired/archive/11.02/">11.02-Feb 03</option>
<option value="http://www.wired.com/wired/archive/11.01/">11.01-Jan 03</option>
<option value="http://www.wired.com/wired/archive/10.12/">10.12-Dec 02</option>
<option value="http://www.wired.com/wired/archive/10.11/">10.11-Nov 02</option>
<option value="http://www.wired.com/wired/archive/10.10/">10.10-Oct 02</option>
<option value="http://www.wired.com/wired/archive/10.09/">10.09-Sep 02</option>
<option value="http://www.wired.com/wired/archive/10.08/">10.08-Aug 02</option>
<option value="http://www.wired.com/wired/archive/10.07/">10.07-Jul 02</option>
<option value="http://www.wired.com/wired/archive/10.06/">10.06-Jun 02</option>
<option value="http://www.wired.com/wired/archive/10.05/">10.05-May 02</option>
<option value="http://www.wired.com/wired/archive/10.04/">10.04-Apr 02</option>
<option value="http://www.wired.com/wired/archive/10.03/">10.03-Mar 02</option>
<option value="http://www.wired.com/wired/archive/10.02/">10.02-Feb 02</option>
<option value="http://www.wired.com/wired/archive/10.01/">10.01-Jan 02</option>
<option value="http://www.wired.com/wired/archive/9.12/">9.12-Dec 01</option>
<option value="http://www.wired.com/wired/archive/9.11/">9.11-Nov 01</option>
<option value="http://www.wired.com/wired/archive/9.10/">9.10-Oct 01</option>
<option value="http://www.wired.com/wired/archive/9.09/">9.09-Sep 01</option>
<option value="http://www.wired.com/wired/archive/9.08/">9.08-Aug 01</option>
<option value="http://www.wired.com/wired/archive/9.07/">9.07-Jul 01</option>
<option value="http://www.wired.com/wired/archive/9.06/">9.06-Jun 01</option>
<option value="http://www.wired.com/wired/archive/9.05/">9.05-May 01</option>
<option value="http://www.wired.com/wired/archive/9.04/">9.04-Apr 01</option>
<option value="http://www.wired.com/wired/archive/9.03/">9.03-Mar 01</option>
<option value="http://www.wired.com/wired/archive/9.02/">9.02-Feb 01</option>
<option value="http://www.wired.com/wired/archive/9.01/">9.01-Jan 01</option>
<option value="http://www.wired.com/wired/archive/8.12/">8.12-Dec 00</option>
<option value="http://www.wired.com/wired/archive/8.11/">8.11-Nov 00</option>
<option value="http://www.wired.com/wired/archive/8.10/">8.10-Oct 00</option>
<option value="http://www.wired.com/wired/archive/8.09/">8.09-Sep 00</option>
<option value="http://www.wired.com/wired/archive/8.08/">8.08-Aug 00</option>
<option value="http://www.wired.com/wired/archive/8.07/">8.07-Jul 00</option>
<option value="http://www.wired.com/wired/archive/8.06/">8.06-Jun 00</option>
<option value="http://www.wired.com/wired/archive/8.05/">8.05-May 00</option>
<option value="http://www.wired.com/wired/archive/8.04/">8.04-Apr 00</option>
<option value="http://www.wired.com/wired/archive/8.03/">8.03-Mar 00</option>
<option value="http://www.wired.com/wired/archive/8.02/">8.02-Feb 00</option>
<option value="http://www.wired.com/wired/archive/8.01/">8.01-Jan 00</option>
<option value="http://www.wired.com/wired/archive/7.12/">7.12-Dec 99</option>
<option value="http://www.wired.com/wired/archive/7.11/">7.11-Nov 99</option>
<option value="http://www.wired.com/wired/archive/7.10/">7.10-Oct 99</option>
<option value="http://www.wired.com/wired/archive/7.09/">7.09-Sep 99</option>
<option value="http://www.wired.com/wired/archive/7.08/">7.08-Aug 99</option>
<option value="http://www.wired.com/wired/archive/7.07/">7.07-Jul 99</option>
<option value="http://www.wired.com/wired/archive/7.06/">7.06-Jun 99</option>
<option value="http://www.wired.com/wired/archive/7.05/">7.05-May 99</option>
<option value="http://www.wired.com/wired/archive/7.04/">7.04-Apr 99</option>
<option value="http://www.wired.com/wired/archive/7.03/">7.03-Mar 99</option>
<option value="http://www.wired.com/wired/archive/7.02/">7.02-Feb 99</option>
<option value="http://www.wired.com/wired/archive/7.01/">7.01-Jan 99</option>
<option value="http://www.wired.com/wired/archive/6.12/">6.12-Dec 98</option>
<option value="http://www.wired.com/wired/archive/6.11/">6.11-Nov 98</option>
<option value="http://www.wired.com/wired/archive/6.10/">6.10-Oct 98</option>
<option value="http://www.wired.com/wired/archive/6.09/">6.09-Sep 98</option>
<option value="http://www.wired.com/wired/archive/6.08/">6.08-Aug 98</option>
<option value="http://www.wired.com/wired/archive/6.07/">6.07-Jul 98</option>
<option value="http://www.wired.com/wired/archive/6.06/">6.06-Jun 98</option>
<option value="http://www.wired.com/wired/archive/6.05/">6.05-May 98</option>
<option value="http://www.wired.com/wired/archive/6.04/">6.04-Apr 98</option>
<option value="http://www.wired.com/wired/archive/6.03/">6.03-Mar 98</option>
<option value="http://www.wired.com/wired/archive/6.02/">6.02-Feb 98</option>
<option value="http://www.wired.com/wired/archive/6.01/">6.01-Jan 98</option>
<option value="http://www.wired.com/wired/archive/5.12/">5.12-Dec 97</option>
<option value="http://www.wired.com/wired/archive/5.11/">5.11-Nov 97</option>
<option value="http://www.wired.com/wired/archive/5.10/">5.10-Oct 97</option>
<option value="http://www.wired.com/wired/archive/5.09/">5.09-Sep 97</option>
<option value="http://www.wired.com/wired/archive/5.08/">5.08-Aug 97</option>
<option value="http://www.wired.com/wired/archive/5.07/">5.07-Jul 97</option>
<option value="http://www.wired.com/wired/archive/5.06/">5.06-Jun 97</option>
<option value="http://www.wired.com/wired/archive/5.05/">5.05-May 97</option>
<option value="http://www.wired.com/wired/archive/5.04/">5.04-Apr 97</option>
<option value="http://www.wired.com/wired/archive/5.03/">5.03-Mar 97</option>
<option value="http://www.wired.com/wired/archive/5.02/">5.02-Feb 97</option>
<option value="http://www.wired.com/wired/archive/5.01/">5.01-Jan 97</option>
<option value="http://www.wired.com/wired/archive/4.12/">4.12-Dec 96</option>
<option value="http://www.wired.com/wired/archive/4.11/">4.11-Nov 96</option>
<option value="http://www.wired.com/wired/archive/4.10/">4.10-Oct 96</option>
<option value="http://www.wired.com/wired/archive/4.09/">4.09-Sep 96</option>
<option value="http://www.wired.com/wired/archive/4.08/">4.08-Aug 96</option>
<option value="http://www.wired.com/wired/archive/4.07/">4.07-Jul 96</option>
<option value="http://www.wired.com/wired/archive/4.06/">4.06-Jun 96</option>
<option value="http://www.wired.com/wired/archive/4.05/">4.05-May 96</option>
<option value="http://www.wired.com/wired/archive/4.04/">4.04-Apr 96</option>
<option value="http://www.wired.com/wired/archive/4.03/">4.03-Mar 96</option>
<option value="http://www.wired.com/wired/archive/4.02/">4.02-Feb 96</option>
<option value="http://www.wired.com/wired/archive/4.01/">4.01-Jan 96</option>
<option value="http://www.wired.com/wired/archive/3.12/">3.12-Dec 95</option>
<option value="http://www.wired.com/wired/archive/3.11/">3.11-Nov 95</option>
<option value="http://www.wired.com/wired/archive/3.10/">3.10-Oct 95</option>
<option value="http://www.wired.com/wired/archive/3.09/">3.09-Sep 95</option>
<option value="http://www.wired.com/wired/archive/3.08/">3.08-Aug 95</option>
<option value="http://www.wired.com/wired/archive/3.07/">3.07-Jul 95</option>
<option value="http://www.wired.com/wired/archive/3.06/">3.06-Jun 95</option>
<option value="http://www.wired.com/wired/archive/3.05/">3.05-May 95</option>
<option value="http://www.wired.com/wired/archive/3.04/">3.04-Apr 95</option>
<option value="http://www.wired.com/wired/archive/3.03/">3.03-Mar 95</option>
<option value="http://www.wired.com/wired/archive/3.02/">3.02-Feb 95</option>
<option value="http://www.wired.com/wired/archive/3.01/">3.01-Jan 95</option>
<option value="http://www.wired.com/wired/archive/2.12/">2.12-Dec 94</option>
<option value="http://www.wired.com/wired/archive/2.11/">2.11-Nov 94</option>
<option value="http://www.wired.com/wired/archive/2.10/">2.10-Oct 94</option>
<option value="http://www.wired.com/wired/archive/2.09/">2.09-Sep 94</option>
<option value="http://www.wired.com/wired/archive/2.08/">2.08-Aug 94</option>
<option value="http://www.wired.com/wired/archive/2.07/">2.07-Jul 94</option>
<option value="http://www.wired.com/wired/archive/2.06/">2.06-Jun 94</option>
<option value="http://www.wired.com/wired/archive/2.05/">2.05-May 94</option>
<option value="http://www.wired.com/wired/archive/2.04/">2.04-Apr 94</option>
<option value="http://www.wired.com/wired/archive/2.03/">2.03-Mar 94</option>
<option value="http://www.wired.com/wired/archive/2.02/">2.02-Feb 94</option>
<option value="http://www.wired.com/wired/archive/2.01/">2.01-Jan 94</option>
<option value="http://www.wired.com/wired/archive/1.06/">1.06-Dec 93</option>
<option value="http://www.wired.com/wired/archive/1.05/">1.05-Nov 93</option>
<option value="http://www.wired.com/wired/archive/1.04/">1.04-S/O 93</option>
<option value="http://www.wired.com/wired/archive/1.03/">1.03-J/A 93</option>
<option value="http://www.wired.com/wired/archive/1.02/">1.02-M/J 93</option>
<option value="http://www.wired.com/wired/archive/1.01/">1.01-M/A 93</option>
</select>
<input type="submit" value="GO" class="whtbtn" id="browse_issue_submit" />
</form>
<p>Browse by <a href="/wired/archive/">cover</a></p>

                </div>
            </div><!-- END colLeft -->

<style>
div#suboffers { width:160px; }
div#suboffers ul#suboffers_list { width:175px; }
div#suboffers ul#suboffers_list li { width:175px; }
</style>

<br clear="all" />
<div id="footer">
	<div id="foot_row1">
		<span class="pad">
			<span class="link_row"><a href="/services/corrections/">Corrections</a> | <a href="/about/sitemap/">Sitemap</a> |  <a href="/about/faq/">FAQ</a> | <a href="/about/feedback/">Contact Us</a> | <a href="/about/staff_web/">Wired Staff</a> | <a href="http://www.condenet.com/contacts.html" target="_blank">Advertising</a> | <a href="/about/press/">Press Center</a> | <a href="http://www.wired.com/customerservice" target="_blank">Subscription Services</a> | <a href="/services/newsletters">Newsletter</a> | <a href="/about/rss_feeds/">RSS Feeds</a> <a href="/about/rss_feeds/"><img src="/images/footer_rss.gif" class="footer_rss"></a></span>
    </div>
	<div id="foot_row3">
		<span class="pad">
			<strong>Cond&eacute; Nast Web Sites:</strong>
			<div class="condenet_sites">
                <a href="http://www.webmonkey.com">Webmonkey</a> | 
                <a href="http://www.reddit.com">Reddit</a> | 
                <a href="http://www.arstechnica.com">ArsTechnica</a> | 
                <a href="http://www.epicurious.com">Epicurious</a> | 
                <a href="http://www.nutritiondata.com">NutritionData</a> | 
                <a href="http://www.concierge.com">Concierge</a> | 
                <a href="http://www.hotelchatter.com">HotelChatter</a> |  
                <a href="http://www.jaunted.com/">Jaunted</a> |  
                <a href="http://www.style.com">Style.com</a> |  
                <a href="http://men.style.com">Men.Style.com</a>
            </div>
			<div id="drop_downs">
                <select>
                    <option>Subscribe to a magazine:</option>
                    <option value="http://www.magazinestoresubscriptions.com?source=SITEFOOTER">View All Titles</option> 
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Allure?source=SITEFOOTER">Allure</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_ArchitecturalDigest?source=SITEFOOTER">Architectural Digest</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_BonAppetite?source=SITEFOOTER">Bon App&#233;tit</option> 
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Brides?source=SITEFOOTER">Brides</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_CondeNastPortfolio?source=SITEFOOTER">Cond&#233; Nast Portfolio</option>            
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_CondeNastTraveler?source=SITEFOOTER">Cond&#233; Nast Traveler</option> 
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Cookie?source=SITEFOOTER">Cookie</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Details?source=SITEFOOTER">Details</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_ElegantBride?source=SITEFOOTER">Elegant Bride</option> 
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Glamour?source=SITEFOOTER">Glamour</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_GolfDigest?source=SITEFOOTER">Golf Digest</option> 
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_GolfWorld?source=SITEFOOTER">Golf World</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Gourmet?source=SITEFOOTER">Gourmet</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_GQ?source=SITEFOOTER">GQ</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Lucky?source=SITEFOOTER">Lucky</option>       
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_ModernBride?source=SITEFOOTER">Modern Bride</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Self?source=SITEFOOTER">Self</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_TeenVogue?source=SITEFOOTER">Teen Vogue</option> 
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_NewYorker?source=SITEFOOTER">The New Yorker</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_VanityFair?source=SITEFOOTER">Vanity Fair</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Vogue?source=SITEFOOTER">Vogue</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_W?source=SITEFOOTER">W</option>
                    <option value="https://www.magazinestoresubscriptions.com/webapp/wcs/stores/servlet/Subscriptions_Wired?source=SITEFOOTER">Wired</option>
                </select>
                <select>
                    <option>Cond&#233; Nast web sites:</option>
                    <option value="http://www.allure.com/">Allure</option>
                    <option value="http://www.architecturaldigest.com/">Architectural Digest</option>
                    <option value="http://www.arstechnica.com/">ArsTechnica</option>
                    <option value="http://www.bonappetit.com/">Bon App&eacute;tit</option>
                    <option value="http://www.brides.com/">Brides.com</option>
                    <option value="http://www.cntraveler.com/">Cond&eacute; Nast Traveler</option>
                    <option value="http://www.portfolio.com/">Cond&eacute; Nast Portfolio</option> 
                    <option value="http://www.concierge.com/">Concierge</option>
                    <option value="http://www.cookiemag.com/">Cookie</option>
                    <option value="http://www.details.com/">Details</option>
                    <option value="http://www.elegantbride.com/">Elegant Bride</option>
                    <option value="http://www.epicurious.com/">Epicurious</option>
                    <option value="http://www.glamour.com/">Glamour</option>
                    <option value="http://www.golfdigest.com">Golf Digest</option>
                    <option value="http://www.golfworld.com">Golf World</option>
                    <option value="http://www.gourmet.com/">Gourmet</option>
                    <option value="http://www.gq.com/">GQ</option>
                    <option value="http://www.hotelchatter.com/">Hotel Chatter</option>
                    <option value="http://www.jaunted.com/">Jaunted</option>
                    <option value="http://www.luckymag.com/">Lucky</option>
                    <option value="http://men.style.com/">Men.Style.com</option>
                    <option value="http://www.modernbride.com/">Modern Bride</option>
                    <option value="http://www.nutritiondata.com/">Nutrition Data</option>
                    <option value="http://www.reddit.com/">Reddit</option>
                    <option value="http://www.self.com/">Self</option>
                    <option value="http://www.style.com">Style.com</option>
                    <option value="http://www.teenvogue.com/">Teen Vogue</option>
                    <option value="http://www.newyorker.com/">The New Yorker</option>
                    <option value="http://www.thesartorialist.com">The Sartorialist</option>
                    <option value="http://www.vanityfair.com/">Vanity Fair</option>
                    <option value="http://www.vogue.com">Vogue</option>
                    <option value="http://www.webmonkey.com">Webmonkey</option>
                    <option value="http://www.wmagazine.com/">W</option> 
                </select>
			</div>
            
            <div class="copyright">
                <p>Registration on or use of this site constitutes acceptance of our <a href="/services/useragreement/">User Agreement</a> (Revised 4/1/2009) and <a href="/services/privacy/">Privacy Policy</a> (Revised 4/1/2009).</p>
                <p>Wired.com &copy 2009 Cond&eacute; Nast Digital. All rights reserved.</p>
                <p>The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond&eacute; Nast Digital.</p>
            </div>
		</span>
	</div>
</div>



<div id="zagHolder">
    <script language="JavaScript1.1" type="text/javascript">
        //<!--
//            TrackingObject.setDomain("/js/stats/zag.js");
            TrackingObject.setStatus(200);
            TrackingObject.setNodeId("zagHolder");
            TrackingObject.drawTracking();
        //-->
    </script>
</div>


	</div><!-- END wrap -->
</div><!-- close shell div -->

<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-2624369-1";
urchinTracker();
</script>
            
<script type="text/javascript"><!--
  collarity_appid="wired";
// -->
</script>
<script type="text/javascript" src="http://service.collarity.com/ucs/tracker.js">
</script> 
<!-- SiteCatalyst code version: H.15.1.
Copyright 1997-2008 Omniture, Inc. More info available at
http://www.omniture.com <http://www.omniture.com>  -->

<script language="JavaScript" type="text/javascript"><!--
var s_account="conde-wired";
var s_linkInternalFilters="javascript:,wired.com";
var s_trackingServer="stats.wired.com";
//-->
</script>

<script language="JavaScript" type="text/javascript" src="/js/omniture/s_code.js"></script> 

<script language="JavaScript" type="text/javascript"><!--
    /* You may give each page an identifying name, server, and channel on
    the next lines. Omniture variables. */
    s.pageType=setPageType
    s.prop1=setProp1
    s.prop2=setProp2
    s.prop3=setProp3
    s.prop5="archive"; 
    s.prop6=setProp6
    s.prop7=setProp7
    s.prop8=setProp8
    s.prop9=setProp9
    s.prop10=s.prop1.replace(/ /g,',')

    s.events=setEvents

    s.hier1=omniHierarchy
    /************* DO NOT ALTER ANYTHING BELOW THIS LINE ! **************/
    var s_code=s.t();if(s_code)document.write(s_code)//--></script>
    <script language="JavaScript" type="text/javascript"><!--
    if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
    //--></script><noscript><a href="http://www.omniture.com" title="Web Analytics"><img
    src="http://condenast.112.2o7.net/b/ss/condenet-dev/1/H.15.1--NS/0"
    height="1" width="1" border="0" alt="" /></a></noscript><!--/DO NOT REMOVE/--> 
    <!-- End SiteCatalyst code version: H.15.1. --> 
</body>  
</html>

<!-- END CONTENT archive template -->


++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.mindspring.com/~mfpatton/Tissues.htm>====================
<HTML>
<HEAD>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
   <META NAME="GENERATOR" CONTENT="Microsoft FrontPage 5.0">
   <TITLE>Brain in a Vat</TITLE>
</HEAD>
<BODY TEXT="#000000" BGCOLOR="#C2C0C0" LINK="#800000" VLINK="#800000" ALINK="#FF0000" BACKGROUND="">

<UL>
<CENTER>
<H3>
<I>Tissues in the Profession:&nbsp;<BR wp="br1">
<BR wp="br2">
</I>CAN BAD MEN MAKE GOOD BRAINS DO BAD THINGS?</H3></CENTER>
</UL>

<CENTER>
<DT>
Michael F. Patton, Jr.</DT></CENTER>

<CENTER>
<DT>
Syracuse University</DT></CENTER>

<CENTER>
<p></p>
</CENTER>

<CENTER><IMG SRC="Trolley.gif" HEIGHT=200 WIDTH=150></CENTER>

<UL>
<UL>
<UL><I>Consider the following case:</I>

<P>On Twin Earth, a brain in a vat is at the wheel of a runaway trolley.
There are only two options that the brain can take: the right side of the
fork in the track or the left side of the fork. There is no way in sight
of derailing or stopping the trolley and the brain is aware of this, for
the brain <I>knows</I> trolleys. The brain is causally hooked up to the
trolley such that the brain can determine the course which the trolley
will take.

<P>On the right side of the track there is a single railroad worker, Jones,
who will definitely be killed if the brain steers the trolley to the right.
If the railman on the right lives, he will go on to kill five men for the
sake of killing them, but in doing so will inadvertently save the lives
of thirty orphans (one of the five men he will kill is planning to destroy
a bridge that the orphans' bus will be crossing later that night). One
of the orphans that will be killed would have grown up to become a tyrant
who would make good utilitarian men do bad things. Another of the orphans
would grow up to become G.E.M. Anscombe, while a third would invent the
pop-top can.

<P>If the brain in the vat chooses the left side of the track, the trolley
will definitely hit and kill a railman on the left side of the track, "Leftie"
and will hit and destroy ten beating hearts on the track that could (and
would) have been transplanted into ten patients in the local hospital that
will die without donor hearts. These are the only hearts available, and
the brain is aware of this, for the brain <I>knows</I> hearts. If the railman
on the left side of the track lives, he too will kill five men, in fact
the same five that the railman on the right would kill. However, "Leftie"
will kill the five as an unintended consequence of saving ten men: he will
inadvertently kill the five men rushing the ten hearts to the local hospital
for transplantation. A further result of "Leftie's" act would be that the
busload of orphans will be spared. Among the five men killed by "Leftie"
are both the man responsible for putting the brain at the controls of the
trolley, and the author of this example. If the ten hearts and "Leftie"
are killed by the trolley, the ten prospective heart-transplant patients
will die and their kidneys will be used to save the lives of twenty kidney-transplant
patients, one of whom will grow up to cure cancer, and one of whom will
grow up to be Hitler. There are other kidneys and dialysis machines available,
however the brain does not <I>know</I> kidneys, and this is not a factor.

<P>Assume that the brain's choice, whatever it turns out to be, will serve
as an example to other brains-in-vats and so the effects of his decision
will be amplified. Also assume that if the brain chooses the right side
of the fork, an unjust war free of war crimes will ensue, while if the
brain chooses the left fork, a just war fraught with war crimes will result.
Furthermore, there is an intermittently active Cartesian demon deceiving
the brain in such a manner that the brain is never sure if it is being
deceived.<FONT SIZE=+1></FONT>

<P><B>QUESTION: <I>What should the brain do?</I></B>

<P>[<I>ALTERNATIVE EXAMPLE</I>: Same as above, except the brain has had
a commisurotomy, and the left half of the brain is a consequentialist and
the right side is an absolutist.]
<BR>&nbsp;

<P>Copyright, 1988 by the American Philosophical Association

<P>Most <B>real</B> philosophers will never be able to read this paragraph.
Several of them have died of laughter-induced heart attacks. Other have
their vision blurred by tears of laughter. If you can still read this,
and are thinking to yourself "Sure, everyone <I>else</I> says this Patton
is a genius, but I don't see it," then you need to go to the <I><A HREF="http://www.mindspring.com/~mfpatton/binvat.htm">Nonphilosopher's
Explanation Page</A></I>! All the people who really appreciate this spent
at least five years in philosophy graduate school. Most of their laughter
would be dismissed by mental health professionals as an hysterical symptom
of some coping mechanism, one desperately trying to reconcile them to their
fates as professional philosophers. <I>You</I>, however, can go on with
your relatively normal life (I say <I>relatively</I> because you are surfing
the web instead of something less geeky) <I>and </I>still get some of the
jokes in this article by reading the <I><A HREF="http://www.mindspring.com/~mfpatton/binvat.htm">Nonphilosopher's
Explanation Page</A></I>. It will be fun, enlightening, and it will forever
remove those nagging doubts you had about what they were doing in philosophy
class--they were ruining their lives.*

<P>* Some people think that explaining a joke sucks all of the humor out
of it. I suggest these people read Dr. Harry Johnson's 546 page manuscript
(as yet unpublished) on the nature of humor. It is tentatively titled <I><A HREF="http://www.mindspring.com/~mfpatton/binvat.htm">The
Roots of Humor in the Denial of the Obvious</A></I>.
<BR>&nbsp;
<CENTER><TABLE BORDER >
<TR>
<TD><A HREF="http://www.mindspring.com/~mfpatton/binvat.htm">Nonphilosopher's
Explanation</A></TD>

<TD ALIGN=CENTER VALIGN=CENTER><A HREF="http://www.mindspring.com/~mfpatton/HARPER3.htm">The
History of an Idea</A></TD>
</TR>

<TR>
<TD ALIGN=CENTER VALIGN=CENTER><A HREF="http://www.mindspring.com/~mfpatton/index.html">
<IMG SRC="idiot.gif" width="31" height="31"></A></TD>

<TD><A HREF="http://www.mindspring.com/~mfpatton/index.html">Back to Patton's
Argument Clinic</A></TD>
</TR>
</TABLE></CENTER>
&nbsp;</UL>
</UL>
</UL>

</BODY>
</HTML>++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.rbjones.com/rbjpub/cs/ai022.htm>====================
<HTML>
<LINK REL=STYLESHEET TYPE="text/css" HREF="../prof/p1sty.txt" TITLE="Factasia">
<HEAD>
<TITLE>MainFrame: Artificial Intelligence</TITLE>
<META name="description" content="Material on Artificial Intelligence as engineering with emphasis on the exploitation of logic.
A topography is presented with logic at the center.">
<META name="keywords" content="RbJ ArtificiaL IntelligencE LogiC">
</HEAD>

<BODY CLASS=con>
<CENTER><IMG SRC="../../rbjgifs/ai.gif" ALT="Artificial Intelligence" BORDER=0 ALIGN=TOP WIDTH=89 HEIGHT=75></CENTER>

<A NAME="over"></A>
<TABLE>
<TR VALIGN=TOP><TD WIDTH=200><H1>Overview:</H1>
</TD>
<TD>
<TABLE BORDER=3 CLASS=con CELLPADDING=5 WIDTH="100%">
<TR><TD><FONT SIZE=4><B>
There must be a pretty good chance that AI really will happen in the 21st Century.
Factasia wants a piece of the action.
</B></FONT></TD></TR>
</TABLE>
</TD></TR></TABLE>
<TABLE WIDTH="100%">
<TR VALIGN=TOP><TD WIDTH="50%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B><A HREF="#wint">What is Intelligence?</A></B></CENTER>
<FONT SIZE=2>
By a way of clarifying the scope of the field and identifying the particular interests of Factasia, we seek a definition of intelligence which is not homo-centric.
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<A HREF="#phil"><IMG SRC="../../rbjgifs/philosop.gif" ALT="Philosophy" BORDER=0  ALIGN=LEFT WIDTH=73 HEIGHT=69></A>
<FONT SIZE=2>
There are many rich connections between philosophy and AI, particularly between analytic philosophy and logical AI.
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<A HREF="#supb"><IMG SRC=../../rbjgifs/globsupb.gif BORDER=0 ALT="The Global Superbrain" ALIGN=LEFT WIDTH=135 HEIGHT=64></A>
<FONT SIZE=2>
This extravagent label covers Factasia's interest in the AI project of the (next!) millenium.
The world transformed by the evolution of intelligence in cyberspace.
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="50%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<A HREF="#reas"><IMG SRC="../../rbjgifs/aod.gif" ALT="Automation of Deduction" BORDER=0 ALIGN=LEFT WIDTH=84 HEIGHT=74></A>
<FONT SIZE=2>
Automation of deductive reasoning is the subdomain of AI of greatest interest to Factasia.
Crystal clear problems, widespread applications.
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<A HREF="#math"><IMG SRC="../../rbjgifs/mom.gif" ALT="Mechanisation of Mathematics" BORDER=0 ALIGN=LEFT WIDTH=94 HEIGHT=73></A>
<FONT SIZE=2>
Mathematics provides the most complex applications of deductive reasoning and is therefore a testbed for the automation of reasoning.
Here we consider the transition from powerful but non-intelligent programs to  intelligent mechanised mathematics.
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<A HREF="#topo"><B>Topography</B><BR><IMG SRC="../../rbjgifs/topai.gif" ALT="AI topography" BORDER=0 WIDTH=115 HEIGHT=80 ALIGN=LEFT></A>
<FONT SIZE=2>
Factasia's architecture for AI places pure logic at the centre of it all.
</FONT>
</TD></TR>
</TABLE>

</TD></TR></TABLE>


<P>
<A NAME="wint"></A>

<TABLE>
<TR VALIGN=TOP><TD WIDTH=200><H1><A TARGET="_top" HREF="ai011.htm">What is Intelligence?</A>:</H1>
</TD><TD>

<TABLE BORDER=3 CLASS=con CELLPADDING=5 WIDTH="100%">
<TR><TD><FONT SIZE=4><B>
By a way of clarifying the scope of the field and identifying the particular interests of Factasia, we seek a definition of intelligence which is not homo-centric.
</B></FONT>
</TD></TR></TABLE>

</TD></TR></TABLE>

<TABLE WIDTH="100%">
<TR VALIGN=TOP><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD></TR></TABLE>

<P>
<A NAME="phil"></A>

<TABLE>
<TR VALIGN=TOP><TD WIDTH=200><H1><A TARGET="_top" HREF="../philos/metap/pcsai001.htm"><IMG SRC="../../rbjgifs/philosop.gif" ALT="Philosophy" BORDER=0  ALIGN=TOP WIDTH=73 HEIGHT=69></A>:</H1>
</TD><TD>

<TABLE BORDER=3 CLASS=con CELLPADDING=5 WIDTH="100%">
<TR><TD><FONT SIZE=4><B>
There are many rich connections between philosophy and AI, particularly between analytic philosophy and logical AI.
</B></FONT>
</TD></TR></TABLE>

</TD></TR></TABLE>

<TABLE WIDTH="100%">
<TR VALIGN=TOP><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD></TR></TABLE>

<P>
<A NAME="supb"></A>

<TABLE>
<TR VALIGN=TOP><TD WIDTH=200><H1><A TARGET="_top" HREF="ai013.htm"><IMG SRC=../../rbjgifs/globsupb.gif BORDER=0 ALT="The Global Superbrain" ALIGN=TOP WIDTH=135 HEIGHT=64></A>
:</H1>
</TD><TD>

<TABLE BORDER=3 CLASS=con CELLPADDING=5 WIDTH="100%">
<TR><TD><FONT SIZE=4><B>
This extravagent label covers Factasia's interest in the AI project of the millenium.
The world transformed by the evolution of intelligence in cyberspace.
</B></FONT>
</TD></TR></TABLE>

</TD></TR></TABLE>

<TABLE WIDTH="100%">
<TR VALIGN=TOP><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD></TR></TABLE>


<P>
<A NAME="reas"></A>

<TABLE>
<TR VALIGN=TOP><TD WIDTH=200><H1><A TARGET="_top" HREF="ai002.htm"><IMG SRC="../../rbjgifs/aod.gif" ALT="Automation of Deduction" BORDER=0 ALIGN=LEFT WIDTH=84 HEIGHT=74></A>:</H1>
</TD><TD>

<TABLE BORDER=3 CLASS=con CELLPADDING=5 WIDTH="100%">
<TR><TD><FONT SIZE=4><B>
Automation of deductive reasoning is the subdomain of AI of greatest interest to Factasia.
Crystal clear problems, widespread applications.
</B></FONT>
</TD></TR></TABLE>

</TD></TR></TABLE>

<TABLE WIDTH="100%">
<TR VALIGN=TOP><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B></B></CENTER>
<FONT SIZE=2>
</FONT>
</TD></TR>
</TABLE>

</TD></TR></TABLE>

<P>
<A NAME="math"></A>

<TABLE>
<TR VALIGN=TOP><TD WIDTH=200><H1><A TARGET="_top" HREF="ai008.htm"><IMG SRC="../../rbjgifs/mom.gif" ALT="Mechanisation of Mathematics" BORDER=0 ALIGN=TOP WIDTH=94 HEIGHT=73></A>:</H1>
</TD><TD>

<TABLE BORDER=3 CLASS=con CELLPADDING=5 WIDTH="100%">
<TR><TD><FONT SIZE=4><B>
We may think of the mechanisation of mathematics as occurring in three phases, the <A HREF="#numeric"><EM>numeric</EM></A>, <A HREF="#numeric"><EM>symbolic</EM></A>, and <A HREF="#numeric"><EM>logical</EM></A> phases.
The logical phase provides a platform for mathematical AI.
</B></FONT>
</TD></TR></TABLE>

</TD></TR></TABLE>

<CENTER><A TARGET="_top" HREF="ai008.htm"><IMG SRC="../../rbjgifs/numsymlo.gif" ALT="Numeric/Symbolic/Logical" BORDER=0></A>
</CENTER>

<TABLE WIDTH="100%">
<TR VALIGN=TOP><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B>numeric</B></CENTER>
<FONT SIZE=2>
The predominant area of application of computers to mathematics is in brute numeric computation.
<I>Numerical analysis</I>, takes the drudgery out of the real number computations needed in science and engineering.
<I>Discrete mathematics</I> involving integer arithmetic is now conspicuous for its applications in cryptography.
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B>symbolic</B></CENTER>
<FONT SIZE=2>
Early AI research on symbolic mathematics has now matured into powerful software packages which transform mathematical formulae as well as undertaking numerical computation.
Capabilities such as symbolic differentiation and integration bring these tools much closer to the capabilities of human mathematicians.
</FONT>
</TD></TR>
</TABLE>
</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B>logical</B></CENTER>
<FONT SIZE=2>
Intelligent mathematicians are able to reason about mathematics, and mechanisation ultimately depends on building tools whose capabilities are grounded in logic.
A successful integration of the power of symbolic mathematics tools with suitable proof technology would provide the basis for intelligent mathematical software.
</FONT>
</TD></TR>
</TABLE>

</TD></TR></TABLE>

<P>
<A NAME="topo"></A>

<CENTER>
<A TARGET="_top" HREF="ai012.htm">
<H2>A Topography for AI</H2>
<IMG SRC="../../rbjgifs/topai.gif" ALT="AI topography" BORDER=0 WIDTH=460 HEIGHT=320 USEMAP="#map"></A>
</CENTER>
<MAP NAME="map">
<AREA COORDS="208,112,267,170" TARGET="_top" HREF="ai012.htm#logic">
<AREA COORDS="171,81,306,170" TARGET="_top" HREF="ai012.htm#formath">
<AREA COORDS="145,47,326,172" TARGET="_top" HREF="ai012.htm#englog">
<AREA COORDS="102,1,359,171" TARGET="_top" HREF="ai012.htm#intlog">
<AREA COORDS="137,1,326,213" TARGET="_top" HREF="ai012.htm#judgement">
<AREA COORDS="125,1,336,260" TARGET="_top" HREF="ai012.htm#values">
<AREA COORDS="4,1,462,315" TARGET="_top" HREF="ai012.htm#emotions">
</MAP>


</TD></TR></TABLE>

<TABLE WIDTH="100%">
<TR VALIGN=TOP><TD WIDTH="27%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B><A TARGET="_top" HREF="../logic/log034.htm"><IMG SRC="../../rbjgifs/logic.gif" ALT="Logic" BORDER=0 WIDTH=42 HEIGHT=41></A></B></CENTER>
<FONT SIZE=2>
At the core of our architecture is a formal logical "inference engine".
A meld of compiler and proof technologies giving fast computation of logical truths rather than data values.
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<CENTER><B><A TARGET="_top" HREF="../cs/ai009.htm"><IMG SRC="../../rbjgifs/formaths.gif" ALT="Formal Maths" BORDER=0 WIDTH=51 HEIGHT=44></A></B></CENTER>
<FONT SIZE=2>
Built on the logical core, the main body of applicable mathematics with just as much pure maths as helps to oil the wheels.
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="40%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B><A TARGET="_top" HREF="../logic/engl001.htm"><IMG SRC="../../rbjgifs/englog.gif" ALT="Engineering Logic" BORDER=0 WIDTH=79 HEIGHT=57></A></B></CENTER>
<FONT SIZE=2>
Beyond the theories into the applications, targeted at engineering applications.
As much automated problem solving as we know how implement within the limits of energetic engineering rather than AI breakthroughs.
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<CENTER><B><IMG SRC="../../rbjgifs/intellog.gif" ALT="Intelligent Logic" BORDER=0 WIDTH=78 HEIGHT=75></B></CENTER>
<FONT SIZE=2>
We seek an environment in which, in an environment full of hard graft algorithmic problem solving, intelligent capabilities can evolve and emerge.
Not by natural selection.
Faster than that.
</FONT>
</TD></TR>
</TABLE>

</TD><TD WIDTH="33%">

<TABLE CELLPADDING=5 WIDTH="100%" CLASS=co2>
<TR VALIGN=TOP><TD>
<CENTER><B><IMG SRC="../../rbjgifs/judgment.gif" ALT="Judgement" BORDER=0 WIDTH=75 HEIGHT=44></B></CENTER>
<FONT SIZE=2>
Beyond logic and mathematics, beyond deduction, into empirical science.
Judgement is called for here, and trusting machines may not be appropriate.
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<CENTER><B><IMG SRC="../../rbjgifs/values.gif" ALT="Values" BORDER=0 WIDTH=88 HEIGHT=25></B></CENTER>
<FONT SIZE=2>
One step further, from objective science to subjective values.
This is part of what human intelligence is about, but do we need it in AI?
</FONT>
</TD></TR>
<TR VALIGN=TOP><TD>
<CENTER><B>Emotions</B></CENTER>
<FONT SIZE=2>
One step further beyond the limits of machinery?
</FONT>
</TD></TR>
</TABLE>

</TD></TR></TABLE>

<P>
<CENTER>
<HR WIDTH=70%>
<A TARGET="_top" HREF="index.htm"><IMG SRC="../../rbjgifs/up.gif" ALT="UP" BORDER=0></A>
<A TARGET="_top" HREF="../index.htm"><IMG SRC="../../rbjgifs/home.gif" ALT="HOME" BORDER=0></A>
&copy;
<A HREF="../rbj.htm" TARGET="_top"><IMG SRC="../../rbjgifs/rbjin1.gif" ALT=RBJ ALIGN=ABSMIDDLE BORDER=0></A>
created 1995/10/7 modified 1998/08/25
</CENTER></BODY></HTML>++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://jasss.soc.surrey.ac.uk/8/4/7.html>====================
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html> <head> 
<meta http-equiv="Content-type" content="text/html; charset=iso-8859-1">
<meta name="DC.Title" content="Epistemological Perspectives on Simulation"> 
<meta name="DC.Creator" content="Ulrich Frank and Klaus G. Troitzsch"> 
<meta name="DC.Creator.Address" content="kgt@uni-koblenz.de"> 
<meta name="DC.Subject" content="
 Simulation, Epistemology, Methodology
"> 
<meta name="DC.Description" content="
 This special section includes papers originally presented at a workshop on \'Epistemological Perspectives on Simulation\' in July 2004 at the University of Koblenz, in which some thirty colleagues participated. It had been our impression that there was (and still is) a small, but growing number of researchers who are interested in investigating the preconditions of successfully deploying simulation as a research tool. We were convinced that discussing the epistemological status of simulation in a cross-disciplinary setting could contribute to a deeper understanding of relevant issues and so it proved.
"> 
 <meta name="DC.Publisher" content="JASSS"> 
 <meta name="DC.Date" content="2005-10-31"> 
<meta name="DC.Type" content="Text.Article"> 
<meta name="DC.Format" content="text/html"> 
<meta name="DC.Identifier" content="http://jasss.soc.surrey.ac.uk/8/4/7.html"> 
<meta name="DC.Language" content="en"> 
<meta name="DC.Rights" content="JASSS@soc.surrey.ac.uk">
<title>Ulrich Frank and Klaus G. Troitzsch: Epistemological Perspectives on Simulation
</title>
</head> 
<body bgcolor="#ffffff" vlink="#006633" link="#0000ff" alink="#99cc99">
<font size=1>&copy;<a href="../../admin/copyright.html">Copyright JASSS</a></font><p>
<a name="top"></a> 
<a href="../../JASSS.html"><img src="../gifs/JASSSMed.GIF" 
 width="189" height="76" border="0" alt="JASSS logo"></a>
<img src="../gifs/bar.gif" width="100%" height="3" alt="----"><p>
<b><font size="4"><a href="http://jasss.soc.surrey.ac.uk/8/4/7/frank.html">Ulrich Frank and Klaus G. Troitzsch</a> (2005)
</font></b>
<p align=CENTER><b><font size=5>
Epistemological Perspectives on Simulation<sup><a href="#fn*">*</a></sup>
</font></b>
<p align=CENTER><font size=4><i>Journal of Artificial Societies and Social Simulation</i>
  vol. 8, no. 4<br>
 &lt;http://jasss.soc.surrey.ac.uk/8/4/7.html&gt;</font>
<p align=CENTER><font size="2">
For information about citing this article, click <a href="http://jasss.soc.surrey.ac.uk/8/4/7/citation.html">here</a></font>
<p align=CENTER><font  size=2>Received: 02-Oct-2005
&nbsp;&nbsp;&nbsp;Published: 31-Oct-2005
</font>
<p align=left><a href="http://jasss.soc.surrey.ac.uk/8/4/7/7.pdf"><img src="../gifs/Acrobat.gif" 
alt="PDF version" title="PDF of this article"></a></p>
<hr>
<h3><img src="../gifs/bullet.gif" alt="* ">Abstract</h3>
<dl compact><dt><dd>
This special section includes papers originally presented at a workshop on 'Epistemological Perspectives on Simulation' in July 2004 at the University of Koblenz, in which some thirty colleagues participated. It had been our impression that there was (and still is) a small, but growing number of researchers who are interested in investigating the preconditions of successfully deploying simulation as a research tool. We were convinced that discussing the epistemological status of simulation in a cross-disciplinary setting could contribute to a deeper understanding of relevant issues and so it proved.
<p><dt><b>Keywords:</b><dd>
 Simulation, Epistemology, Methodology
</dl><hr noshade>
<h3><img align=Bottom src="../gifs/bullet.gif" width="23" height="23" alt="* "> Introduction
</h3><dl compact>
<dt><b><a name="1.1">1.1</a></b><dd>Simulation has been a research instrument for long in various disciplines. In recent years, it is gaining further attention. This may be contributed to the lack of theories that would allow for explaining and predicting the behaviour of complex systems. In addition to that, new modelling paradigms, associated with object-oriented concepts, intelligent agents, or models of (business) processes inspire the use of simulation. Also, the availability of computers with ever growing processing power makes it feasible to increase considerably the complexity of simulation models. Furthermore, it seems that simulation is regarded by some as an alternative to research methods that do not provide convincing support for certain research topics. At the same time, the epistemological status of simulation remains unclear. This is, for instance, the case for its relationship to core epistemological concepts, like truth and reason. Against this background, it seems worthwhile to reflect upon the preconditions of using simulation successfully as a research tool.

<p><dt><b><a name="1.2">1.2</a></b><dd>Two years ago, the simsoc mailing list experienced a longish discussion<sup><a href="#fn1">[1]</a></sup> among social scientists using simulation in their research. This discussion originated from Thomas Kron's question "about the relation of computer simulation and explanation, especially sociological explanation". More than fifty contributions to this discussion followed within less than three weeks, and contributors discussed the role of simulation in theory building (mostly, but not only) in the social, economic and management sciences - as well as the relation between observation on one hand and computer-assisted theory building (Hanneman 1988) on the other. Scott Moss came back to his presidential address at the 1st conference of the European Social Simulation Association, Groningen, September 2003, in which he said "that if social simulation with agents is to be anything other than another in the long line of failed approaches to social science, it will be a positive departure only because it facilitates the dominance of observation over theory" and continued that the great successful scientists (outside the social sciences) built their generalisations around observation, developing new theoretical structures based on and validated by new evidence (quoted from his contribution to the simsoc mailing list as of November 14, 2003). 

<p><dt><b><a name="1.3">1.3</a></b><dd>This discussion was one of the reasons for us to convene a workshop on "Epistemological Perspectives on Simulation" (EPOS) in July 2004, in which some thirty colleagues participated. It had been our impression that there was (and still is) a small, but growing number of researchers who are interested in investigating the preconditions of successfully deploying simulation as a research tool. While some of those have deployed simulation already in research projects, others are considering to use simulation. This is especially the case for those disciplines, where simulation plays a marginal role only, e.g. Business and Administration or Information Systems. While there is no established community so far especially in these disciplines, we were convinced that discussing the epistemological status of simulation in a cross-disciplinary setting could contribute to a deeper understanding of relevant issues. The issues which we wanted to be discussed were the following:

<ul><li>What kind of research questions can be addressed by simulation? 
<li>What are preconditions to be fulfilled for the proper use of simulation? 
<li>What are lessons learnt from deploying simulation? 
<li>How does a simulation model relate to reality? 
<li>What kind of real world decisions can be supported by simulation? 
<li>Are there any substantial advantages of particular paradigms, such as e. g. agent-based systems? 
<li>What are prerequisites for simulating business processes? 
<li>Is there a difference between approaches to simulation in different disciplines? 
<li>What makes the quality of a simulation model? 

</ul>
Scientists from eight countries responded to the call for papers. A selection of the papers presented at the workshop is published in this special issue of JASSS.
<p><dt><b><a name="1.4">1.4</a></b><dd>In an inspiring and partially provocative article,  <a href="http://jasss.soc.surrey.ac.uk/8/4/13.html">Scott Moss and Bruce Edmonds</a> argue that simulation provides the social sciences with a powerful instrument to generate empirical evidence &ndash; thereby contributing to better social sciences.<p>
<a href="http://jasss.soc.surrey.ac.uk/8/4/1.html">J&ouml;rg Becker, Bj&ouml;rn Niehaves and Karsten Klose</a> develop a framework for epistemological perspectives on simulation, which can be used to analyse and to systematise the implicit epistemological assumptions underlying most simulations. Their main concern is that these are often not made explicit and the framework they offer should help to explicate hidden assumptions. <p>
<a href="http://jasss.soc.surrey.ac.uk/8/4/5.html">Alex Schmid</a> tries to answer the question "What is the truth of simulation?"For this purpose, he considers well known theories of truth to analyse how they could contribute to a concept of truth or appropriateness applicable to simulations.<p>
<a href="http://jasss.soc.surrey.ac.uk/8/4/2.html"> Nuno David, Jaime Sichman and Helder Coelho</a> analyse the methodological status of computer-based simulation in the social sciences. For this purpose, they introduce the term 'intentional computing', which accounts for the specific epistemological characteristics of agent-based simulation.   <p>
<a href="http://jasss.soc.surrey.ac.uk/8/4/3.html">G&uuml;nter K&uuml;ppers and Johannes Lenhard</a> distinguish between the natural sciences and the social sciences mainly under the aspect that the former enjoy having well-accepted mathematical models while the latter have not. They argue that in the former case validation is no problem once it can be shown that a computer simulation model performs exactly the numerical calculations postulated by the mathematical model. As the social sciences have not yet developed generally accepted mathematical models, validation in this case means trying to find that "some of the characteristics of the social dynamics known from experience with the social world are reproduced by the simulation". <p>
<a href="http://jasss.soc.surrey.ac.uk/8/4/4.html">Matthias Meyer, Bernd O. Heine and Oliver Strangfeld</a> analyse the special validation problems which arise from the fact that in most cases the system modelled in a simulation is only a stylised fact instead of a part of the real world. Thus in a way they tackle the same aspect as G&uuml;nter K&uuml;ppers and Johannes Lenhard as what they call "characteristics of the social dynamics known from experience with the social world" are often enough nothing but stylised facts.<p>
<a href="http://jasss.soc.surrey.ac.uk/8/4/6.html">Riccardo Boero and Flaminio Squazzoni</a> suggest validating simulation through empirical research. They discuss and classify various validation strategies, and they argue for case-based models which lend themselves to falsification..  <p>
Finally, <a href="http://jasss.soc.surrey.ac.uk/8/4/14.html">Petra Ahrweiler and Nigel Gilbert</a> present a framework for evaluating the quality of simulations. For this purpose, they differentiate various views on a simulation. To illustrate their approach, they introduce the case study of a 'simulated' coffee shop.<p>
<p><dt><b><a name="1.5">1.5</a></b><dd>The co-editors hope that these papers revive the discussion of the epistemological status of simulation which will perhaps never be finalised, and they are happy to be able to announce that the 1st EPOS workshop will have a successor, organised by Flaminio Squazzoni at the University of Brescia on October 4-5, 2006.

<p></dl><hr><h3><img align=Bottom src="../gifs/bullet.gif" width=23 height=23 alt="* ">Notes</h3>
<dl compact><dd>
<a name="fn*"><sup>*</sup></a>This article has been translated into <a href="http://webhostinggeeks.com/science/Epistemological-Perspective-ua">Belorussian</a>.<p>
<a name="fn1"><sup>1</sup></a>The discussion can be found in the November 2003 section of <a href="http://www.jiscmail.ac.uk/archives/simsoc.html">http://www.jiscmail.ac.uk/archives/simsoc.html</a>, topics "simulation and explanation" and "theory and simulation".  <p>
</dl><img src="../gifs/bar.gif" width="100%" height="3" alt="----"><p>
<a href="contents.html"><img src="../gifs/JASSSBut.JPG" width="71" height="68" border="0" align="RIGHT" alt="Button">Return to Contents of this issue</a>
<p>
<font size=1>&copy;<a href="../../admin/copyright.html"> 
 Copyright Journal of Artificial Societies and Social Simulation, 
 [2005]</a></font>
</body>
</html>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?5.59>====================
<hr> Selmer Bringsjord (1994) What Robots can and Can't be. Psycoloquy: 5(59) Robot Consciousness (1)<br><br>
<b>Volume:</b> 5 (<a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?6.1>next</a>, <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?4.1>prev</a>) <b>Issue</b>: 59 (<a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?5.60>next</a>, <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?5.58>prev</a>) <b>Article:</b> 1 (<a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?robot-consciousness.2>next</a> <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?robot-consciousness.1>prev</a> <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?robot-consciousness.1>first</a>) <b>Alternate versions:</b> <a href="http://www.cogsci.ecs.soton.ac.uk/psycoloquy/raw//1994.volume.5/psyc.94.5.59.robot-consciousness.1.bringsjord">ASCII</a> <a href="http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/psummary?5.59">Summary</a>
<form method=get action=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/ptopic> <b>Topic:</b> <select name=topic>
<option value="Ai-cognitive-science"> Ai-cognitive science
<option value="Autonomous-brain"> Autonomous brain
<option value="Base-rate"> Base rate
<option value="Behavioral-knowledge"> Behavioral knowledge
<option value="Bell-curve"> Bell curve
<option value="Biological-psychiatry"> Biological psychiatry
<option value="Brain-expertise"> Brain expertise
<option value="Brain-intelligence"> Brain intelligence
<option value="Brain-rhythms"> Brain rhythms
<option value="Categorization"> Categorization
<option value="Cognition-action"> Cognition action
<option value="Cognitive-illusion"> Cognitive illusion
<option value="Cognitive-mapping"> Cognitive mapping
<option value="Coma-biochemistry"> Coma biochemistry
<option value="Connectionist-explanation"> Connectionist explanation
<option value="Consciousness"> Consciousness
<option value="Consciousness-report"> Consciousness report
<option value="Consensus-journals"> Consensus journals
<option value="Data-archive"> Data archive
<option value="Eeg-chaos"> Eeg chaos
<option value="Efference-knowledge"> Efference knowledge
<option value="Electronic-journals"> Electronic journals
<option value="Evolution-bipolar-disorder"> Evolution-bipolar disorder
<option value="Evolution-thinking"> Evolution thinking
<option value="Family-therapy"> Family therapy
<option value="Fodor-representation"> Fodor representation
<option value="Frame-problem"> Frame problem
<option value="Frontal-cortex"> Frontal cortex
<option value="Group-selection"> Group selection
<option value="Human-animal-bond"> Human-animal bond
<option value="Human-choice"> Human choice
<option value="Hyperstructure"> Hyperstructure
<option value="Intelligence-g-factor"> Intelligence-g factor
<option value="Language-complexity"> Language complexity
<option value="Language-comprehension"> Language comprehension
<option value="Language-gesture"> Language gesture
<option value="Language-network"> Language network
<option value="Language-origins"> Language origins
<option value="Language-prerequisites"> Language prerequisites
<option value="Language-retardation"> Language retardation
<option value="Language-sex-chromosomes"> Language-sex chromosomes
<option value="Lashley-hebb"> Lashley hebb
<option value="Least-squares"> Least squares
<option value="Lithium-toxicity"> Lithium toxicity
<option value="Locating-consciousness"> Locating consciousness
<option value="Mating-mind"> Mating mind
<option value="Meaning-belief"> Meaning belief
<option value="Memory-brain"> Memory brain
<option value="Mental-disorder"> Mental disorder
<option value="Metapsychology"> Metapsychology
<option value="Mirror-reversal"> Mirror reversal
<option value="Mood"> Mood
<option value="Movement-primacy"> Movement primacy
<option value="Nicotine-addiction"> Nicotine addiction
<option value="Optimal-cognition"> Optimal cognition
<option value="Origin-culture"> Origin culture
<option value="Paradoxical-cognition"> Paradoxical cognition
<option value="Part-whole-perception"> Part-whole perception
<option value="Pattern-recognition"> Pattern recognition
<option value="Pavlov-bell"> Pavlov bell
<option value="Posture-locomotion"> Posture locomotion
<option value="Purposeful-processes"> Purposeful processes
<option value="Reading"> Reading
<option value="Reading-inference"> Reading inference
<option value="Reading-inference-1"> Reading-inference 1
<option value="Reduced-wason-task"> Reduced-wason task
<option value="Representation-mediation"> Representation mediation
<option selected value="Robot-consciousness"> Robot consciousness
<option value="Scientific-cognition"> Scientific cognition
<option value="Self-consciousness"> Self consciousness
<option value="Sex-brain"> Sex brain
<option value="Sex-odor"> Sex odor
<option value="Social-bias"> Social bias
<option value="Space"> Space
<option value="Split-brain"> Split brain
<option value="Stroop-differences"> Stroop differences
<option value="Subtlety-emotion"> Subtlety emotion
<option value="Symbolism-connectionism"> Symbolism connectionism
<option value="Turing-test"> Turing test
<option value="Witness-memory"> Witness memory
</select><input type=submit name=submit value="View Topic"></form><form method=get action=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy><b>Article:</b><select name=article>
<option Selected Value="5.59">1) Bringsjord 5(59)	What Robots can and Can't be
<option Value="5.82">2) Tirassa 5(82)	Is Consciousness Necessary to
<option Value="5.83">3) Brown 5(83)	Agnosticism About the Arbitrary
<option Value="5.84">4) Scholl 5(84)	Intuitions, Agnosticism, and Conscious
<option Value="6.10">5) Bringsjord 6(10)	Computationalism is Doomed, and we
<option Value="6.11">6) Rickert 6(11)	A Computer is not an Automaton
<option Value="6.12">7) Barresi 6(12)	Building Persons: Some Rules for the
<option Value="6.13">8) Dacosta 6(13)	Is There More to Personhood
<option Value="6.14">9) Hobbs 6(14)	Creating Computer Persons: More Likely
<option Value="6.15">10) Korb 6(15)	Persons and Things: Book Review of
<option Value="6.16">11) Massing 6(16)	Metaphysical Windmills in Robotland
<option Value="6.19">12) Bringsjord 6(19)	Why Didn't Evolution Produce Turing
<option Value="6.20">13) Bringsjord 6(20)	Agnosticism About Neuron-level
<option Value="6.21">14) Brown 6(21)	Agnosticism Revisited Reply to
<option Value="6.28">15) Mulhauser 6(28)	What Philosophical Rigour can and
<option Value="6.30">16) Bringsjord 6(30)	Agnosticism Re-revisited
<option Value="6.39">17) Bringsjord 6(39)	Are Computers Automata? Reply to
<option Value="7.30">18) Bringsjord 7(30)	Artificial Intelligence and the
</select> <input type=submit name=submit value="View Article"></form>
PSYCOLOQUY (ISSN 1055-0143)  is sponsored by the American Psychological Association (APA).<hr>
<TITLE>Psycoloquy 5(59): What Robots can and Can't be</TITLE>
<H1>WHAT ROBOTS CAN AND CAN'T BE                     <br>
[Kluwer Academic Publishers, 1992, 10 chapters, 380 pages]<br>
Precis of Bringsjord on Robot-Consciousness<br>
</H1>
<ADDRESS>Selmer Bringsjord<br>
Dept. of Philosophy, Psychology & Cognitive Science <br>
Department of Computer Science<br>
Rensselaer Polytechnic Institute<br>
Troy, NY 12180<br>
<br>
<a href=mailto:selmer@rpi.edu>selmer@rpi.edu</a> 
</ADDRESS>
<P><H1>Abstract</H1><BLOCKQUOTE>
This book argues that (1) AI will continue to produce
machines with the capacity to pass stronger and stronger versions
of the Turing Test but that (2) the "Person Building Project" (the
attempt by AI and Cognitive Science to build a machine which is a
person) will inevitably fail. The defense of (2) rests in large
part on a refutation of the proposition that persons are automata
-- a refutation involving an array of issues, from free will to
Godel to introspection to Searle and beyond. The defense of (1)
brings the reader face to face with Sherlock Holmes and Dr. Watson
as they tackle perhaps their toughest case (Silver Blaze); the
upshot of this visit with Conan Doyle's duo is an algorithm-sketch
for solving murder mysteries. The author's mechanical approach to
writing fiction and the philosophical side of computerized story
generation are also discussed.
</BLOCKQUOTE>
<P><H1>Keywords</H1><i>
behaviorism, Chinese Room Argument, cognition,
consciousness, finite automata, free will, functionalism,
introspection, mind, story generation, Turing machines, Turing
Test.
</i>
<HR>
<H2>I. CHAPTER 1: INTRODUCTION</H2>
<P>
I.1 THE GENERAL POSITION
<P>
1. My book (Bringsjord 1992a) argues that Artificial Intelligence will
eventually produce robots (or androids) whose behavior is dazzling, but
it will not produce robotic persons. Robots will DO a lot, but they
won't BE a lot. The reader is asked to evaluate this claim on the
basis of my defense of this position (and other arguments in the
literature), rather than on the basis of slippery metadisputes about
whether or not my position and arguments for it are prima facie
plausible.
<P>
2. My position accords well with the decline of behaviorism, and
specifically the apparent decline of the behavioristic Turing Test (see
Rey, 1986) and any number of the Turing-like Tests proposed in the
literature [NOTE #1]. Readers familiar only with Turing's original test
(Turing, 1964), and not with the variations that have been derived from
it, should imagine now an ever more stringent sequence of Turing-like
tests T1, T2, T3,..., the first member of which is the original
imitation game. How does the sequence arise? In T2 we might allow the
judge to observe the physical appearance of the contestants; in T3 we
might allow the judge to make requests concerning the sensorimotor
behavior of the contestants; in T4 we might allow the judge to take
skin samples; in T5 we might allow the judge to run brain scans, then
surgical probing, and so on. The point is that we can pretty much rest
assured that AI will gradually climb up the sequence; that soon we'll
have T.75, eventually T1 (though probably not by 2000 as Turing had
predicted), etc. I hold that robots will pass, if not all, then at
least a goodly number of tests in the Turing Test sequence, but they
will always lack some of the properties claimed, in "What Robots Can
and Can't Be" (henceforth, ROBOTS), to be necessary for personhood. I
defend this position with precise deductive arguments which (in my
opinion) sometimes border on proofs.
<P>
I.2 THE TARGET
<P>
3. What group of people, what field or discipline, aims at bringing us
these powerful robots? Candidate terms abound: "Strong" AI (Searle,
1980), GOFAI, or Good Old Fashioned Artificial Intelligence (Haugeland,
1986), "Old Hand" AI (Doyle, 1988), "Person Building" AI (Charniak &amp;
McDermott, 1985; Pollock, 1989), etc. All these AI researchers envision
the building of an "intelligent robot," one who excels in the Turing
Test sequence, able not only to checkmate you, but to debate you. If
such a vision will sooner or later come to pass, as I'm quite sure it
will, then, again, a question worth asking now is: will robots, in the
coming age in which they excel in the Turing Test sequence, be
persons?
<P>
4. Let us call the AI/Cog-Sci project to build a person the "Person
Building Project." PBP will denote the proposition that the Person
Building Project will succeed. This project has flesh-and-blood
proponents, optimistic ones. For example, according to Charniak and
McDermott (1985, p. 7), "The ultimate goal of AI research (which we are
very far from achieving) is to build a person, or more humbly, an
animal." Some of the arguments in ROBOTS, if sound, could, with minor
modification, refute Charniak and McDermott's thesis that AI can
succeed in building a sophisticated animal. But what I wish to attack
directly is the heart of the Person Building Project: the proposition
that persons are automata.
<P>
5. Here, in a nutshell, is why I think the Person Building Project
will fail. (The symbol -&gt; stands for material implication; ~ stands for
truth-functional negation):
<P>
<PRE>    (1)  PBP -&gt; Persons are automata.  </PRE>
<P>
<PRE>    (2)  ~ Persons are automata.</PRE>
<P>
Therefore:
<P>
<PRE>    (3)  ~ PBP.</PRE>
<P>
6. This is a formally valid argument: simple modus tollens. Premise
(2) is repeatedly established in ROBOTS through instantiations of a
simple schema, viz,
<P>
<PRE>    (4)  Persons have F.</PRE>
<P>
<PRE>    (5)  Automata can't have F.</PRE>
<P>
Therefore:
<P>
<PRE>    (6)  Persons can't be automata.</PRE>
<P>
In the book, F stands for such things as free will, the ability to
infallibly introspect (over a narrow range of properties), an inner
"what it's like to be" experience, etc.
<P>
7. Why is (1) true? Those engaged in the Person Building Project are
committed to certain well-defined algorithmic techniques which, though
hard to enumerate precisely, are used when you construct and program a
high-speed computer with sensors and effectors. If someone managed to
build a person by stirring up some fertile biological soup in the right
way, or by somehow compressing all of evolution into a second of
development that could be magically applied to a single-cell creature,
this would not spell success for the person builders I have in mind. To
affirm PBP is to hold that certain computer techniques will produce
people. Nor is the idea that by using these techniques you'll get lucky
and bring a person into existence through a side-effect of what you've
done. There are those whose ultimate aim is this side-effect --
thinkers who hope to build a computational device whose structure is
appropriate for "ensoulment," a device alongside which a person, an
immaterial entity, will pop into existence and connect up with the
device in some way (e.g., see Turkle, 1984). These thinkers aren't my
concern herein. I'm concerned with those who think AI techniques are
near the essence of personhood, or mindedness (or mentality, mentation,
cognition) itself.
<P>
8. For such cognitive engineers, the success of their techniques won't
show that people are, essentially and in general, the particular
computers they are working on. If a team of cognitive engineers
succeeded beyond their wildest dreams and happened to do so by
programming a Cray 4, they would not be entitled to hold that persons
are Cray 4s. There is no reason to think that the specific physical
material (the particular computer and peripheral components)
constituting the robots produced by the Person Building Project will be
essential. Human persons happen to be made of flesh, not silicon; AI
(unlike, say, neurophysiology) does not work with flesh. So behind PBP
is "AI-Functionalism," according to which people are idealized
computers. This intuition is, as Haugeland (1986) has suggested,
captured elegantly by "Persons are automata," or at least by something
very close to it.
<P>
<H2>II. CHAPTER 2: OUR MACHINERY</H2>
<P>
9. Chapter 2 contains the rough-and-ready ontology presupposed
throughout the book, and an account of the logico-mathematical language
used. It also characterizes personhood on the basis of some crucial
prephilosophical data and gives definitions of finite automata, Turing
machines, and cellular automata. Using these definitions, I clarify
"Persons are automata," and distinguish between the different versions
of this proposition that arise when one specifies the automaton in
question. I also say a little about Church's Thesis and, via the "Busy
Beaver" function and the Halting Problem, about uncomputability (see
also Bringsjord 1993a,b; Bringsjord &amp; Zenzen, forthcoming).
<P>
<H2>III. CHAPTER 3: ARGUMENTS PRO, DESTROYED</H2>
<P>
10. Chapter 3 presents refutations of five arguments for the view that
persons are automata: the Argument from Analogy (Nelson, 1982), the
Argument from What Should Remain Unexplained (Dennett, 1976), the
Argument from Natural Functions (Burks, 1973), the How to Build a
Person Argument (Pollock, 1989), and the Pretty Much What Everyone
Believes Argument (Cole, personal communication).
<P>
11. Cole summarizes his argument as follows:
<P>
<PRE>    I suppose that many like myself who believe that persons are
    automata suppose this because we see that neurons appear to be
    finite probabilistic automata, that is to say they have computable
    transfer functions.  From there we note that brains are composed
    merely of neurons (neural nets), along with some supporting
    structures, glial cells, etc., and that brains produce mentality.
    (ROBOTS, P. 126)</PRE>
<P>
12. I show that this argument, tempting though it is, is ultimately
untenable. If one assumes agent materialism and jumps beyond what we
know to be the case (that brains, with supporting structures, produce
mentality), to what many suspect is the case (that brains, with
supporting structures, are persons), then Cole's argument does work --
but such a strategy would need independent defense (Pollock 1989).
<P>
13. Overall, Cole seems to vote "yes" on all six components of the
Contemporary Cognitive Sextet:
<P>
<PRE>    (C1) Token Physicalism,
    (C2) Agent Materialism,
    (C3) Functionalism,
    (C4) Persons are Automata,
    (C5) Person Building will succeed,
    (C6) Robot Building will succeed.</PRE>
<P>
My own vote on each, supported by the arguments in the book, would be:
<P>
<PRE>    (C1) Maybe
    (C2) Maybe
    (C3) No
    (C4) No
    (C5) No
    (C6) Yes</PRE>
<P>
<H2>IV. CHAPTER 4: WHAT ROBOTS CAN BE</H2>
<P>
14. The 4th chapter provides some evidence that robots will ascend
the Turing Test sequence. Two questions are addressed: (1) Are
mysteries of the sort solved by Sherlock Holmes solvable by an expert
system of the future? (2) Is it possible to get a computer to write
sophisticated fiction? I argue that both these questions should be
answered in the affirmative; my argument provides reason for optimism
concerning the powers of future robots. Why address mystery-solving?
It's one of the few concrete human abilities that a philosopher
(Manning, 1987) has argued cannot be matched by a machine. And
computer-generated fiction is my own area of research in Cognitive
Engineering (Bringsjord 1992b). The rest of ROBOTS consists of a series
of deductive arguments against the Person Building Project.
<P>
<H2>V. CHAPTER 5: SEARLE</H2>
<P>
15. My Searlean (Chinese Room) attack on person-building is based on
Jonah, an imaginary mono savant. Jonah is blessed with the following
powers. He can -- automatically, swiftly, without conscious
deliberation -- reduce high-level computer programs (in, say, PROLOG
and LISP) to the super-austere language that drives a Register machine
(or Turing machine). Once he has carried out this reduction, he can use
his incredible powers of mental imagery to visualize a Register
machine, and to visualize this machine running the program that results
from his reduction. So if you give Jonah a LISP program, he translates
it into a Register program, without giving any thought whatever to the
MEANING of the LISP program. Jonah, in some attenuated sense, knows
the syntax of LISP, but he doesn't have any semantics for the language.
He doesn't know, for example, that (DEFUN ...) is a string that defines
a function; he doesn't even know that (+ ...) is a built-in function
for addition. He DOES know, however, how to "run" his visualized
Register machine given a Register program and data put into the first
register R0. Jonah is also capable of taking input through his senses
and translating it into input to his visualized machine [NOTE #2].
<P>
16. It should be obvious how Jonah gives rise to a Chinese Room-like
situation. Suppose it's 2040, and that person-builders have produced
robots which they herald as persons. Since one of the hallmarks of
persons is that they can converse in and understand natural languages,
the person-builders will claim that their robots can do the same. If
these robots converse in and understand some natural language L, it
should be a trivial matter to get them to speak and understand
Chinese. So, here we are in 2040: some no doubt super-long computer
program P enables robots to speak and understand Chinese. And here is
how Jonah enters the picture. We simply give him P, ask him to reduce P
to a Register program P', and then ask him to run P' on his visualized
Register machines in such a way that input we give him on index cards
(strings in Chinese) goes into register R0; and the output, after
processing, comes back into R0, whereupon Jonah spits back this output,
writing it down for us on an index card. Jonah does not himself speak a
word of Chinese.
<P>
17. The argument then runs as follows. It appears that Person-Building
AI/Cog Sci is committed to
<P>
<PRE>    (7) If the Person Building Project will succeed, then there is a
	computer program P such that when P runs on a computer M there
	is a person s associated with M who understands Chinese.</PRE>
<P>
And
<P>
<PRE>    (8) If there is a computer program P such that when P runs on a
	computer M there is a person s associated with M who
	understands Chinese, then if Jonah reduces P to P' and runs P'
	Jonah understands Chinese.</PRE>
<P>
But
<P>
<PRE>    (9) It's not the case that if Jonah runs P' Jonah understands
        Chinese.</PRE>
<P>
18. Hence, by hypothetical syllogism and modus tollens it follows from
these three propositions that the Person Building Project won't
succeed. Proposition (9) is not to be viewed as a premise, but rather
as an intermediate conclusion following (by elementary logic) from the
following three propositions.
<P>
<PRE>    (L*) If an agent s understands two natural languages L0 and L1, then
         s can (perhaps only after considerable effort that produces a
	 long-winded translation) translate between L0 and L1.</PRE>
<P>
<PRE>    (10) Jonah (by hypothesis) understands English.</PRE>
<P>
<PRE>    (11) Jonah CAN'T translate between English and Chinese.</PRE>
<P>
19. Three objections to Searlean arguments appear to be the most up-to-
date and promising, one from Churchland &amp; Churchland (1990; cf. Searle
1990), and two rather more subtle ones, one from Cole, and one
from Rapaport (personal communication). I rebut all three.
<P>
<H2>VI. CHAPTER 6: ARBITRARY REALIZATION</H2>
<P>
20. We start with what should be an uncontroversial conditional,
namely,
<P>
<PRE>        If the Person Building Project will succeed, then AI-
        Functionalism is true.</PRE>
<P>
Now, assume that person-builders will manage to build robotic persons.
By modus ponens, then, we of course have AI-Functionalism, the "flow
chart" version (Dennett, 1978) of which is
<P>
<PRE>    (AI-F) For every two "brains" x and y, possibly constituted by
	   radically different physical stuff, if the overall flow of
	   information in x and y, represented as a pair of flow charts
	   (or a pair of Turing machines, or a pair of Turing machine
	   diagrams,...), is the same, then if "associated" with x
	   there is an agent s in mental state S, there is an agent s'
	   associated with or constituted by y which is also in S.</PRE>
<P>
21. Now let 'B' denote the brain of some person s
and let s be in the mental state FEARING PURPLE UNICORNS. Now
imagine that a Turing machine M, representing exactly the same flow
chart as that which governs B, is built out of 4 billion Norwegians all
working on railroad tracks in boxcars with chalk and erasers (etc.)
across the state of Texas. From this hypothesis and (AI-F), it follows
that there is some agent m constituted by M which also fears purple
unicorns. But it seems intuitively obvious that
<P>
<PRE>        There is no agent m constituted by M that fears purple
        unicorns.</PRE>
<P>
We've reached a contradiction. Hence our original assumption, that the
Person Building Project will succeed, is wrong. I consider and rebut
the best objections I know of to this reasoning.
<P>
<H2>VII. CHAPTER 7: GODEL</H2>
<P>
22. The 7th chapter is an argument that Godelian incompleteness at
least threatens the thesis that persons are automata. Godelian attacks
on such theses are not new, but they are currently thought by most
philosophers and AI researchers to be unsound, perhaps even rather
silly. I try to resurrect the Godelian case. Without claiming it is
demonstrative, I do try to show that, contrary to current opinion, it
should be taken seriously. Lack of space precludes encapsulating the
relevant arguments here.
<P>
23. The book ends with two arguments without precedent in the
literature, one concerning free will and the other concerning
introspection.
<P>
<H2>VIII. CHAPTER 8: FREE WILL</H2>
<P>
24. Chapter 8 is a rigorous reconstruction of the extremely vague
argument that people can't be machines because people enjoy autonomy,
while the behavior of machines is causally predetermined by their
programs operating in conjunction with laws of nature. The
reconstruction hinges on the proposition, defended in the chapter, that
people enjoy what I call 'iterative agent causation,' the view
that people can directly bring about certain of their own
mental events (e.g., decisions), AND bring about the bringing about of
these events, ad infinitum. The reasoning is as follows:
<P>
<PRE>    (12) If determinism, the view that all events are causally
	 necessitated, is true, then no one ever has power over any
	 state of affairs.</PRE>
<P>
<PRE>    (13) If indeterminism, the view that determinism is false, is true,
	 then, unless people enjoy iterative agent causation, no one
	 ever has power over any state of affairs.</PRE>
<P>
<PRE>    (14) Either determinism or indeterminism is true (a tautology).</PRE>
<P>
Therefore:
<P>
<PRE>    (15) Unless iterative agent causation is true, no one ever has power
	 over any state of affairs. [from (12)-(14)]</PRE>
<P>
<PRE>    (16) If no one ever has power over any state of affairs, then no one
	 is ever morally responsible for anything that happens.</PRE>
<P>
<PRE>    (17) Someone is morally responsible for something that happens.</PRE>
<P>
Therefore:
<P>
<PRE>    (18) It's not the case that no one ever has power over any state of
         affairs. [from (16), (17)]</PRE>
<P>
Therefore:
<P>
<PRE>   (19) Iterative agent causation is true. [from (18), (15)]</PRE>
<P>
<PRE>   (20) If iterative agent causation is true, then people aren't
        automata.</PRE>
<P>
Therefore:
<P>
<PRE>   (21) People aren't automata. [from (8), (9)]</PRE>
<P>
The chapter includes a defense of all the premises in this argument.
<P>
<H2>IX. CHAPTER 9: INTROSPECTION</H2>
<P>
25. Chapter 9 revolves around what I call 'hyper-weak incorrigibilism,'
the view that humans have, WITH RESPECT TO A RESTRICTED CLASS OF MENTAL
PROPERTIES, the ability to ascertain infallibly, via introspection,
whether they have these properties. Here is how the first version of
the argument, which is aimed at a symbolicist version of the Person
Building Project, runs. Suppose that this project will succeed; then it
would seem that three things are true of the robots that will be the
crowning achievement of this project:
<P>
<PRE>    (22) If there is some significant mental property that persons have,
	 these robots must also have this property;</PRE>
<P>
<PRE>    (23) The objects of these robots' "beliefs" (hopes, fears, etc.)
	 -- the objects of their propositional attitudes  -- are
	 represented by formulas of some symbol system, and these
	 formulas will be present in these robots' knowledge bases;</PRE>
<P>
<PRE>    (24) These robots will be physical instantiations of automata
	 (the physical substrate of which will be something like
	 current silicon hardware, but may be something as extravagant
	 as optically based parallel hardware).</PRE>
<P>
26. It follows from the doctrine of hyper-weak incorrigibilism and (22)
that the powerful robot (call it 'r') eventually to be produced by
Strong AI/Cog Sci will be able to introspect infallibly with respect to
a certain privileged set of mental properties C'. That is, it follows
that the relevant instantiation of hyper-weak incorrigibilism is the
case, viz,
<P>
<PRE>    (25) For every property F, if it's a member of C', then it is
	 necessarily true that: if r believes r has F, r does indeed
	 have F.</PRE>
<P>
But now in light of (23) it follows that (25) implies that
<P>
<PRE>    (26) For every property F, if it is a member of C', then,
	 necessarily: if the formula corresponding to r's belief
	 that r has F is an element of r's knowledge base, then
	 r does indeed have F.</PRE>
<P>
27. Let's suppose, then, that we have in the picture, along with our
robot r, a certain particular property from C', say the property
SEEMING TO BE IN PAIN, a property we'll designate 'F*'. It follows that
<P>
<PRE>    (27) It is logically necessary that: if the formula corresponding to
	 r's belief that r has F* is in r's knowledge base, then r does
	 indeed have F*.</PRE>
<P>
28. Now, having arrived at this point, let's turn to a simple and well-
known fact about hardware (ANY hardware), namely, that it is physically
possible (that is, not contrary to the laws of physics) that hardware
fails. Accordingly, it is physically possible that the substrate of r
fails, and since, in turn, it is physically possible that this failure is
the cause of the fact that the formula in question (the formula
corresponding to r's belief that r has F*) is in r's knowledge base:
<P>
<PRE>    (28) It is logically possible that the formula in question is in r's
	 knowledge base while r does NOT have F*.</PRE>
<P>
29. But (27) and (28), by an elementary law of modal logic (in a word:
if it's logically necessary that if P then Q, then it's not logically
possible that P while not-Q) form a contradiction. Hence, by indirect
proof, our original assumption, that symbolicist Person Building will
succeed, is wrong. I go on to consider and refute a number of
objections to this line of reasoning, including one that is likely to
come from connectionists.
<P>
<H2>X. CHAPTER 10: CONCLUSION</H2>
<P>
30. The final chapter offers a retrospective view of the colorful
thought-experimental characters visited along the journey and makes
some brief concluding remarks about the overall case for the view that
robots will largely do what we do, but won't be one of us.
<P>
<H2>XI. ERRATA</H2>
<P>
31. I have assembled a list of typos and so on (e.g., p. 19's list is in
error: the first two conditionals are supposed to be prefixed by
necessity operators, and the S5 derivability claim in line 9 should
have its schematic conditional necessitated; Harnad (1991) was
inadvertently omitted from the bibliography, etc.), but I should inform
my critics that none of these glitches seems to spell genuine trouble
for the arguments at the heart of the book. If any of my arguments
fail, I'm afraid it will be due to deeper defects.
<P>
<H2>NOTES</H2>
<P>
#1. For a lucid discussion of the Turing Test, the Total Turing Test, and
the Total Total Turing Test, see (Harnad, 1991). For an argument that
even more stringent tests, mathematically speaking, than those
considered by Harnad cannot separate the "thinkers" from the
"pretenders," see Bringsjord (1994).
<P>
#2 For a fascinating account of a real-life idiot savant reminiscent of
Jonah, see the case of Christopher, in Blakelee (1991).
<P>
<H2>REFERENCES</H2>
<P>
Blakelee, S. (1991) "Brain Yields New Clues on Its Organization for
Language," Science Times of The New York Times, September 10, pp.
C1, C10.
<P>
Bringsjord, S. (1994) Could, How Could We Tell If, and Why Should --
Androids Have Inner Lives. Chapter forthcoming in Android Epistemology,
JAI Press, Greenwich, CT. Ken Ford &amp; Clark Glymour, eds.
<P>
Bringsjord, S. (1993a) Church's Thesis, Contra Mendelson, is Unprovable
... And Worse: It May Be False. Presented at the annual Eastern
Division meeting of the American Philosophical Association, December
30, 1993, Atlanta, Georgia.
<P>
Bringsjord, S. (1993b) Toward Non-Algorithmic AI. In Ryan, K.T. &amp; 
Sutcliffe, R.F.E., eds. AI and Cog Sci T92, in the Workshop in 
Computing Series, (New York, NY: Springer-Verlag), pp. 277-288.
<P>
Bringsjord, S. (1992a) What Robots Can and Can't Be. Boston: Kluwer.
<P>
Bringsjord, S. (1992b) CINEWRITE: an Algorithm-Sketch for Writing
Novels Cinematically, and Two Mysteries Therein. Instructional Science
21: 155-168.
<P>
Bringsjord, S. &amp; Zenzen, M. (forthcoming) In Defense of Non-
Algorithmic Cognition (The Netherlands: Kluwer).
<P>
Burks, A. (1973) Logic, Computers, and Men. Presidential Address,
Western Division of the American Philosophical Association, in
Proceedings of the American Philosophical Association April: 39-57.
<P>
Charniak, E. &amp; McDermott, D. (1985) Introduction to Artificial
Intelligence (Reading, MA: Addison-Wesley).
<P>
Churchland, P.M. &amp; Churchland, P.S. (1990) Could a Machine Think?
Scientific American 262.1: 32-37.
<P>
Dennett, D. (1978) Brainstorms (Cambridge, MA: Bradford Books, MIT
Press).
<P>
Dennett, D. (1976) Why The Law of Effect Will Not Go Away. Journal of
the Theory of Social Behavior 5: 169-187.
<P>
Doyle, J. (1988) Big Problems for Artificial Intelligence. AI Magazine,
Spring: 19-22.
<P>
Harnad, S. (1991) Other Bodies, Other Minds: A Machine Incarnation of
an Old Philosophical Problem. Minds &amp; Machines 1.1: 43-55.
<P>
Haugeland, J. (1986) Artificial Intelligence: the Very Idea (Cambridge,
MA: Bradford Books, MIT Press).
<P>
Manning, R. (1987) Why Sherlock Holmes Can't Be Replaced By An Expert
System. Philosophical Studies 51: 19-28.
<P>
Nelson, R.J. (1982) The Logic of Mind (Dordrecht, The Netherlands: D.
Reidel).
<P>
Pollock, J. (1989) How to Build a Person: A Prolegomenon (Cambridge, 
MA: Bradford Books, MIT Press).
<P>
Rey, G. (1986) What's Really Going on in Searle's 'Chinese Room'.
Philosophical Studies 50: 169-185.
<P>
Searle, J. (1990) Is the Brain's Mind a Computer Program? Scientific
American 262.1: 25-31.
<P>
Searle, J. (1980) Minds, Brains, and Programs. Behavioral &amp; Brain
Sciences 3: 417-424.
<P>
Turkle, S. (1984) The Second Self (New York, NY: Simon &amp; Shuster).
<P>
Turing, A. M. (1964) Computing machinery and intelligence.
In: Minds and machines. A. Anderson (ed.), Engelwood Cliffs NJ:
Prentice Hall.
<P>
--------------------------------------------------------------------
<P>
<PRE>        PSYCOLOQUY Book Review Instructions</PRE>
<P>
The PSYCOLOQUY book review procedure is very similar to the commentary
procedure except that it is the book itself, not a target article, that
is under review. (The Precis summarizing the book is intended to permit
PSYCOLOQUY readers who have not read the book to assess the exchange,
but the reviews should address the book, not primarily the Precis.)
<P>
Note that as multiple reviews will be co-appearing, you need only
comment on the aspects of the book relevant to your own specialty and
interests, not necessarily the book in its entirety. Any substantive
comments and criticism -- including points calling for a detailed and
substantive response from the author -- are appropriate. Hence,
investigators who have already reviewed or intend to review this book
elsewhere are still encouraged to submit a PSYCOLOQUY review specifically
written with this specialized multilateral review-and-response feature
in mind.
<P>
1.  Before preparing your review, please read carefully
<PRE>    the Instructions for Authors and Commentators and examine
    recent numbers of PSYCOLOQUY.</PRE>
<P>
2.  Reviews should not exceed 500 lines. Where judged necessary
<PRE>    by the Editor, reviews will be formally refereed.</PRE>
<P>
3.  Please provide a title for your review. As many
<PRE>    commentators will address the same general topic, your
    title should be a distinctive one that reflects the gist
    of your specific contribution and is suitable for the
    kind of keyword indexing used in modern bibliographic
    retrieval systems. Each review should also have a brief
    (~50-60 word) Abstract</PRE>
<P>
4.  All paragraphs should be numbered consecutively. Line length
<PRE>    should not exceed 72 characters.  The review should begin with
    the title, your name and full institutional address (including zip
    code) and email address.  References must be prepared in accordance
    with the examples given in the Instructions.  Please read the
    sections of the Instruction for Authors concerning style,</PRE>
<P>
<PRE>    INSTRUCTIONS FOR PSYCOLOQUY AUTHORS AND COMMENTATORS</PRE>
<P>
PSYCOLOQUY is a refereed electronic journal (ISSN 1055-0143) sponsored
on an experimental basis by the American Psychological Association
and currently estimated to reach a readership of 40,000. PSYCOLOQUY
publishes brief reports of new ideas and findings on which the author
wishes to solicit rapid peer feedback, international and
interdisciplinary ("Scholarly Skywriting"), in all areas of psychology
and its related fields (biobehavioral science, cognitive science,
neuroscience, social science, etc.). All contributions are refereed.
<P>
Target article length should normally not exceed 500 lines [c. 4500 words].
Commentaries and responses should not exceed 200 lines [c. 1800 words].
<P>
All target articles, commentaries and responses must have (1) a short
abstract (up to 100 words for target articles, shorter for commentaries
and responses), (2) an indexable title, (3) the authors' full name(s)
and institutional address(es).
<P>
In addition, for target articles only: (4) 6-8 indexable keywords,
(5) a separate statement of the authors' rationale for soliciting
commentary (e.g., why would commentary be useful and of interest to the
field? what kind of commentary do you expect to elicit?) and
(6) a list of potential commentators (with their email addresses).
<P>
All paragraphs should be numbered in articles, commentaries and
responses (see format of already published articles in the PSYCOLOQUY
archive; line length should be &lt; 80 characters, no hyphenation).
<P>
It is strongly recommended that all figures be designed so as to be
screen-readable ascii. If this is not possible, the provisional
solution is the less desirable hybrid one of submitting them as
postscript files (or in some other universally available format) to be
printed out locally by readers to supplement the screen-readable text
of the article.
<P>
PSYCOLOQUY also publishes multiple reviews of books in any of the above
fields; these should normally be the same length as commentaries, but
longer reviews will be considered as well. Book authors should submit a
500-line self-contained Precis of their book, in the format of a target
article; if accepted, this will be published in PSYCOLOQUY together
with a formal Call for Reviews (of the book, not the Precis). The
author's publisher must agree in advance to furnish review copies to the
reviewers selected.
<P>
Authors of accepted manuscripts assign to PSYCOLOQUY the right to
publish and distribute their text electronically and to archive and
make it permanently retrievable electronically, but they retain the
copyright, and after it has appeared in PSYCOLOQUY authors may
republish their text in any way they wish -- electronic or print -- as
long as they clearly acknowledge PSYCOLOQUY as its original locus of
publication. However, except in very special cases, agreed upon in
advance, contributions that have already been published or are being
considered for publication elsewhere are not eligible to be considered
for publication in PSYCOLOQUY,
<P>
Please submit all material to psyc@pucc.bitnet or psyc@pucc.princeton.edu
Anonymous ftp archive is HOST princeton.edu DIRECTORY pub/harnad/Psycoloquy
URLs are:
<a href=ftp://ftp.princeton.edu/pub/harnad/Psycoloquy/1994.volume.5/>ftp://ftp.princeton.edu/pub/harnad/Psycoloquy/1994.volume.5/</a>
<a href=http://www.princeton.edu/~harnad/psyc.html>http://www.princeton.edu/~harnad/psyc.html</a>
gopher://gopher.princeton.edu:9000/1
<P>
<hr>
<b>Volume:</b> 5 (<a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?6.1>next</a>, <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?4.1>prev</a>) <b>Issue</b>: 59 (<a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?5.60>next</a>, <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?5.58>prev</a>) <b>Article:</b> 1 (<a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?robot-consciousness.2>next</a> <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?robot-consciousness.1>prev</a> <a href=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?robot-consciousness.1>first</a>) <b>Alternate versions:</b> <a href="http://www.cogsci.ecs.soton.ac.uk/psycoloquy/raw//1994.volume.5/psyc.94.5.59.robot-consciousness.1.bringsjord">ASCII</a> <a href="http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/psummary?5.59">Summary</a>
<form method=get action=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/ptopic> <b>Topic:</b> <select name=topic>
<option value="Ai-cognitive-science"> Ai-cognitive science
<option value="Autonomous-brain"> Autonomous brain
<option value="Base-rate"> Base rate
<option value="Behavioral-knowledge"> Behavioral knowledge
<option value="Bell-curve"> Bell curve
<option value="Biological-psychiatry"> Biological psychiatry
<option value="Brain-expertise"> Brain expertise
<option value="Brain-intelligence"> Brain intelligence
<option value="Brain-rhythms"> Brain rhythms
<option value="Categorization"> Categorization
<option value="Cognition-action"> Cognition action
<option value="Cognitive-illusion"> Cognitive illusion
<option value="Cognitive-mapping"> Cognitive mapping
<option value="Coma-biochemistry"> Coma biochemistry
<option value="Connectionist-explanation"> Connectionist explanation
<option value="Consciousness"> Consciousness
<option value="Consciousness-report"> Consciousness report
<option value="Consensus-journals"> Consensus journals
<option value="Data-archive"> Data archive
<option value="Eeg-chaos"> Eeg chaos
<option value="Efference-knowledge"> Efference knowledge
<option value="Electronic-journals"> Electronic journals
<option value="Evolution-bipolar-disorder"> Evolution-bipolar disorder
<option value="Evolution-thinking"> Evolution thinking
<option value="Family-therapy"> Family therapy
<option value="Fodor-representation"> Fodor representation
<option value="Frame-problem"> Frame problem
<option value="Frontal-cortex"> Frontal cortex
<option value="Group-selection"> Group selection
<option value="Human-animal-bond"> Human-animal bond
<option value="Human-choice"> Human choice
<option value="Hyperstructure"> Hyperstructure
<option value="Intelligence-g-factor"> Intelligence-g factor
<option value="Language-complexity"> Language complexity
<option value="Language-comprehension"> Language comprehension
<option value="Language-gesture"> Language gesture
<option value="Language-network"> Language network
<option value="Language-origins"> Language origins
<option value="Language-prerequisites"> Language prerequisites
<option value="Language-retardation"> Language retardation
<option value="Language-sex-chromosomes"> Language-sex chromosomes
<option value="Lashley-hebb"> Lashley hebb
<option value="Least-squares"> Least squares
<option value="Lithium-toxicity"> Lithium toxicity
<option value="Locating-consciousness"> Locating consciousness
<option value="Mating-mind"> Mating mind
<option value="Meaning-belief"> Meaning belief
<option value="Memory-brain"> Memory brain
<option value="Mental-disorder"> Mental disorder
<option value="Metapsychology"> Metapsychology
<option value="Mirror-reversal"> Mirror reversal
<option value="Mood"> Mood
<option value="Movement-primacy"> Movement primacy
<option value="Nicotine-addiction"> Nicotine addiction
<option value="Optimal-cognition"> Optimal cognition
<option value="Origin-culture"> Origin culture
<option value="Paradoxical-cognition"> Paradoxical cognition
<option value="Part-whole-perception"> Part-whole perception
<option value="Pattern-recognition"> Pattern recognition
<option value="Pavlov-bell"> Pavlov bell
<option value="Posture-locomotion"> Posture locomotion
<option value="Purposeful-processes"> Purposeful processes
<option value="Reading"> Reading
<option value="Reading-inference"> Reading inference
<option value="Reading-inference-1"> Reading-inference 1
<option value="Reduced-wason-task"> Reduced-wason task
<option value="Representation-mediation"> Representation mediation
<option selected value="Robot-consciousness"> Robot consciousness
<option value="Scientific-cognition"> Scientific cognition
<option value="Self-consciousness"> Self consciousness
<option value="Sex-brain"> Sex brain
<option value="Sex-odor"> Sex odor
<option value="Social-bias"> Social bias
<option value="Space"> Space
<option value="Split-brain"> Split brain
<option value="Stroop-differences"> Stroop differences
<option value="Subtlety-emotion"> Subtlety emotion
<option value="Symbolism-connectionism"> Symbolism connectionism
<option value="Turing-test"> Turing test
<option value="Witness-memory"> Witness memory
</select><input type=submit name=submit value="View Topic"></form><form method=get action=http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy><b>Article:</b><select name=article>
<option Selected Value="5.59">1) Bringsjord 5(59)	What Robots can and Can't be
<option Value="5.82">2) Tirassa 5(82)	Is Consciousness Necessary to
<option Value="5.83">3) Brown 5(83)	Agnosticism About the Arbitrary
<option Value="5.84">4) Scholl 5(84)	Intuitions, Agnosticism, and Conscious
<option Value="6.10">5) Bringsjord 6(10)	Computationalism is Doomed, and we
<option Value="6.11">6) Rickert 6(11)	A Computer is not an Automaton
<option Value="6.12">7) Barresi 6(12)	Building Persons: Some Rules for the
<option Value="6.13">8) Dacosta 6(13)	Is There More to Personhood
<option Value="6.14">9) Hobbs 6(14)	Creating Computer Persons: More Likely
<option Value="6.15">10) Korb 6(15)	Persons and Things: Book Review of
<option Value="6.16">11) Massing 6(16)	Metaphysical Windmills in Robotland
<option Value="6.19">12) Bringsjord 6(19)	Why Didn't Evolution Produce Turing
<option Value="6.20">13) Bringsjord 6(20)	Agnosticism About Neuron-level
<option Value="6.21">14) Brown 6(21)	Agnosticism Revisited Reply to
<option Value="6.28">15) Mulhauser 6(28)	What Philosophical Rigour can and
<option Value="6.30">16) Bringsjord 6(30)	Agnosticism Re-revisited
<option Value="6.39">17) Bringsjord 6(39)	Are Computers Automata? Reply to
<option Value="7.30">18) Bringsjord 7(30)	Artificial Intelligence and the
</select> <input type=submit name=submit value="View Article"></form>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://mind.sourceforge.net/theory5.html>====================
<html lang="en">
<head>
<title>Theory of Cognitivity - Basis of Mind.Forth Robot AI and Mind.html Tutorial AI</title>
<mwta name="description" 
 content="A theory of mind implemented in Mind.Forth artificial intelligence." />
<meta name="keywords" 
 content="AI theory, artificial intelligence, brain, central nervous system, 
 CNS, cognitivity, concept, concepts, evolution, feature extraction, language, 
 neuroscience, philosophy of mind, tag, theory of cognitivity, theory of mind" />
</head>
<body bgcolor="#FFFACD">
<a name="top"></a>

<center><font color="navy" size="+3"><b>
Brain-Mind: Know Thyself!</b></font></center>

<center><font color="navy" size="+2"><b>
A Theory of Cognitivity for 
 <a href="http://mind.sourceforge.net/mind4th.html" 
 title="Mind.Forth -- the AI Mind in Win32Forth" 
 style="text-decoration:none;">
Artificial Intelligence</a></b></font></center>

<center><a name="mind-diagram"></a><font color="navy"><b><pre>
 _______________________________________________________________
|                             The Environment                   |
|                ____________                _____________      |
|  _____________| The Senses |______________| The Muscles |___  |
| |                \ \ \ \ \      The Body     | | | | |      | |
| |         ________\ \ \ \ \__________________|_|_|_|_|____  | |
| |        |         \ \ \ \ \       |      Cerebellum     || | |
| |        |          \ \ \ \ \      | (Motor Habituation) || | |
| |        |           \ \ \ \ \      \___________________/ | | |
| |        |            \ \ \ \ \            / / / / /      | | |
| Feature Extraction:   | | | | | The Brain / / / / /       | | |
| |        |------------+-+-+-+-+----------+-+-+-+-+--------| | |
| | Oldest |Memories:  S| |M| |C| |||||||| |M| |M| |C       | | |
| |        |           e| |e| |h| |Concept |o| |e| |h       | | |
| |        |           n| |m| |a| |||||||| |t| |m| |a       | | |
| |        |           s| |o| |n| |Fibers| |o| |o| |n       | | |
| |        |           o| |r| |n| |||||||| |r| |r| |n       | | |
| |        |           r| |y| |e| |as the| | | |y| |e       | | |
| | Newest |Memories:  y| | | |l| |||||||| | | | | |l       | | |
| |        |            | | | |s| | Core | | | | | |        | | |
| |        |            | | | | | |||||||| | | | | |        | | |
| |        |            | | | | | |of the| | | | | |        | | |
| |        |            | | | | | |||||||| | | | | |        | | |
| |        |            | | | | | | Mind | | | | | |        | | |
| |(Future |Memories:)  | | | | | |||||||| | | | | |        | | |
| |        |________________________________________________| | |
| |___________________________________________________________| |
|_______________________________________________________________|

</b></font></pre>
</center>

View the complete set of original, non-derivative 
 <a href="http://mind.sourceforge.net/diagrams.html"
 title="In sequence from the most general to the most detailed">
AI theory brain-mind diagrams</a>.<br />

<p>
<h4>(Artificial Intelligence Theory Document No. Five of Five)</h4></p>
<p>
This paper was originally commissioned by and published in 
<a href="http://www.locusmag.com/index//chklst/mg0571.htm" 
 title="a rare, hard-to-find magazine">
NOVEMBER Magazine</a>.<br />
Approximately five hundred (500) copies of the Summer 1981 issue 
were printed by<br />
the publisher in Seattle WA USA, and about 170 free copies were mailed in
1981 to<br />
contemporary (1980-1981) authors of computer-related articles in BYTE Magazine.
<br /></p>

<a href="http://mind.sourceforge.net/aisteps.html"
 title="How to program artificial intelligence 
based on the Theory of Cognitivity.">
AI Algorithm Steps</a> 
are the instructions for implementing the AI Theory of Cognitivity.<br />
<a href="http://mind.sourceforge.net/mind4th.html" 
 title="Watch Mind.Forth think in its Tutorial mode.">
http://mind.sourceforge.net/mind4th.html</a> achieved True AI functionality on 22 January 2008.<br />
<a href="http://mind.sourceforge.net/Mind.html" 
 title="AI Mind in JavaScript that people may copy to 
their own Web site to engender Singularity AI.">
http://mind.sourceforge.net/Mind.html</a> is a tutorial Seed AI implementation in 
 <a href="http://mind.sourceforge.net/js.html" 
 title="JavaScript for Artificial Intelligence">
JavaScript</a>.<br />
</p>

<p><br /></p><p><br /></p>

<pre>
     Once we know all there is to know  about the workings of the
human brain, we will have a choice of several  obvious approaches
to the task  of teaching students  the essential workings  of the
mind.  We could teach  about the brain-mind  in terms of  how  it
evolved through the eons,  or how it develops  in the life of the
individual, or how it functions in a mature specimen.

     This article presents the author's model  of the workings of
the brain-mind,  not in terms of sweeping generalizations  but on 
the ultimate and unambiguous level of the switching-circuit logic
of nerve cells.  You are invited to comprehend this mind-model --
to refute it if it is erroneous, or, if it makes sense to you, to
use it  in fulfilling  the  ancient  imperative,  "Know thyself!"  
Either way, you the sovereign mind are offered something to react
against, and possibly a revelation of your inmost mental nature.

     Of three obvious approaches  to explaining  the mind  inside 
the  brain  --  evolution,  individual  development,  and  static
functioning in maturity  --  this author chooses  the third route 
and seeks to describe your mature mind as you read and comprehend
this article.

     The other two approaches  --  evolution  of  the mind in the
species, development of mind in the specimen -- would  inherently
contain directions  for  the  starting-place  and  the  order  of
presentation  of all essential details  about the brain-mind.  In 
both cases,  we would simply describe  how a single-cell creature 
turned into a brain of one hundred billion cells.

     But let's take the hundred billion cells and find an obvious
point of departure for describing a model of the organization and
function  of  that purposive  web  of cells,  the brain.  Let  us
approach  the function  of the  evolved,  mature  mind  from  the 
obvious starting-point of sensory inputs into the mind.

     This article  leads you  through  a functional model  of the
brain-mind.   Although  the  brain  is  perhaps  the most complex
structure  on  earth,  it is  no more  than  a  three-dimensional
arrangement  of flows  of information.  The information-flows are
arranged in such a way as to achieve consciousness and thought.

     Each flow of information  is along  one of the dimensions of
the mind.  If you  are to comprehend  this  mind-model,  you must
understand  each   dimension   and  also  the  very   concept  of 
dimensionality.   The  dimensions  play  a  double  role  in this
article:  firstly  as the building-blocks of the mind  for you to
comprehend  both one by one  and as a grand edifice, and secondly
as the  chief  arguments  to convince you  of the validity of the 
mind-model.

     Dimensionality  is the  quality  of  being  dimensional,  of
having  dimensions.  The mind  is not  a  seething  lump  like an 
anthill,  but  a  strictly  dimensional  structure.  Although the 
brain  is  curved and convoluted, the  mind  inside  the brain is 
rigidly straight  (like a taut string or a beam of light)  in all 
its dimensions,  and  orthogonal  through ninety degrees wherever
the information  in one dimension  changes  its direction of flow
into another dimension.

     Although the mind exists within the brain, the mind is not a
material,  physical being.   The  mind  is  a structure  composed 
purely  of  information.  The  physical  structure  of the  brain
determines the informational structure of the mind, but these two
structures are  not identical.  Put it this way:  The brain holds
information,  and  information  holds  the  mind.  The  brain  is
organized physically, but the mind is organized logically.

     The  dimensionality  of the mind  is crucial  to its logical 
structure.  In some parts of the mind,  information  must be kept 
apart, while in other parts of the  mind  information  must  flow
together.  The dimensions  of  the  mind  serve  the purposes  of 
isolating and combining information.

     The first dimensional component of your mind is the straight
and linear record of its  sensory  input,  in  parallel  with the
straight  and  linear  "keyboard"  of its  motor  output.  Please 
examine the "mind-diagram" appearing with this article.
     A polarity exists between the mind and its environment.   An
environment  to develop in  is just as essential to the mind as a 
brain to exist in.

     A second polarity exists between our  sensory  perception of 
the environment and our motor manipulation of the environment.

     The two polarities -- organism/environment and sensory/motor
-- constitute sufficient logical differentiation  for the genesis
of an informational loop.

     Your mind sits at one end of the loop  and contemplates your
environment  at the other end  of the loop.  Your environment  is
the whole cosmos, including your body, brain and mind.  Your mind
starts  out  as  <i>tabula  rasa</i>,  "a  clean  slate."   As your mind
develops and fills with knowledge,  it tries to mirror internally
the cosmos which it perceives externally.   Who can say  which is 
the agent -- the cosmos organizing minds,  or mind organizing the
cosmos?

     Your mind starts out as an empty, but vastly capacious, link
in the loop.   Information starts in the environment and flows in
one  direction  through  the  loop:  through your senses into the
mind,  and  from your mind  out through  the motor nerves  to the
environment.

     It takes a while for your  neonatal  pathways -- sensory and
motor -- to communicate  internally  and thus  to close  the loop
with the environment.   The sensory and motor pathways develop in
parallel along the temporal dimension of the mind.

     Although your mind is constantly  thinking and acting in the
present,  its  existence  stretches  off  into  the  past.  Every
thought which you think in the present,  shapes your mind for the
future.  Your mind is the sum of all its past reality.

     It is critical to your comprehension of this mind-model that
you  think  of  the  sensory  and  motor  pathways  as flowing in 
parallel, but in opposite directions along the temporal dimension
of the mind.  When we go on now to examine in detail the sensory-
input system, you must  keep in mind  that the  sensory and motor
systems develop and operate side by side in lock-step fashion.

     A human brain has the five commonly acknowledged  senses  of
vision, audition (hearing), the tactile sense (touch),  gustation
(taste),  and olfaction (smell),  plus a few other senses such as
the sense of balance and the somesthetic sense.

     According to this mind-model,  all the senses  feed into the
mind  in  parallel  in a flat array  like  a woven rug.  For each 
sense, be it vision or audition or smelling the flowers, there is
a flat channel of  perception and memory  flowing along the time-
dimension of the mind.

     The nerves  from the sense-receptors  travel  to the  brain.
Inside  the  brain,  the  sensory  information  from  vision, and
perhaps other senses,  undergoes the pre-processing  of  feature-
extraction  before  it enters  the mind.  In  feature-extraction,
basic  patterns  are discriminated  to reduce  the work-load  and
hasten the operation  of the  conscious mind.  In the brain there 
operates a principle of rendering automatic (and subconscious) as
many things as possible.

     After the information in any one sensory pathway has reached
the brain  and  gone through all required feature-extraction, the 
information  enters  the  mind  by entering  the permanent memory
channel for that particular sensory modality.   Short-term memory
and permanent memory are identical in terms of physical location,
but they differ with respect to the  associative processes  which
catalog the memory-traces  and control their future accessability
through  recall.   In  other  words,  short-term memory  is not a
function of location but rather of associativity.  This assertion
is supported better  by the  large-scale  mind-model  than by any
local arguments  which may appear  in this topical discussion  of
memory.

     The distinction  between  preliminary  portions of the brain
and the mind itself is  based upon  a functional demarcation line
beyond which  information  is free  to flow not  just  along  its  
original  dimension  but  orthogonally  sideways  out  into other 
dimensions of the mind.  In other words the mind is circumscribed
and defined by its own dimensionality.

     It is important  that you now  comprehend  both  a  specific
design  for  memory  and  a  general  concept  of  memory.  It is
axiomatic   that   whatever   macroscopic   information   can  be
transmitted  can also be recorded.  To record information  during
transmission, one simply captures samples of the information at a
rate quick enough to catch all instances of significant change in
the information.

     The brain-mind  records  the  informational content  of each
sensory channel by routing the information through what is both a
transmission channel and an extremely long series of engram-nodes.
Once each sensory  information-flow  passes  the demarcation-line
into the mind, the information in each sensory channel floods the
transmission  "fibers"  of that permanent  memory  channel.  Each
fiber in the memory channel is like a series of millions of nodes.
Within  the particular  memory channel  for each sense, there are
thousands  of  the  nodal  fibers.   Your  oldest  memories  were
deposited and permanently, unchangeably  fixed in the first nodes
of  the  lifetime-long   memory  channels.   At  each  moment  of
sensation and perception, all the  simultaneously occupied  nodes
among  all the memory fibers  of each memory channel  irrevocably 
fix their contents.   The group of nodes fixed on parallel fibers
at one moment in time is like  a "slice" of memory of that moment
in time.

     You start out  with  your sensory nerves and pathways  going  
through  any  required  feature-extraction  and then feeding into
immensely  long  channels  of  tabula  rasa  memory.  Your myriad
moments of experience are deposited in densely packed "slices" of
and by simultaneity.

     Each  sensory  (and motor)  memory  channel  is like  a flat
ribbon  flowing  across  the  logical  surface  of the mind.  The 
memory-ribbon  is composed  of thousands  of  nodal  fibers.  The
first  experiences  go into  the first  nodal slices.  Subsequent
experiences  have to travel  through  all the slices  of previous 
experience  to reach and occupy  fresh  nodal slices,  which will
then be  filled  and  fixed  with  the experience  of the moment,
before serving as a bridge to all future moments.

     Although it is critical for you  to understand the essential
characteristics of the permanent  memory  channels  in this mind-
model, these essential characteristics are  not  introduced  here
all at once.  Advance notice  can  be given,  however,  that each 
sensory memory channel serves three main purposes, simultaneously
and  everywhere  along the memory channel:  transmission, memory, 
and comparison.

     Each sensory memory channel is like a pipeline full of nodal
fibers.  The nodal fibers are already there, genetically provided
and  ready  to  receive  engrams  of  memory.   The  pipeline  is 
gradually filling up with memory slices all through your lifetime.
The memory-slices are so densely packed that you could live to be
over a hundred years old and not run out of fresh, unused, tabula
rasa  memory  locations.  The gradual fixation  or consumption of 
memory-slices is like a slow burning fuse,  so long that it takes
over a hundred years to burn to the end.  Even if you did run out
of fresh memory-spaces in your old age,  you would still function 
as an intelligent  mind  with full retention of your many decades 
of  old  memories  and  with  the loss  of  only  your ability to
remember  each  passing  moment  of the present.  You could still
speak, for instance, several languages  and do anything else that
you learned to do  before  your tabula rasa memory ran out.  This
assertion is another one which ought to be judged in the light of
the total mind-model.

     The flatness  of each memory-channel  matters  to the brain,
but  not  to the mind.  The serial order  or  arrangement  of the
nodal fibers  does not matter at all.  Note  that the information
recorded  in a flat  slice  of memory  is  certainly  not  "flat"
information.  The flat memory channel  for the  tactile sense  of
touch contains a sensory mapping of the whole surface of the body.
The flat  auditory memory channel  contains  a mapping of a broad
range  of frequencies  of sound.   The flat visual memory channel
contains  two-dimensional images  in a one-dimensional series  of
fiber-nodes.  The mind does not know  and does not care  that the
images are flat.  When the mind associatively  recalls  an image-
slice, the one-dimensional memory-slice springs to life as if  it
were the two-dimensional image seen through the eye.

     We are really  getting into  the dimensionality  of the mind
when we bring in the idea of associativity.  Sensory  information
flows  into  the mind  along  the time-dimension,  but  it  moves
sideways within the mind along the associative dimension.   Every
sensory memory slice is attached to a  "concrete associative tag"
that is like a fiber flowing  at a right angle to all the  fibers
in  the  flat  memory  channels  of  the  time-dimension.   These 
concrete associative tag-fibers are not shown in the mind-diagram,
because they would completely  black out  the mind portion of the
diagram.  They are called "concrete" (as opposed  to  "abstract")
because they coordinate by simultaneity all  the sensory  memory-
slices of  "concrete"  experience.  They are called "associative"
because they are the  mechanism  by which  the mind  associates a
memory-slice in  one  sensory modality  with memory-slices in all
other sensory modalities  and even  in the same sensory modality.
For instance, they are the mechanism by which you might associate
the sound with the image of a dog, and vice versa.

     A single  associative  tag  governs a whole memory-slice and
associates  it  with  all  the rest  of the mind.  It may look as
though  there  is  a tremendously  unworkable  ratio  of the vast
information  that can be contained in the slice  to  the unitary,
off-or-on information that can flow over the tag,  but it will be
argued  in this article  that the vast information  stored in any
sensory  memory  channel  flows sideways  to the core of the mind
solely  over  aggregates  of these unitary,  off-or-on  "concrete
associative tags."  In other words, each lifetime-long  permanent
sensory memory channel is quite isolated unto itself and does not
flow at its end into some region  of further  or final processing
of the sensory information.   Wherever the sensory memory channel
comes to an end, it just stops.   Let us hope that the end of our 
tabula rasa memory channels is so  remote  that we never reach it
in our natural lifetime.   (In an artificially  intelligent robot
we might recirculate the  memory channels  by looping  around and
erasing the oldest memory-slices  just before reaching the end of
the first full loop of the memory-slices.)

     Each sensory memory channel is isolated unto itself,  except
for the associative tags  which lead away  at right  (orthogonal)
angles from the  time-dimension  of the memory  channel.  Over an
associative tag, you can go from one sensory  memory channel into
the memory channels  of all other senses.  For instance,  you can
go from vision to audition, or from olfaction to vision.  But you
can go  only  at a right angle;  you can  not cross  directly  by 
associative  tag  from  a present memory-slice  to one  laid down
years  or  even   minutes   ago.   Each  associative  fiber  that
interconnects all the senses is a guarantee of simultaneity.  The
associative tags  are laid down  at each successive moment of the
fleeting  present, and they can  never  after  be disconnected or
altered.  As the poet says, "The moving finger writes, and having
writ, moves on."

     You must have  a thorough comprehension  of the sensory  and
motor plane or "grid" of the mind before you study the two levels
of superstructure by which  mankind  achieves rational intellect.
You can maintain that  thorough  comprehension  as we examine the
three levels of complexity which are operative at the peak of the
human central nervous system.  The three levels to be studied are:
     1.  The  sentient  plane  of  the  sensory/motor grid.  (The
         interface between the external world and the core of the
         mind.)
     2.  The  abstract  core  of  the  mind.  (This core brings a
         central nervous system  to the level attained by "smart"
         mammals, such as dogs.)
     3.  The  linguistic  spiral  in  the  abstract  core  of the
         rational mind.

     It is important to go level by level so that you see clearly
what  the  mind  is capable of  at each level  and  what is still
lacking.  You should  be certain  to understand  the situation at
each  lower  level  before  you study  a higher level.  As with a
ladder of evolution, each level makes sense by itself and without
reference to any higher level.

     So far  we have discussed  the  sensory  input  part  of the
sensory/motor grid, which is the flat, two-dimensional substratum
of the mind.  It remains only to explain the  role played  by the
motor-output  side  of the  grid,  and then  you  should  have  a 
sufficient comprehension of the first  of the three levels of the
mind.

     Let us call  this sensory/motor grid  at the lowest level of
mind  the  "sentient grid."   If we were  to examine an animal or
automaton that had only such a  "sentient grid"  at the summit of
its  central  nervous system,  that  creature  would be  severely
limited  in its capabilities.  It would have  the power  of brute
sensation, and its repertoire of motor behaviors might consist of
many  reflex  and  instinctual  actions  which  it would  be able
crudely  to  link  with  sensory  inputs   as  triggers  for  the
initiation (or cessation) of motor activity.   Now let us examine
the motor memory channels, in accordance with the mind-diagram.

     The  motor  memory  channels  are  the polar opposite of the
sensory  memory  channels.   The  motor  memory  channels contain
memory slices not of external experience, but rather of internal,
dynamic  activation  of themselves.   This difference is critical
for your understanding  of the sentient grid  at the bottom level
of the mind.  Motor memory is not passive, it is dynamic.  If you
make associative access to a motor memory node  on a motor memory
fiber,  you unavoidably send out a signal to contract a muscle at
the destination of the associated motor nerve.

     As  you  examine  the mind-diagram,  notice that the sensory
memory fibers flow in parallel with,  but never touch,  the motor
memory fibers.   Yet the  sensory  side of the mind controls  the
motor side of the mind.   "Concrete associative tag fibers"  flow
between the sensory and the motor sides of the sentient grid.  As
was  discussed  above  with reference  to the sensory modalities,
concrete associative tags  flow at a right angle to all the life-
long  memory  channels.  Just as the  memory  fibers  are  all in
parallel, likewise all the associative tags  in the flat sentient
grid flow in parallel.  By flowing in parallel,  the  associative
tags  preserve the historical record of each successive moment in
time.

     If a central nervous system did not have memory  as a record
of experience (and as an  enabling mechanism for learning),  then
its  sensory  nerves  would have  to lead  directly  to its motor
nerves.   No  variations  of behavior  would be possible, and the
whole organism would be pre-programmed  genetically to respond to
stimuli always in the same way.

     When evolution introduces  memory  channels, it is essential
to buffer or separate the sensory and motor systems  so that they
do  not fuse together  and  so that  what intercourse occurs  can
occur  with  great  discrimination and precision.  Therefore, the
sensory and motor channels do  not  meet head-on, but rather they
attain  a close  proximity  and then  flow  in parallel.  At each
successive moment  in time and experience,  the sensory and motor
memory channels have the possibility of becoming linked by  nodal
fusing at both ends of the  particular  concrete associative  tag
fiber which was provided genetically  for  that moment  in  time.
The whole lifelong tapestry of experience has a fresh, new, blank,
concrete  associative  tag  fiber  for each moment of experience,
like a corduroy road made out of logs.

     But just  how do  the associative cross-tags link up sensory
experience with motor dynamism?  Why do we call it motor "memory,"
when no experience is recorded there?

     The motor memory channel is like a giant keyboard of a piano.
The purpose of the  motor  memory is not to record events, but to
cause them.  Or we could say that the purpose of the motor memory 
is to cause an event and then remember how to cause it again.

     In the infant organism of our sentient being, a mechanism of
"random  dynamics"  permits  various  motor  nerve cells  to fire 
spontaneously.  When  a motor nerve fiber  in  the  motor  memory
channel  fires, it causes  muscle-activation.   Then  information
starts flowing  in the sentient loop.   While the infant organism
randomly moves its limbs,  it experiences  aspects of that motion
through  its sensory apparatus  leading into  its  sensory memory
channels.  At each moment in time during the random motion, nodal
fixation at both end-regions of a concrete  associative tag fiber 
is associating passive sensory engrams with dynamic motor engrams.
Before long, control of the motor apparatus ceases  to be  random
and spontaneous.  Instead, associative control passes over to the
sensory side of the sentient grid.

     In the mature organism,  all motor activation occurs  across
associative  tag  connections laid down  in the past, and present
associative  tag  connections  are made solely for the purpose of
re-affirming   or  updating   or  strengthening  sensory-to-motor 
connections made in the past.

     This immediately previous statement  offers  an  explanation
why motor-learning time in infancy  is crucial to the development 
of motor skill.  During infancy, the organism  has the benefit of 
the random and spontaneous firing  of its motor control elements.
The sensory side of the sentient grid seizes  upon  these  random
firings and takes control of them.   Once a particular pattern of
sensory  memory  has taken  associative  control  of a particular
pattern of motor memory, all subsequent uses of that control-loop
are recorded  and thus re-affirmed  by concrete  associative tag,
and a habit of routine or skill becomes entrenched.

     Note that this mind-model offers an explanation for volition,
although  the explanation  is  different  for  each  of the three
levels of mind.   On the level  of the sentient grid,  and in the
absence  of  any  higher  superstructure,  volition  consists  of  
automatic response to the stimulus of a sensory pattern.  No lee-
way is allowed  in the response  to a given stimulus, but varying 
stimuli are allowed to elicit varying responses.

     Notice something general about the information-loop in which
the  sensory and motor  pathways  do not meet  but instead launch
into a parallel race into the future.   Remember, the interior of
the mind is trying to mirror  the exterior  of  the  environment.
Well, just as things are not steadfast and "hardwired" out in the
environment, likewise on the inside the associative sentient grid,
by  flowing  through  time  and  allowing  all  manner  of  novel
associative  connections,  can be  just as  varied and changeable
internally   as   the   environment   is   externally.   However,
an organism  with no nervous level  higher than the sentient grid
is forced to learn unchanging laws from its environment, and such
a sentient being is not free to make its own decisions by letting
logical data  freely  interact internally.  The sentient organism
lacks an  abstract  core of the mind  where the strict bondage of
stimulus-response  can be broken down  on the one hand  and goal-
directedly built back up again on the other hand.

     In other words, if you  comprehend  the associative sentient
grid which is the lowest of the three levels of mind, you are now
ready to proceed to the examination of the  second level of mind.
That is the  abstract core  which further buffers the sensory and
motor memory channels to such a degree that the formerly ironclad
and inviolable principle  of simultaneity in stimulus-response is
overruled in one way but kept intact in another.

     The  second  level  of  mind  is roughly  on a par  with the
central nervous system  of dogs  or monkeys  or horses.  Learning
and Pavlovian conditioning are possible.   The organism can be so
"smart" as to impress humans and to generate a sense of kinship.

     After eons of evolution, when an organism attains the second
level, the sentient grid of the first level  is still present and
operative in the now  more evolved  organism.   The sentient grid
neither withers away  nor changes significantly in its operation.
Indeed, in the literature about brains you will find  a generally
accepted principle  to the effect that lower levels of brains are
designed to operate  rather independently of higher levels in the
event of  successive  breakdown or impairment  starting  from the
topmost levels.  The principle is that the higher level dominates 
by consistently inhibiting  the  lower  level,  so  that,  if the
higher level is damaged or removed,  the lower level is no longer
inhibited  and  functions  in a role  perhaps  of inadequacy  but
certainly of the best coping ability  that the impaired brain has
to offer.

     The second level  of the mind-model  is that of the abstract
core of the mind.  If this second level seems ridiculously simple
to  you,  wait  until  we  fashion  from it  earth's most complex 
mechanism  on the  third level.  But you are correct  if you deem
simple  the innovation  worked upon the sentient grid to raise it
to the second level.  The innovation  is so simple  that  perhaps
you will now deign to consider how easily evolution  (which "does
not  make  a  leap")  could  have  stumbled  upon  the  wonderful
innovation.

     In  the  sentient  grid  of level one, there are two massive
neuronal flows  at right angles to each other.  The  one  massive
flow is that of the permanent memory  channels, both  sensory and
motor.  These memory channels  flow  along  the time-dimension of
the  grid.  The  other  massive  flow  is  that  of  the concrete 
associative  tag fibers  which cover  in blanket fashion  all the
memory channels  so as to provide their  only  internal avenue of
connection.  Every  associative tag fiber  is at a right angle to
whatever memory fiber it touches.  A  memory  fiber flows through
the time-dimension, but an  associative  fiber  is frozen at, and
indeed represents,  a particular, concrete moment in the lifetime
of the organism.

     The innovation  in the  second  level -- the  tiny  step  in
evolution -- involves the lifetime-long  memory fibers  that flow
along the time-dimension.   On the  merely  sentient level, these
fibers are supposed  to contain  either  sensory or motor memory,
because  they are connected  either to sensory input  or to motor 
output.  In a level-one system, all memory fibers are "dedicated"
-- either to  sensation  or to  motor activation -- and since the
fibers  are  not  free, the  level-one organism  is not free.  If
evolution had never progressed beyond level one,  we humans might
still be starfish or barnacles.  But  the step  or stumble  among
the dedicated memory fibers was unavoidably,  beckoningly easy to
make, and somehow  somewhere  long ago in the primordial eons the
great escape was made and they got loose!  Some of the supposedly
dedicated memory fibers got away from their origin as elongations
of the pathways  to the  external  world.  Getting loose from the
external world, they became creatures of the internal world - and
rational mind was on its way.

     The  brain-mind  diagram  of  this article  is actually more 
descriptive of  level two  than of  level one or three.  Note the
central  core  of time-dimensional  memory  fibers  which are not
attached and not dedicated to either the sensory or motor side of
the mind-grid.  Since these memory fibers at the core of the mind
are unattached and undedicated, we call them "abstract" fibers.

     Once evolution stumbled  and let loose of a few of the life-
long memory fibers, these formerly dedicated, now abstract fibers
turned  around  and  took over  the course  of evolution.  As the
embodiment of the negentropic principle, they became an "abstract"
vault of the mind and an ordering force.  They set about creating
internal  order  within  the  mind.  On level two  they passively 
accepted order  from without,  and next on level three  they will 
actively impose order from within.

     Throughout this article, the term  "abstract  fiber"  refers
only  to fibers  in  the  abstract  core  of the mind.  The  term
"concrete  fiber" refers only to the associative tag fibers which
lie  at right angles  to the time-dimension  of both the abstract
and the experiential fibers.   So there are three types of fibers
in  this  mind-model:  experiential (sensory or motor), abstract,
and concrete.

     When the  abstract  fibers  got loose from their dedication,
they did not  lose  their ability  to store memories within their
nodes that lie along each fiber like a chain of beads.  They lost
neither   their   orthogonal   juxtaposition   to  the   concrete
associative  fibers  nor their ability  to fuse nodes and thus be
tagged  by the associative fibers.   Since they no longer had any
direct  source  of memory data,  either  sensory  or  motor,  the
abstract fibers could henceforth be filled  with memory-data only
by receiving inputs sideways from the  concrete associative tags,
and that indirect, abstract function is what they fulfill even to
this day.  An  abstract  fiber  in  the core  of the mind  serves
associatively as  a unifying fiber  which crosses time-boundaries
and  interconnects  potentially  all  original  and  re-occurring
instances of the experience of a particular pattern of perception.
A sensory memory fiber is for sensation; an abstract memory fiber
is for perception.

     In order to understand how an  abstract memory  fiber works,
you  must  keep  in  mind  the  two-fold  mechanism  of  original
association and subsequent reaffirmation.  The original, neonatal
sensory inputs to level two of the mind  flow first directly into
memory nodes in the sensory memory channel and thence indirectly,
associatively, via  the  concrete  associative  tags, into memory
nodes  in the  abstract  memory  channel.  In a newly constructed
organism (such as a baby), the first memory deposits are of a low
level of complexity.  The abstract memory channel stands ready to
receive and record  whatever  inputs  are fed  to it  across  the
associative tags.  Therefore, in the earliest  moments of  memory,
identical engrams are formed in the  sensory and abstract  memory
channels.  At its neonatal origin, the  abstract  memory  channel
mirrors the sensory memory channels.  Remember, the abstract core
of the mind is trying to mirror the external world, which it must
perceive through the medium of the sensory channels.

     However,  as  time  goes  by,  each  abstract fiber  becomes
extremely differentiated from  its neighbors.  The original level
of complexity  of the data  in the abstract memory channel  is on
the order of  off-or-on  and  yes-or-no.  This irreducibly simple
logical content is the mirrored reflection of a jumble of data in
the sensory  memory  channels.  The sensory memory channels never
actually  become  organized  internally,  but the abstract memory
fibers do become organized.  Order develops  within  the abstract
memory  channel  through the  incessant and potent  mechanism  of
associative reaffirmation.

     Please examine the abstract memory channel from the point of
view of identical contents  being held in both the sensory memory
channels and the  abstract  memory channel.  Suppose that through
the eye a particular feature, such as  a geometric line, has been
seen  and  recorded,  first  in  the visual  memory  channel, and
simultaneously by associative tag in the abstract memory channel.
Every subsequent time that  that particular feature is seen again
along the  same  sensory  memory fiber, two important events will
occur.  The one rather simple event is that the sensation of that
feature will be recorded  one  more  time  within a freshly fixed
node at that point along the sensory memory fiber where the march
of time is presently fixing nodes  by simultaneity across a wide,
associative  front.  Meanwhile,  as  the  signal  of  the  sensed
feature travels along the sensory memory fiber and briefly floods
the fiber at every point, the originally fixed node is faithfully
doing its duty as a comparison  device.  By simple unitary logic,
it recognizes the (umpteenth)  reoccurrence  of the signal of the
same sensed feature with which it was originally fixed or written
as an engram.

     The sensory memory node, stimulated by the transient signal,
blips out a signal across its associative tag over to the related
node  on  the  related  abstract  memory  fiber.  Now in turn the
abstract  memory  node, stimulated  by  the transient associative
signal, blips out a signal which travels down the abstract memory
fiber to where unfixed tabula rasa nodes are being fixed by every
data-laden  moment  of  the  present.  So  now  we have  a mirror
phenomenon occurring  in both the sensory  memory  fiber  and the 
abstract memory fiber.   The associative tag fiber of the present
moment fuses across nodes  on both  the abstract memory fiber and
the  sensory  memory  fiber.  Thus the  logical  content  and the
"dedication"  of  the  abstract  memory  fiber  are reaffirmed by
simultaneity in the present moment of perception.

     The  concrete  associative  fiber  of the present  moment of
perception will fuse with sensory and abstract nodes wherever two
or more signals are present orthogonally.   Suppose that  the eye 
of the organism  is seeing  an image or pattern  composed of many 
features.  Each  extracted  feature floods its own sensory memory
fiber within the visual memory channel.  The concrete associative
fiber of the present,  which is activated by an internal clock of
the brain, fuses nodes with any feature-fiber that is momentarily
being activated  by the total sensation  of the image or pattern.
Therefore,  this   concrete   associative   fiber  is  henceforth
irrevocably linked  to the group  of features  which comprise the
seen image.   Henceforth this associative fiber can either recall
the image internally or recognize the image seen again externally.
The  concrete  associative  fiber  is  now  an  associative "tag"
attached to the image.

     Although the associative tag  may connect  to many fibers in
the  sensory  memory  channel,  it can connect  to as few  as one 
single fiber in the abstract memory channel.  Thus a single fiber
in the  abstract  memory  channel  can come  to represent a whole
class of fibers in the sensory memory channel and lo, an abstract
concept is born.

     If you pause to think, you  may  see how it makes sense that
often  multiple  fibers  will be activated  in the sensory memory
channel while only  one  or  a few  fibers  are  activated in the
abstract memory channel.   In the neonatal period, there may be a
releasing  mechanism  which  lets  loose  of only  a few abstract
fibers at a time.  Or the  abstract fibers  may compete to be the
first abstract fiber to be reaffirmed by the associative tag over
to a bundle  of  sensory fibers  comprising  a pattern.  The main
thing is, each abstract memory fiber can serve as a reaffirmative
collection-point  for  associations  to a whole class  of similar
sensory  patterns.   Voila -- pattern  recognition  occurs.   The
abstract fiber is not in the thick of sensation; it stands aside
and is abstract.

     An abstract  memory fiber  (spoken of  in the singular here,
although a gang  of thousands of logically fused fibers is meant)
can become the physical and logical seat of a concept in the mind.
For  instance, a dog  that  knows and recognizes  its master will
have  at least  one  abstract  memory  fiber  which serves as the
ultimate, concentrated  association-point  for memory-information
related to the dog's master.  This assertion is so serious and so
evocative  of hasty disbelief  that it is  now time to invoke the 
force of the dimensionality of the mind.

     The  level-two  mind  has two dimensions, the lifelong time-
dimension and the simultaneity-dimension.   Within  the level-two
mind (and the level-three mind),  memory fibers flow  in parallel
and only along the time-dimension.

     You know  from experience  that your mind has held a concept
of something or other,  such as a concept of the sun around which
our earth orbits.   All your knowledge of the sun is tied to that
concept,  and that concept is tied to the word "sun."  Of course,
your conceptual knowledge  of the sun  could be broken down  into
ingredient concepts,  such as the concepts  of warmth or light or
chariots.  But it seems  as if  you have one unitary point within
your mind where all the constituent concepts  are subsumed  under
the  operative  concept  of "sun."  So the dimensionality of your
concept  of "sun" is punctiform.   If  your concept  of sun  were
triangular or circular,  you would not be able to focus your mind
upon the same pinnacle of conceptuality  each time that you think
about the sun.

     But your concept of the sun is not only unitary,  it is also
quite constant over time.  Just as a point extended through space
becomes  a line,  likewise  a unitary concept  held constant over
time can best be represented, both physically and logically, as a
unitary fiber (or its logical equivalent, a gang of fused fibers)
flowing along the time-dimension of the mind.  The dimensionality
of a concept  is double:  it is  punctiformly  unitary  and it is
chronologically linear.

     Does it seem  ridiculous  that this  mind-model  claims that
perhaps a single gang  of fibers in your brain holds your concept
of a thing such as the sun, or of your pet dog, or of yourself --
your concept of ego?  But think:  the concept-fiber  is operative
not  by  itself,  but  by virtue of  the myriad  associative tags
leading  from  it.   Many  concepts  are  interrelated  and  they
contribute  to the composition of one another.  Conceptual fibers
are associated  not just to sensory data, but also to one another
within the  abstract  memory  channel.  Therefore a slice of your
abstract memory channel is  like  a  conceptual  topography.  The
maze of concepts is like a stick-forest of interrelated points of
knowledge.  Concepts are neighbors or relatives  of  one  another
not by physical proximity, but by logical proximity.

     Your pet dog has  a stick-forest  of concepts, but, alas! he
has no words  (or symbols)  attached to them and therefore he can
not manipulate them in a rational way.   Even though your dog may
hear  words  quite  often,  he does not develop the use of words.
Your baby, however, quickly develops the use of hundreds of words.
How is the level-three mind of your baby different from the level-
two mind of your dog?

     On the third level of mind,  rational intellect springs into
being in a process whereby rigid  informational  structures arise
amid  the  hodgepodge  informational milieu  which was level two.
These new structures arise as the means to express  relationships
among concepts.  They are to some degree  logical  structures and
to a larger degree linguistic structures.  The structures  remove
the mind from the bondage of immediate,  concrete experience and
allow the genesis of abstract thought.

     We  can  first  examine  the  existence  in  the  mind  of a 
vocabulary of words solely with respect to level two, and then we
can describe the level-three structures  which govern these words
in linguistic thought.

     Let us discuss the relationship between word-memories in the
auditory memory channel and image-memories  in  the visual memory 
channel.  Let us confine our discussion to concrete  nouns  which
are readily linked to concrete images.

     First  of  all,  the  association  between  the  two  memory
channels is a two-way street.   Activation of the image can evoke
the word in auditory memory, and activation of the word can evoke 
many images in visual memory.  Note that "word" here is singular,
but "images" is plural.  This difference obtains because a single
word can serve as a control-symbol for a whole class of images.

     For instance, if you see any  one of many varieties  of dog,
the word "dog" can come to mind  in your auditory memory channel.
If many people  listening  to a story  hear  the word "dog," they
will  probably  summon  up  quite   varying   images  of  dog  to
instantiate the concept of "dog."

     Humans  with  words  as   control-symbols  have  an  extreme
advantage over the level-two minds of animals.  The word attached
to a concept  makes that concept  utterly and fluidly manipulable
within the ratiocinative structures of the mind.  Even though the
word is an extended  string  of phonemes, it behaves logically as
if it were a unitary point.

     Indeed, in the level-three mind,  each word is attached to a
unitary point, namely an abstract conceptual fibergang associated
with the word in the abstract memory channel.

     In a level-one mind  that contained  words, there would be a
direct associative link  between  an image and  a word.   In  the
level-three mind,  concrete associative tags do not flow directly
between  images  and  words.  Instead, from  the  sensory  memory
channels  the associative tags  make  contact with  the  abstract
conceptual fiber, which is the  focal embodiment  of a particular 
concept and which serves  as a unifying point for the development
and  linguistic  activity   of  the  concept.   If  a  linguistic
structure  is going to control  a vocabulary of words,  each word
must have  a sort of  "handle"  upon it,  by which the word, as a
symbol, can be controlled.  That handle is an abstract conceptual
fiber.

     The abstract memory channel  is a set of all abstract memory
fibers.  An abstract conceptual fiber is an abstract memory fiber
which happens to hold a concept  (by gathering up the associative
tags of a concept).  Therefore the set of all abstract conceptual
fibers is a subset of the set of all abstract memory fibers.

     Thus far  in  our  discussion,  a concept  has  a tripartite
existence  within  the brain-mind.  Firstly, the word exists as a
short string of sounds within the auditory memory channel.   Note
that  no word  will exist at only one memory location  within the
auditory memory channel,  but rather  each word  will be recorded
there in hundreds or thousands of historical instances, depending
upon how frequently the word is used.  Furthermore, be very aware
that,  since  each  instance  of the word  is  the same string of
sounds (phonemes), all  instances of  a word  within the auditory
memory  channel  are  logically  equivalent.  Since  the auditory
memory  channel  is not just a transmission-channel, and not just
a memory-channel, but also a comparison-channel, any one instance
of a word can quickly be compared with all other instances of the
same or even a similar word, so that a word existing in thousands
of spots  within the auditory memory channel  functions as if all
the spots were interconnected, as indeed they are.  To illustrate
this point, think  of the word "dog" and how you  can  conjure up
many different images of "dog."

     The second part  of the tripartite existence of a concept is
at the  abstract conceptual fiber  for the concept.  The abstract
conceptual fiber is the main and focal seat of the concept within
the  mind.   From  the  abstract  conceptual  fiber, thousands of
concrete associative tags flow across the sentient  mind-grid  to
make reference to and control word-engrams in the auditory memory
channel.  If you hear  (or think)  a particular word through your
auditory memory channel, that word instantly gains access, across
at least  one  of the concrete associative tags,  to the abstract
conceptual fiber for that word so that your understanding of that
concept  is activated  within  your mind.  Likewise,  if, in  the
interplay of concepts within your mind, that  particular  concept
fiber is activated, the following scenario takes place.

     From  the activated  concept-fiber,  thousands  of  concrete
associative  tags  flowing in parallel are activated in parallel.
Only  one  of them has to reach  the word-engram in your auditory
memory channel for that word to be activated and flow through the
channel  to the present-most end  of the consumed portion  of the
tabula  rasa  channel.  In all likelihood,  many of the tags will
gain access  to the word, but, since it is  the same word  in all
instances, your mind  will hear just  one  standard production of
the  constituent  sounds  of  the  word.  Note, however, that the
parallel  activation  of thousands  of concrete  associative tags
serves, by  sheer redundancy, to make for  an extremely  reliable
mechanism for the internal recall of words during verbal thought.
Note also that your auditory memory channel  is a self-perceiving
channel.  Although  word-engrams  are controlled  en masse by the
abstract conceptual fiber outside of the auditory memory channel,
we are consciously aware  of the words  only  as they flow within
the auditory memory channel.

     The  third  part  or area  of the tripartite existence  of a
concept within the mind is spread out over all the sensory memory
channels  which  are  associatively  connected  to  the  abstract
conceptual fiber of the concept.   If the concept is evocative of
images  (or sounds or smells or feels or tastes),  then  from the
abstract  conceptual  fiber  many concrete associative tags  will
flow out  orthogonally  over to the sensory memory data which the
unitary concept represents.  An abstract conceptual fiber  may be
associatively  connected  to many visual images, not all of which
are  necessarily  identical  or  even  similar  to  one  another.
Remember, a word is always the same, but most images will have at
least  minor  differences.   Such a  state of affairs  is fit and
proper, because a word is an unchanging symbol, while an image is
just a variable slice of the rich pageantry of experience.

     An abstract conceptual fiber  reigns supreme  as the unitary
point under which or toward which all the constituent information
of a concept is subsumed.  The abstract concept develops or grows
by the accretion  of  concrete  associative tags  over time.  The
abstract conceptual fiber is not itself a symbol, but it is often
attached quite fixedly to a symbol, namely a word in the auditory
memory channel.

     The abstract conceptual fiber governs both the word attached
to aconcept and also the sensory data associated with the concept.
An abstract conceptual fiber  can have  concrete associations not
only to sensory engrams, but to other abstract conceptual fibers.
This ability  of a concept  to exist  within a network of related
concepts allows the genesis of such truly abstract and intangible
concepts as our notions of "honesty" and "courage."

     Remember  that  all  the abstract conceptual fibers  flow in
parallel in a flat plane along the temporal dimension of the mind.
The logical relationships  among  abstract conceptual fibers  are
determined   not  by  physical  position,  such as  contiguity or
proximity,   but  solely   by   interconnection   over   concrete 
associative tags.  Thus,  although the fibers lie in a flat plane
across the surface  of the brain-mind,  their associative  inter-
connections  can   generate  the  analog  of  superstructures  or
hierarchies among the abstract conceptual fibers.

     To discuss the psycholinguistic nature of language,  we must
for the first time in this article  introduce  the notion  of the
control of one abstract conceptual fiber over one or more  (i.e.,
thousands) of other abstract conceptual fibers.  Up until now  we 
have discussed  how one fiber might influence another fiber,  but
not how one fiber would dominate another.

     The ability of a neuron to require the summation of multiple 
inputs, before firing, permits some fibers to control others.  In
that portion  of the abstract memory channel  which we may hence-
forth call the "linguistic cable," some abstract fibers gradually
take on the role  of governing and dominating  whole  classes  of
other fibers.  For purposes of simplicity and clarity, we discuss
here only two linguistic classes of words:  nouns and verbs.

     As an  infant learns  nouns, he  or she  also subconsciously
assigns abstract fibers in the linguistic cable to the control of
the whole class of nouns.   As each new noun is learned, concrete
associative tags are bonded from general noun-control fibers over
to the abstract  conceptual  fiber  of the particular noun.  From
the noun-fiber  in turn  a concrete associative tag  goes  to the
engram of the word in the auditory memory channel.  Gradually the
noun-control fiber latches on to a burgeoning  "family" of nouns,
all segregated conveniently as a class so  that they  will remain
distinct when other parts of speech are learned.

     Suppose that the infant,  seeing and recognizing  an object,
wants to name that object in a blurt of speech.  The "wanting" is
actually  the build-up  of logical tension  within  the  abstract
memory channel.  The general noun-control fibergang  is activated
by the confluence  of all the logical tension  stemming both from
the perceived object  and from the internal state  of the infant.
This  general  noun-control  fiber-gang  sends  a  blanket  semi-
activation signal to all the nouns in the vocabulary of the baby.
In a way, all the noun-fibers are being invited to activate their
word-engrams in the auditory memory channel.  But, because of the
multiple-input requirement,  no noun-fiber can fire solely on the
basis  of the blanket  semi-activation  signal  going out  to all
nouns as a class.  Only that noun-fiber can fire which is already
or simultaneously semiactivated, so that the two semi-activations
cause full activation,  and a recall-signal is fired  over to the
word-engram in the auditory memory channel.

     Remember, the baby is seeing an object out in the real world.
The perception of that object causes associative  links to filter 
through  and  semi-activate  the one noun-fiber  within the whole
class of nouns.  The desire  to speak  a word  causes the general
noun-control fiber to send the blanket signal to all noun fibers.
Two semi-activation signals -- the blanket one  and  the specific
one -- meet in the appropriate noun-fiber  and cause it to fire a
recall-signal over to a word-engram stored in the auditory memory
channel.   In this system,  if the infant has not yet learned the
most appropriate word  for the perceived object,  he or she  will
blurt out  some nearly appropriate word  which  bears the closest
associative  relationship  to  the  perceived  object.  The  word
chosen by the baby may sound funny to adults,  but it makes sense
within the mind of the infant.

     In like manner,  an abstract control-fiber  for each part of
speech  governs all the members  within the class of that part of
speech.   When the infant goes on from learning nouns to learning
verbs,  likewise general verb-control fibers govern all available
verbs.

     Once we clearly make the point here that one  abstract  gang
of control-fibers for a particular part of speech  can govern all
the members of the class of that part of speech, we have finished
the fundamental description  of level three  of the mind  and  we
have described the part-of-speech building-blocks  which  make up
the  sentence-structures in natural human languages.

     If we describe a particular human language, we move from the
internal domain of genetically provided, universal deep  features
of the  level-three mind  out  to the external field  of cultural
tradition.  We see the innate ability of the mind to segregate or
classify various parts of speech, and we see the cultural ability
of the mind  to concatenate  part-of-speech  control-fibers  into
sentence structures.   The combinatorial power  of the linguistic 
portion of the abstract memory channel  allows many influences to
affect and determine the dynamic operation of sentence structures.
These influences  can include  considerations  of  number, logic,
time or tense,  emotion,  and so on.   Any semantic consideration
that can  be conceptualized (preferably  subconsciously)  can  be
represented  as a control-fiber  which figures in the composition
of sentence structures within a natural language.

     This paper does not attempt  to formalize the representation
of  natural  language  within  a  machine  mind.  We  avoid  such
formalization by means of utter simplification, and then we leave
the elaborate formalizations to the expert professional linguists.

     Our utter simplification of human language  consists here in
treating language  as if it had  only two parts of speech:  nouns
and verbs.   We want to simplify language so utterly that readers
will, on the one hand, grant that noun-plus-verb is the essential
core  of human language,  and, on the other hand,  comprehend how
this design for a mind  generates utterances  consisting of noun-
plus-verb.

     Therefore,  instead  of formalizing  an elaborate design for
one of the natural languages,  we ask  the following common-sense
questions.  Is it not clear,  that a mind,  which  can  grasp the
concept  of the doer  of some action  and then link that concept,
expressed  as a noun,  with  another  concept (that of the action
itself expressed as a verb)  has performed  the basic  linguistic
feat  which  is  both  representative  and  definitive  of  human
linguistic achievement?   Is not  everything else  refinement and
enhancement?

     This design  does not beg the question  by declaring an easy
system of syntax and  by ignoring semantics.   The foregoing bulk
of this article  has laid  the semantic groundwork  for proposing
that  part-of-speech  control-fibers  are  the semantic building-
blocks which the mind  concatenates into the sentence-structures,
or syntax, of a human language.   This informal simplification of
language is  meant  as  a  common  meeting-ground  for  a view of
language and a view of the brain-mind.

     Each abstract-memory control-fiber gang for a part of speech
becomes a node  on  a sentence-structure  of  concatenated nodes.
The nodes are concatenated by a spiral of linguistic habituation.
Just as an associative tag  fetches a word stored in the auditory
memory channel,  another associative tag,  attached to the end of
the stored word, sends a signal  back  to the sentence-structure,
reporting that the task of one node is complete  and that now the
next node should go into operation.   Thus dynamic control of the
semantically  driven  process  of sentence-generation shifts back
and forth between the abstract memory channel where the syntax is
stored and the auditory memory channel where the words are stored.
This  shifting  back and forth,  although it happens  in the flat
plane of the mind grid,  is extended  over time  and is logically
complex enough to be the flat analog of a spiral  winding through
time.

     Each use of a sentence-structure  reaffirms  the habituation
of  the  sentence-structure.   Any  typical node in the sentence-
structure can be added or deleted  by the habituational device of
practice.   The associative tags  which operate under the (short-
term)  domination  of  a sentence-structure  exercise  their  own
(long-term) domination over the sentence-structure by reaffirming
and habituating it.  Change is caused from without, but then each
subsequently identical loop of the spiral  takes hold of what was
initially change and habituates it into a long-term structure.

     The  concatenated  nodes  of sentence-structures  within the
abstract memory channel  reach over, so to speak, via associative
tags and string together  words and morphemes within the auditory
memory  channel.   We  hear  our  own  verbal thought  within our 
auditory memory channel.

     When  this system  of  generating  sentences  is  worked  in
reverse,  it comprehends  sentences  by decoding the associations
among concepts conveyed by the linguistic sentence-structure.  In
the comprehension of a sentence, new associative links are formed
among  the  abstract  conceptual  fibers  in  the abstract memory
channel of the receiving mind.   The sentence is recorded both as
an episode  in experiential memory  and as a slight rearrangement
of the associative links  among abstract conceptual fibers in the
abstract memory channel.

     In this system,  an incoming sentence  does  not  have to be
believed.  The entrenched, pre-existing associative links  in the
receiving mind  can withstand and overwhelm the links asserted by
the linguistic structure of an incoming sentence.

     This design seeks to explain how a multi-lingual speaker can
keep his or her languages apart and  avoid  running them together
while speaking.   Since  the vocabulary items  are all segregated
down at the deep levels, they  remain  segregated  at the highest
level, that of the particular language.

     If  you  build  an artificial mind, do not try to program it
like a computer.   Build it, turn it on, and commence teaching it.
</pre>

<hr align="left" width="600" />

<ul><a name="acm"></a><font color="navy"><b> 
<li>Association for Computing Machinery (ACM)</b><br />
Special Interest Group on Programming Languages (SIGPLAN)<br />
Frenger, Paul -- <i>ACM SIGPLAN Notices</i> (1998 and 2004)<br />
<ul> <a href="http://mind.sourceforge.net/mf980528.html"
 title="Early Mind.Forth of 28 May 1998, as 
described in the ACM Sigplan Notices."
 style="text-decoration:none">
Mind.Forth</a>: Thoughts on Artificial Intelligence and Forth<br />
 <li><a href="http://doi.acm.org/10.1145/307824.307853" 
 target="_new" 
 title="Dec. 1998 -- about the Mentifex Mind.Forth project in AI">
http://doi.acm.org/10.1145/307824.307853</a></ul>
<ul>Forth and AI revisited: BRAIN.FORTH<br />
 <li><a href="http://doi.acm.org/10.1145/1052883.1052885"
 target="_new"
 title="Dec. 2004 -- about the Brain.Forth work of Dr. Frenger">
http://doi.acm.org/10.1145/1052883.1052885<a><br />
<ul><i>AI4U</i> 
  (<a href="http://mind.sourceforge.net/ai4udex.html" 
 title="On-line index may be printed out.">Index</a>)
 among references in ACM SIGPLAN Notices<br />
 <li><a href="http://books.iuniverse.com/viewgiftoc.asp?isbn=0595654371&page=1"
 title="Read AI4U online and tag/review it on Amazon, etc.">
http://books.iuniverse.com/viewgiftoc.asp?isbn=0595654371&page=1</a><br />
 <li><a href="http://dogbert.abebooks.com/servlet/BookSearchPL?ph=2&sn=0595654371"
 title="Advanced Book Exchange of first editions and rare books">
http://dogbert.abebooks.com/servlet/BookSearchPL?ph=2&sn=0595654371</a><br />
 <li><a href="http://74.75.86.182/turingstore/books.htm" 
 title="Turing Store with informative AI4U review.">
http://74.75.86.182/turingstore/books.htm</a></font></ul>
</ul></ul>

<ul><a name="computationalization"></a><font color="navy"><b>
Computationalization of Mental Phenomena in Artificial Intelligence</b></font><br />
<li><a href="http://mind.sourceforge.net/computationalization.html" 
 title="How to implement the theory of mind in computer software.">
http://mind.sourceforge.net/computationalization.html</a></ul>

<ul><a name="jspj"></a><font color="navy"><b>
JavaScript AI Mind Programming Journal</b></font><br />
<li><a href="http://mentifex.virtualentity.com/js080815.html" 
 title="2008 AUG 15 -- planning improvements beyond basic AI functionality." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/js080815.html</a><br />
<li><a href="http://mentifex.virtualentity.com/js080816.html" 
 title="2008 AUG 16 -- audRecog acquires same functionality as in MindForth." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/js080816.html</a>
<li><a href="http://mentifex.virtualentity.com/js080819.html" 
 title="2008 AUG 19 -- audRecog recognizes plural forms of singular nouns." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/js080819.html</a> <br />
<li><a href="http://mentifex.virtualentity.com/js080822.html" 
 title="2008 AUG 22 -- psi flag-panel now includes num(ber) flag." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/js080822.html</a> <br />
<li><a href="http://mentifex.virtualentity.com/js080823.html" 
 title="2008 AUG 23 -- introduction of an Article module." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/js080823.html</a> <br />
<li><a href="http://mentifex.virtualentity.com/js080826.html" 
 title="2008 AUG 26 -- debugging of the Article module." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/js080826.html</a> <br />
<li><a href="http://mentifex.virtualentity.com/js080904.html" 
 title="2008 SEP 4 -- implementation of KB-traversal." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/js080904.html</a></ul>

<ul>
<b>MindForth Programming Journal</b> <br />
<li><a href="http://mentifex.virtualentity.com/fp080824.html" 
 title="2008 AUG 24 -- psi flag-panel now includes num(ber) flag." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/fp080824.html</a> <br />

<li><a href="http://mentifex.virtualentity.com/fp080825.html" 
 title="2008 AUG 25 -- Article module inserts 'THE' before nouns." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/fp080825.html</a> <br />

<li><a href="http://mentifex.virtualentity.com/fp080827.html" 
 title="2008 AUG 27 -- num flag selects 'A' or 'THE'." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/fp080827.html</a> <br />

<li><a href="http://mentifex.virtualentity.com/fp080829.html" 
 title="2008 AUG 29 -- dismantles SVO for intransitive verbs." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/fp080829.html</a> <br />

<li><a href="http://mentifex.virtualentity.com/fp080831.html" 
 title="2008 AUG 31 -- keeps verbs of being always activated." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/fp080831.html</a> <br />

<li><a href="http://mentifex.virtualentity.com/fp080901.html" 
 title="2008 SEP 1 -- uses whatIs module for verbs of being." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/fp080901.html</a></font> <br />

<li><a href="http://mentifex.virtualentity.com/fp080903.html" 
 title="2008 SEP 3 -- uses KB-traversal to make the AI more interesting." 
 style="text-decoration:none;">
http://mentifex.virtualentity.com/fp080903.html</a></ul>


<font face="verdana" color="navy"><ul>
<b>Minsky and Mentifex discuss AI philosophy</b><br /></font>
<li><a href="http://tech.groups.yahoo.com/group/ai-philosophy/message/15504" 
 title="Yahoo group AI Philosophy discussion on 24 August 2008"
 style="text-decoration:none;">
http://tech.groups.yahoo.com/group/ai-philosophy/message/15504</a></ul>


<font face="verdana" color="navy"><ul>
<b>Museums for AI Theory-of-Mind Exhibits</b><br /></font>
Ask your local science museum if they have an AI Mind exhibit. <br />
If they do not, volunteer to install 
 <a href="http://mind.sourceforge.net/mind4th.html" 
 title="Requires downloading Win32Forth and the AI Mind program." 
 style="text-decoration:none;">
MindForth</a> as an AI exhibit. <br />
See which museum has the oldest living artificial intelligence. <br />
<li><a href="http://en.wikipedia.org/wiki/Maryland_Science_Center" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Baltimore</a> MD --  
 <a href="http://www.marylandsciencecenter.org" 
 title="Maryland Science Center
601 Light Street 
Baltimore, MD 21230" 
 style="text-decoration:none;">
Maryland Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Lawrence_Hall_of_Science" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Berkeley</a> CA -- 
 <a href="http://www.lawrencehallofscience.org" 
 title="Lawrence Hall of Science 
University of California 
Centennial Drive 
Berkeley, CA 94720" 
 style="text-decoration:none;">
Lawrence Hall of Science</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Bloomington,_Indiana" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Bloomingtown</a> IN -- 
 <a href="http://www.wonderlab.org" 
 title="Wonderlab Museum 
308 W. Fourth St.
Bloomington, IN 47404" 
 style="text-decoration:none;">
Wonderlab Museum of Science, Health, & Technology</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Museum_of_Science,_Boston" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Boston</a> MA -- 
 <a href="http://www.mos.org" 
title="Museum of Science
1 Science Park
Boston, MA 02114" 
 style="text-decoration:none;">
Museum of Science</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Personal_Computer_Museum" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Brantford</a>, Ontario, Canada -- 
 <a href="http://www.pcmuseum.ca" 
 title="Personal Computer Museum, 
13 Alma Street, Brantford, ON (off Sydenham or Grand St)
MUSEUM IS LOCATED IN BUILDING OUT BACK" 
 style="text-decoration:none;">
Personal Computer Museum</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Discovery_Place" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Charlotte</a> NC -- 
 <a href="http://www.discoveryplace.org/home/discovery_place-home.php" 
 title="Discovery Place
301 N. Tryon St. 
Charlotte, NC 28202" 
 style="text-decoration:none;">
Discovery Place</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Museum_of_Science_and_Industry_(Chicago)" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Chicago</a> IL -- 
 <a href="http://www.msichicago.org" 
 title="Museum of Science and Industry
57th Street and Lake Shore Drive
Chicago, IL 60637" 
 style="text-decoration:none;">
Museum of Science and Industry</a> <br />

<li><a href="http://en.wikipedia.org/wiki/COSI_Columbus"
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Columbus</a> OH -- 
<a href="http://www.cosi.org"
 title="COSI Columbus 
333 West Broad Street
Columbus, OH 43215" 
 style="text-decoration:none;">
Center of Science and Industry</a> (COSI) <br />

<li><a href="http://en.wikipedia.org/wiki/Detroit_Science_Center" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Detroit</a> MI -- 
 <a href="http://www.detroitsciencecenter.org" 
 title="Detroit Science Center
5020 John R Street
Detroit MI 48202" 
 style="text-decoration:none;">
Detroit Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Liberty_Science_Center" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Jersey City</a> NJ -- 
 <a href="http://www.lsc.org" 
 title="Liberty Science Center 
Liberty State Park 
222 Jersey City Boulevard 
Jersey City, NJ 07305" 
 style="text-decoration:none;">
Liberty Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Science_City_at_Union_Station" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Kansas City</a> MO -- 
 <a href="http://www.sciencecity.com" 
 title="Science City at 
Union Station 
30 West Pershing Road
Kansas City, MO 64108" 
 style="text-decoration:none;">
Science City</a> at Union Station <br />

<li><a href="http://en.wikipedia.org/wiki/California_Science_Center" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Los Angeles</a> CA -- the 
 <a href="http://www.californiasciencecenter.org" 
 title="official website" 
 style="text-decoration:none;">
California Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Louisville_Science_Center" 
 title="Wikipedia AI4U background article" 
 style="text-decoration:none;">
Louisville</a> KY -- the 
 <a href="http://www.louisvillescience.org" 
 title="official site" 
 style="text-decoration:none;">
Louisville Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Museum_of_Science_and_Industry_in_Manchester" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Manchester</a> UK -- 
 <a href="http://www.mosi.org.uk" 
 title="Museum of Science & Industry
Liverpool Road
Castlefield
Manchester
M3 4FP" 
 style="text-decoration:none;">
Museum of Science and Industry</a> (MoSI) <br />

<li><a href="http://en.wikipedia.org/wiki/Gulf_Coast_Exploreum" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Mobile</a> AL -- the 
 <a href="http://www.exploreum.net" 
 title="official site" 
 style="text-decoration:none;">
Gulf Coast Exploreum Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Computer_History_Museum" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Mountain View</a> CA -- 
 <a href="http://www.computerhistory.org" 
 title="Computer History Museum
1401 N Shoreline Blvd. 
Mountain View, CA 94043" 
 style="text-decoration:none;">
Computer History Museum</a> <br />

<li><a href="http://en.wikipedia.org/wiki/New_York_Hall_of_Science" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
New York City</a> NY -- the 
 <a href="http://www.nyscience.org" 
 title="official site"
 style="text-decoration:none;">
New York Hall of Science</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Montshire_Museum_of_Science"
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Norwich</a> VT  -- 
 <a href="http://www.montshire.org" 
 title="official site" 
 style="text-decoration:none;">
Montshire Museum of Science</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Franklin_Institute" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Philadelphia</a> PA -- the 
 <a href="http://www.fi.edu" 
 title="official site" 
 style="text-decoration:none;">
Franklin Institute Science Museum</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Carnegie_Museums_of_Pittsburgh" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Pittsburgh</a> PA -- 
 <a href="http://www.carnegiesciencecenter.org" 
 title="official site" 
 style="text-decoration:none;">
Carnegie Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Exploratorium" 
 title="Wikipedia article on The Exploratorium" 
 style="text-decoration:none;">
San Francisco CA</a> -- 
 <a href="http://www.exploratorium.edu" 
 title="The Exploratorium
3601 Lyon Street, 
San Francisco, CA 94123"
 style="text-decoration:none;">
The Exploratorium</a> 
 <ul><li><a href="http://www.exploratorium.edu/mind/" 
 title="Exhibits about the mind" 
 style="text-decoration:none;">
Mind exhibit</a> at The Exploratorium</ul>

<li><a href="http://en.wikipedia.org/wiki/Discovery_Science_Center" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Santa Ana</a> CA -- 
 <a href="http://www.discoverycube.org" 
 title="official site" 
 style="text-decoration:none;">
Discovery Science Center</a> <br />

<li><a href="http://en.wikipedia.org/wiki/Pacific_Science_Center" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Seattle</a> WA -- The 
 <a href="http://www.pacsci.org" 
 title="official site" 
 style="text-decoration:none;">
Pacific Science Center</a> <br />

<li>Shreveport LA -- the Sci-Port Discovery Center <br />

<li><a href="http://en.wikipedia.org/wiki/St._Louis_Science_Center" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
St. Louis</a> MO -- the 
 <a href="http://www.slsc.org" 
 title="official site" 
 style="text-decoration:none;">
St. Louis Science Center</a> <br />

<li>Troy NY -- the Children's Museum of Science and Technology <br />

<li>Tyler TX --  Discovery Science Place <br />

<li><a href="http://en.wikipedia.org/wiki/SciWorks" 
 title="Wikipedia AI4U background information" 
 style="text-decoration:none;">
Winston-Salem</a> NC -- 
 <a href="http://www.sciworks.org" 
 title="official site" 
 style="text-decoration:none;">
Sci-Works</a> <br /></ul>


<ul><a name="redwood"></a><font color="navy"><b>
Redwood Center for Theoretical Neuroscience</b></font><br />
<li><a href="http://redwood.berkeley.edu" 
 target="_new" 
 title="Established in July 2005.">
http://redwood.berkeley.edu</a></ul>


<ul><li><a name="social"></a><font color="navy"><b>
Social Networking Sites</b></font> making reference to the 
 <a href="http://mind.sourceforge.net/theory5.html" 
 title="Recursive link to the source of this document." 
 style="text-decoration:none;">
<b>Theory of Cognitivity</b></a><br />

<ul><li><a href="http://del.icio.us/url/e2c27ccbe6cc35d8fcec1ec6fc7d2258" 
 title="Theory of Cognitivity - Basis of Mind.Forth Tutorial AI" 
 style="text-decoration:none;">
http://<b>del.icio.us</b>/url/e2c27ccbe6cc35d8fcec1ec6fc7d2258</a></ul>

<ul><li><a href="http://digg.com/programming/Brain-Mind_Know_Thyself!" 
 title="Diggers" 
 style="text-decoration:none;">
http://<b>digg</b>.com/programming/Brain-Mind_Know_Thyself!</a></ul>

<ul><li><a href="http://www.stumbleupon.com/url/mind.sourceforge.net/theory5.html" 
 title="Stumble Upon" 
 style="text-decoration:none;">
http://www.<b>stumbleupon</b>.com/url/mind.sourceforge.net/theory5.html</a></ul></ul>


<ul><a name="tom"></a><font color="navy"><b>
Theory of Cognitivity for Artificial Intelligence</b></font><br />
<li><a href="http://mind.sourceforge.net/theory1.html" 
 target="_new" 
 title="Naive speculation on the organization of memory channels, etc.">
Nolarbeit Theory Journal -- Part One</a><br />
<li><a href="http://mind.sourceforge.net/theory2.html" 
 target="_new"
 title="Mature ideas prior to the discovery of sideways association.">
Nolarbeit Theory Journal -- Part Two</a><br />
<li><a href="http://mind.sourceforge.net/theory3.html" 
 target="_new" 
 title="The mind arises not where memory channels end 
but among concepts and cognitive structures 
interspersed sideways among memory channels.">
Nolarbeit Theory Journal -- Part Three</a><br />
<li><a href="http://mind.sourceforge.net/theory4.html" 
 target="_new" 
 title="Technical paper">
Natural Language Through Abstract Memory</a><br />
<li><a href="http://mind.sourceforge.net/theory5.html" 
 target="_new" 
 title="As published in NOVEMBER Magazine">
Brain-Mind: Know Thyself!</a></ul>

<ul><a name="peer-review"></a><font color="navy" size="+1">
Theory of Cognitivity -- Critique and Discussion</font><br /><font color="navy">
<b>Ayers, Andrew:</b> 
Why his AI research library includes 
 <a href="http://books.iuniverse.com/viewgiftoc.asp?isbn=0595654371&page=1" 
 title="Artificial Intelligence For You 
computer science textbook" 
 style="text-decoration:none;">
<b><i>AI4U</i></b></a>.<br />
<li><a href="http://books.slashdot.org/comments.pl?sid=159819&cid=13428608" 
 target="_new" 
 title="29 August 2005 incidental Slashdot comments on 
the Mentifex AI design as documented in AI4U.">
http://books.slashdot.org/comments.pl?sid=159819&cid=13428608</a><br />
<b>Detre, Greg:</b> Notes - Mentifex (Arthur Murray) 'Know thyself!' AI document<br />
<li><a href="http://www.yek18.dial.pipex.com/greg/docs/reading - Mentifex AI document.htm" 
 target="_new" 
 title="Greg Detre, Saturday, September 30, 2000">
http://www.yek18.dial.pipex.com/greg/docs/reading - Mentifex AI document.htm</a><br />
<b>Frenger, Paul:</b> Mind.Forth: thoughts on artificial intelligence and Forth<br />
<li><a href="http://doi.acm.org/10.1145/307824.307853" 
 target="_new" 
 title="December 1998  ACM SIGPLAN Notices, Volume 33 Issue 12: 25-31">
http://doi.acm.org/10.1145/307824.307853</a><br />
<b>Frenger, Paul:</b> Forth and AI revisited: BRAIN.FORTH<br />
 <li><a href="http://doi.acm.org/10.1145/1052883.1052885"
 target="_new"
 title="Dec. 2004 -- about the Brain.Forth work of Dr. Frenger">
http://doi.acm.org/10.1145/1052883.1052885<a><br />
<b>Futrelle, Robert:</b> Re: The future of AI<br />
<li><a href="http://groups.yahoo.com/group/aima-talk/message/596" 
 target="_new" 
 title="From the textbook discussion forum of 
Artificial Intelligence: A Modern Approach">
http://groups.yahoo.com/group/aima-talk/message/596</a><br />
<b>Goertzel, Ben:</b> 28 May 2002 discussion of the Mentifex AI approach<br />
<li><a href="http://www.sl4.org/archive/0205/3836.html" 
 target="_new" 
 title="principal researcher of Webmind and its Novamente successor">
http://www.sl4.org/archive/0205/3836.html</a><br />
<b>Moore, Ryan:</b> A Theory of Cognitivity for Artificial Intelligence<br />
<li><a href="http://blogs.ittoolbox.com/c/engineering/archives/002296.asp" 
 title="Software Engineering: From Flash to .NET & Beyond 
(29 November 2004)">
http://blogs.ittoolbox.com/c/engineering/archives/002296.asp</a></font><br />
<b>Robinson, Linton:</b> Mentifex: A.I. (meme) loose on the Net<br />
<li><a href="http://dev.null.org/psychoceramics/archives/1998.05/msg00018.html" 
 title="The mentifeX Files for SURFACE TENSION Column by Linton Robinson">
http://dev.null.org/psychoceramics/archives/1998.05/msg00018.html</a><br />
</ul>

<ul><a name="ai4u"></a><b>
<a href="http://books.iuniverse.com/viewgiftoc.asp?isbn=0595654371&page=1"
 title="Free of charge to read on-line" 
 style="text-decoration:none;">
<i>AI4U: Mind-1.1 Programmer's Manual</i></a></b><br />
describes the software implementation of the above theory of mind <br />
and is to be found at prestigious universities in the library collection: <br />
<li><a href="http://library.hku.hk/search/i?SEARCH=0595654371" 
 target="_new" 
 title=" University of Hong Kong Libraries ">
Hong Kong University</a> Call Number: 006.3 M981 <br />
<li><a href="http://www.lib.ncsu.edu" 
 target="_new" 
 title="Raleigh NC USA">
North Carolina State University (NCSU)</a> Call Number: Q335 .M87 2002 <br />
<li><a href="http://library.tamu.edu" 
 target="_new"
 title=" College Station TX USA ">
Texas A&M University</a><br />
At your own library you may submit a request for <br />
the acquisition of <i>AI4U</i> with ISBN 0595654371. <br />
</ul>

<ul><a name="m4thuser"></a><font color="navy"><b>
User Manual of  
 <a href="http://mind.sourceforge.net/mind4th.html" 
 title="Mind.Forth in Win32Forth is more powerful 
than the JavaScript Mind.html Tutorial AI." 
 style="text-decoration:none;">
Mind.Forth</a> AI for robots</b></font><br />
<li><a href="http://mind.sourceforge.net/m4thuser.html" 
 target="_new" 
 title="See also the User Manual for the 
JavaScript Mind.html Tutorial AI.">
http://mind.sourceforge.net/m4thuser.html</a></ul>


<ul><font size="+2">
<a href="http://mentifex.virtualentity.com/userman.html" 
 title="The AI4U tutorial version of Mind.Forth free 
artificial intelligence for autonomous robots.">
User Manual of <i>AI4U</i> Textbook Theory-Based Artificial Intelligence</a></font><br />

<font color="navy" size="+1">
Table of Contents<br /></font>

<li>1 <a href="http://mentifex.virtualentity.com/userman.html#1" title="Congratulations">Overview</a>
 <ul><li>1.1 <a href="http://mentifex.virtualentity.com/userman.html#1.1">What is Mind.html?</a></li></ul>
 <ul><li>1.2 <a href="http://mentifex.virtualentity.com/userman.html#1.2">History of Mind.html</a></li></ul>
 <ul><li>1.3 <a href="http://mentifex.virtualentity.com/userman.html#1.3">Does Mind.html think?</a></li></ul>
 <ul><li>1.4 <a href="http://mentifex.virtualentity.com/userman.html#1.4">Is Mind.html conscious?</a></li></ul>
 <ul><li>1.5 <a href="http://mentifex.virtualentity.com/userman.html#1.5">Can Mind.html feel emotions?</a></li></ul>
 <ul><li>1.6 <a href="http://mentifex.virtualentity.com/userman.html#1.6">Uses of Mind.html</a></li>

<ul><li>1.6.01 <a href="http://mentifex.virtualentity.com/userman.html#1.6.01">For teaching computer programming.</a></li></ul>
<ul><li>1.6.02 <a href="http://mentifex.virtualentity.com/userman.html#1.6.02">For teaching JavaScript to students.</a></li></ul>
<ul><li>1.6.03 <a href="http://mentifex.virtualentity.com/userman.html#1.6.03">For learning JavaScript</a></li></ul>
<ul><li>1.6.04 <a href="http://mentifex.virtualentity.com/userman.html#1.6.04">For teaching artificial intelligence at a school for the gifted.</a></li></ul>
<ul><li>1.6.05 <a href="http://mentifex.virtualentity.com/userman.html#1.6.05">For teaching artificial intelligence on the high-school level.</a></li></ul>
<ul><li>1.6.06 <a href="http://mentifex.virtualentity.com/userman.html#1.6.06">For teaching artificial intelligence at a community college.</a></li></ul>
<ul><li>1.6.07 <a href="http://mentifex.virtualentity.com/userman.html#1.6.07">For teaching artificial intelligence at a university.</a></li></ul>
<ul><li>1.6.08 <a href="http://mentifex.virtualentity.com/userman.html#1.6.08">For exploring artificial intelligence at a think tank.</a></li></ul>
<ul><li>1.6.09 <a href="http://mentifex.virtualentity.com/userman.html#1.6.09">For teaching linguistics.</a></li></ul>
<ul><li>1.6.10 <a href="http://mentifex.virtualentity.com/userman.html#1.6.10">For teaching neuroscience.</a></li></ul>
<ul><li>1.6.11 <a href="http://mentifex.virtualentity.com/userman.html#1.6.11">For teaching psychology.</a></li></ul>
<ul><li>1.6.12 <a href="http://mentifex.virtualentity.com/userman.html#1.6.12">For teaching philosophy, especially the philosophy of mind.</a></li></ul>
<ul><li>1.6.13 <a href="http://mentifex.virtualentity.com/userman.html#1.6.13">For customized installation on a Web site to increase visitor traffic.</a></li></ul>
<ul><li>1.6.14 <a href="http://mentifex.virtualentity.com/userman.html#1.6.14">For release on the Web to carry advertisements with viral marketing.</a></li></ul>
<ul><li>1.6.15 <a href="http://mentifex.virtualentity.com/userman.html#1.6.15">As a prop for giving presentations on artificial intelligence.</a></li></ul>
<ul><li>1.6.16 <a href="http://mentifex.virtualentity.com/userman.html#1.6.16">As an interactive exhibit with a core knowledge base in a museum.</a></li></ul>
<ul><li>1.6.17 <a href="http://mentifex.virtualentity.com/userman.html#1.6.17">As a background element in a science fiction movie.</a></li></ul>
<ul><li>1.6.18 <a href="http://mentifex.virtualentity.com/userman.html#1.6.18">For venture capitalists to evaluate AI projects -- as a standard of comparison.</a></li></ul>
<ul><li>1.6.19 <a href="http://mentifex.virtualentity.com/userman.html#1.6.19">As an AI Engine for core functionality in other AI development projects.</a></li></ul>
<ul><li>1.6.20 <a href="http://mentifex.virtualentity.com/userman.html#1.6.20">For triggering a Technological Singularity.</a></li></ul></ul>

 <ul><li>1.7 <a href="http://mentifex.virtualentity.com/userman.html#1.7">Proliferation of Mind.html</a></li></ul>
 <ul><li>1.8 <a href="http://mentifex.virtualentity.com/userman.html#1.8">Timeline of Technological Singularity</a></li></ul>
</ul></ul>

<ul><li>2 <a href="http://mentifex.virtualentity.com/userman.html#2">Getting Started</a>
  <ul><li>2.1 <a href="http://mentifex.virtualentity.com/userman.html#2.1">Obtaining Mind.html</a></li></ul>
  <ul><li>2.2 <a href="http://mentifex.virtualentity.com/userman.html#2.2">Downloading Mind.html</a></li></ul>
  <ul><li>2.3 <a href="http://mentifex.virtualentity.com/userman.html#2.3">Distributing Mind.html</a></li></ul></ul></ul>

<ul><li>3 <a href="http://mentifex.virtualentity.com/userman.html#3">Running the Mind.html JSAI</a>

<ul><li>3.1 <a href="http://mentifex.virtualentity.com/userman.html#3.1">Pre-flight check-out</a></li>
  <ul><li>3.1.0 <a href="http://mentifex.virtualentity.com/userman.html#3.1.0">Sensory deprivation -- wait for AI to think.</a></li></ul>
  <ul><li>3.1.1 <a href="http://mentifex.virtualentity.com/userman.html#3.1.1">Minimal input -- enter a noun.</a></li></ul>
  <ul><li>3.1.2 <a href="http://mentifex.virtualentity.com/userman.html#3.1.2">Typical input -- enter a sentence.</a></li></ul>
  <ul><li>3.1.3 <a href="http://mentifex.virtualentity.com/userman.html#3.1.3">Looping chain of thought</a></li></ul>
  <ul><li>3.1.4 <a href="http://mentifex.virtualentity.com/userman.html#3.1.4">Meandering chains of thought</a></li></ul>
  <ul><li>3.1.5 <a href="http://mentifex.virtualentity.com/userman.html#3.1.5">Testing for self-awareness</a></li></ul></ul>

<ul><li>3.2 <a href="http://mentifex.virtualentity.com/userman.html#3.2">Interaction</a></li>
  <ul><li>3.2.1 <a href="http://mentifex.virtualentity.com/userman.html#3.2.1">Expanding the Knowledge Base (KB)</a></li></ul>
  <ul><li>3.2.2 <a href="http://mentifex.virtualentity.com/userman.html#3.2.2">Negation and Logic</a></li></ul>
  <ul><li>3.2.3 <a href="http://mentifex.virtualentity.com/userman.html#3.2.3">Questions and Answers</a></li></ul>
  <ul><li>3.2.4 <a href="http://mentifex.virtualentity.com/userman.html#3.2.4">Conjunctions: if, or, because etc.</a></li></ul>
  <ul><li>3.2.5 <a href="http://mentifex.virtualentity.com/userman.html#3.2.5">Psychological experimentation</a></li></ul></ul>

<ul><li>3.3 <a href="http://mentifex.virtualentity.com/userman.html#3.3">Display Modes</a></li>
  <ul><li>3.3.0 <a href="http://mentifex.virtualentity.com/userman.html#3.3.0">Normal Mode</a></li></ul>
  <ul><li>3.3.1 <a href="http://mentifex.virtualentity.com/userman.html#3.3.1">Transcript Mode</a></li></ul>
  <ul><li>3.3.2 <a href="http://mentifex.virtualentity.com/userman.html#3.3.2">Tutorial Mode</a></li></ul>
  <ul><li>3.3.3 <a href="http://mentifex.virtualentity.com/userman.html#3.3.3">Diagnostic Mode</a></li></ul></ul>

<ul><li>3.4 <a href="http://mentifex.virtualentity.com/userman.html#3.4">Troubleshooting</a></li>
<ul><li>3.4.1 <a href="http://mentifex.virtualentity.com/userman.html#3.4.1">Problems</a></li></ul>
<ul><li>3.4.2 <a href="http://mentifex.virtualentity.com/userman.html#3.4.2">Getting Help</a></li></ul></ul>

<ul><li>3.5 <a href="http://mentifex.virtualentity.com/userman.html#3.5">Departing from Mind.html</a></li>
 <ul><li>3.5.1 <a href="http://mentifex.virtualentity.com/userman.html#3.5.1">Keeping Mind.html alive indefinitely</a></li></ul>
 <ul><li>3.5.2 <a href="http://mentifex.virtualentity.com/userman.html#3.5.2">Shutting down Mind.html</a></li></ul></ul></ul>

<ul><li>4 <a href="http://mentifex.virtualentity.com/userman.html#4">Documentation of Mind.html</a>
 <ul><li>4.1 <a href="http://mentifex.virtualentity.com/userman.html#4.1">Mind project documentation</a></li></ul>
 <ul><li>4.2 <a href="http://mentifex.virtualentity.com/userman.html#4.2">External, independent documentation</a></li></ul></ul>
</ul></ul>

<ul><li>5 <a href="http://mentifex.virtualentity.com/userman.html#5">Programming Mind.html</a>
 <ul><li>5.0 <a href="http://mentifex.virtualentity.com/userman.html#5.0">Superficial changes without knowledge of JavaScript</a></li></ul>
 <ul><li>5.1 <a href="http://mentifex.virtualentity.com/userman.html#5.1">Learning JavaScript</a></li></ul>
 <ul><li>5.2 <a href="http://mentifex.virtualentity.com/userman.html#5.2">Enhancing Mind..html</a></li></ul>
 <ul><li>5.3 <a href="http://mentifex.virtualentity.com/userman.html#5.3">Porting Mind.html to other languages</a></li></ul></ul>

<ul><li>6 <a href="http://mentifex.virtualentity.com/userman.html#6">Hosting Mind.html on the Web</a>
<ul><li>6.1 <a href="http://mentifex.virtualentity.com/userman.html#6.1">Metempsychosis</a></li></ul></ul></ul>

<ul><li>7 <a href="http://mentifex.virtualentity.com/userman.html#7">In a robot, install Mind.Forth, not Mind.html.</a>
<ul><li>7.1 <a href="http://mentifex.virtualentity.com/userman.html#7.1">Robots as persons</a></li></ul>
<ul><li>7.2 <a href="http://mentifex.virtualentity.com/userman.html#7.2">Leave your fortune to your robot.</a></li></ul></ul></ul>

<ul><li>8 <a href="http://mentifex.virtualentity.com/userman.html#8">Careers in AI</a>
<ul><li>8.1 <a href="http://mentifex.virtualentity.com/userman.html#8.1">Non-technical careers</a></li></ul>
<ul><li>8.2 <a href="http://mentifex.virtualentity.com/userman.html#8.2">Technical careers</a></li></ul></ul>


<p><br /></p>
<a href="#top" 
 title="Click here or use the browser scroll-bar." 
 style="text-decoration:none;">
Return to top</a>; or to 
 <a href="http://mind.sourceforge.net/sitemap.html" 
 title="Site Map" 
 style="text-decoration:none;">
sitemap</a>; or to <br />
<a href="C:\Windows\Desktop\Mind.html" 
 target="_new" 
 title="Click here only if you have planted a local Seed AI.">
C:\Windows\Desktop\Mind.html</a> <br />
[For the above link to work, copy to your local hard disk<br />
<a href="http://mind.sourceforge.net/Mind.html"
 title="Use the dropdown MSIE/ View/ Source (let go) menu 
File/ Save As... (let go) Save in: [Desktop] 
File name: Mind.html 
Save as type: Text Document - MS-DOS Format">
http://mind.sourceforge.net/Mind.html</a> <br />
and name it Mind.html in the C:\Windows\Desktop\ directory.]<br />

<br />
<a href="http://www.iuniverse.com/bookstore/book_detail.asp?isbn=0595259227" 
 title="Information about the AI4U textbook of artificial intelligence">
<img src="http://farm1.static.flickr.com/51/179758367_f283f0d6e0_s.jpg"></a> <br />
 
<!--WEBBOT bot="HTMLMarkup" startspan alt="Site Meter" -->
<script type="text/javascript" language="JavaScript">var site="s13ai4udex"</script>
<script type="text/javascript" language="JavaScript1.2" src="http://s13.sitemeter.com/js/counter.js?site=s13ai4udex">
</script>
<noscript>
<a href="http://s13.sitemeter.com/stats.asp?site=s13ai4udex" target="_top">
<img src="http://s13.sitemeter.com/meter.asp?site=s13ai4udex" alt="Site Meter" border=0></a>
</noscript>
<!-- Copyright (c)2002 Site Meter -->
<!--WEBBOT bot="HTMLMarkup" Endspan --><br />

<a href="http://sourceforge.net"> 
<img src="http://sourceforge.net/sflogo.php?group_id=31619" 
 width="88" height="31" border="0" alt="SourceForge Logo"></a> <br />
</body>
</html>++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://news.zdnet.co.uk/hardware/0,1000000091,2083942,00.htm>====================
ï»¿<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="no-js ie ie6" lang="en" xmlns:fb="http://www.facebook.com/2008/fbml" xmlns:v="http://rdf.data-vocabulary.org/#"><![endif]-->
<!--[if IE 7 ]><html class="no-js ie ie7" lang="en" xmlns:fb="http://www.facebook.com/2008/fbml" xmlns:v="http://rdf.data-vocabulary.org/#"><![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en" xmlns:fb="http://www.facebook.com/2008/fbml" xmlns:v="http://rdf.data-vocabulary.org/#"><![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="en" xmlns:fb="http://www.facebook.com/2008/fbml" xmlns:v="http://rdf.data-vocabulary.org/#">
<!--<![endif]-->
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:image" content="http://cdn-static.zdnet.com/i/library/uk-thumbs/processor.jpg">
<meta property="news_keywords" content="Robots, Artificial intelligence, ai, moral dilemma, sentience">
<meta itemprop="datePublished" content="2001-01-24T17:30:00Z">
<meta itemprop="dateModified" content="2001-01-24T17:30:00Z">
<meta itemprop="dateCreated" content="2001-01-24T17:30:00Z">
<meta itemprop="image" content="http://cdn-static.zdnet.com/i/library/uk-thumbs/processor.jpg">
<meta itemprop="url" content="http://www.zdnet.com/sentience-the-next-moral-dilemma-3002083942/">
<meta name="application-name" content="Sentience: The next moral dilemma | ZDNet">
<meta name="msapplication-TileColor" content="#24486B">
<meta name="msapplication-TileImage" content="/images/base/logo-144x144.png">
<meta property="og:title" content="Sentience: The next moral dilemma | ZDNet">
<meta property="og:url" content="http://www.zdnet.com/sentience-the-next-moral-dilemma-3002083942/">
<meta name="description" content="Humankind will have to decide how to live with a new sentient race">
<meta property="og:description" content="Humankind will have to decide how to live with a new sentient race">
<meta property="og:site_name" content="ZDNet">
<title>Sentience: The next moral dilemma | ZDNet</title>
<link rel="stylesheet" href="/css/scaffolding.css?1392906492">
<!--[if (lt IE 9)&(!IEMobile)]>
<link rel="stylesheet" href="/css/scaffolding.768.css?1392906492" media="screen">
<link rel="stylesheet" href="/css/scaffolding.1024.css?1392906492" media="screen">
<![endif]-->
<link rel="stylesheet" href="/css/scaffolding.768.css?1392906492" media="screen and (min-width:768px)">
<link rel="stylesheet" href="/css/scaffolding.1024.css?1392906492" media="screen and (min-width:1024px)">
<link rel="stylesheet" href="/css/print.css?1392906492" media="print">
<link rel="canonical" href="http://www.zdnet.com/sentience-the-next-moral-dilemma-3002083942/">
<script src="/frontend/js/external/modernizr-custom.2.5.3.js?1392906587"></script>
<script src="//cdn.optimizely.com/js/328981956.js"></script>
<script src="http://www.google.com/recaptcha/api/js/recaptcha_ajax.js"></script>
<script src="/js/s_code.js?1392906500" type="text/javascript"></script>
<script src="/js/omniture.js?1392906500" type="text/javascript"></script>
<script src="/js/history.js?1392906500" type="text/javascript"></script>
<script src="/js/uuid.js?1392906500" type="text/javascript"></script>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/frontend/js/external/jquery-1.7.1.min.js?1392906587"><\/script>')</script>
<script type="text/javascript">
if (typeof uuid === "undefined") {
	var page_guid = null;
} else {
	var page_guid = uuid.v1();
}		
</script>
<!-- Start BounceX tag. Deploy at the beginning of document head. -->
<script>
(function(d) {
    var e = d.createElement('script');
    e.src = d.location.protocol + '//bounceexchange.com/tag/765/i.js';
    e.async = true;
    d.getElementsByTagName("head")[0].appendChild(e);
}(document));
</script>
<!-- End BounceX tag -->


    <script type="text/javascript">
		  var googletag = googletag || {};
		  googletag.cmd = googletag.cmd || [];
		  (function() {
		    var gads = document.createElement("script");
		    gads.async = true;
		    gads.type = "text/javascript";
		    var useSSL = "https:" == document.location.protocol;
		    gads.src = (useSSL ? "https:" : "http:") + "//www.googletagservices.com/tag/js/gpt.js";
		    var node =document.getElementsByTagName("script")[0];
		    node.parentNode.insertBefore(gads, node);
		   })();
		  googletag.cmd.push(function() {
		    googletag.pubads().set("adsense_background_color", "FFFFFF");
		  });
		</script><script type="text/javascript">
if (typeof page_guid == "undefined") {
	var page_guid = 'c7d6cd5d171785fdb88';
}
var adSlots= {};$(function() {googletag.cmd.push(function() {	if ($('#feature-sponsor').length > 0) {	adSlots["feature-sponsor"] = googletag.defineSlot("/8264/in-zdnet/processors", [88,31], "feature-sponsor")
		.addService(googletag.pubads());
	}	if ($('#hotspot').length > 0) {	adSlots["hotspot"] = googletag.defineSlot("/8264/in-zdnet/processors", [165,421], "hotspot")
		.addService(googletag.pubads());
	}	if ($('#leaderboard-top').length > 0) {	adSlots["leaderboard-top"] = googletag.defineSlot("/8264/in-zdnet/processors", [[728,90],[970,66],[970,250],[980,150]], "leaderboard-top")
		.addService(googletag.pubads())
		.setTargeting("pos", "top");
	}	if ($('#leaderboard-bottom').length > 0) {	adSlots["leaderboard-bottom"] = googletag.defineSlot("/8264/in-zdnet/processors", [[728,90],[970,66],[970,250],[980,150]], "leaderboard-bottom")
		.addService(googletag.pubads())
		.setTargeting("pos", "bottom");
	}	if ($('#marquee').length > 0) {	adSlots["marquee"] = googletag.defineSlot("/8264/in-zdnet/processors", [300,60], "marquee")
		.addService(googletag.pubads());
	}	if ($('#mpu-top').length > 0) {	adSlots["mpu-top"] = googletag.defineSlot("/8264/in-zdnet/processors", [[300,250],[300,600],[300,1050]], "mpu-top")
		.addService(googletag.pubads())
		.setTargeting("pos", "top");
	}	if ($('#mpu-bottom').length > 0) {	adSlots["mpu-bottom"] = googletag.defineSlot("/8264/in-zdnet/processors", [[300,250],[300,600],[300,1050]], "mpu-bottom")
		.addService(googletag.pubads())
		.setTargeting("pos", "bottom");
	}	if ($('#multiplexer').length > 0) {	adSlots["multiplexer"] = googletag.defineSlot("/8264/in-zdnet/processors", [460,170], "multiplexer")
		.addService(googletag.pubads());
	}	if ($('#replay').length > 0) {	adSlots["replay"] = googletag.defineSlot("/8264/in-zdnet/processors", [460,160], "replay")
		.addService(googletag.pubads());
	}	if ($('#resource-center').length > 0) {	adSlots["resource-center"] = googletag.defineSlot("/8264/in-zdnet/processors", [300,261], "resource-center")
		.addService(googletag.pubads());
	}	if ($('#skin').length > 0) {	adSlots["skin"] = googletag.defineSlot("/8264/in-zdnet/processors", [1600,1000], "skin")
		.addService(googletag.pubads());
	}	if ($('#sponsor-logo').length > 0) {	adSlots["sponsor-logo"] = googletag.defineSlot("/8264/in-zdnet/processors", [120,60], "sponsor-logo")
		.addService(googletag.pubads());
	}	if ($('#sponsored-text-link').length > 0) {	adSlots["sponsored-text-link"] = googletag.defineSlot("/8264/in-zdnet/processors", [401,11], "sponsored-text-link")
		.addService(googletag.pubads());
	}	if ($('#ticker').length > 0) {	adSlots["ticker"] = googletag.defineSlot("/8264/in-zdnet/processors", [980,45], "ticker")
		.addService(googletag.pubads());
	}	if ($('#vendor-text-link').length > 0) {	adSlots["vendor-text-link"] = googletag.defineSlot("/8264/in-zdnet/processors", [300,450], "vendor-text-link")
		.addService(googletag.pubads());
	}	if ($('#interstitial').length > 0) {	adSlots["interstitial"] = googletag.defineOutOfPageSlot("/8264/in-zdnet/processors",   "interstitial")
		.addService(googletag.pubads());
	}
	googletag.pubads().setTargeting("cid", "3002083942");
	googletag.pubads().setTargeting("device", "desktop");
	googletag.pubads().setTargeting("ptype", "story");
	googletag.pubads().setTargeting("session", "b");
	googletag.pubads().setTargeting("firstpg", "1");
	googletag.pubads().setTargeting("vguid", page_guid);

	googletag.pubads().enableAsyncRendering();
	googletag.pubads().collapseEmptyDivs();
	googletag.pubads().enableSingleRequest();
	googletag.enableServices();
});});</script>

<script type="text/javascript" src="http://i.i.cbsi.com/cnwk.1d/Ads/common/manta/adFunctionsD-zdnet.js"></script>
<script type="text/javascript" src="http://cn.cbsimg.net/cnwk.1d/Aud/javascript/zdnet/apex.js"></script>
<script type="text/javascript">
	var cbsiAdGlobal = {
		"SITE" : "86",
		"NCAT" : "800063",
		"PTYPE" : "2100",
		"CID" : "3002083942",
		"NODE" : "800063",
		"BRAND" : "2",
		"STAGING" : "0",
		"CNET-PAGE-GUID" : page_guid,
		"TAG" : "Processors",
		"regSys" : "1",
		"regId" : "",
		"lgnSts" : "0",
		"BK_REGION" : "us"
	},
	cbsiAds = [];
	cbsiRegisterAdGlobals(cbsiAdGlobal);
	cbsiSetDeferredLocalPage("/MantaRay_LocalPage.html");
</script>

<script type="text/javascript" src="http://dw.cbsimg.net/js/cbsi/dw.js"></script>
<script type="text/javascript">
DW.pageParams = {
	asid: '110020036',
	astid: '136',
	ctype: 'asset',
	cval: '3002083942',
	onid: '800063',
	pgnbr: '1',
	ptid: '2100',
	siteid: '86',
        pguid: page_guid
};
DW.regSilo = 3;
DW.pageParams.x_breadcrumb = 800063;
</script>

<!--
<PageMap>
<DataObject type="content">
<Attribute name="type" value="text"/>
<Attribute name="id" value="3002083942"/>
<Attribute name="title" value="Sentience: The next moral dilemma"/>
<Attribute name="author" value="Richard Barry"/>
<Attribute name="author_ids" value="10001350"/>
<Attribute name="summary" value="Humankind will have to decide how to live with a new sentient race"/>
<Attribute name="published" value="2001-01-24T17:30:00+0530"/>
<Attribute name="published_timestamp" value="980357400"/>
<Attribute name="country" value="uk"/>
<Attribute name="page_count" value="1"/>
<Attribute name="eu_last_30_days" value="0"/>
<Attribute name="eu_last_7_days" value="0"/>
<Attribute name="global_last_30_days" value="2"/>
<Attribute name="global_last_7_days" value="2"/>
<Attribute name="us_last_30_days" value="0"/>
<Attribute name="us_last_7_days" value="0"/>
<Attribute name="tags" value="Robots,Artificial intelligence,ai,moral dilemma,sentience"/>
</DataObject>
</PageMap>
-->

</head>
<body id="story" data-is-logged-in="false">

            <div id="ticker"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["ticker"]) {
			googletag.cmd.push(function() {
				googletag.display("ticker");
			});
		};
	});
	</script>

    
	<!-- ClickTale Top part -->
	<script type='text/javascript'>
	    document.write(unescape("%3Cscript%20src='" +
	                            (document.location.protocol == 'https:' ?
	                             'https://clicktalecdn.sslcs.cdngc.net/' :
	                             'http://cdn.clicktale.net/') +
	                            "www09/phc/5a999966-75a6-4b89-a92c-23702f4d9c94.js'%20type='text/javascript'%3E%3C/script%3E"));
	</script>
	<!-- ClickTale end of Top part -->


<script>
	var cacheBustingId = 42402,
        userRegion = 'in';
        userTwoLetterCountry = 'in';
</script>
<div id="fb-root"></div>
<header role="banner">
	<div class="header container">
		<a href="http://www.zdnet.com/" class="siteLogo">ZDNet</a>
		<div class="lvl-search">
			
            <div id="sponsored-text-link"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["sponsored-text-link"]) {
			googletag.cmd.push(function() {
				googletag.display("sponsored-text-link");
			});
		};
	});
	</script>

    
			
			<form id="search" class="siteSearch" action="http://www.zdnet.com/search" onsubmit="Omniture.trackSearchSubmit(this, $(this).find('[name=q]').val());">
	<fieldset class="box">
		<input type="text" placeholder="Search ZDNet" tabindex="1" name="q" value="" />
		<input type="submit" value="Search" />
	</fieldset>
</form>

		</div>
		<div class="lvl-nav">
			<nav class="secondaryNav">
									<div class="siteUtils loggedOut">
						<a href="http://www.zdnet.com/membership/log-in/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-member="showLogIn">Log In</a> | <a href="http://www.zdnet.com/membership/register/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-omniture='{"channel":"processors", "reg_form_type":"short", "registration_driver":"header"}' data-member="showRegister">Join ZDNet</a> <span class="avatar"><img src="/images/base/avatar-20x20.jpg" alt="" width="20" height="20" /></span>
					</div>
								<ul class="bar">
					<li>
						<a href="http://www.zdnet.com/"><span class="icon home">Home</span></a>
					</li>
																		<li><a href="http://www.zdnet.com/topic/">Hot Topics</a></li>
													<li><a href="http://www.zdnet.com/newsletters/">Newsletters</a></li>
													<li><a href="http://www.zdnet.com/topic-reviews/">Reviews</a></li>
													<li><a href="http://www.zdnet.com/downloads/">Downloads</a></li>
													<li><a href="http://www.zdnet.com/whitepapers/">White Papers</a></li>
															</ul>
			</nav>
		</div>
	</div>
	<nav class="primaryNav container">
		<ul class="bar editions">
			<li class="expandable"><a href="javascript:void(0);">India Edition<span class="icon arrow"></span></a>
				<nav class="menu">
					<ul>
						<li><span class="label">ZDNet.com is available in the following editions:</span></li>
																				<li><a href="" data-edition="asia" class='editionSwitch'>Asia</a></li>
																											<li><a href="" data-edition="au" class='editionSwitch'>Australia</a></li>
																											<li><a href="" data-edition="eu" class='editionSwitch'>Europe</a></li>
																											<li><a href="" data-edition="in" class='editionSwitch'>India</a></li>
																											<li><a href="" data-edition="uk" class='editionSwitch'>United Kingdom</a></li>
																											<li><a href="" data-edition="us" class='editionSwitch'>United States</a></li>
																			<li><span class="label">ZDNet around the globe:</span></li>
													<li><a href="http://www.zdnet.be/" target="_blank">ZDNet Belgium</a></li>
													<li><a href="http://www.zdnet.com.cn/" target="_blank">ZDNet China</a></li>
													<li><a href="http://www.zdnet.fr/" target="_blank">ZDNet France</a></li>
													<li><a href="http://www.zdnet.de/" target="_blank">ZDNet Germany</a></li>
													<li><a href="http://www.zdnet.co.kr/ " target="_blank">ZDNet Korea</a></li>
													<li><a href="http://japan.zdnet.com/" target="_blank">ZDNet Japan</a></li>
													<li><a href="http://www.zdnet.nl/ " target="_blank">ZDNet Netherlands</a></li>
											</ul>
				</nav>
			</li>
		</ul>

		<ul class="bar mobile">
							<li class="nav expandable"><a class="title">Topics<span class="icon arrow"></span></a>
					<nav class="menu">
						<ul>
															<li><a href="http://www.zdnet.com/topic-debate-tech/">DebateTech</a></li>
															<li><a href="http://www.zdnet.com/topic-windows-xp-and-the-future-of-the-desktop/">Future of desktops</a></li>
															<li><a href="topic-cxo">CXO</a></li>
															<li><a href="http://www.zdnet.com/topic-telcos/">Telcos</a></li>
															<li><a href="http://www.zdnet.com/topic-cloud-how-to-do-saas-right/">SaaS</a></li>
															<li><a href="http://www.zdnet.com/topic-outsourcing/">Outsourcing</a></li>
															<li><a href="http://www.zdnet.com/topic-security/">Security</a></li>
															<li><a href="http://www.zdnet.com/topic-smartphones/">Smartphones</a></li>
															<li><a href="http://www.zdnet.com/topic-india/">All India</a></li>
															<li><a href="http://www.zdnet.com/topic-smbs/">SMBs</a></li>
															<li><a href=""></a></li>
															<li><a href=""></a></li>
															<li><a href=""></a></li>
															<li><a href=""></a></li>
															<li><a href=""></a></li>
													</ul>
					</nav>
				</li>
						<li class="nav expandable siteUtils"><a>Log In<span class="icon arrow"></span></a>
				<nav class="menu">
					<ul>
													<li><a href="http://www.zdnet.com/membership/log-in/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" data-member="showLogIn">Log In</a></li>
							<li><a href="http://www.zdnet.com/membership/register/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" data-omniture='{"channel":"processors", "reg_form_type":"short", "registration_driver":"header"}' data-member="showRegister">Join ZDNet</a></li> 
											</ul>
				</nav>
			</li>
		</ul>
	</nav>
</header>

<div id="mantle_skin">

            <div id="skin"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["skin"]) {
			googletag.cmd.push(function() {
				googletag.display("skin");
			});
		};
	});
	</script>

    

							<div id="page" >
							
    
	<div id="leaderTop" class="leader">
    <div class="container">
            <div id="leaderboard-top"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["leaderboard-top"]) {
			googletag.cmd.push(function() {
				googletag.display("leaderboard-top");
			});
		};
	});
	</script>

    		</div>
	</div>

						<div id="content" class="container">

						<div class="breakingNews"><span>JUST IN:</span> <a href="http://www.zdnet.com/microsoft-delivers-service-pack-1-for-office-2013-client-and-servers-7000026754/">Microsoft delivers Service Pack 1 for Office 2013 client and servers</a></div>



<script type="text/javascript">
  function showRecaptcha(element) {
    Recaptcha.create("6LczBtgSAAAAAEfZMKzfcE9k3F4WBiurn-feXRgJ", element, {
        theme: "red",
        callback: Recaptcha.focus_response_field
    });
  }
</script>



	

    
	
	

	<div id="main">

		
	    
		
					<div class="navSupplement">
				
					<p class="relatedTopics">
									Topic: <a href="/topic-processors/">Processors</a>	
						</p>

				
				<ul class="followOptions">
	<li>Follow via: </li>
	<li><a href="http://www.zdnet.com/topic-processors/rss.xml" title="RSS Feed" rel="nofollow"><span class="icon rss">RSS</span></a></li>
	<li><a href="http://www.zdnet.com/membership/create-alert/?url=http%3A%2F%2Fwww.zdnet.com%2Ftopic-processors%2Frss.xml&amp;subject=Processors&amp;frequency=weekly&amp;source=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" title="Create an Email Alert" rel="nofollow" data-member="gated" data-app_id="1101"><span class="icon alerts">Email Alert</span></a></li> 
</ul>

			</div>
				<article itemscope itemtype="http://schema.org/Article" id="siu-container" class="post">
							<header class="storyHeader">
			<h1 itemprop="headline">Sentience: The next moral dilemma</h1>
			<p itemprop="description" class="summary"><span>Summary:</span> Humankind will have to decide how to live with a new sentient race</p>
			<div class="byline">
													<div><a href="" class="thumb"><img src="http://cdn-static.zdnet.com/i/r/author/zdnet-staff-60x45.png?hash=MTIwAGL1BJ&upscale=1" alt="Richard Barry" width="60" height="45" /></a></div>
									
		<p class="meta" itemprop="author">By Richard Barry |			<time datetime="2001-01-24"  itemprop="datePublished">January 24, 2001 -- 17:30 GMT (23:00 IST)</time>
		</p>
														
		
	</div>
	    		<div id="siu-horizontal" data-module="sharebar" data-title="Sentience: The next moral dilemma" data-summary="Humankind will have to decide how to live with a new sentient race" data-url="http://www.zdnet.com/sentience-the-next-moral-dilemma-3002083942/" data-short-url="http://zd.net/1hX5mSF" data-action="text" data-content-id="" data-story-id="zdgl_3002083942" data-cmnt-count="2" ></div>

</header>
										<div class="storyBody" itemprop="articleBody">
		
		
		
		
						<p>Sometime in the future machines will reach a level of intelligence that will challenge, or even surpass our own.
</p>

<p>Revered members of the academic community deem the event an inevitability. These include names like Ray Kurzweil -- inventor of the first reading machine for the blind -- Berkeley's John Searle and perhaps the man who deserves most credit for adding legitimacy to this belief, Sun Microsystems' Bill Joy.
</p>

<p>If they are right, one day man will give life to a new race of intelligent sentient beings powered by artificial means.
</p>

<p>If we can, for argument's sake, agree that this is possible we should consider how a sentient artificial being would be received by man and by society. Would it be forced to exist like its automaton predecessors who have effectively been our slaves, or would it enjoy the same rights as the humans who created it, simply because of its intellect?
</p>

<p>It is an enormous question that touches religion, politics and law, but little consideration is given to dawn of a new intelligent species and to the rights an autonomous sentient being could.
</p>

<p>For a start, it would have to convince us that it was truly sentient: intelligent and able to feel (although it is debateable whether its feelings would mirror our own).
</p>

<p>Peter Garrett, director of research and education at pro-life charity Life takes a strong stance: &quot;I think it would take around four years of questioning before I would be satisfied that this being could be considered a person.&quot;
</p>

<p>Garrett's prudence is perhaps born of his strong religious convictions, which can weigh heavily people's thoughts about whether or not an artificial sentient being could ever hope to be seen as an autonomous person (not to be confused with becoming a human being).
</p>

<p>&quot;I think even when we grant the label <I>person</I> to this new entity, it would still not be a human being... It is still a man made being and not made in the image of God... and while that may not be important on one level -- I think the secular world and the secular legal system regard it as being very unimportant -- I feel that the robot would still be a product of humanity, whereas man is believed to be a creation of God, made in the image and likeness of God,&quot; he says.
</p>

<p>This is significant because it marks a boundary around us as a species and protects us from usurpers that can never hope to be like us. Or more accurately, like God.
</p>

<p>Garrett's way of thinking is reflected when you look at why moral abuses were inflicted, for example, on black people in South Africa. Venture into the northern province of Pretoria where hundreds of thousands of Boer -- the Dutch settlers who became the fathers of apartheid -- still send their children to white only schools -- Volkskool -- and you will be told that blacks are not, like them, made in the image of God.
</p>

<p>But Garrett thinks religions would be able, in the end, to cope with the idea of a new sentient race, and that these beings would be allowed to worship: &quot;I think the Catholic church would say: 'You are not a human being, you are not Imago Dei but you are a person and we should perhaps have a third Vatican council to discuss terms under which persons of your type can join the Catholic church. I think it might take some time and a fair bit of getting used to but I cannot see any justified reason why it could not happen.&quot;
</p>

<p>Even Buddhists, who profess to honour and respect &quot;all sentient beings&quot;, as written in the Dharma, admit to some confusion over artificial worshippers. &quot;Of course we believe all sentient beings have the right to live a full life with all the blessings all living creatures enjoy,&quot; a spokesman for the Buddhist Cooperative in London says. &quot;It is a curious thing to even imagine, but we believe all that has life has the right to enjoy it to its full. I see no reason to make an exception to this new life form, although I am sure initially many eyebrows will be raised, if only out of wonder.&quot;
</p>

<p>But Garrett believes that sentient beings will never be the <I>same</I> as humans. &quot;I think what we would have created would be yes a person, but not a human being and not Imago Dei. I still believe the category of human being would be very different, and one reason is that as human beings we have to move forward towards death and we have to learn how to face that. That is part of being human.&quot;
</p>

<p>In the film <I>Bicentennial Man</I> in which Robin Williams plays Andrew, a sentient robot who looks, feels and thinks like a human but is still classed as a droid, the death issue provides the final step toward the revered status of &quot;human&quot;. Andrew swaps his mechanical innards for a set of organic ones that eventually age and kill him off in his sleep, earning him the posthumous award of <I>human being</I>.
</p>

<p>The reality of artificial beings being granted immortality through upgrades and repairs does nothing to quell the fears of those who believe robots could one day replace man as Earth's dominant species. For them at least, the question is not about whether a robot is equal to man, but rather, through its intellect and potential immortality, superior to us -- some kind of god-like race.
</p>

<p><B>Take me Pt II/ <A href="http://www.zdnet.co.uk/news/2001/3/ns-20481.html">Legal protection and the right to choose</A>.</B>
</p>

<p><B>In <A href="http://www.zdnet.co.uk/news/specials/2001/01/ai/welcome.html">ZDNet's Artificial Intelligence Special</A>, ZDNet charts the road to sentience, examines the technologies that will take us from sci-fi to sci-fact, and asks if machines should have rights.</B>
</p>

<p><B>Have your say instantly, and see what others have said. Click on the <FONT COLOR="Red"> <A href="http://forums.zdnet.co.uk/community/wwwthreads.cgi?forum=anchordesk#ZDNetNews">TalkBack</A></FONT> button and go to the ZDNet News forum.</B>
</p>

<p><B>Let the editors know what you think in the <A href="/mailto:mailroomuk@zdnet.com">Mailroom</A>. And <A href="http://www.zdnet.co.uk/news/mailroom.html">read</A> what others have said.</B>
</p>

				
	


	</div>
	

							<p class="relatedTopics">
									Topic: <a href="/topic-processors/">Processors</a>						</p>

								
						<p class="fancy">Kick off your day with ZDNet's <a href="/newsletters/">daily email newsletter</a>. It's the freshest tech news and opinion, served hot. <a href="/newsletters/">Get it.</a></p>

		</article>

                        
<div id="nrelate_related_placeholder" data-nrelate="103" data-url="http://www.zdnet.com/sentience-the-next-moral-dilemma-3002083942/" data-region="in"></div>


        
        
		
		<section id="comments" class="module">
	<h2 class="heading"><span class="int">Talkback</span></h2>
	<div class="head">
		<div class="commentsCount"><span>2</span> comments</div>
					<div class="fancy"><a href="http://www.zdnet.com/membership/log-in/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-member="showLogIn"><strong>Log in</strong></a> or <a href="http://www.zdnet.com/membership/register/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-omniture='{"channel":"processors", "reg_form_type":"short", "registration_driver":"comments"}' data-member="showRegister"><strong>register</strong></a> to join the discussion</div>
			</div>
	<ul class="commentsList">
																				 
	 

<li id="comment-10191287" class="comment">
	<div class="commentWrapper">
		
		
						<div class="commentBody">as god made us in their image, so will we make things in our image. when this happens I believe only the qualities of the image will be apparent. Much like looking in a mirror at your own image. it looks like you, it emulates everything you do while you are in front of it, but under all circumstances it will always retain the qualities of an image and nothing more. That is why gods (while they are gods) are gods, and nothing more or less. Humans are humans, and computers are computers. It can be seen as a &quot;fail-safe system&quot; when dealing with the many mysteries of creation.</div>
		<div class="commentMeta">
			<div><img src="http://i1.zdnetstatic.com/gallery/6343316-40-40.jpg" alt="" class="avatar" height="40" width="40"></div>
																<div class="author">anonymous</div>
										<time>20 September, 2004 04:07</time>
		</div>
		<div class="commentActions">
							<a href="http://www.zdnet.com/membership/log-in/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-member="showLogIn"><span class="icon reply"></span> Reply</a> 
						<a href="http://www.zdnet.com/vote/" rel="nofollow" data-action="vote" data-asset-id="10191287" data-asset-content-type="comment" data-content-type="up"><span class="icon vote"></span> <span class="count"></span> <span class="suffix">Vote</span></a>
								</div>
	</div>
	</li>

																					 
	 

<li id="comment-10208419" class="comment">
	<div class="commentWrapper">
		
		
						<div class="commentBody">Computers are masters of illusion and every human attempt to rebuildt a computer as a human will always remain an illusion - it remains an appearance of something it is not. Time will decide whether man will master to discover the substance of his spirit and consciousness, but then he may ones again find himself standing before a galaxy of mysteries of which he has only discovered the first stars...<br />
<br />
Claudia</div>
		<div class="commentMeta">
			<div><img src="http://i1.zdnetstatic.com/gallery/6343316-40-40.jpg" alt="" class="avatar" height="40" width="40"></div>
																<div class="author">anonymous</div>
										<time>15 June, 2006 18:26</time>
		</div>
		<div class="commentActions">
							<a href="http://www.zdnet.com/membership/log-in/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-member="showLogIn"><span class="icon reply"></span> Reply</a> 
						<a href="http://www.zdnet.com/vote/" rel="nofollow" data-action="vote" data-asset-id="10208419" data-asset-content-type="comment" data-content-type="up"><span class="icon vote"></span> <span class="count"></span> <span class="suffix">Vote</span></a>
								</div>
	</div>
	</li>

										</ul>
			
	</section>
		
	</div>
	<!-- //main -->
	<aside id="secondary">
					

			
            <div id="marquee"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["marquee"]) {
			googletag.cmd.push(function() {
				googletag.display("marquee");
			});
		};
	});
	</script>

    
			
            <div id="vendor-text-link"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["vendor-text-link"]) {
			googletag.cmd.push(function() {
				googletag.display("vendor-text-link");
			});
		};
	});
	</script>

    
							
            <div id="mpu-top" class="mpu"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["mpu-top"]) {
			googletag.cmd.push(function() {
				googletag.display("mpu-top");
			});
		};
	});
	</script>

    

	        
            <div id="hotspot"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["hotspot"]) {
			googletag.cmd.push(function() {
				googletag.display("hotspot");
			});
		};
	});
	</script>

    
	        
            <div id="resource-center"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["resource-center"]) {
			googletag.cmd.push(function() {
				googletag.display("resource-center");
			});
		};
	});
	</script>

    
								<section class="module">
					<h2 class="heading"><span class="int">Related Stories</span></h2>
				<div class="box">
			<ul>
															<li>
															<div>
									<a href="http://www.zdnet.com/sentience-the-next-moral-dilemma-pt-ii-3002083943/" class="thumb">
										<img src="http://cdn-static.zdnet.com/i/r/library/uk-thumbs/processor-60x45.jpg?hash=ZQpmMJSuLG&amp;upscale=1" alt="Sentience: The next moral dilemma Pt II" width="60" height="45" />
									</a>
								</div>
														<div class="content">
								<p><a href="http://www.zdnet.com/sentience-the-next-moral-dilemma-pt-ii-3002083943/">Sentience: The next moral dilemma Pt II</a></p>
								
							</div>
						</li>
																				<li>
															<div>
									<a href="http://www.zdnet.com/ai-gets-down-to-business-3002083916/" class="thumb">
										<img src="http://cdn-static.zdnet.com/i/r/library/uk-thumbs/networking-60x45.jpg?hash=BGVmLmZ1ZQ&amp;upscale=1" alt="AI gets down to business" width="60" height="45" />
									</a>
								</div>
														<div class="content">
								<p><a href="http://www.zdnet.com/ai-gets-down-to-business-3002083916/">AI gets down to business</a></p>
								
							</div>
						</li>
																				<li>
															<div>
									<a href="http://www.zdnet.com/smart-chips-get-under-our-skin-3002083914/" class="thumb">
										<img src="http://cdn-static.zdnet.com/i/r/library/uk-thumbs/hardware-60x45.jpg?hash=ZwIuMJDlZw&amp;upscale=1" alt="Smart chips get under our skin" width="60" height="45" />
									</a>
								</div>
														<div class="content">
								<p><a href="http://www.zdnet.com/smart-chips-get-under-our-skin-3002083914/">Smart chips get under our skin</a></p>
								
							</div>
						</li>
																				<li>
															<div>
									<a href="http://www.zdnet.com/can-a-human-love-a-robot-3002083913/" class="thumb">
										<img src="http://cdn-static.zdnet.com/i/r/library/uk-thumbs/processor-60x45.jpg?hash=ZQpmMJSuLG&amp;upscale=1" alt="Can a human love a robot?" width="60" height="45" />
									</a>
								</div>
														<div class="content">
								<p><a href="http://www.zdnet.com/can-a-human-love-a-robot-3002083913/">Can a human love a robot?</a></p>
								
							</div>
						</li>
																</ul>
		</div>
	</section>

						
			
<section id="resourceCentre" class="module resourceCentre">
	<div class="header">
		<h2>Resource Centre</h2>
		<p>Useful content from our premier sponsors</p>
	</div>
	<ul>
					
				 
									
				<li class="collapse">
					<div><a href="http://pubads.g.doubleclick.net/gampad/clk?id=158731569&iu=/8264/in-zdnet" class="thumb" target="_blank"><img src="http://www.cnetdirectintl.com/direct/sg/2013/oracle/q4_saas/i/rescenter_60x46.gif" alt="" width="60" height="46" /></a></div>					<h3><a href="http://pubads.g.doubleclick.net/gampad/clk?id=158731569&iu=/8264/in-zdnet" target="_blank">Cloud: How to Do SaaS Right</a></h3>
					<p class="description"><a href="http://pubads.g.doubleclick.net/gampad/clk?id=158731569&iu=/8264/in-zdnet" target="_blank">In this ZDNet Special Feature, we offer guidance on avoiding the pitfalls of the cloud and choosing your SaaS partners well.</a></p>					<div class="more"><a href="http://pubads.g.doubleclick.net/gampad/clk?id=158731569&iu=/8264/in-zdnet" target="_blank">Read now</a></div>
				</li>
						</ul>
</section>

	        
            <div id="power-center"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["power-center"]) {
			googletag.cmd.push(function() {
				googletag.display("power-center");
			});
		};
	});
	</script>

    

	        				
									<section class="ad-adx">
	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<ins class="adsbygoogle" style="display:inline-block;width:300px;height:250px" 
	data-ad-slot="9418269643" 
	data-ad-client="ca-pub-1991679624331369"> 
	<!-- AFC - ZDNet --> 
	</ins>
	<script>
	(adsbygoogle = window.adsbygoogle || []).push({});
	</script>
</section>
						    

	        			<section class="module">
	<h2 class="heading"><span class="int">Facebook Activity</span></h2>
	<div class="fb-activity" data-site="zdnet.com" data-width="300" data-max-age="7" data-height="300" data-header="false" data-recommendations="true"></div>
</section>

			
				<section class="module medusa">
		<h2 class="heading"><span class="int">White Papers, Webcasts, &amp; Resources</span></h2>
		<div class="box">
			<ul>
									<li>
						<h3><a href="http://dw.cbsi.com/redir?tag=medccnbwp&siteId=86&ptid=2100&onid=800063&q=&ctype=docids&cval=32949453&destUrl=http%3A%2F%2Fwww.techrepublic.com%2Fresource-library%2Fwhitepapers%2Fadvanced-evasion-techniques-for-dummies%2F%3Fpromo%3D999516%26cval%3Dwhitepapers">Advanced Evasion Techniques for Dummies</a></h3>
						<p>This book provides an overview of network security in general and explains how cybercriminals can use hidden and mostly undetectable methods to penetrate network systems. <br><br>
You don't have to be a Security Expert to understand how Advanced Evasion Techniques will break the security protection model most businesses are using today. Download this book today to understand the threats and get useful pointers and advice to help secure your organisation.
</p>
					</li>
									<li>
						<h3><a href="http://dw.cbsi.com/redir?tag=medccnbwp&siteId=86&ptid=2100&onid=800063&q=&ctype=docids&cval=32946259&destUrl=http%3A%2F%2Fwww.techrepublic.com%2Fresource-library%2Fwhitepapers%2Fcryptolocker-your-money-or-your-life%2F%3Fpromo%3D999516%26cval%3Dwhitepapers">CryptoLocker - Your Money or Your Life</a></h3>
						<p>CryptoLocker belongs to a family of malware called "ransomware", which is designed to extort money from victims by denying them access to their personal files. Once CryptoLocker has infiltrated a computer, it holds files hostage by encrypting them with a unique key. Read more details on the challenges and the solution for this new and vicious from of malware.</p>
					</li>
									<li>
						<h3><a href="http://dw.cbsi.com/redir?tag=medccnbwp&siteId=86&ptid=2100&onid=800063&q=&ctype=docids&cval=32948303&destUrl=http%3A%2F%2Fwww.techrepublic.com%2Fresource-library%2Fwhitepapers%2Finfographic-who-s-minding-your-cloud%2F%3Fpromo%3D999516%26cval%3Dwhitepapers">Infographic: Who&#039;s minding your cloud?</a></h3>
						<p>Based on the results and findings from the "Security of Cloud Computing Users Study". Read this infographic and the report to gain insight on the current state of cloud security and to help you assess your company's cloud services and applications security.  </p>
					</li>
							</ul>
							<span style="display:none;">
    <img src="http://dw.cbsi.com/redir?tag=medicnbwp&siteId=86&ptid=2100&onid=800063&q=&ctype=docids&cval=32949453,32946259,32948303&destUrl=http%3A%2F%2Fb2b.cbsimg.net%2Fb.gif" width="1" height="1">
  </span>
					</div>
	</section>

				
            <div id="mpu-bottom" class="mpu"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["mpu-bottom"]) {
			googletag.cmd.push(function() {
				googletag.display("mpu-bottom");
			});
		};
	});
	</script>

    

			
							
		    	    		

	</aside>
	<!-- //secondary -->

			</div>
							
    
	<div id="leaderBottom" class="leader">
    <div class="container">
            <div id="leaderboard-bottom"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["leaderboard-bottom"]) {
			googletag.cmd.push(function() {
				googletag.display("leaderboard-bottom");
			});
		};
	});
	</script>

    		</div>
	</div>

					</div>
	</div>
<!-- //mantle skin -->

<footer role="contentinfo">
	<div class="container">
		
					<div class="row">
				<div class="column-8 siteHighlights">
					<h2>Featured Articles</h2>
					<div class="row">
													<article class="column-2">
																	<div>
										<a href="http://www.zdnet.com/au/aapt-ceo-departs-ahead-of-tpg-takeover-7000026778/" class="thumb">
											<img src="http://cdn-static.zdnet.com/i/r/story/70/00/026778/aapt-ceo-departs-ahead-of-tpg-takeover-60x45.jpg?hash=ZmqyMQZ2ZG&amp;upscale=1" data-src="http://cdn-static.zdnet.com/i/r/story/70/00/026778/aapt-ceo-departs-ahead-of-tpg-takeover-60x45.jpg?hash=ZmqyMQZ2ZG&amp;upscale=1" data-src-768="http://cdn-static.zdnet.com/i/r/story/70/00/026778/aapt-ceo-departs-ahead-of-tpg-takeover-140x105.jpg?hash=MQIyAmxkBG&amp;upscale=1" alt="AAPT CEO departs ahead of TPG takeover" class="lazyload" width="" height="" />
										</a>
									</div>
																<h3><a href="http://www.zdnet.com/au/aapt-ceo-departs-ahead-of-tpg-takeover-7000026778/">AAPT CEO departs ahead of TPG takeover</a></h3>
								
							</article>
																			<article class="column-2">
																	<div>
										<a href="http://www.zdnet.com/hello-ms-android-good-bye-windows-phone-7000026774/" class="thumb">
											<img src="http://cdn-static.zdnet.com/i/r/story/70/00/026774/ms-android-is-here-60x45.jpg?hash=ZQEzMwIvMw&amp;upscale=1" data-src="http://cdn-static.zdnet.com/i/r/story/70/00/026774/ms-android-is-here-60x45.jpg?hash=ZQEzMwIvMw&amp;upscale=1" data-src-768="http://cdn-static.zdnet.com/i/r/story/70/00/026774/ms-android-is-here-140x105.jpg?hash=LzAxAQt0Lm&amp;upscale=1" alt="Hello, MS-Android. Good-bye, Windows Phone" class="lazyload" width="" height="" />
										</a>
									</div>
																<h3><a href="http://www.zdnet.com/hello-ms-android-good-bye-windows-phone-7000026774/">Hello, MS-Android. Good-bye, Windows Phone</a></h3>
								
							</article>
																			<article class="column-2">
																	<div>
										<a href="http://www.zdnet.com/lenovo-thinkpad-yoga-review-a-flexible-hybrid-tablet-7000026411/" class="thumb">
											<img src="http://cdn-static.zdnet.com/i/r/story/70/00/026411/lenovo-thinkpad-yoga-review-a-flexible-hybrid-tablet-60x45.jpg?hash=ZGx4LmuzAz&amp;upscale=1" data-src="http://cdn-static.zdnet.com/i/r/story/70/00/026411/lenovo-thinkpad-yoga-review-a-flexible-hybrid-tablet-60x45.jpg?hash=ZGx4LmuzAz&amp;upscale=1" data-src-768="http://cdn-static.zdnet.com/i/r/story/70/00/026411/lenovo-thinkpad-yoga-review-a-flexible-hybrid-tablet-140x105.jpg?hash=Lmx1ZJSxAG&amp;upscale=1" alt="Lenovo ThinkPad Yoga review: A flexible hybrid tablet" class="lazyload" width="" height="" />
										</a>
									</div>
																<h3><a href="http://www.zdnet.com/lenovo-thinkpad-yoga-review-a-flexible-hybrid-tablet-7000026411/">Lenovo ThinkPad Yoga review: A flexible hybrid tablet</a></h3>
								
							</article>
																			<article class="column-2">
																																									<div>
									<a href="http://www.zdnet.com/debate/the-smartwatch-tomorrows-must-have-gear-or-a-waste-of-time/10135518/" class="thumb">
										<img src="http://cdn-static.zdnet.com/i/r/library/us-authors/larry-dignan-640x465-60x45.jpg?hash=AwOvLJAyA2&amp;upscale=1" data-src="http://cdn-static.zdnet.com/i/r/library/us-authors/larry-dignan-640x465-60x45.jpg?hash=AwOvLJAyA2&amp;upscale=1" data-src-768="http://cdn-static.zdnet.com/i/r/library/us-authors/larry-dignan-640x465-140x105.jpg?hash=BQL5LmxmMT&amp;upscale=1" alt="The smartwatch: Tomorrow&#039;s must-have gear or a waste of time?" class="lazyload" width="" height="" />
									</a>
								</div>
								<h3><a href="http://www.zdnet.com/debate/the-smartwatch-tomorrows-must-have-gear-or-a-waste-of-time/10135518/">The smartwatch: Tomorrow&#039;s must-have gear or a waste of time?</a></h3>
							</article>
											</div>
				</div>
				<nav class="column-2 footerMap">
					<h2>Around ZDNet</h2>
					<ul>
						<li><a href="http://www.zdnet.com/topic/">Topics</a></li>
						<li><a href="http://www.zdnet.com/broadband-speedtest/">Broadband Speed Test</a></li>
						<li><a href="http://www.zdnet.com/eventscalendar/">Events Calendar</a></li>
						<li><a href="http://www.zdnet.com/meet-the-team/">Meet the Team</a></li>
						<li><a href="http://www.zdnet.com/about/">About ZDNet</a></li>
						<li><a href="http://www.zdnet.com/sitemap/">Site Map</a></li>
					</ul>
				</nav>
				<nav class="column-2 footerMap">
					<h2>Services</h2>
					<ul>
													<li><a href="http://www.zdnet.com/membership/log-in/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-member="showLogIn">Log In</a> | <a href="http://www.zdnet.com/membership/register/?app_id=1101&amp;path=http%3A%2F%2Fwww.zdnet.com%2Fsentience-the-next-moral-dilemma-3002083942%2F" rel="nofollow" data-omniture='{"channel":"processors", "reg_form_type":"short", "registration_driver":"footer"}' data-member="showRegister">Join ZDNet</a></li>
												<li><a href="http://www.zdnet.com/membership/" rel="nofollow">Membership</a></li>
						<li><a href="http://www.zdnet.com/newsletters/">Newsletters</a></li>
						<li><a href="http://www.zdnet.com/rssfeeds/">RSS Feeds</a></li>
						<li><a href="http://www.zdnet.com/mobile-apps/">ZDNet Mobile</a></li>
						<li><a href="https://cbsi.secure.force.com/CBSi/knowledgehome">Site Assistance</a></li>
					</ul>
				</nav>
			</div>
		
				<p class="copyright">&copy; 2014 CBS Interactive. All rights reserved. <a href="http://legalterms.cbsinteractive.com/privacy" rel="nofollow" target="_blank">Privacy Policy</a> | <a href="https://cbsi.secure.force.com/CBSi/articles/FAQ/Managing-Cookies-PP?template=template_privacyzd&referer=privacyzd.com" rel="nofollow" target="_blank">Cookies</a> | <a href="https://cbsi.secure.force.com/CBSi/articles/FAQ/Third-Party-Online-Advertising?template=template_privacyzd&referer=privacyzd.com&cfs=default" rel="nofollow" target="_blank">Ad Choice</a> |  <a href="http://www.zdnet.com/advertise/?tag=boilerplate%3bz" rel="nofollow" target="_blank">Advertise</a> | <a href="https://cbsi.secure.force.com/CBSi/articles/FAQ/CBS-Interactive-Terms-of-Use?template=template_touzd&referer=touzd.com" rel="nofollow" target="_blank">Terms of Use</a></p>
					<div class="networkSites">
				<form>
					<label for="siteTarget">Visit other CBS Interactive sites</label>
					<select id="siteTarget" name="target" onchange="window.location=document.getElementById('siteTarget').options[document.getElementById('siteTarget').selectedIndex].value; return false">
						<option selected="selected" value="">Select Site</option>
						<option value="http://www.cbscares.com">CBS Cares</option>
						<option value="http://www.cbsfilms.com">CBS Films</option>
						<option value="http://www.cbsradio.com/streaming/index.html">CBS Radio</option>
						<option value="http://www.cbs.com">CBS.com</option>
						<option value="http://www.cbsinteractive.com">CBSInteractive</option>
						<option value="http://www.cbsnews.com">CBSNews.com</option>
						<option value="http://www.cbssports.com">CBSSports.com</option>
						<option value="http://www.chow.com">CHOW</option>
						<option value="http://www.clicker.com">Clicker</option>
						<option value="http://www.cnet.com">CNET</option>
						<option value="http://collegenetwork.cbssports.com">College Network</option>
						<option value="http://www.gamespot.com">GameSpot</option>
						<option value="http://www.last.fm">Last.fm</option>
						<option value="http://www.maxpreps.com">MaxPreps</option>
						<option value="http://www.metacritic.com">Metacritic.com</option>
						<option value="http://www.cbsnews.com/moneywatch/">Moneywatch</option>
						<option value="http://www.mysimon.com">mySimon</option>
						<option value="http://www.radio.com">Radio.com</option>
						<option value="http://www.search.com">Search.com</option>
						<option value="http://www.shopper.com">Shopper.com</option>
						<option value="http://www.sho.com">Showtime</option>
						<option value="http://www.smartplanet.com">SmartPlanet</option>
						<option value="http://www.techrepublic.com">TechRepublic</option>
						<option value="http://www.theinsider.com">The Insider</option>
						<option value="http://www.tv.com">TV.com</option>
						<option value="http://www.urbanbaby.com">UrbanBaby.com</option>
						<option value="http://www.zdnet.com">ZDNet</option>
					</select>
				</form>
			</div>
			</div>
</footer>


 
	<img src="http://ads.adzhub.com/seg?add=872804" width="1" height="1"/>
<script src="http://i1.zdnetstatic.com/js/iau-min-76485.js"></script>

<script src="/js/build-core.js?1392906500"></script>
<script>
(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
  js.async = true;
}(document, 'script', 'facebook-jssdk'));
</script>
<script>
 window.twttr = (function (d,s,id) {
    var t, js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return; js=d.createElement(s); js.id=id;
    js.src="//platform.twitter.com/widgets.js"; fjs.parentNode.insertBefore(js, fjs);
    return window.twttr || (t = { _e: [], ready: function(f){ t._e.push(f) } });
  }(document, "script", "twitter-wjs"));

twttr.ready(function (twttr)
{
	var opts   = {event  : 'share',
		      eventt : 'socialsite',
		      wdloc  : 'unknown'};
	var params = {ssite: 'twitter'};

	twttr.events.bind('follow', function(event)
	{
		var dom_element = event.target;		
		//CBSI.EventTracking.trackEvent({
	        //	ssite  : params.ssite,
	        //        event  : 'follow',
        	//        eventt : params.eventt || opts.eventt,
                //	wdloc  : params.wdloc || opts.wdloc,
	        //        wd     : params.wd || 'sharedropdown',
        	//        tasid  : DW.pageParams.asid || 0,
                //	tastid : DW.pageParams.astid || 0,
	        //        turl   : this.url,
        	//        tname  : this.title
		//});
	});
});
</script>

<script type="text/javascript">
	cbsiRunApexTargets(cbsiAdGlobal, 1000);
</script>


            <div id="interstitial"></div>
	<script type="text/javascript">
	$(function() {		if (adSlots["interstitial"]) {
			googletag.cmd.push(function() {
				googletag.display("interstitial");
			});
		};
	});
	</script>

    
<div id="omnitureTracking" style="display: none; height: 1px; width: 1px; top: 0px; left: 0px;">
<!-- SiteCatalyst code version: H.1.
Copyright 1997-2005 Omniture, Inc. More info available at
http://www.omniture.com -->
<script type="text/javascript">
if (s)
{
	s.pageName = 'zdgl:Sentience: The next moral dilemma:p1:text:Processors';
	s.channel = 'processors';
	s.server = 'zdnet.com';
	s.pageType = '';
	
	s.hier1 = 'zdgl:processors,text';

	s.prop1 = 'zdnet';	s.prop2 = 'in';	s.prop3 = 'responsive web';	s.prop7 = 'D=g';	s.prop8 = 'Sentience: The next moral dilemma | ZDNet';	s.prop9 = 'D=User-Agent';	s.prop10 = 'story';	s.prop11 = 'D=ch+\":\"+c10';	s.prop12 = '2100';	s.prop20 = 'Sentience: The next moral dilemma';	s.prop21 = 'Sentience: The next moral dilemma';	s.prop22 = 'text';	s.prop23 = 'Processors';	s.prop24 = page_guid;	s.prop30 = 'zdgl_3002083942';
	s.eVar1 = 'D=c1';
	s.eVar2 = 'D=c2';
	s.eVar3 = 'D=c3';
	s.eVar7 = 'D=g';
	s.eVar8 = 'D=c8';
	s.eVar10 = 'D=c10';
	s.eVar11 = 'D=ch+\":\"+c10';
	s.eVar12 = 'D=c12';
	s.eVar15 = '';
	s.eVar20 = 'D=c20';
	s.eVar21 = 'D=c21';
	s.eVar22 = 'D=c22';
	s.eVar23 = 'D=c23';
	s.eVar24 = 'D=c24';
	s.eVar26 = 'D=c26';
	s.eVar30 = 'D=c30';
	s.eVar32 = 'D=c32';
	s.eVar63 = 'D=c63';
	s.eVar69 = 'D=c69';

	s.list2 = 'zdgl:800063';
	s.list3 = '10001350';

	s.events = 'event30';

}
/************* DO NOT ALTER ANYTHING BELOW THIS LINE ! **************/
var s_code=s.t();if(s_code)document.write(s_code)//--></script>
<script type="text/javascript"><!--
if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
//--></script><!--/DO NOT REMOVE/-->
<!-- End SiteCatalyst code version: H.1. -->
</div>

<iframe name="__bkframe" height="0" width="0" frameborder="0" src="javascript:void(0)"></iframe><script type="text/javascript" src="http://tags.bkrtx.com/js/bk-coretag.js"></script><script type="text/javascript">
bk_addPageCtx("anon_id", $.cookie('XCLGFbrowser'));
bk_addPageCtx("site", "cnetzdnetglobalsite");
bk_addPageCtx("region", "in");
bk_addPageCtx("ptype", "story");
bk_addPageCtx("ch", "processors");
bk_addPageCtx("path", "in-zdnet/processors")
bk_addPageCtx("tag", "processors");
bk_ignore_meta = true;
bk_doJSTag(3319, 4);
</script>

<div id="DWClickTracking" style="display: none; height: 1px; width: 1px; top: 0px; left: 0px;">
	<script type="text/javascript">
				DW.clear();
        DW.trackClicks(DW.noTagClickHandler);
	</script>
</div>



		
<!-- CBSi Content Checker -->
	<!-- ClickTale Bottom part -->
	<script type='text/javascript'>
	    document.write(unescape("%3Cscript%20src='" +
	                            (document.location.protocol == 'https:' ?
	                             'https://clicktalecdn.sslcs.cdngc.net/' :
	                             'http://cdn.clicktale.net/') +
	                            "www09/ptc/5a999966-75a6-4b89-a92c-23702f4d9c94.js'%20type='text/javascript'%3E%3C/script%3E"));
	</script>
	<!-- ClickTale end of Bottom part -->

</body>
</html>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.theassc.org/>====================
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns:fb="http://www.facebook.com/2008/fbml" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="alternate" type="application/rss+xml" title="ASSC RSS" href="http://www.theassc.org/rss.xml" />
  <title>ASSC</title>
  <link type="text/css" rel="stylesheet" media="all" href="/files/assc/css/css_089b5823d0079f30702735e8f73ac925.css" />
  <script type="text/javascript" src="/files/assc/js/js_dccf49d2af55230566efe562eda22922.js"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
jQuery.extend(Drupal.settings, { "basePath": "/", "googleanalytics": { "trackOutgoing": 1, "trackMailto": 1, "trackDownload": 1, "trackDownloadExtensions": "7z|aac|avi|csv|doc|exe|flv|gif|gz|jpe?g|js|mp(3|4|e?g)|mov|pdf|phps|png|ppt|rar|sit|tar|torrent|txt|wma|wmv|xls|xml|zip" } });
//--><!]]>
</script>

<script type="text/javascript">
$(document).ready(function(){
  
$('.showhide').hide();

$(".showhidenext").click(function() {
$(this).parent().parent().next().next().toggle();
});

});

</script>


</head>
<body id="genesis-1b" >
  <div id="container" class="front not-logged-in no-sidebars">

    
    <div id="header" class="clear-block">

              <div id="branding">
	
                           
              <h1 class="logo-site-name">
                <span id="logo"><a href="/" title="Home page" rel="home"><img src="/files/assc/logo.jpg" alt="ASSC logo" /></a></span>                             </h1>
                      

        </div> <!-- /branding -->
      
      
              <div id="header-blocks" class="sectionregion"><div id="block-search-0" class="block block-search">

  
  <form action="/"  accept-charset="UTF-8" method="post" id="search-block-form">
<div><div class="container-inline">
  <div class="form-item" id="edit-search-block-form-1-wrapper">
 <label for="edit-search-block-form-1">Search this site: </label>
 <input type="text" maxlength="128" name="search_block_form" id="edit-search-block-form-1" size="15" value="" title="Enter the terms you wish to search for." class="form-text" />
</div>
<input type="submit" name="op" id="edit-submit" value="Search"  class="form-submit" />
<input type="hidden" name="form_build_id" id="form-af6b9449e5f131fd47069e480ff85533" value="form-af6b9449e5f131fd47069e480ff85533"  />
<input type="hidden" name="form_id" id="edit-search-block-form" value="search_block_form"  />
</div>

</div></form>

  
</div> <!-- /block --><div id="block-user-0" class="block block-user">

      <h2 class="title">Member Login</h2>
  
  <form action="/node?destination=node"  accept-charset="UTF-8" method="post" id="user-login-form">
<div><div class="form-item" id="edit-name-wrapper">
 <label for="edit-name">Username: <span class="form-required" title="This field is required.">*</span></label>
 <input type="text" maxlength="60" name="name" id="edit-name" size="15" value="" class="form-text required" />
</div>
<div class="form-item" id="edit-pass-wrapper">
 <label for="edit-pass">Password: <span class="form-required" title="This field is required.">*</span></label>
 <input type="password" name="pass" id="edit-pass"  maxlength="60"  size="15"  class="form-text required" />
</div>
<input type="submit" name="op" id="edit-submit-1" value="Log in"  class="form-submit" />
<div class="item-list"><ul><li class="first last"><a href="/user/password" title="Request new password via e-mail.">Request new password</a></li>
</ul></div><input type="hidden" name="form_build_id" id="form-61ee996aad7c043054adc85f3a45490f" value="form-61ee996aad7c043054adc85f3a45490f"  />
<input type="hidden" name="form_id" id="edit-user-login-block" value="user_login_block"  />

</div></form>

  
</div> <!-- /block --></div> <!-- /header-blocks -->
      
    </div> <!-- /header -->

    


          <div id="secondary-content" class="section region"><div id="block-nice_menus-1" class="block block-nice_menus">

  
  <ul class="nice-menu nice-menu-down" id="nice-menu-1"><li id="menu-254" class="menu-path-front"><a href="/" class="active">Home</a></li>
<li id="menu-51" class="menuparent menu-path-node-2"><a href="/about_assc">About us</a><ul><li id="menu-177" class="menu-path-node-560"><a href="/assc_executive_committee">Board</a></li>
<li id="menu-127" class="menu-path-node-562"><a href="/assc_committees">Committees</a></li>
<li id="menu-198" class="menu-path-node-564"><a href="/past_assc_leadership">Past Leadership</a></li>
<li id="menu-172" class="menu-path-node-563"><a href="/assc_bylaws">Bylaws</a></li>
<li id="menu-126" class="menu-path-node-561"><a href="/contact_us">Contact Us</a></li>
</ul>
</li>
<li id="menu-191" class="menuparent menu-path-node-496"><a href="/join_assc">Membership</a><ul><li id="menu-192" class="menu-path-node-496"><a href="/join_assc">Join ASSC</a></li>
<li id="menu-288" class="menu-path-node-2804"><a href="/membership_renewals">Membership Renewals</a></li>
<li id="menu-265" class="menu-path-node-2803"><a href="/member_benefits">Member Benefits</a></li>
</ul>
</li>
<li id="menu-143" class="menuparent menu-path-node-1472"><a href="/eprints_archive">Documents</a><ul><li id="menu-144" class="menu-path-search_publications"><a href="/search_publications">Search</a></li>
<li id="menu-286" class="menu-path-node-2807"><a href="/submit_publication">Submit</a></li>
</ul>
</li>
<li id="menu-53" class="menuparent menu-path-node-558"><a href="/student_pages/about_the_assc_student_committee">Students</a><ul><li id="menu-260" class="menu-path-node-730"><a href="/student_pages/news">News</a></li>
<li id="menu-266" class="menu-path-node-753"><a href="/student_pages/conference_photos">Conference Photos &amp; Reports</a></li>
<li id="menu-176" class="menu-path-node-567"><a href="/student_pages/assc_student_committee">Student Committee</a></li>
</ul>
</li>
<li id="menu-2696" class="menuparent menu-path-node-5725"><a href="/conferences" title="Conferences">Conferences</a><ul><li id="menu-3091" class="menuparent menu-path-node-8194"><a href="/assc_18" title="ASSC 18">ASSC 18 - 2014</a><ul><li id="menu-4765" class="menu-path-node-10555"><a href="/assc_18_symposia" title="ASSC 18 Symposia">Symposia</a></li>
<li id="menu-4766" class="menu-path-node-10556"><a href="/assc_18_tutorials" title="ASSC 18 Tutorials">Tutorials</a></li>
<li id="menu-2765" class="menu-path-node-5740"><a href="/assc_18_abstract_submission" title="ASSC 18 Abstract Submission">Abstract Submission</a></li>
<li id="menu-4776" class="menu-path-node-10611"><a href="/assc_18_registration" title="ASSC 18 - Registration">Registration</a></li>
<li id="menu-4767" class="menu-path-node-10588"><a href="/assc_18_dinner" title="ASSC 18 Dinner">Dinner</a></li>
<li id="menu-4768" class="menu-path-node-10601"><a href="/consciousness_here_there_everywhere_the_prospects_for_panpsychism" title="Consciousness - here, there, everywhere?  The prospects for panpsychism">Panpsychism Workshop</a></li>
<li id="menu-4761" class="menu-path-node-10489"><a href="/assc_18_accommodation" title="ASSC 18 Accommodation">Accommodation</a></li>
<li id="menu-4762" class="menu-path-node-10490"><a href="/assc_18_travel_and_local_information" title="ASSC 18 - Travel and local information">Travel &amp; Local Info</a></li>
</ul>
</li>
<li id="menu-3093" class="menuparent menu-path-node-8208"><a href="/future_conferences" title="Future Conferences">Future</a><ul><li id="menu-3092" class="menu-path-node-8203"><a href="/assc_19" title="ASSC 19">ASSC 19 - 2015</a></li>
<li id="menu-3222" class="menu-path-node-10248"><a href="/assc_20" title="ASSC 20">ASSC 20 - 2016</a></li>
</ul>
</li>
<li id="menu-157" class="menuparent menu-path-node-555"><a href="/past_conferences" title="">Past</a><ul><li id="menu-3084" class="menuparent menu-path-node-8164"><a href="/assc_17" title="ASSC 17">ASSC 17 - 2013</a><ul><li id="menu-3196" class="menu-path-node-8261"><a href="/assc_17_program" title="ASSC 17 Program">Program</a></li>
<li id="menu-3215" class="menu-path-node-8745"><a href="/program_book" title="Program Book">Program Book</a></li>
<li id="menu-3197" class="menu-path-node-8262"><a href="/assc_17_registration" title="ASSC 17 Registration">Registration</a></li>
<li id="menu-3195" class="menu-path-node-8241"><a href="/assc_17_abstract_submission" title="ASSC 17 Abstract Submission">Abstract Submission</a></li>
<li id="menu-3205" class="menu-path-node-8629"><a href="/assc_17_keynote_talks" title="ASSC 17 Keynote Talks">Keynotes</a></li>
<li id="menu-3201" class="menu-path-node-8503"><a href="/assc_17_symposia" title="Symposia">Symposia</a></li>
<li id="menu-3209" class="menu-path-node-8695"><a href="/assc_17_concurrent_talks" title="ASSC 17 Concurrent Talks">Concurrent Talks</a></li>
<li id="menu-3212" class="menu-path-node-8740"><a href="/assc_17_poster_sessions" title="ASSC 17 Poster Sessions">Poster Sessions</a></li>
<li id="menu-3213" class="menu-path-node-8742"><a href="/poster_sessions_addendum_errata_additions" title="Poster Sessions: Addendum (Errata)">Posters: Addendum (Errata &amp; Additions)</a></li>
<li id="menu-3203" class="menu-path-node-8522"><a href="/assc_17_tutorials" title="ASSC 17 Tutorials">Tutorials</a></li>
<li id="menu-3211" class="menu-path-https--maps.google.com-maps-msmsid202603254644207124157.0004dce3c35077dbeafacmsa0"><a href="https://maps.google.com/maps/ms?msid=202603254644207124157.0004dce3c35077dbeafac&amp;msa=0" title="">Consciousness Research Map</a></li>
<li id="menu-3214" class="menu-path-node-8744"><a href="/roundtable_discussion_debating_the_integrated_information_theory_of_consciousness_0" title="Roundtable Discussion: Debating the Integrated Information Theory of Consciousness">Roundtable: Debating IIT</a></li>
<li id="menu-3202" class="menu-path-node-8512"><a href="/assc_17_and_the_5d_institute_present_perception_and_action_in_immersive_worlds" title="ASSC 17 and the 5D Institute Present: Perception and Action in Immersive Worlds">Satellite: Perception and Action in Immersive Worlds</a></li>
<li id="menu-189" class="menu-path-node-487"><a href="/assc_17_accommodation" title="">Accommodations</a></li>
<li id="menu-3204" class="menu-path-node-8571"><a href="/assc_17_poster_and_talk_criteria" title="ASSC 17 Poster Criteria">Preparation of Posters &amp; Talks</a></li>
</ul>
</li>
<li id="menu-383" class="menuparent menu-path-node-5685"><a href="/conferences_assc16">ASSC 16 - July 2012</a><ul><li id="menu-3068" class="menu-path-node-7492"><a href="/assc16_keynotes_symposia" title="ASSC16 Keynotes &amp; Symposia">Keynotes &amp; Symposia</a></li>
<li id="menu-3077" class="menu-path-node-8123"><a href="/assc16_travel_information" title="ASSC16 Travel Information">Travel Information</a></li>
<li id="menu-3072" class="menu-path-node-7491"><a href="/assc16_tutorials" title="ASSC16 Tutorials">Tutorials</a></li>
<li id="menu-2948" class="menu-path-node-7275"><a href="/assc16_abstract_submission" title="ASSC16 Abstract Submission">Abstract Submission</a></li>
<li id="menu-3074" class="menu-path-node-7656"><a href="/neuropsychiatry_and_consciousness_bringing_consciousness_science_to_the_clinic" title="Neuropsychiatry and Consciousness: Bringing Consciousness Science to the Clinic">Satellite: Neuropsychiatry</a></li>
<li id="menu-3076" class="menu-path-node-7918"><a href="/assc16_registration" title="ASSC16 Registration">Registration</a></li>
<li id="menu-3073" class="menu-path-node-7712"><a href="/assc16_accommodation_information" title="ASSC16 Accommodation Information">Accommodation</a></li>
<li id="menu-3081" class="menu-path-node-8143"><a href="/online_discussions" title="Online Discussions">Online Discussions</a></li>
</ul>
</li>
<li id="menu-289" class="menuparent menu-path-node-2806"><a href="/conferences/assc_15">ASSC 15 - June 2011</a><ul><li id="menu-2763" class="menu-path-node-5739"><a href="/assc_15_schedule" title="ASSC 15 Schedule">Full Schedule</a></li>
<li id="menu-2859" class="menu-path-node-5847"><a href="/assc15_registration" title="ASSC15 - Registration">Registration</a></li>
<li id="menu-2940" class="menu-path-node-6549"><a href="/assc15_talks_posters" title="ASSC15 Talks &amp; Posters">Talks &amp; Posters</a></li>
<li id="menu-2858" class="menu-path-node-5846"><a href="/assc15_keynotes_symposia" title="ASSC15 Keynotes &amp; Symposia">Keynotes &amp; Symposia</a></li>
<li id="menu-2843" class="menu-path-node-5827"><a href="/assc15_tutorials" title="ASSC15 Tutorials">Tutorials</a></li>
<li id="menu-384" class="menu-path-node-5687"><a href="/conferences/assc_15/social_neuroscience_satellite">Social Neuroscience Satellite</a></li>
<li id="menu-2851" class="menu-path-node-5839"><a href="/metacogniton_and_consciousness_from_animals_to_humans" title="Metacogniton and Consciousness: from animals to humans">Metacognition Sattelite</a></li>
<li id="menu-385" class="menu-path-node-5688"><a href="/conferences/assc_15/neurophysiology_satellite">Neurophysiology Satellite</a></li>
<li id="menu-2941" class="menu-path-node-7009"><a href="/assc15_presenter_information" title="ASSC15 - Presenter Information">Presenter Information</a></li>
<li id="menu-2929" class="menu-path-node-6322"><a href="/assc15_accommondation_tourist_information_earthquake_updates" title="ASSC15 - Accommondation, Tourist Information &amp; Earthquake updates">Tourist Information &amp; Earthquake Updates</a></li>
</ul>
</li>
<li id="menu-287" class="menuparent menu-path-node-2800"><a href="/assc_14">ASSC 14</a><ul><li id="menu-382" class="menu-path-node-5671"><a href="/assc_14_registration">Registration</a></li>
<li id="menu-339" class="menu-path-node-5369"><a href="/assc_14_accommodation_information">Accommodation</a></li>
<li id="menu-366" class="menu-path-node-5448"><a href="/schedule_venue_overview">Schedule &amp; Venue Overview</a></li>
<li id="menu-373" class="menu-path-node-5548"><a href="/assc_14_program_titles_and_author_details_only">Program </a></li>
<li id="menu-374" class="menu-path-node-5549"><a href="/assc_14_full_program_including_abstracts">Full Program (With Abstracts)</a></li>
<li id="menu-343" class="menu-path-node-5380"><a href="/assc_14_tutorials">Tutorials</a></li>
<li id="menu-371" class="menu-path-node-5499"><a href="/assc14_presenter_information">Presenter Information</a></li>
<li id="menu-338" class="menu-path-node-5361"><a href="/assc_14_venue_tourist_information">Venue &amp; Tourist Info</a></li>
</ul>
</li>
<li id="menu-293" class="menuparent menu-path-node-5235"><a href="/assc_13_0">ASSC 13</a><ul><li id="menu-322" class="menu-path-node-5334"><a href="/abstract_booklet">Abstract booklet</a></li>
<li id="menu-323" class="menu-path-node-5340"><a href="/venue_information">Venues</a></li>
<li id="menu-324" class="menu-path-node-5341"><a href="/tutorials_0">Tutorials</a></li>
<li id="menu-326" class="menu-path-node-5343"><a href="/plenary_lectures">Plenary Lectures</a></li>
<li id="menu-327" class="menu-path-node-5344"><a href="/symposia">Symposia</a></li>
<li id="menu-328" class="menu-path-node-5345"><a href="/concurrent_talks">Concurrent Talks</a></li>
<li id="menu-329" class="menu-path-node-5346"><a href="/posters">Posters</a></li>
<li id="menu-330" class="menu-path-node-5347"><a href="/satellite_event">Satellite Event</a></li>
<li id="menu-331" class="menu-path-node-5348"><a href="/registration">Registration</a></li>
<li id="menu-332" class="menu-path-node-5349"><a href="/accomodation">Accomodation</a></li>
<li id="menu-325" class="menu-path-node-5342"><a href="/schedule">Schedule</a></li>
<li id="menu-333" class="menu-path-node-5350"><a href="/presenter_information">Presenter Information</a></li>
<li id="menu-334" class="menu-path-node-5352"><a href="/travel_information">Travel Information</a></li>
<li id="menu-335" class="menu-path-node-5358"><a href="/acknowledgements">Acknowledgements</a></li>
<li id="menu-336" class="menu-path-node-5359"><a href="/contact">Contact</a></li>
<li id="menu-337" class="menu-path-node-5360"><a href="/imprint">Imprint</a></li>
</ul>
</li>
<li id="menu-164" class="menuparent menu-path-node-580"><a href="/the_12th_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness_assc_12">ASSC 12</a><ul><li id="menu-165" class="menu-path-node-581"><a href="/committees">Committees</a></li>
<li id="menu-184" class="menu-path-node-682"><a href="/program_1">Program</a></li>
<li id="menu-202" class="menu-path-node-617"><a href="/presidential_address">Presidential address</a></li>
<li id="menu-180" class="menu-path-node-583"><a href="/keynote_speakers">Keynote speakers</a></li>
<li id="menu-200" class="menu-path-node-594"><a href="/symposium_speakers">Symposium speakers</a></li>
<li id="menu-201" class="menu-path-node-607"><a href="/tutorial_workshops">Tutorial workshops</a></li>
<li id="menu-233" class="menuparent menu-path-node-686"><a href="/poster_sessions">Poster Sessions</a><ul><li id="menu-234" class="menu-path-node-684"><a href="/poster_session_i">Session I</a></li>
<li id="menu-236" class="menu-path-node-685"><a href="/poster_sessions_ii">Session II</a></li>
</ul>
</li>
<li id="menu-231" class="menuparent menu-path-node-687"><a href="/concurrent_sessions_0">Concurrent sessions</a><ul><li id="menu-232" class="menu-path-node-683"><a href="/concurrent_session_i">Session I</a></li>
<li id="menu-235" class="menu-path-node-688"><a href="/concurrent_session_ii">Session II</a></li>
<li id="menu-238" class="menu-path-node-689"><a href="/concurrent_session_iii">Session III</a></li>
</ul>
</li>
<li id="menu-237" class="menu-path-node-690"><a href="/special_events">Special events</a></li>
</ul>
</li>
<li id="menu-203" class="menuparent menu-path-node-618"><a href="/the_11th_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness">ASSC 11</a><ul><li id="menu-209" class="menu-path-node-629"><a href="/committees_0">Committees</a></li>
<li id="menu-208" class="menu-path-node-628"><a href="/program_0">Program schedule</a></li>
<li id="menu-204" class="menu-path-node-620"><a href="/keynote_speakers_0">Keynote speakers</a></li>
<li id="menu-205" class="menu-path-node-624"><a href="/plenary_symposia">Plenary symposia</a></li>
<li id="menu-206" class="menu-path-node-625"><a href="/tutorials">Tutorial workshops</a></li>
<li id="menu-207" class="menu-path-node-627"><a href="/the_magic_of_consciousness_symposium">Magic symposium</a></li>
</ul>
</li>
<li id="menu-210" class="menuparent menu-path-node-630"><a href="/the_10th_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness_assc_10">ASSC 10</a><ul><li id="menu-213" class="menu-path-node-634"><a href="/committees_1">Committees</a></li>
<li id="menu-211" class="menu-path-node-632"><a href="/program_schedule">Program schedule</a></li>
<li id="menu-212" class="menu-path-node-633"><a href="/tutorial_workshops_0">Tutorial workshops</a></li>
</ul>
</li>
<li id="menu-214" class="menuparent menu-path-node-635"><a href="/the_9th_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness_assc9">ASSC 9</a><ul><li id="menu-215" class="menu-path-node-637"><a href="/committees_2">Committees</a></li>
<li id="menu-217" class="menu-path-node-639"><a href="/assc9_program_schedule">Program schedule</a></li>
<li id="menu-216" class="menu-path-node-638"><a href="/assc9_tutorial_workshops">Tutorial workshops</a></li>
</ul>
</li>
<li id="menu-173" class="menuparent menu-path-node-641"><a href="/the_8th_annual_conference_of_the_association_for_the_scientific_study_of_consiousness">ASSC 8</a><ul><li id="menu-221" class="menu-path-node-656"><a href="/committees_3">Committees</a></li>
<li id="menu-174" class="menu-path-node-642"><a href="/the_eighth_conference_of_the_association_for_the_scientific_study_of_consciousness">Program</a></li>
<li id="menu-218" class="menu-path-node-643"><a href="/workshops">Workshops</a></li>
<li id="menu-219" class="menuparent menu-path-node-644"><a href="/assc8_satellite_symposium">Satellite symposium</a><ul><li id="menu-220" class="menu-path-node-645"><a href="/satellite_symposium_workshops">Workshops</a></li>
</ul>
</li>
</ul>
</li>
<li id="menu-222" class="menuparent menu-path-node-667"><a href="/the_seventh_conference_of_the_association_for_the_scientific_study_of_consciousness">ASSC 7</a><ul><li id="menu-226" class="menu-path-node-671"><a href="/committees_4">Committees</a></li>
<li id="menu-225" class="menu-path-node-670"><a href="/assc_7_program">Program</a></li>
<li id="menu-224" class="menu-path-node-669"><a href="/plenary_speakers">Plenary speakers</a></li>
<li id="menu-223" class="menu-path-node-668"><a href="/workshops_0">Workshops</a></li>
</ul>
</li>
<li id="menu-227" class="menuparent menu-path-node-672"><a href="/the_sixth_conference_of_the_association_for_the_scientific_study_of_consciousness">ASSC 6</a><ul><li id="menu-229" class="menu-path-node-677"><a href="/scientific_program_overview">Program</a></li>
<li id="menu-228" class="menu-path-node-676"><a href="/plenary_speakers_0">Plenary speakers</a></li>
<li id="menu-230" class="menu-path-node-678"><a href="/concurrent_sessions">Sessions</a></li>
</ul>
</li>
<li id="menu-162" class="menuparent menu-path-node-691"><a href="/the_5th_annual_conference_of_the_association_for_the_scientific_study_of_consiousness">ASSC 5</a><ul><li id="menu-163" class="menu-path-node-726"><a href="/program">Program</a></li>
</ul>
</li>
<li id="menu-239" class="menuparent menu-path-node-692"><a href="/the_4th_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness_assc_4">ASSC 4</a><ul><li id="menu-255" class="menu-path-node-715"><a href="/assc4_committees">Committees</a></li>
<li id="menu-256" class="menu-path-node-716"><a href="/program_3">Program</a></li>
<li id="menu-258" class="menu-path-node-719"><a href="/abstracts">Abstracts</a></li>
<li id="menu-257" class="menu-path-node-718"><a href="/concurrent_sessions_2">Concurrent sessions</a></li>
<li id="menu-259" class="menu-path-node-720"><a href="/workshops_2">Workshops</a></li>
</ul>
</li>
<li id="menu-240" class="menuparent menu-path-node-693"><a href="/the_3rd_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness_assc_3">ASSC 3</a><ul><li id="menu-250" class="menu-path-node-711"><a href="/program_2">Program</a></li>
<li id="menu-251" class="menu-path-node-712"><a href="/concurrent_sessions_1">Concurrent sessions</a></li>
<li id="menu-252" class="menu-path-node-713"><a href="/poster_sessions_0">Poster sessions</a></li>
<li id="menu-249" class="menu-path-node-710"><a href="/workshops_1">Workshops</a></li>
</ul>
</li>
<li id="menu-242" class="menuparent menu-path-node-695"><a href="/the_2nd_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness_assc_2">ASSC 2</a><ul><li id="menu-253" class="menu-path-node-714"><a href="/audio_cuts">Audio cuts</a></li>
</ul>
</li>
<li id="menu-243" class="menu-path-node-696"><a href="/the_1st_annual_meeting_of_the_association_for_the_scientific_study_of_consciousness_assc_1">ASSC 1</a></li>
</ul>
</li>
</ul>
</li>
<li id="menu-185" class="menuparent menu-path-node-574"><a href="/journal_psyche">Journal Psyche</a><ul><li id="menu-2714" class="menuparent menu-path-node-5727"><a href="/archive" title="Archive">Archive</a><ul><li id="menu-380" class="menu-path-node-5638"><a href="/vol_16_no_1_2010" title="">Vol 16, No 1 (2010)</a></li>
<li id="menu-381" class="menu-path-node-5639"><a href="/vol_16_no_2_2010" title="">Vol 16, No 2 (2010)</a></li>
<li id="menu-357" class="menu-path-node-5401"><a href="/vol_15_no_1_2009">Vol 15 No 1 (2009)</a></li>
<li id="menu-356" class="menu-path-node-5399"><a href="/vol_15_no_2_2009">Vol 15 No 2 (2009)</a></li>
<li id="menu-355" class="menu-path-node-5397"><a href="/vol_14_2008">Vol 14 (2008)</a></li>
<li id="menu-354" class="menu-path-node-5395"><a href="/vol_13_2007">Vol 13 (2007)</a></li>
<li id="menu-353" class="menu-path-node-5394"><a href="/vol_12_2006">Vol 12 (2006)</a></li>
<li id="menu-352" class="menu-path-node-5393"><a href="/vol_11_2005">Vol 11 (2005)</a></li>
<li id="menu-350" class="menu-path-node-5391"><a href="/vol_9_2003">Vol 9 (2003)</a></li>
<li id="menu-349" class="menu-path-node-5390"><a href="/vol_8_2002">Vol 8 (2002)</a></li>
<li id="menu-348" class="menu-path-node-5389"><a href="/vol_7_2001">Vol 7 (2001)</a></li>
<li id="menu-347" class="menu-path-node-5388"><a href="/vol_6_2000">Vol 6 (2000)</a></li>
<li id="menu-346" class="menu-path-node-5387"><a href="/vol_5_1999">Vol 5 (1999)</a></li>
<li id="menu-345" class="menu-path-node-5386"><a href="/vol_4_1998">Vol 4 (1998)</a></li>
<li id="menu-319" class="menu-path-node-5385"><a href="/vol_3_1997">Vol 3 (1997)</a></li>
<li id="menu-320" class="menu-path-node-5384"><a href="/vol_2_1995_1996">Vol 2 (1995-6)</a></li>
<li id="menu-315" class="menu-path-node-5383"><a href="/vol_1_1994">Vol 1 (1994)</a></li>
</ul>
</li>
</ul>
</li>
<li id="menu-160" class="menuparent menu-path-node-348"><a href="/the_assc_william_james_prize_for_contributions_to_the_study_of_consciousness">James Prize</a><ul><li id="menu-161" class="menu-path-node-349"><a href="/past_recipients">Past Recipients</a></li>
</ul>
</li>
<li id="menu-2947" class="menu-path-node-7256"><a href="/assc_newsletters" title="ASSC Newsletters">Newsletters</a></li>
<li id="menu-386" class="menuparent menu-path-node-5710"><a href="/non_assc_links_and_events">Links</a><ul><li id="menu-3223" class="menu-path-node-10261"><a href="/jobs" title="Jobs">Jobs</a></li>
</ul>
</li>
</ul>

  
</div> <!-- /block --></div> <!-- /secondary-content -->
    



    
    <div id="columns"><div class="columns-inner clear-block">

      <div id="content-column"><div class="content-inner">

                  <div id="content-top" class="section region"><div id="block-nodeblock-5730" class="block block-nodeblock">

  
  <div id="node-5730" class="node clear-block">



  <div class="meta">
  
    </div>

  <div class="content">
    <p><strong>The ASSC is an academic society that promotes rigorous research directed toward understanding the nature, function, and underlying mechanisms of consciousness. The ASSC includes members working in the fields of cognitive science, medicine, neuroscience, philosophy, and other relevant disciplines in the sciences and humanities.</strong></p>

<p>The ASSC web site has several main functions:</p><p>* co-ordination of annual conferences on the scientific study of consciousness<br>* promotion of other activities in the field of consciousness studies (smaller conferences, mailing lists, bibliographic resource, etc.)<br>* maintain the Psyche journal archive<br>* highlight recipients of the William James Prize</p>  </div>

  </div>
  
</div> <!-- /block --></div> <!-- /content-top -->
        

        <div id="main-content" class="section region">
                                                  <div id="node-8194" class="node node-promoted node-teaser node-web_page">

      <h2 class="title">
      <a href="/assc_18" rel="bookmark">ASSC 18</a>
          </h2>
  
  
  
  <p><img src="/files/assc/websitebannerSmall_0.png" alt="" height="334" width="962"></p><h2 class="MsoNormal" style="margin-right: -52.8pt;">&nbsp;&nbsp; <a href="http://www.theassc.org/assc_18_abstract_submission">[Abstract Submission]</a>&nbsp; <a href="http://www.theassc.org/assc_18_symposia">[Symposia]</a>&nbsp; <a href="http://www.theassc.org/assc_18_tutorials">[Tutorials]</a>&nbsp; <a href="http://www.theassc.org/assc_18_registration">[Registration]</a>&nbsp; <a href="http://www.theassc.org/assc_18_dinner">[Dinner]</a>&nbsp; <a href="http://www.theassc.org/assc_18_accommodation">[Accommodation]</a>&nbsp; <a href="http://www.theassc.org/assc_18_travel_and_local_information">[Travel &amp; local info]</a></h2><p><strong>Local organising committee:</strong> <a href="mailto:b.vanswinderen@uq.edu.au">Bruno van Swinderen</a> (chair), Derek Arnold, Ross Cunnington</p><p><strong>Scientific program committee:</strong> <a href="mailto:ocarter@unimelb.edu.au">Olivia Carter</a> (chair), Sid Kouider, David Chalmers, Nao Tsuchiya, Qiufang Fu, Melanie Boly, Tobias Schlicht, Steve Fleming</p><p><strong>Date:</strong> July 16th-19th 2014</p><h1>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; ***** ABSTRACT SUBMISSION NOW OPEN *****</h1><h2>--------------------------------------------------------------------------------------------------------------------------------------------------</h2><h2>THE PROGRAM</h2>

<table class="mceVisualAid" align="left" border="0" cellpadding="0" height="389" width="840"><tbody><tr><td class="mceVisualAid" align="left" valign="middle"><h3>Keynote speakers: </h3>
<ul><li><strong>David Chalmers </strong>(Australian National University and New York University)<strong>&nbsp;</strong></li><li><strong>Emery Brown </strong>(Massachusetts Institute of Technology)</li><li><strong>Sheng He</strong> (University of Minnesota)</li><li><strong>Melanie Wilke</strong> (University Medical Centre Goettingen)</li><li><strong>Jesse Prinz </strong>(City University of New York)</li></ul><h3>Symposium Speakers: </h3><ul><li><strong>David Carmel </strong>(University of Edinburgh, UK)</li><li><strong>Joel Pearson</strong> (The University of New South Wales, Australia)</li><li><strong>Zoltan Dienes</strong> (University of Sussex, UK)</li><li><strong>Axel Cleeremans</strong> (UniversitÃ© Libre de Bruxelles, Belgium)</li><li><strong>Adam Shriver</strong> (The University of Pennsylvania, USA) </li><li><strong><strong>Victorial Braithwaite </strong></strong>(Pennsylvania State University, USA)&nbsp;&nbsp; </li><li><strong>Dan Weary </strong>(The University of British Columbia, Canada)</li><li><strong>D</strong><strong>avid Edelman </strong>(Bennington College, USA) </li><li><strong>Paula Droege </strong>(Pennsylvania State University, USA)</li><li><strong>Aaron Schurger </strong>(Ãcole Polytechnique FÃ©dÃ©rale de Lausanne, Switzerland)</li><li><strong>Marcellow Massimini</strong> (The University of Milan, Italy) </li><li><strong>Jacobo Sitt</strong> (L'Institut du Cerveau et de la Moelle ÃpiniÃ¨re, France) </li><li><strong>Anil Seth</strong> (University of Sussex, UK)</li><li><strong>Chiara Cirelli </strong>(University of Wisconsin-Madison, USA)</li><li><strong><strong>Francesca Siclari </strong></strong>(University of Wisconsin-Madison, USA)</li><li><strong><strong>Michael Czisch </strong></strong>(Max Planck Institute of Psychiatry, Germany) </li><li><strong><strong><strong>Thomas Metzinger </strong></strong></strong>(Johannes Gutenberg University of Mainz; Frankfurt Institute for Advanced Studies, Germany)</li><li><strong><strong><strong><strong>Jennifer Windt</strong></strong></strong></strong>  (Johannes Gutenberg University of Mainz, Germany) </li></ul></td><td class="mceVisualAid" align="left" valign="top"><h3>Tutorial &amp; Short-Course Presenters: </h3><ul><li><strong>Giulio Tononi </strong>(University of Wisconsin, USA) </li><li><strong>Christof Koch </strong>(Allen Institute for Brain Science)</li><li><strong>Naotsugu Tsuchiya</strong> (Monash University, Australia)</li><li><strong>Masafumi Oizumi </strong>(Riken Brain Science Institute, Japan)</li><li><strong>Larissa Albantakis</strong> (University of Wisconsin, USA)</li><li><strong>Claude Touzet </strong>(Aix-Marseille University, France)</li><li><strong>Colin Hales</strong> (The University of Melbourne, Australia)</li><li><strong>Andreas Keller </strong>(The Rockerfeller University, USA) </li></ul><p><br><br><br><br><br></p></td></tr></tbody></table><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2>--------------------------------------------------------------------------------------------------------------------------------------------------</h2><h2>THE VENUE</h2><p>Located on a lush subtropical setting on a bend in the Brisbane River, the <a href="http://www.uq.edu.au/">University of Queensland</a> is an easy ferry ride from downtown Brisbane, the state capital. July (the Australian winter) is the best season to visit tropical north Queensland and the Great Barrier Reef. The main conference will be held in the Advanced Engineering Building (AEB), which was constructed in 2013.&nbsp; It is uniquely designed to achieve harmony with the natural environment, reducing energy consumption and attaining certified 5 Star Green ratings.&nbsp;&nbsp; It houses the&nbsp; state-of-the-art GHD Auditorium, a 500-seat lecture theatre built in an earthy, timber style with beautiful lake views.</p><h2 class="MsoNormal" style="margin-right: -52.8pt;"><img style="margin-left: 100px; margin-right: 100px;" src="/files/assc/UQvenue.png" alt="" height="671" width="674"></h2><p class="MsoNormal" style="margin-right: -52.8pt;"><img style="margin-left: 100px; margin-right: 100px;" src="/files/assc/QBI_logo_UQGold_web1.jpg" alt="" height="154" width="580"></p><h2 class="MsoNormal" style="margin-right: -52.8pt;">&nbsp;&nbsp; <a href="http://www.theassc.org/assc_18_abstract_submission">[Abstract Submission]</a>&nbsp; <a href="http://www.theassc.org/assc_18_symposia">[Symposia]</a>&nbsp; <a href="http://www.theassc.org/assc_18_tutorials">[Tutorials]</a>&nbsp; <a href="http://www.theassc.org/assc_18_registration">[Registration]</a>&nbsp; <a href="http://www.theassc.org/assc_18_dinner">[Dinner]</a>&nbsp; <a href="http://www.theassc.org/assc_18_accommodation">[Accommodation]</a>&nbsp; <a href="http://www.theassc.org/assc_18_travel_and_local_information">[Travel &amp; local info]</a></h2><h2>--------------------------------------------------------------------------------------------------------------------------------------------------</h2><table border="0"><tbody><tr><td><a href="http://www.icon2014.org"><img src="/files/assc/ICON.png" alt="" height="176" width="483"></a></td><td><h2>Note that a week following the ASSC conference the international conference on 
cognitive neuroscience (ICON) will be held in Brisbane from July 27th-31st.&nbsp; In addition to the conference there are likely to be a number workshops and satellite events that will be of interest to some of you. Check the website for details <a href="http://acns.org.au/icon2014">www.icon2014.org</a> </h2></td></tr></tbody></table><p><span style="font-family: Arial; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; color: green;">&nbsp;</span><span style="font-family: Arial; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; color: black; mso-themecolor: text1;"><br></span></p>
  <ul class="links tags"><li class="taxonomy_term_263 first last"><a href="/category/access/public" rel="tag" title="">Public</a></li>
</ul>  
</div> <!-- /node -->        </div> <!-- /main-content -->

                
      </div></div> <!-- /content-column -->

      
      
    </div></div> <!-- /columns -->

    
          <div id="footer" class="section region"><div id="block-nodeblock-7287" class="block block-nodeblock">

  
  <div id="node-7287" class="node clear-block">



  <div class="meta">
  
    </div>

  <div class="content">
    <h2>ASSC Social Media </h2><p><strong>click to find out more</strong></p><p><a href="https://plus.google.com/b/118418999033484480977/"><img src="/files/assc/images/icon_gp24.png" alt="" height="24" width="24"></a>&nbsp;&nbsp;<a href="https://www.facebook.com/theASSC"><img src="/files/assc/images/icon_fb24.png" alt="" height="24" width="24"></a>&nbsp;&nbsp;<a href="https://twitter.com/#%21/TheASSC"><img src="/files/assc/images/icon_tw24.png" alt="" height="24" width="24"></a></p>  </div>

  </div>
  
</div> <!-- /block --></div> <!-- /footer -->
    
          <div id="footer-message"></div> <!-- /footer-message -->
    
  </div> <!-- /container -->

  <script type="text/javascript" src="/files/assc/js/js_029e5ddab09b55570379bf8e2eb74bf4.js"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
//--><!]]>
</script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
try{var pageTracker = _gat._getTracker("UA-8381165-16");pageTracker._trackPageview();} catch(err) {}
//--><!]]>
</script>

</body>
</html>++++++++++++++++++++<Over>++++++++++++++++++++
====================<https://sites.google.com/site/minddict/>====================
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage">
<head>
<meta http-equiv="X-UA-Compatible" content="chrome=1" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var b=window,e="chrome",g="tick",h="wtsrt_",l="tbsd_",m="tbnd_",n="start",p="_wtsrt",q="_tbnd",r="CSI/";(function(){function k(a){this.t={};this.tick=function(a,d,c){this.t[a]=[void 0!=c?c:(new Date).getTime(),d];if(void 0==c)try{b.console.timeStamp(r+a)}catch(f){}};this[g](n,null,a)}var a;b.performance&&(a=b.performance.timing);var s=a?new k(a.responseStart):new k;b.jstiming={Timer:k,load:s};if(a){var d=a.navigationStart,f=a.responseStart;0<d&&f>=d&&(b.jstiming.srt=f-d)}if(a){var c=b.jstiming.load;0<d&&f>=d&&(c[g](p,void 0,d),c[g](h,p,f),c[g](l,h))}try{a=null,b[e]&&b[e].csi&&(a=Math.floor(b[e].csi().pageT),
c&&0<d&&(c[g](q,void 0,b[e].csi().startE),c[g](m,q,d))),null==a&&b.gtbExternal&&(a=b.gtbExternal.pageT()),null==a&&b.external&&(a=b.external.pageT,c&&0<d&&(c[g](q,void 0,b.external.startE),c[g](m,q,d))),a&&(b.jstiming.pt=a)}catch(t){}})(); })()
</script>
<link rel="shortcut icon" href="/site/minddict/_/rsrc/1363539839581/favicon.ico" type="image/x-icon" />
<link rel="apple-touch-icon" href="https://ssl.gstatic.com/sites/p/0fe980/system/app/images/apple-touch-icon.png" type="image/png" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var d=window,e="length",h="",k="__duration__",l="function";function m(c){return document.getElementById(c)}d.byId=m;function n(c){return c.replace(/^\s+|\s+$/g,h)}d.trim=n;var p=[],q=0;d.JOT_addListener=function(c,a,b){var f=new String(q++);c={eventName:c,handler:a,compId:b,key:f};p.push(c);return f};d.JOT_removeListenerByKey=function(c){for(var a=0;a<p[e];a++)if(p[a].key==c){p.splice(a,1);break}};d.JOT_removeAllListenersForName=function(c){for(var a=0;a<p[e];a++)p[a].eventName==c&&p.splice(a,1)};
d.JOT_postEvent=function(c,a,b){var f={eventName:c,eventSrc:a||{},payload:b||{}};if(d.JOT_fullyLoaded)for(a=p[e],b=0;b<a&&b<p[e];b++){var g=p[b];g&&g.eventName==c&&(f.listenerCompId=g.compId||h,(g=typeof g.handler==l?g.handler:d[g.handler])&&g(f))}else d.JOT_delayedEvents.push({eventName:c,eventSrc:a,payload:b})};d.JOT_delayedEvents=[];d.JOT_fullyLoaded=!1;
d.JOT_formatRelativeToNow=function(c,a){var b=((new Date).getTime()-c)/6E4;if(1440<=b||0>b)return null;var f=0;60<=b&&(b/=60,f=2);2<=b&&f++;return a?d.JOT_siteRelTimeStrs[f].replace(k,Math.floor(b)):d.JOT_userRelTimeStrs[f].replace(k,Math.floor(b))}; })()
</script>
<script>


var webspace = {"scottyUrl":"/_/upload","isConsumer":true,"canPublishScriptToAnyone":true,"serverFlags":{"cajaBaseUrl":"//www.gstatic.com/caja","cajaDebugMode":false},"sharingUrlPrefix":"/_/sharing","csiReportUri":"https://gg.google.com/csi","sharingPolicy":"OPENED","analyticsAccountId":"","baseUri":"/site/minddict","name":"minddict","domain":"defaultdomain","features":{"ritzSupport":true,"asyncPermanentDelete":false,"horizontalNavLayout":true,"folderEmbed":true,"moreBackgroundTweaks":true,"flipFolderUrls":true,"animateNavigation":true,"driveInFileCabinet":true,"skiThemeIsDefault":true,"pdfEmbedSupport":false,"animateToc":true,"siteChromeSidebarWidgetsEditDialog":true,"canonicalLinkTagInHead":true,"analyticsTrackingForCorp":false,"driveImageEmbed":true,"siteChromeSystemFooterDialog":true,"plusOneButtonOptions":true,"plusOneButton":true,"adSenseDeprecate":true,"photoAlbumsInOnePick":true,"docosHideNotificationSettings":true,"skiTheme":true,"siteChromeDialogsToolbar":true,"plusBadge":false,"siteChromeHorizontalNavigationDialog":true,"youTubeEmbedSize":true,"adSenseDeprecateMsg":true,"htmlEmbed":true,"plusPost":true,"siteChromeHeaderDialog":true,"photoAlbumsGPlusUrlSupport":true,"sitesLoveFixes":true},"adsensePublisherId":null,"gvizVersion":1,"siteTitle":"Dictionary of Philosophy of Mind","pageSharingId":"jotspot_page","plusPageId":"","onepickBaseUrl":"https://docs.google.com","termsUrl":"http://sites.google.com/site/sites/system/app/pages/meta/terms","enableAnalytics":false,"isPublic":true,"plusPageUrl":"","homePath":"/","sharingId":"jotspot","isAdsenseEnabled":true,"adsensePromoClickedOrSiteIneligible":true,"isStartPageEnabled":false,"domainAnalyticsAccountId":""};



webspace.gadgets = {"baseUri":"/site/minddict/system/app/pages/gadgets"};


webspace.user = {"uid":"","renderMobile":false,"primaryEmail":"guest","sessionIndex":"","namespaceUser":false,"displayNameOrEmail":"guest","namespace":"","hasAdminAccess":false,"guest_":true,"keyboardShortcuts":true,"domain":"","hasWriteAccess":false,"dasherUser":false,"userName":"guest"};

webspace.page = {"canDeleteWebspace":null,"locale":"en","state":"","wuid":"wuid:gx:47c5a288cbd4f47b","pageInheritsPermissions":null,"timeZone":"America/Los_Angeles","properties":{},"type":"text","canChangePath":false,"parentWuid":null,"revision":80,"title":"Home","isRtlLocale":false,"bidiEnabled":false,"siteLocale":"en","name":"home","path":"/home","isSiteRtlLocale":false,"parentPath":null};
webspace.page.breadcrumbs = [{"title":"Home","dir":"ltr","path":"/site/minddict/home","deleted":false}];


webspace.editorResources = {
  text: [
    'https://ssl.gstatic.com/sites/p/0fe980/system/js/codemirror.js',
    'https://ssl.gstatic.com/sites/p/0fe980/system/app/css/codemirror_css.css',
    'https://ssl.gstatic.com/sites/p/0fe980/system/js/trog_edit__en.js',
    'https://ssl.gstatic.com/sites/p/0fe980/system/app/css/trogedit.css',
    '/site/minddict/_/rsrc/1392203398000/system/app/css/editor.css',
    'https://ssl.gstatic.com/sites/p/0fe980/system/app/css/codeeditor.css',
    '/site/minddict/_/rsrc/1392203398000/system/app/css/camelot/editor-jfk.css'
  ],
  sitelayout: [
    'https://ssl.gstatic.com/sites/p/0fe980/system/app/css/sitelayouteditor.css'
  ]
};

var JOT_clearDotPath = 'https://ssl.gstatic.com/sites/p/0fe980/system/app/images/cleardot.gif';


var JOT_userRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];


webspace.siteTemplateId = false;


webspace.page.currentTemplate = {"title":"Web Page","path":"/system/app/pagetemplates/text"};



var JOT_siteRelTimeStrs = ["a minute ago","__duration__ minutes ago","an hour ago","__duration__ hours ago"];

</script>
<script type="text/javascript">
                window.jstiming.load.tick('scl');
              </script>
<meta name="title" content="Dictionary of Philosophy of Mind" />
<meta itemprop="name" content="Dictionary of Philosophy of Mind" />
<meta property="og:title" content="Dictionary of Philosophy of Mind" />
<meta name="description" content="This dictionary is intended as a free resource for all those interested in the philosophy of mind. It is designed to provide general information about key terms and concepts in order to aid those new to the discipline, or for those who are curious about current views in the field." />
<meta itemprop="description" content="This dictionary is intended as a free resource for all those interested in the philosophy of mind. It is designed to provide general information about key terms and concepts in order to aid those new to the discipline, or for those who are curious about current views in the field." />
<meta id="meta-tag-description" property="og:description" content="This dictionary is intended as a free resource for all those interested in the philosophy of mind. It is designed to provide general information about key terms and concepts in order to aid those new to the discipline, or for those who are curious about current views in the field." />
<style type="text/css">
      
      @font-face {
  font-family: 'Montserrat Subrayada';
  font-style: normal;
  font-weight: 400;
  src: local('MontserratSubrayada-Regular'), url('//themes.googleusercontent.com/static/fonts/montserratsubrayada/v2/nzoCWCz0e9c7Mr2Gl8bbgkk91NeiEk8oQQPCeZ5CN8w.woff') format('woff');
}
@font-face {
  font-family: 'Montserrat Subrayada';
  font-style: normal;
  font-weight: 700;
  src: local('MontserratSubrayada-Bold'), url('//themes.googleusercontent.com/static/fonts/montserratsubrayada/v2/wf-IKpsHcfm0C9uaz9IeGKlknUw7DcFY8X2UkbwMLDg.woff') format('woff');
}
@font-face {
  font-family: 'Monda';
  font-style: normal;
  font-weight: 700;
  src: local('Monda Bold'), local('Monda-Bold'), url('//themes.googleusercontent.com/static/fonts/monda/v2/uCFS-jQepl-zVlhjycME2fesZW2xOQ-xsNqO47m55DA.woff') format('woff');
}
@font-face {
  font-family: 'Monda';
  font-style: normal;
  font-weight: 400;
  src: local('Monda Regular'), local('Monda-Regular'), url('//themes.googleusercontent.com/static/fonts/monda/v2/sk05J8GA1NvUxDnk43EgAQ.woff') format('woff');
}

    
    </style>
<link rel="stylesheet" type="text/css" href="https://ssl.gstatic.com/sites/p/0fe980/system/app/themes/simplywhite/standard-css-simplywhite-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="/site/minddict/_/rsrc/1392203398000/system/app/css/overlay.css?cb=simplywhite30a960px84236goog-ws-nav-leftnonethemedefaultstandard" />
<link rel="stylesheet" type="text/css" href="/site/minddict/_/rsrc/1392203398000/system/app/css/camelot/allthemes-view.css" />
<!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/site/minddict/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->
<title>Dictionary of Philosophy of Mind</title>
<script type="text/javascript">
                window.jstiming.load.tick('cl');
              </script>
</head>
<body xmlns="http://www.google.com/ns/jotspot" id="body" class=" en            ">
<script src="//www.gstatic.com/caja/5660/caja.js"> </script>
<script src="https://ssl.gstatic.com/sites/p/0fe980/system/js/jot_caja.js"> </script>
<div id="sites-page-toolbar" class="sites-header-divider">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-status" class="sites-status" style="display:none;"><div id="sites-notice" class="sites-notice" role="status" aria-live="assertive"> </div></div>
</div>
<div id="sites-chrome-everything-scrollbar">
<div id="sites-chrome-everything">
<div id="sites-chrome-page-wrapper" style="direction: ltr">
<div id="sites-chrome-page-wrapper-inside">
<div xmlns="http://www.w3.org/1999/xhtml" id="sites-chrome-header-wrapper" style="">
<table id="sites-chrome-header" class="sites-layout-hbox" cellspacing="0" style="">
<tr class="sites-header-primary-row" id="sites-chrome-userheader">
<td id="sites-header-title" class="" style="height: 84px"><div class="sites-header-cell-buffer-wrapper"><h2><a href="https://sites.google.com/site/minddict/" dir="ltr" id="sites-chrome-userheader-title">Dictionary of Philosophy of Mind</a></h2></div></td><td class="sites-layout-searchbox "><div class="sites-header-cell-buffer-wrapper"><form id="sites-searchbox-form" action="/site/minddict/system/app/pages/search"><input type="hidden" id="sites-searchbox-scope" name="scope" value="search-site" /><input type="text" id="jot-ui-searchInput" name="q" size="20" value="" aria-label="Search this site" /><div id="sites-searchbox-button-set" class="goog-inline-block"><div role="button" id="sites-searchbox-search-button" class="goog-inline-block jfk-button jfk-button-standard" tabindex="0">Search this site</div></div></form></div></td>
</tr>
<tr class="sites-header-secondary-row" id="sites-chrome-horizontal-nav">
<td colspan="2" id="sites-chrome-header-horizontal-nav-container">
<div class="sites-header-nav"><ul class="sites-header-nav-container-links"><li class="current"><a class="sites-navigation-link current" href="/site/minddict/home">Home</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="/site/minddict/deliverables">About</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="/site/minddict/index">Index</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="/site/minddict/contributors">Contributors</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="/site/minddict/contact">Contact Us</a></li><li class="unselected"><a class="sites-navigation-link unselected" href="/site/minddict/system/app/pages/sitemap/hierarchy">Sitemap</a></li></ul><div style="clear: both;"></div></div>
</td>
</tr>
</table> 
</div> 
<div id="sites-chrome-main-wrapper">
<div id="sites-chrome-main-wrapper-inside">
<table id="sites-chrome-main" class="sites-layout-hbox" cellspacing="0" cellpadding="{scmCellpadding}" border="0">
<tr>
<td id="sites-chrome-sidebar-left" class="sites-layout-sidebar-left" style="width:236px">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_2bd" class="sites-embed"><div class="sites-embed-content sites-sidebar-nav"><ul jotId="navList"></ul></div></div>
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_47459081075329534" class="sites-embed"><h4 class="sites-embed-title"></h4><div class="sites-embed-content sites-embed-content-sidebar-textbox"><div dir="ltr"><font face="arial, sans-serif"><div>Â </div><strong><div></div><font size="3"><div>Â Â Â Â Â Â Â Â Â  <img border="0" height="155" src="https://sites.google.com/site/minddict/_/rsrc/1374281297098/config/only-image-white-transparent.png" style="width:111px;height:135px" width="115" /></div></font><div>Â </div></strong><div><font size="5">Â Â  </font></div><div><strong><font size="3">Navigating the Dictionary:</font></strong>
</div><div style="font-size:medium">Â </div>
<div><font face="arial,sans-serif"><em><font size="3">There are different ways to navigate the dictionary. You can use our search engine at the top of the page, the index located in the menuÂ above, or browse entries alphabetically. </font></em><em><font size="3">Alphabetical entries can be accessed via the alphabetÂ on theÂ home page.</font></em></font></div>
<div style="font-size:medium">Â </div>
<div style="font-size:medium">Â </div>
<div style="font-size:medium">Â </div>
<div><strong><font size="3">Other Resources:</font></strong></div><font size="3">
</font><div><font size="3">Â <span><em>Â </em></span></font></div><em><font size="3">
</font></em><div><em><font size="3">- </font></em><a href="http://plato.stanford.edu/" rel="nofollow"><em><font size="3">Stanford Encyclopedia of Philosophy</font></em></a></div><div><em><font size="3">Â </font></em></div><em><font size="3">
</font></em><div><em><font size="3">- </font></em><a href="http://www.bcp.psych.ualberta.ca/~mike/Pearl_Street/Dictionary/" rel="nofollow"><em><font size="3">Dictionary of Cognitive Science</font></em></a></div><div><font size="3"><em>Â </em><em>Â </em></font></div><em><font size="3">
</font></em><div><em><font size="3">- </font></em><a href="http://philpapers.org/" rel="nofollow"><em><font size="3">Philpapers</font></em></a></div><div><em><font size="3">Â </font></em></div><div><div><em><font size="3">- </font></em><a href="http://www.iep.utm.edu/" rel="nofollow"><em><font size="3">Internet Encyclopedia of Philosophy</font></em></a></div></div><div><em><font size="3">Â </font></em></div><div><em><font size="3">- </font></em><a href="http://www.philjobs.org/" rel="nofollow"><em><font size="3">Philjobs: Jobs in Philosophy</font></em></a></div><em><font size="3">
</font></em><div><font size="2">Â </font></div>
<div>Â </div>
<div style="font-size:medium">Â </div>
<div style="text-align:left;display:block"><a href="https://sites.google.com/site/minddict/config/dict-bw.gif?attredirects=0" imageanchor="1"></a><a href="https://sites.google.com/site/minddict/config/dict-bw.gif?attredirects=0" imageanchor="1"></a></div>
<div style="font-size:medium">Â </div>
<div style="font-size:medium">Â Â </div>
<div style="font-size:medium">Â </div>
<div align="center" style="font-size:medium">Â </div>
<div style="text-align:left">Â </div>
<div style="text-align:left">Â </div>
</font>
<div><font face="arial, sans-serif" size="3">Â </font></div>
<div></div>
<p><font face="arial, sans-serif" size="3">Â </font></p></div></div></div>
</td>
<td id="sites-canvas-wrapper">
<div id="sites-canvas">
<div id="goog-ws-editor-toolbar-container"> </div>
<div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="display: none;">
</div>
<h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="display: none;" align="left">
<span id="sites-page-title" dir="ltr">Home</span>
</h3>
<div id="sites-canvas-main" class="sites-canvas-main">
<div id="sites-canvas-main-content">
<table xmlns="http://www.w3.org/1999/xhtml" cellspacing="0" class="sites-layout-name-one-column sites-layout-hbox"><tbody><tr><td class="sites-layout-tile sites-tile-name-content-1"><div dir="ltr"><div style="text-align:center"><img border="0" height="929" src="https://sites.google.com/site/minddict/_/rsrc/1364646973789/test2/logo4.jpg?height=929&amp;width=1691" style="width:591px;height:342px" width="1691" /></div>
<div style="text-align:center">
<div style="text-align:left">Â </div>
</div>
<div style="text-align:center">Â </div>
<div style="text-align:center">Â Â Â <font size="3">We hope you find this resource useful<br />
-- and make it even more so.</font>Â </div>
<table border="0" cellpadding="10" cellspacing="0">
<tbody>
<tr>
<td><div><font size="4">Â Â Â Â  </font></div><div><font size="3"><strong><a href="https://sites.google.com/site/minddict/home/icon_risks.gif?attredirects=0" imageanchor="1"><img border="0" height="64" src="https://sites.google.com/site/minddict/_/rsrc/1363539839581/home/icon_risks.gif?height=64&amp;width=63" style="width:39px;height:45px" width="63" /></a>Â Please note, this site is under heavy construction at the moment.Â  Old entries are in the process of being transferred over to the new site, and many of the links in entries have not been added yet.Â  The website should be fully updatedÂ by February 2014.</strong></font></div><div>Â </div><div>Â </div><div>Â Â </div><div><font size="3"><strong>Welcome to our new website!Â </strong></font></div><div>Â </div><div><font size="3">This dictionary is intended as a free resource for all those interested in the philosophy of mind. It is designed to provide general information about key terms and conceptsÂ in order to aid those new to the discipline, or for those who are curious about current views in the field.<br />
<br />
Please see the "about" tab for more details</font></div><div>Â </div><div><font size="3">Â 
</font></div>
<div><font size="4">Â </font></div><font size="4">
</font><div style="text-align:center"><a href="https://sites.google.com/site/minddict/a"><strong><font size="4">A</font></strong></a><strong><font size="4">Â  </font><a href="https://sites.google.com/site/minddict/b"><font size="4">B</font></a><font size="4">Â  </font><a href="https://sites.google.com/site/minddict/c"><font size="4">C</font></a><font size="4">Â  </font><a href="https://sites.google.com/site/minddict/d"><font size="4">D</font></a><font size="4">Â  </font><a href="https://sites.google.com/site/minddict/e"><font size="4">E</font></a><font size="4">Â  <a href="https://sites.google.com/site/minddict/f">F</a>Â  <a href="https://sites.google.com/site/minddict/g">G</a>Â  <a href="https://sites.google.com/site/minddict/h">H</a>Â  <a href="https://sites.google.com/site/minddict/i">I</a>Â  <a href="https://sites.google.com/site/minddict/j">J</a>Â  <a href="https://sites.google.com/site/minddict/k">K</a>Â  <a href="https://sites.google.com/site/minddict/l">L</a>Â  <a href="https://sites.google.com/site/minddict/m">M</a>Â  <a href="https://sites.google.com/site/minddict/n">N</a>Â  <a href="https://sites.google.com/site/minddict/o">O</a>Â  <a href="https://sites.google.com/site/minddict/p">P</a>Â  <a href="https://sites.google.com/site/minddict/q">Q</a>Â  <a href="https://sites.google.com/site/minddict/r">R</a>Â  <a href="https://sites.google.com/site/minddict/s">S</a>Â  TÂ  UÂ  VÂ  WÂ  XÂ  YÂ  ZÂ  Bios</font></strong></div>
<div>Â </div>
<div>Â </div><div>Â </div>
<div>
<hr />
</div>
<div style="text-align:center">Â Special Thanks to Anatoly Zhitnik forÂ designing the image above, andÂ <a href="http://www.logobee.com/" target="_blank" rel="nofollow"><font color="#0072c6">logo design</font></a> company <em>Logobee</em> for the design of our logo.</div><div style="text-align:center">Â </div>
<div>Â </div>
</td></tr>
</tbody>
</table></div></td></tr></tbody></table>
</div> 
</div> 
<div id="sites-canvas-bottom-panel">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-subpages"> </div>
</div>
</div> 
</td> 
</tr>
</table> 
</div> 
</div> 
<div id="sites-chrome-footer-wrapper">
<div id="sites-chrome-footer-wrapper-inside">
<div id="sites-chrome-footer">
</div>
</div>
</div>
</div> 
</div> 
<div id="sites-chrome-adminfooter-container">
<div xmlns="http://www.w3.org/1999/xhtml" class="sites-adminfooter"><p><a class="sites-system-link" href="https://www.google.com/a/UniversalLogin?service=jotspot&amp;continue=https://sites.google.com/site/minddict/home">Sign in</a>|<a class="sites-system-link" href="/site/minddict/system/app/pages/reportAbuse" target="_blank">Report Abuse</a>|<a class="sites-system-link" href="javascript:;" onclick="window.open(webspace.printUrl)">Print Page</a>|<a class="sites-system-link" href="/site/minddict/system/app/pages/removeAccess" target="_blank">Remove Access</a>|<span class="sites-system-link">Powered By</span> <b class="powered-by"><a href="http://sites.google.com">Google Sites</a></b></p></div>
</div>
</div> 
</div> 
<div id="sites-chrome-onebar-footer">
</div>

<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('sjl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" src="https://ssl.gstatic.com/sites/p/0fe980/system/js/jot_min_view__en.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    window.jstiming.load.tick('jl');
  </script>
<script xmlns="http://www.w3.org/1999/xhtml">
    
        sites.core.Analytics.createTracker();
        sites.core.Analytics.trackPageview();
      
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
                    sites.Searchbox.initialize(
                        'sites-searchbox-search-button',
                        {"object":[]}['object'],
                        'search-site',
                        {"label":"Configure search options...","url":"/site/minddict/system/app/pages/admin/settings"});
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
      gsites.HoverPopupMenu.createSiteDropdownMenus('sites-header-nav-dropdown', false);
    </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
            JOT_setupNav("2bd", "Other Philosophy Resources:", false);
            JOT_addListener('titleChange', 'JOT_NAVIGATION_titleChange', 'COMP_2bd');
          </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
  setTimeout(function() {
    var fingerprint = gsites.date.TimeZone.getFingerprint([]);
    gsites.Xhr.send('https://sites.google.com/site/minddict/_/tz', null, null, 'GET', null, null, { afjstz: fingerprint });
  }, 500);
</script>
<script xmlns="http://www.w3.org/1999/xhtml">
                    window.onload = function() {
                      if (false) {
                        JOT_setMobilePreview();
                      }
                      var loadTimer = window.jstiming.load;
                      loadTimer.tick("ol");
                      loadTimer["name"] = "load," + webspace.page.type + ",user_page";
                      window.jstiming.report(loadTimer, {}, 'https://gg.google.com/csi');
                    }
                  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
        JOT_insertAnalyticsCode(false);
      </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    var maestroRunner = new gsites.pages.view.SitesMaestroRunner(
        webspace, "en");
    maestroRunner.initListeners();
    maestroRunner.installEditRender();
  </script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript" defer="true">
  //<![CDATA[
    // Decorate any fastUI buttons on the page with a class of 'goog-button'.
    if (webspace.user.hasWriteAccess) {
      JOT_decorateButtons();
    }

    // Fires delayed events.
    (function() {
      JOT_fullyLoaded = true;
      var delayedEvents = JOT_delayedEvents;
      for (var x = 0; x < delayedEvents.length; x++) {
        var event = delayedEvents[x];
        JOT_postEvent(event.eventName, event.eventSrc, event.payload);
      }
      JOT_delayedEvents = null;
      JOT_postEvent('pageLoaded');
    })();
 //]]>
</script>
<script xmlns="http://www.w3.org/1999/xhtml" type="text/javascript">
    JOT_postEvent('decorateGvizCharts');
  </script>
<script type="text/javascript">
              JOT_postEvent('renderPlus', null, 'sites-chrome-main');
            </script>
<div id="server-timer-div" style="display:none"> </div>
<script>
          window.jstiming.load.tick('render');
        </script>
</body>
</html>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://consc.net/mindpapers/6/all>====================
<html>
<head>
<title>MindPapers: 6. Philosophy of Artificial Intelligence</title>
<link rel="icon" type="image/gif" href="/raw/icons/favicon-mp.gif" />
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta http-equiv="content-language=" content="en">
<meta name="description" content="A bibliography of work in the philosophy of mind, the philosophy of cognitive science, and the science of consciousness consisting of over 18,000 entries organized by fine-grained topics. Both online and offline material is included, with links wherever possible. Compiled by David Chalmers (editor) and David Bourget (assistant editor)."> 
<meta name="keywords" content="philosophy, mind, consciousness, qualia, phenomenology, intentionality, perception, cognitive science, online, reduction, supervenience, identity, behaviorism, causation, zombie, conceivability, chalmers, bourget">
<style>
body, td, p {
    font-size:14px;
    font-family: Arial,Verdana;
}
</style>
<link rel="stylesheet" href="/raw/style.css" type="text/css">
<link rel="stylesheet" href="/mindpapers/menustyle.css" type="text/css">
<script type='text/javascript' src='/raw/js/xpapers-m-j.js'></script>

<script language="Javascript">

</script>

<script language="Javascript">
    var reloadPage = new RegExp("(search\.pl|mindpapers\/|online\/)");
    var dont = new RegExp("((mindpapers|online)\/?#?[1-9]?$)|(\/pages\/|page=)");
    var u = window.location + "";
    function refreshSelect() {
        if (u.match(reloadPage) && !u.match(dont)) {
            refresh();
        }
    }

    /* Check that we don't have to change page to make old anchor valid */
    var m = u.match(/([1-9])\/all#([1-9])(.+)$/);
    if (m && m.length > 0) {
        var sp = new Array();
        sp["1.4h"] = "4";
        sp["1.4g"] = "4";
        sp["1.5c"] = "3";
        sp["1.5d"] = "3";
        sp["2.7"] = "5";
        sp["3.8"] = "5";
        sp["3.9"] = "5";
        sp["5.3"] = "5";
        sp["5.3a"] = "5";
        sp["5.3b"] = "5";
        sp["5.3c"] = "5";
        sp["5.3d"] = "5";
        sp["5.3e"] = "5";
        sp["5.3f"] = "3";
        sp["5.5"] = "5";
        var n = sp[m[2]+m[3]];
        if (n && n != m[1]) {
            window.location = "/mindpapers/" + n + "/all#" + m[2] + m[3];
        }

    }

  
</script>
</head>

<BODY onload="" TEXT="#000000" BGCOLOR="#FFFFFF" LINK="#0000EE" VLINK="#551A8B" ALINK="#FF0000">
<div style="display:none"><a href=http://deluxe-menu.com/>Javascript Menu by Deluxe-Menu.com</a></div>
<div style="background-color:#eee;margin-bottom:10px;text-align:center">
MindPapers is now part of <a href="http://philpapers.org">PhilPapers: online research in philosophy</a>, a new service with many more features.
</div>

<table width=100% border='0' cellpadding=0 cellspacing=0>

<tr>
    <td align=left height=35 width=600 style="border-bottom: 3px solid #006600"><a valign=absbottom alt="Table of contents" href="/mindpapers/"><img border=0 src="/raw/title9.jpg"></a></td>
    <td align=right valign=bottom style="border-bottom: 3px solid #006600">
     <span class="updated">
     &nbsp;
     
     

     </span>
    </td>
</tr>
<tr>
    <td colspan='2' style='background-color:#ffffff'><img border=0 style="padding:0px; margin:0px" src='/raw/spacer.gif' height=6></td>
</tr>
<tr>
    <td colspan='2' style="border-bottom:3px #006600 solid;background-color:#ffffff">
    <div class="compiled">
        &nbsp;Compiled by <a href="http://consc.net/chalmers">David Chalmers</a> (Editor) &amp; <a href="http://www.dbourget.com">David Bourget</a> (Assistant Editor), Australian National University. <a href="/mindpapers/suggestion.html">Submit an entry.</a>

    </div>

    <table cellpadding=0 cellspacing=0 border=0>
        <td valign=top>
            <noscript>
                <a href="/mindpapers//latest.html">Latest additions</a> |
                <a href="/mindpapers//offcampus.html">Off-campus access</a> |
                <a href="/mindpapers//suggestion.html">Submit and entry</a> |
                <a href="/mindpapers//bug.html">Bugs? Errors?</a> 
            </noscript>
        </td>
        <td width=15>
            &nbsp;
        </td>
        <td>
            <table border=0 cellpadding=0 cellspacing=0>
                <tr><td><img src='/raw/spacer.gif' height='3'></td></tr>
                <tr><td> <form name=myform style='display:inline' onsubmit="if ($F('topSearch') == 'search for..' || $F('topSearch').length < 3) { alert('You must specify a search query of three or more characters'); return false}" method=GET action="/mindpapers/search">
<div style="display:inline">
<!--<input type="hidden" name="renderer" value="HTMLRenderer">-->
<!--
<input type="hidden" name="editMode" value="">
<input type="hidden" name="TOC" value="">
<input type="hidden" name="root" value="6">
-->

<table border="0" cellpadding=0 cellspacing=0>
    <tr>
    <td>

    <input id="topSearch" type="text" name="searchStr" style="color:grey" onfocus="if (this.value == 'search for..') {this.value = '';this.style.color='black'}" value="search for..">
    </td>
    <td>
    &nbsp;<select name="filterMode" style="width:90px" onChange="adjust(selectVal(this),new Array('authors','keywords','advanced'))">
        <option name='keywords' value='keywords' >All fields</option>
        <option name='authors' value='authors' >Surname</option>
        <!--
        <option name='advanced' value='advanced' >Advanced</option>
        -->
    </select>
    </td>
    <td>
    &nbsp;<a href="javascript:myform.submit()"><img border=0 src="/raw//go3.gif"></a>
    </td>
    </tr>
</table>
</div>
</form>
 </td></tr>
            </table>
        </td>
        </tr>
        <tr height="9" style="height=9px">
        <td colspan=2></td>
        <td>
            <span style='vertical-align:top; font-size:9px;color:#666666;margin-bottom:0px;padding-bottom:0px'><a style="margin-bottom:0px;padding-bottom:0px" href="javascript:show('search_help')">click here for help on how to search</a></span>
            </td>
        </tr>
    </table>

<!-- SEARCH HELP -->
    <div id="search_help" style="display:none;" class="extra-header">
    <div class="search_tips">
    <h3>Search tips</h3>
    There are two kinds of search you can perform on MindPapers:
    <p><b>All fields</b></p>
    <p>This mode searches for entries containing the entered words in their title, author, date, comment field, or in any of many other fields showing on MindPapers pages. Entries are ranked by their relevance as calculated from the informativeness of the words they contain and their numbers. You may search for a literal string composed of several words by putting them in double quotation marks (")

    <p><b>Surname</b></p>
    <p>This mode searches for entries containing the text string you entered in their author field.  Note that the database does not have first names for all authors, so it is preferable to search only by surnames. If you search for a full name or a name with an initial, enter it in the format used internally by MindPapers, namely the "Lastname, Firstname" or "Lastname, F." format.

    <p><b>Remember: viewing options in the menu above affect the results you get when searching.</b>
    <p>Note that short and / or common words are ignored by the search engine. 
    <p><a href="javascript:hide('search_help');">close help</a>
    </div>
    </div>

<!-- OFF-CAMPUS ACCESS -->
    <div class="extra-header" style="text-align:right">&nbsp;
    <div id="notconfigured" style="text-align:right;display:inline"><span class="small"><a class="small perm" href='/mindpapers/offcampus.html'>Your browser is not configured for off-campus access. Click here to configure it.</a></span></div>
    <div id="configured" style="text-align:right;display:none"><span class="small"><a class="small perm" href='/mindpapers/offcampus.html'>Off-campus access settings.</a></span></div>
    <!--
    <script language="JavaScript">
        if (readCookie('ez-server').length <= 0) { show("notconfigured"); } else { show("configured"); }
        hide('failure'); hide('success');
    </script>
    -->

</td>
</tr>
</table> <!-- header -->


<div class='searchHeader'><div class='searchHeaderM'></div></div>
<p><span class='toc_heading'>6. Philosophy of Artificial Intelligence <span style='font-size:12px'>(<a style='font-size:12px' href='http://philpapers.org/browse/philosophy-of-artificial-intelligence'>Philosophy of Artificial Intelligence on PhilPapers</a>)</span></span></p>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.1</td><td>&nbsp;<a href='#.6.1'>Can Machines Think?</a> [506]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=21></td><td></td></tr></table></li>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.1a</td><td>&nbsp;<a href='#.6.1a'>The Turing Test</a> [101]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.1b</td><td>&nbsp;<a href='#.6.1b'>Godelian arguments</a> [87]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.1c</td><td>&nbsp;<a href='#.6.1c'>The Chinese Room</a> [113]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.1d</td><td>&nbsp;<a href='#.6.1d'>Machine Consciousness</a> [105]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.1e</td><td>&nbsp;<a href='#.6.1e'>Machine Mentality, Misc</a> [100]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
</ul>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.2</td><td>&nbsp;<a href='#.6.2'>Computation and Representation</a> [97]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=21></td><td></td></tr></table></li>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.2a</td><td>&nbsp;<a href='#.6.2a'>Symbols and Symbol Systems</a> [20]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.2b</td><td>&nbsp;<a href='#.6.2b'>Computational Semantics</a> [29]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.2c</td><td>&nbsp;<a href='#.6.2c'>Implicit/Explicit Rules and Representations</a> [17]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.2d</td><td>&nbsp;<a href='#.6.2d'>AI without Representation?</a> [12]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.2e</td><td>&nbsp;<a href='#.6.2e'>Computation and Representation, Misc</a> [19]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
</ul>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3</td><td>&nbsp;<a href='#.6.3'>Philosophy of Connectionism</a> [261]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=21></td><td></td></tr></table></li>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3a</td><td>&nbsp;<a href='#.6.3a'>Connectionism and Compositionality</a> [54]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3b</td><td>&nbsp;<a href='#.6.3b'>Representation in Connectionism</a> [43]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3c</td><td>&nbsp;<a href='#.6.3c'>Connectionism and Eliminativism</a> [20]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3d</td><td>&nbsp;<a href='#.6.3d'>The Connectionist/Classical Debate</a> [36]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3e</td><td>&nbsp;<a href='#.6.3e'>Subsymbolic Computation</a> [10]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3f</td><td>&nbsp;<a href='#.6.3f'>Philosophy of Connectionism, Misc</a> [76]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.3g</td><td>&nbsp;<a href='#.6.3g'>Philosophy of Connectionism, Foundational Empirical Issues</a> [22]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
</ul>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4</td><td>&nbsp;<a href='#.6.4'>Special Topics in AI</a> [186]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=21></td><td></td></tr></table></li>
</ul>
</ul>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td></td><td>&nbsp;<a href='#.'>The Singularity</a> [9]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=0></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td></td><td>&nbsp;<a href='#.'>Mind Uploading</a> [1]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=0></td><td></td></tr></table></li>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4a</td><td>&nbsp;<a href='#.6.4a'>Cyborgs</a> [0]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4b</td><td>&nbsp;<a href='#.6.4b'>Transhumanism</a> [0]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4c</td><td>&nbsp;<a href='#.6.4c'>Cybernetics</a> [1]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4d</td><td>&nbsp;<a href='#.6.4d'>Dynamical Systems</a> [57]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4e</td><td>&nbsp;<a href='#.6.4e'>The Nature of AI</a> [13]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4f</td><td>&nbsp;<a href='#.6.4f'>The Frame Problem</a> [34]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4g</td><td>&nbsp;<a href='#.6.4g'>AI Methodology</a> [35]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.4h</td><td>&nbsp;<a href='#.6.4h'>Robotics</a> [35]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
</ul>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5</td><td>&nbsp;<a href='#.6.5'>Computationalism</a> [103]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=21></td><td></td></tr></table></li>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a</td><td>&nbsp;<a href='#.6.5a'>Computation and Physical Systems</a> [85]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a.1</td><td>&nbsp;<a href='#.6.5a.1'>Computation and Physical Systems, Misc</a> [2]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=42></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a.2</td><td>&nbsp;<a href='#.6.5a.2'>Analog and Digital Computation</a> [14]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=42></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a.3</td><td>&nbsp;<a href='#.6.5a.3'>Computers</a> [1]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=42></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a.4</td><td>&nbsp;<a href='#.6.5a.4'>Implementing Computations</a> [4]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=42></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a.5</td><td>&nbsp;<a href='#.6.5a.5'>Noncomputable Processes</a> [1]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=42></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a.6</td><td>&nbsp;<a href='#.6.5a.6'>Pancomputationalism</a> [7]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=42></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.5a.7</td><td>&nbsp;<a href='#.6.5a.7'>Quantum Computation</a> [9]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=42></td><td></td></tr></table></li>
</ul>
</ul>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.6</td><td>&nbsp;<a href='#.6.6'>Philosophy of AI, Miscellaneous</a> [83]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=21></td><td></td></tr></table></li>
<ul class='toc_item'>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.6a</td><td>&nbsp;<a href='#.6.6a'>Philosophy of AI, General Works</a> [1]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
<li class='toc_item'><table style='margin:0; padding=0;' border=0 cellpadding=0 cellspacing=0><tr><td>6.6b</td><td>&nbsp;<a href='#.6.6b'>Philosophy of AI, Misc</a> [5]</td></tr><tr><td><img src='/raw/spacer.gif' height=0 width=28></td><td></td></tr></table></li>
</ul>
</ul>
</ul>
<div id='cat_6' class='cat_content'>
<div id='__new_entries_6__'></div><div id='__new_entry_6__' class='entry'></div>
<div id='_1_entry' class='entry'><span ><span class='name'>Broadbent, Donald E.</span> (ed.) (1993). <em><span class='pub_name'>The Simulation of Human Intelligence.</span></em></span> Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Simulation%20of%20Human%20Intelligence+author%3ABroadbent&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_2_entry' class='entry'><span ><span class='name'>Cloos, Christopher</span> (2005). The Utilibot Project: An Autonomous Mobile Robot Based on Utilitarianism.</span> In Anderson Michael, Anderson Susan &amp; Armen Chris (eds.), <em>AAAI Fall Symposium</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Utilibot%20Project+author%3ACloos&amp;btnG=Search'>Google</a>)</span><div id='_2_abstract' class='extra' style='font-size:12px;'>Abstract: As autonomous mobile robots (AMRs) begin living in the home, performing service tasks and assisting with daily activities, their actions will have profound ethical implications. Consequently, AMRs need to be outfitted with the ability to act morally with regard to human life and safety. Yet, in the area of robotics where morality is a relevant field of endeavor (i.e. human-robot interaction) the sub-discipline of morality does not exist. In response, the Utilibot project seeks to provide a point of initiation for the implementation of ethics in an AMR. The Utilibot is a decision-theoretic AMR guided by the utilitarian notion of the maximization of human well-being. The core ethical decision-making capacity of the Utilibot consists of two dynamic Bayesian networks that model human and environmental health, a dynamic decision network that accounts for decisions and utilities, and a Markov decision process (MDP) that decomposes the planning problem to solve for the optimal course of action to maximize human safety and well-being.</div>
</div><!--entry-->

<div id='_3_entry' class='entry'><span ><span class='name'>Goel, Vinod</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("GOEBR",this.href,0);return true;' href='http://philmat.oxfordjournals.org/cgi/reprint/2/1/89'>Book reviews.</a></span> <span class='pub_name'>Philosophia Mathematica</span> 2 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Book%20reviews+author%3AGoel&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_4_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1984). <a rel="nofollow" class='article_title' onclick='trackclick("HARVMM",this.href,0);return true;' href='http://www.ecs.soton.ac.uk/~harnad/Temp/Kata/verifying.minds.html'>Verifying machines' minds.</a></span> <span class='pub_name'>Contemporary Psychology</span> 29:389 - 391. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Verifying%20machines%27%20minds+author%3AHarnad&amp;btnG=Search'>Google</a>)</span><div id='_4_abstract' class='extra' style='font-size:12px;'>Abstract: he question of the possibility of artificial consciousness is both very new and very old. It is new in the context of contemporary cognitive science and its concern with whether a machine can be conscious; it is old in the form of the mind/body problem and the &quot;other minds&quot; problem of philosophy. Contemporary enthusiasts proceed at their peril if they ignore or are ignorant of the false starts and blind alleys that the older thinkers have painfully worked through</div>
</div><!--entry-->

<div id='_5_entry' class='entry'><span ><span class='name'>Morreau, Michael</span> &amp; <span class='name'>Kraus, Sarit</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("MORSTO",this.href,0);return true;' href='http://www.sciencedirect.com/science?_ob=MImg&amp;_imagekey=B6TYF-3VXR2J1-5-1&amp;_cdi=5617&amp;_user=961305&amp;_pii=S000437029800085X&amp;_orig=search&amp;_coverDate=11%2F30%2F1998&amp;_sk=998939998&amp;view=c&amp;wchp=dGLbVzW-zSkWb&amp;md5=1eae7443a37667f0619f1a553c8ff3b4&amp;ie=/sdarticle.pdf'>Syntactical Treatments of Propositional Attitudes.</a></span> <span class='pub_name'>Artificial Intelligence</span> 106 (1):161-177. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Syntactical%20Treatments%20of%20Propositional%20Attitudes+author%3AMorreau&amp;btnG=Search'>Google</a>)</span><div id='_5_abstract' class='extra' style='font-size:12px;'>Abstract: Syntactical treatments of propositional attitudes are attractive to artificial intelligence researchers. But results of Montague (1974) and Thomason (1980) seem to show that syntactical treatments are not viable. They show that if representation languages are sufficiently expressive, then axiom schemes characterizing knowledge and belief give rise to paradox. Des RiviÃ¨res and Levesque (1988) characterize a class of sentences within which these schemes can safely be instantiated. These sentences do not quantify over the propositional objects of knowledge and belief. We argue that their solution is incomplete, and extend it by characterizing a more inclusive class of sentences over which the axiom schemes can safely range. Our sentences do quantify over propositional objects.</div>
</div><!--entry-->

<div id='_6_entry' class='entry'><span ><span class='name'>PÃ¡ez, AndrÃ©s</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("PEZAET",this.href,0);return true;' href='http://www.springerlink.com/content/24u70623wu051007/fulltext.pdf'>Artificial explanations: The epistemological interpretation of explanation in ai.</a></span> <span class='pub_name'>Synthese</span> 170 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20explanations+author%3AP%C3%A1ez&amp;btnG=Search'>Google</a>)</span><div id='_6_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper I critically examine the notion of explanation used in artificial intelligence in general, and in the theory of belief revision in particular. I focus on two of the best known accounts in the literature: Pagnuccoâs abductive expansion functions and GÃ¤rdenforsâ counterfactual analysis. I argue that both accounts are at odds with the way in which this notion has historically been understood in philosophy. They are also at odds with the explanatory strategies used in actual scientific practice. At the end of the paper I outline a set of desiderata for an epistemologically motivated, scientifically informed belief revision model for explanation</div>
</div><!--entry-->
</div>
<p><a name='.6.1'></a><a name=''></a><span class='myh2'>6.1 Can Machines Think?</span></p>

<div id='cat_6.1' class='cat_content'>
<div id='__new_entries_6.1__'></div><div id='__new_entry_6.1__' class='entry'></div></div>
<p><a name='.6.1a'></a><a name=''></a><span class='myh3'>6.1a The Turing Test</span></p>

<div id='cat_6.1a' class='cat_content'>
<div id='__new_entries_6.1a__'></div><div id='__new_entry_6.1a__' class='entry'></div>
<div id='_7_entry' class='entry'><span ><span class='name'>Akman, Varol</span> &amp; <span class='name'>Blackburn, Patrick</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("AKMEAT",this.href,0);return true;' href='http://cogprints.org/1058/'>Editorial: Alan Turing and artificial intelligence.</a></span> <span class='pub_name'>Journal of Logic, Language and Information</span> 9 (4):391-395. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Editorial+author%3AAkman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_7_links")'>More links</a>)</span><div id='_7_abstract' class='extra' style='font-size:12px;'>Abstract: Department of Computer Engineering, Bilkent University, 06533 Ankara, Turkey E-mail: akman@cs.bilkent.edu.tr; http://www.cs.bilkent.edu.tr/?akman..</div>
<div id='_7_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/377438.html">http://citeseer.ist.psu.edu/377438.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=595992">http://portal.acm.org/citation.cfm?id=595992</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001058/00/intro.ps">http://cogprints.ecs.soton.ac.uk/archive/00001058/00/intro.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://www.cs.bilkent.edu.tr/~akman/jour-papers/jolli/jolli2000.pdf">http://www.cs.bilkent.edu.tr/~akman/jour-papers/jolli/jolli2000.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1058">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1058</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://www.springerlink.com/content/rm454307n5h9k066/fulltext.pdf">http://www.springerlink.com/content/rm454307n5h9k066/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=269485&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=269485&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://www.springerlink.com/index/RM454307N5H9K066.pdf">http://www.springerlink.com/index/RM454307N5H9K066.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMEAT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269485">http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269485</a><br></div></div>
</div><!--entry-->

<div id='_8_entry' class='entry'><span ><span class='name'>Alper, G.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("ALPAPT",this.href,0);return true;' href='http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=pubmed&amp;list_uids=2111562&amp;dopt=Citation'>A psychoanalyst takes the Turing test.</a></span> <span class='pub_name'>Psychoanalytic Review</span> 77:59-68. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1588737181936147927'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20psychoanalyst%20takes%20the%20Turing%20test+author%3AAlper&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_9_entry' class='entry'><span ><span class='name'>Barresi, John</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("BARPFT",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-5914.1987.tb00086.x'>Prospects for the cyberiad: Certain limits on human self-knowledge in the cybernetic age.</a></span> <span class='pub_name'>Journal for the Theory of Social Behavior</span> 17 (March):19-46. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13077617421699099522'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Prospects%20for%20the%20cyberiad+author%3ABarresi&amp;btnG=Search'>Google</a> | <a href='javascript:show("_9_links")'>More links</a>)</span>
<div id='_9_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BARPFT",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120019196/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120019196/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_10_entry' class='entry'><span ><span class='name'>Beenfeldt, Christian</span> (2006). The Turing test: An examination of its nature and its mentalistic ontology.</span> <span class='pub_name'>Danish Yearbook of Philosophy</span> 40:109-144. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test+author%3ABeenfeldt&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_11_entry' class='entry'><span ><span class='name'>Ben-Yami, Hanoch</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("BENBAP",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a713997477~fulltext=713240930'>Behaviorism and psychologism: Why Block's argument against behaviorism is unsound.</a></span> <span class='pub_name'>Philosophical Psychology</span> 18 (2):179-186. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14839291251449595281'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Behaviorism%20and%20psychologism+author%3ABen-Yami&amp;btnG=Search'>Google</a> | <a href='javascript:show("_11_links")'>More links</a>)</span><div id='_11_abstract' class='extra' style='font-size:12px;'>Abstract: Ned Block ((1981). Psychologism and behaviorism. Philosophical Review, 90, 5-43.) argued that a behaviorist conception of intelligence is mistaken, and that the nature of an agent's internal processes is relevant for determining whether the agent has intelligence. He did that by describing a machine which lacks intelligence, yet can answer questions put to it as an intelligent person would. The nature of his machine's internal processes, he concluded, is relevant for determining that it lacks intelligence. I argue against Block that it is not the nature of its processes but of its linguistic behavior which is responsible for his machine's lack of intelligence. As I show, not only has Block failed to establish that the nature of internal processes is conceptually relevant for psychology, in fact his machine example actually supports some version of behaviorism. As Wittgenstein has maintained, as far as psychology is concerned, there may be chaos inside</div>
<div id='_11_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BENBAP",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/MX24138627651300.pdf">http://taylorandfrancis.metapress.com/index/MX24138627651300.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BENBAP",this.href,0);return true;' href="http://www.informaworld.com/index/713997477.pdf">http://www.informaworld.com/index/713997477.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BENBAP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2005/00000018/00000002/art00002">http://www.ingentaconnect.com/content/routledg/cphp/2005/00000018/00000002/art00002</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BENBAP",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713997477~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713997477~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_12_entry' class='entry'><span ><span class='name'>Block, Ned</span> (1981). <a rel="nofollow" class='article_title' onclick='trackclick("BLOPAB",this.href,0);return true;' href='http://doran.persiangig.com/other/Psychologism.pdf'>Psychologism and behaviorism.</a></span> <span class='pub_name'>Philosophical Review</span> 90 (1):5-43. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16781673855197390448'>Cited by 88</a> | <span class='ll' onclick='$("_12_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Psychologism%20and%20behaviorism+author%3ABlock&amp;btnG=Search'>Google</a> | <a href='javascript:show("_12_links")'>More links</a>)</span><div id='_12_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A look-up table could pass the Turing test, and surely isn't intelligent. The TT errs in testing behavior and not mechanisms. A nice, thorough paper.</div></div><div id='_12_abstract' class='extra' style='font-size:12px;'>Abstract: Let psychologism be the doctrine that whether behavior is intelligent behavior depends on the character of the internal information processing that produces it. More specifically, I mean psychologism to involve the doctrine that two systems could have actual and potential behavior _typical_ of familiar intelligent beings, that the two systems could be exactly alike in their actual and potential behavior, and in their behavioral dispositions and capacities and counterfactual behavioral properties (i.e., what behaviors, behavioral dispositions, and behavioral capacities they would have exhibited had their stimuli differed)--the two systems could be alike in all these ways, yet there could be a difference in the information processing that mediates their stimuli and responses that determines that one is not at all intelligent while the other is fully intelligent</div>
<div id='_12_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BLOPAB",this.href,0);return true;' href="http://philosophy.wisc.edu/shapiro/Phil951/Block.pdf">http://philosophy.wisc.edu/shapiro/Phil951/Block.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BLOPAB",this.href,0);return true;' href="http://www.nyu.edu/gsas/dept/philo/faculty/block/papers/Psychologism.pdf">http://www.nyu.edu/gsas/dept/philo/faculty/block/papers/Psychologism.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BLOPAB",this.href,0);return true;' href="http://www.nyu.edu/gsas/dept/philo/faculty/block/papers/Psychologism.htm">http://www.nyu.edu/gsas/dept/philo/faculty/block/papers/Psychologism.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BLOPAB",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0031-8108(198101)90:1&lt;5:PAB&gt;2.0.CO;2-J">http://links.jstor.org/sici?sici=0031-8108(198101)90:1<5:PAB>2.0.CO;2-J</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BLOPAB",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8108(198101)90:1&lt;5:PAB&gt;2.0.CO;2-J">http://www.jstor.org/sici?sici=0031-8108(198101)90:1<5:PAB>2.0.CO;2-J</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BLOPAB",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2184371.pdf">http://www.jstor.org/stable/pdfplus/2184371.pdf</a><br></div></div>
</div><!--entry-->

<div id='_13_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BRIAZA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/302190.html'>Animals, zombanimals, and the total Turing test: The essence of artificial intelligence.</a></span> <span class='pub_name'>Journal of Logic Language and Information</span> 9 (4):397-418. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11151800594851133254'>Cited by 32</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Animals%2C%20zombanimals%2C%20and%20the%20total%20Turing%20test+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_13_links")'>More links</a>)</span>
<div id='_13_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIAZA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=595843.595993">http://portal.acm.org/citation.cfm?id=595843.595993</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIAZA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/bringsjord00animals.html">http://citeseer.ist.psu.edu/bringsjord00animals.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIAZA",this.href,0);return true;' href="http://www.rpi.edu/~faheyj2/SB/SELPAP/ZOMBANIMALS/zombanimals2.pdf">http://www.rpi.edu/~faheyj2/SB/SELPAP/ZOMBANIMALS/zombanimals2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIAZA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=269486&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=269486&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIAZA",this.href,0);return true;' href="http://www.springerlink.com/index/TV852P4283211235.pdf">http://www.springerlink.com/index/TV852P4283211235.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIAZA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269486">http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269486</a><br></div></div>
</div><!--entry-->

<div id='_14_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span>; <span class='name'>Caporale, Clarke</span> &amp; <span class='name'>Noel, Ron</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BRIAZA-2",this.href,0);return true;' href='http://www.springerlink.com/content/tv852p4283211235/fulltext.pdf'>Animals, zombanimals, and the total Turing test.</a></span> <span class='pub_name'>Journal of Logic, Language and Information</span> 9 (4). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Animals%2C%20zombanimals%2C%20and%20the%20total%20Turing%20test+author%3ABringsjord&amp;btnG=Search'>Google</a>)</span><div id='_14_abstract' class='extra' style='font-size:12px;'>Abstract:  Alan Turing devised his famous test (TT) through a slight modificationof the parlor game in which a judge tries to ascertain the gender of twopeople who are only linguistically accessible. Stevan Harnad hasintroduced the Total TT, in which the judge can look at thecontestants in an attempt to determine which is a robot and which aperson. But what if we confront the judge with an animal, and arobot striving to pass for one, and then challenge him to peg which iswhich? Now we can index TTT to a particular animal and its syntheticcorrelate. We might therefore have TTTrat, TTTcat,TTTdog, and so on. These tests, as we explain herein, are abetter barometer of artificial intelligence (AI) than Turing's originalTT, because AI seems to have ammunition sufficient only to reach thelevel of artificial animal, not artificial person</div>
</div><!--entry-->

<div id='_15_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span>; <span class='name'>Bello, P.</span> &amp; <span class='name'>Ferrucci, David A.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("BRICTT-3",this.href,0);return true;' href='http://citeseer.ist.psu.edu/372829.html'>Creativity, the Turing test, and the (better) Lovelace test.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (1):3-27. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11337573643143181580'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Creativity%2C%20the%20Turing%20test%2C%20and%20the%20%28better%29%20Lovelace%20test+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_15_links")'>More links</a>)</span><div id='_15_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The Turing Test (TT) is claimed by many to be a way to test for the presence, in computers, of such ``deep'' phenomena as thought and consciousness. Unfortunately, attempts to build computational systems able to pass TT (or at least restricted versions of this test) have devolved into shallow symbol manipulation designed to, by hook or by crook, trick. The human creators of such systems know all too well that they have merely tried to fool those people who interact with their systems into believing that these systems really have minds. And the problem is fundamental: the structure of the TT is such as to cultivate tricksters. A better test is one that insists on a certain restrictive epistemic relation between an artificial agent (or system) A, its output o, and the human architect H of A â a relation which, roughly speaking, obtains when H cannot account for how A produced o. We call this test the ``Lovelace Test'' in honor of Lady Lovelace, who believed that only when computers originate things should they be believed to have minds</div>
<div id='_15_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596904">http://portal.acm.org/citation.cfm?id=596904</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://citeseer.ist.psu.edu/bringsjord00creativity.html">http://citeseer.ist.psu.edu/bringsjord00creativity.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://www.rpi.edu/~faheyj2/SB/SELPAP/DARTMOUTH/lt3.pdf">http://www.rpi.edu/~faheyj2/SB/SELPAP/DARTMOUTH/lt3.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://www.springerlink.com/content/content/nrvl130w46xj6g22/fulltext.pdf">http://www.springerlink.com/content/content/nrvl130w46xj6g22/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://www.springerlink.com/content/nrvl130w46xj6g22/fulltext.pdf">http://www.springerlink.com/content/nrvl130w46xj6g22/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319539&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319539&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://www.springerlink.com/index/NRVL130W46XJ6G22.pdf">http://www.springerlink.com/index/NRVL130W46XJ6G22.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICTT-3",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319539">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319539</a><br></div></div>
</div><!--entry-->

<div id='_16_entry' class='entry'><span ><span class='name'>Clark, Thomas W.</span> (1992). The Turing test as a novel form of hermeneutics.</span> <span class='pub_name'>International Studies in Philosophy</span> 24 (1):17-31. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17097880219185983369'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test%20as%20a%20novel%20form%20of%20hermeneutics+author%3AClark&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_17_entry' class='entry'><span ><span class='name'>Clifton, Andrew</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("CLIBMB",this.href,0);return true;' href='http://cogprints.org/3480/1/Blind_mans_bluff_and_the_Turing_test.pdf'>Blind man's bluff and the Turing test.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Blind%20man%27s%20bluff%20and%20the%20Turing%20test+author%3AClifton&amp;btnG=Search'>Google</a>)</span><div id='_17_abstract' class='extra' style='font-size:12px;'>Abstract: It seems plausible that under the conditions of the Turing test, congenitally blind people could nevertheless, with sufficient preparation, successfully represent themselves to remotely located interrogators as sighted. Having never experienced normal visual sensations, the successful blind player can prevail in this test only by playing a âlying gameââimitating the phenomenological claims of sighted people, in the absence of the qualitative visual experiences to which such statements purportedly refer. This suggests that a computer or robot might pass the Turing test in the same way, in the absence not only of visual experience, but qualitative consciousness in general. Hence, the standard Turing test does not provide a valid criterion for the presence of consciousness. A âsensorimetricâ version of the Turing test fares no better, for the apparent correlations we observe between cognitive functions and qualitative conscious experiences seems to be contingent, not necessary. We must therefore define consciousness not in terms of its causes and effects, but rather, in terms of the distinctive properties of its content, such as its possession of qualitative character and apparent intrinsic valueâthe property which confers upon consciousness its moral significance. As a means of determining whether or nor a machine is conscious, in this sense, an alternative to the standard Turing test is proposed</div>
</div><!--entry-->

<div id='_18_entry' class='entry'><span ><span class='name'>Copeland, B. Jack</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("COPTTT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596953'>The Turing test.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (4):519-539. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15272756469214654558'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test+author%3ACopeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_18_links")'>More links</a>)</span><div id='_18_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Turing''s test has been much misunderstood. Recently unpublished material by Turing casts fresh light on his thinking and dispels a number of philosophical myths concerning the Turing test. Properly understood, the Turing test withstands objections that are popularly believed to be fatal</div>
<div id='_18_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTTT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=PA519&amp;ots=blQICrgbeX&amp;sig=4woWcfbL_fO5zip_aVT89VSM390">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=PA519&ots=blQICrgbeX&sig=4woWcfbL_fO5zip_aVT89VSM390</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTTT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=5BJaXSedqfIC&amp;oi=fnd&amp;pg=PA519&amp;ots=rzjaTOxdpq&amp;sig=slbbZKdPbjoJsVO44CwfWr3oSMo">http://books.google.com/books?hl=en&lr=&id=5BJaXSedqfIC&oi=fnd&pg=PA519&ots=rzjaTOxdpq&sig=slbbZKdPbjoJsVO44CwfWr3oSMo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTTT",this.href,0);return true;' href="http://www.springerlink.com/content/content/w103433h4g273841/fulltext.pdf">http://www.springerlink.com/content/content/w103433h4g273841/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTTT",this.href,0);return true;' href="http://www.springerlink.com/content/w103433h4g273841/fulltext.pdf">http://www.springerlink.com/content/w103433h4g273841/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTTT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319531&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319531&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTTT",this.href,0);return true;' href="http://www.springerlink.com/index/W103433H4G273841.pdf">http://www.springerlink.com/index/W103433H4G273841.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTTT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319531">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319531</a><br></div></div>
</div><!--entry-->

<div id='_19_entry' class='entry'><span ><span class='name'>Cowen, Tyler</span> &amp; <span class='name'>Dawson, Michelle</span>, What does the Turing test really mean? And how many human beings (including Turing) could pass?</span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20does%20the%20Turing%20test%20really%20mean%3F%20And%20how%20many%20human%20beings%20%28including%20Turing%29%20could%20pass%3F+author%3ACowen&amp;btnG=Search'>Google</a>)</span><div id='_19_abstract' class='extra' style='font-size:12px;'>Abstract: The so-called Turing test, as it is usually interpreted, sets a benchmark standard for determining when we might call a machine intelligent. We can call a machine intelligent if the following is satisfied: if a group of wise observers were conversing with a machine through an exchange of typed messages, those observers could not tell whether they were talking to a human being or to a machine. To pass the test, the machine has to be intelligent but it also should be responsive in a manner which cannot be distinguished from a human being. This standard interpretation presents the Turing test as a criterion for demarcating intelligent from non-intelligent entities. For a long time proponents of artificial intelligence have taken the Turing test as a goalpost for measuring progress</div>
</div><!--entry-->

<div id='_20_entry' class='entry'><span ><span class='name'>Crawford, C.</span> (1994). Notes on the Turing test.</span> <span class='pub_name'>Communications of the Association for Computing Machinery</span> 37 (June):13-15. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Notes%20on%20the%20Turing%20test+author%3ACrawford&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_21_entry' class='entry'><span ><span class='name'>Crockett, L.</span> (1994). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("CROTTT",this.href,0);return true;' href='http://books.google.com/books?id=sKntHyioe20C&amp;printsec=front_cover'>The Turing Test and the Frame Problem: AI's Mistaken Understanding of Intelligence.</a></span></em></span> Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7606731511007008963'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20Test%20and%20the%20Frame%20Problem+author%3ACrockett&amp;btnG=Search'>Google</a>)</span><div id='_21_abstract' class='extra' style='font-size:12px;'>Abstract: I have discussed the frame problem and the Turing test at length, but I have not 
attempted to spell out what I think the implications of the frame problem ...</div>
</div><!--entry-->

<div id='_22_entry' class='entry'><span ><span class='name'>Cutrona, Jr</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("CUTZIS",this.href,0);return true;' href='http://cogprints.org/4636/1/TR-05-002.pdf'>Zombies in Searle's chinese room: Putting the Turing test to bed.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Zombies%20in%20Searle%27s%20chinese%20room+author%3ACutrona%2C%20Jr&amp;btnG=Search'>Google</a> | <a href='javascript:show("_22_links")'>More links</a>)</span><div id='_22_abstract' class='extra' style='font-size:12px;'>Abstract: Searleâs discussions over the years 1980-2004 of the implications of his âChinese Roomâ Gedanken experiment are frustrating because they proceed from a correct assertion: (1) âInstantiating a computer program is never by itself a sufficient condition of intentionality;â and an incorrect assertion: (2) âThe explanation of how the brain produces intentionality cannot be that it does it by instantiating a computer program.â In this article, I describe how to construct a Gedanken zombie Chinese Room program that will pass the Turing test and at the same time unambiguously demonstrates the correctness of (1). I then describe how to construct a Gedanken Chinese brain program that will pass the Turing test, has a mind, and understands Chinese, thus demonstrating that (2) is incorrect. Searleâs instantiation of this program can and does produce intentionality. Searleâs longstanding ignorance of Chinese is simply irrelevant and always has been. I propose a truce and a plan for further exploration</div>
<div id='_22_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CUTZIS",this.href,0);return true;' href="http://cogprints.org/4636/1/TR%2D05%2D002.pdf">http://cogprints.org/4636/1/TR%2D05%2D002.pdf</a><br></div></div>
</div><!--entry-->

<div id='_23_entry' class='entry'><span ><span class='name'>Davidson, Donald</span> (1990). Turing's test.</span> In K. Said (ed.), <em>Modelling the Mind</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%27s%20test+author%3ADavidson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_24_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1984). Can machines think?</span> In M. G. Shafto (ed.), <em>How We Know</em>. Harper & Row. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4590289152323472424'>Cited by 24</a> | <span class='ll' onclick='$("_24_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20machines%20think%3F+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_24_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Defending the Turing test as a good test for intelligence.</div></div>
</div><!--entry-->

<div id='_25_entry' class='entry'><span ><span class='name'>Drozdek, Adam</span> (2001). Descartes' Turing test.</span> <span class='pub_name'>Epistemologia</span> 24 (1):5-29. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Descartes%27%20Turing%20test+author%3ADrozdek&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_26_entry' class='entry'><span ><span class='name'>Edmonds, Bruce</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("EDMTCO",this.href,0);return true;' href='http://www.springerlink.com/content/u121t003r65q802w/fulltext.pdf'>The constructability of artificial intelligence (as defined by the Turing test).</a></span> <span class='pub_name'>Journal of Logic Language and Information</span> 9 (4):419-424. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20constructability%20of%20artificial%20intelligence%20%28as%20defined%20by%20the%20Turing%20test%29+author%3AEdmonds&amp;btnG=Search'>Google</a> | <a href='javascript:show("_26_links")'>More links</a>)</span><div id='_26_abstract' class='extra' style='font-size:12px;'>Abstract:  The Turing Test (TT), as originally specified, centres on theability to perform a social role. The TT can be seen as a test of anability to enter into normal human social dynamics. In this light itseems unlikely that such an entity can be wholly designed in anoff-line mode; rather a considerable period of training insitu would be required. The argument that since we can pass the TT,and our cognitive processes might be implemented as a Turing Machine(TM), that consequently a TM that could pass the TT could be built, isattacked on the grounds that not all TMs are constructible in a plannedway. This observation points towards the importance of developmentalprocesses that use random elements (e.g., evolution), but in these casesit becomes problematic to call the result artificial. This hasimplications for the means by which intelligent agents could bedeveloped</div>
<div id='_26_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EDMTCO",this.href,0);return true;' href="http://cogprints.org/397/3/consai.pdf">http://cogprints.org/397/3/consai.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EDMTCO",this.href,0);return true;' href="http://cogprints.org/397/0/consai.pdf">http://cogprints.org/397/0/consai.pdf</a><br></div></div>
</div><!--entry-->

<div id='_27_entry' class='entry'><span ><span class='name'>Edmonds, B.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("EDMTCO-3",this.href,0);return true;' href='http://cogprints.org/397/3/consai.pdf'>The constructability of artificial intelligence (as defined by the Turing test).</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20constructability%20of%20artificial%20intelligence%20%28as%20defined%20by%20the%20Turing%20test%29+author%3AEdmonds&amp;btnG=Search'>Google</a> | <a href='javascript:show("_27_links")'>More links</a>)</span><div id='_27_abstract' class='extra' style='font-size:12px;'>Abstract: The Turing Test, as originally specified, centres on the ability to perform a social role. The TT can seen as a test of an ability to enter into normal human social dynamics. In this light it seems unlikely that such an entity can be wholly designed in an `off-line' mode, but rather a considerable period of training in situ would be required. The argument that since we can pass the TT and our cognitive processes might be implemented as a TM that, in theory, an TM that could pass the TT could be built is attacked on the grounds that not all TMs are constructable in a planned way. This observation points towards the importance of developmental processes that include random elements (e.g. evolution), but in these cases it becomes problematic to call the result artificial</div>
<div id='_27_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EDMTCO-3",this.href,0);return true;' href="http://cogprints.org/397/0/consai.pdf">http://cogprints.org/397/0/consai.pdf</a><br></div></div>
</div><!--entry-->

<div id='_28_entry' class='entry'><span ><span class='name'>Erion, Gerald J.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("ERITCT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596905'>The cartesian test for automatism.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (1):29-39. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11320177450894946986'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20cartesian%20test%20for%20automatism+author%3AErion&amp;btnG=Search'>Google</a> | <a href='javascript:show("_28_links")'>More links</a>)</span><div id='_28_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In Part V of his Discourse on the Method, Descartes introduces a test for distinguishing people from machines that is similar to the one proposed much later by Alan Turing. The Cartesian test combines two distinct elements that Keith Gunderson has labeled the language test and the action test. Though traditional interpretation holds that the action test attempts to determine whether an agent is acting upon principles, I argue that the action test is best understood as a test of common sense. I also maintain that this interpretation yields a stronger test than Turing's, and that contemporary artificial intelligence should consider using it as a guide for future research</div>
<div id='_28_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ERITCT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=RA4-PA241&amp;ots=blQICrghbY&amp;sig=dV16mfWZM_Qoj6YrtNA26fR1IZk">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=RA4-PA241&ots=blQICrghbY&sig=dV16mfWZM_Qoj6YrtNA26fR1IZk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ERITCT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=5BJaXSedqfIC&amp;oi=fnd&amp;pg=RA5-PA241&amp;ots=rzjaTOxjmr&amp;sig=MTJT29H2X-bBW0rfBOaTIEju52o">http://books.google.com/books?hl=en&lr=&id=5BJaXSedqfIC&oi=fnd&pg=RA5-PA241&ots=rzjaTOxjmr&sig=MTJT29H2X-bBW0rfBOaTIEju52o</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ERITCT",this.href,0);return true;' href="http://www.springerlink.com/content/content/h814j04926567527/fulltext.pdf">http://www.springerlink.com/content/content/h814j04926567527/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ERITCT",this.href,0);return true;' href="http://www.springerlink.com/content/h814j04926567527/fulltext.pdf">http://www.springerlink.com/content/h814j04926567527/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ERITCT",this.href,0);return true;' href="http://www.springerlink.com/index/H814J04926567527.pdf">http://www.springerlink.com/index/H814J04926567527.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ERITCT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319541">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319541</a><br></div></div>
</div><!--entry-->

<div id='_29_entry' class='entry'><span ><span class='name'>Floridi, Luciano</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("FLOCAA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1107816'>Consciousness, agents and the knowledge game.</a></span> <span class='pub_name'>Minds and Machines</span> 15 (3):415-444. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9047457771344836839'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%2C%20agents%20and%20the%20knowledge%20game+author%3AFloridi&amp;btnG=Search'>Google</a> | <a href='javascript:show("_29_links")'>More links</a>)</span><div id='_29_abstract' class='extra' style='font-size:12px;'>Abstract:  This paper has three goals. The first is to introduce the âknowledge gameâ, a new, simple and yet powerful tool for analysing some intriguing philosophical questions. The second is to apply the knowledge game as an informative test to discriminate between conscious (human) and conscious-less agents (zombies and robots), depending on which version of the game they can win. And the third is to use a version of the knowledge game to provide an answer to Dretskeâs question âhow do you know you are not a zombie?â</div>
<div id='_29_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FLOCAA",this.href,0);return true;' href="http://philsci-archive.pitt.edu/archive/00002546/">http://philsci-archive.pitt.edu/archive/00002546/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FLOCAA",this.href,0);return true;' href="http://philsci-archive.pitt.edu/archive/00002546/01/caatkg.pdf">http://philsci-archive.pitt.edu/archive/00002546/01/caatkg.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FLOCAA",this.href,0);return true;' href="http://www.springerlink.com/content/f52pq39812453221/fulltext.pdf">http://www.springerlink.com/content/f52pq39812453221/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FLOCAA",this.href,0);return true;' href="http://www.springerlink.com/index/F52PQ39812453221.pdf">http://www.springerlink.com/index/F52PQ39812453221.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FLOCAA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2005/00000015/F0020003/00009005">http://www.ingentaconnect.com/content/klu/mind/2005/00000015/F0020003/00009005</a><br></div></div>
</div><!--entry-->

<div id='_30_entry' class='entry'><span ><span class='name'>Floridi, Luciano</span> &amp; <span class='name'>Taddeo, Mariarosaria</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("FLOTIG",this.href,0);return true;' href='http://www.springerlink.com/content/02x45275n1625257/fulltext.pdf'>Turing's imitation game: Still an impossible challenge for all machines and some judgesââan evaluation of the 2008 loebner contest.</a></span> <span class='pub_name'>Minds and Machines</span> 19 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%27s%20imitation%20game+author%3AFloridi&amp;btnG=Search'>Google</a>)</span><div id='_30_abstract' class='extra' style='font-size:12px;'>Abstract: An evaluation of the 2008 Loebner contest</div>
</div><!--entry-->

<div id='_31_entry' class='entry'><span ><span class='name'>Floridi, Luciano</span>; <span class='name'>Taddeo, Mariarosaria</span> &amp; <span class='name'>Turilli, Matteo</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("FLOTIG-2",this.href,0);return true;' href='http://www.springerlink.com/content/02x45275n1625257/'>Turingâs Imitation Game: Still an Impossible Challenge for All Machines and Some Judges.</a></span> <span class='pub_name'>Minds and Machines</span> 19 (1):145-150. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%E2%80%99s%20Imitation%20Game+author%3AFloridi&amp;btnG=Search'>Google</a>)</span><div id='_31_abstract' class='extra' style='font-size:12px;'>Abstract: An Evaluation of the 2008 Loebner Contest.</div>
</div><!--entry-->

<div id='_32_entry' class='entry'><span ><span class='name'>French, Robert M.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("FREPBT",this.href,0);return true;' href='http://citeseer.ist.psu.edu/324229.html'>Peeking behind the screen: The unsuspected power of the standard Turing test.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 12 (3):331-340. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 10 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Peeking%20behind%20the%20screen+author%3AFrench&amp;btnG=Search'>Google</a> | <a href='javascript:show("_32_links")'>More links</a>)</span><div id='_32_abstract' class='extra' style='font-size:12px;'>Abstract: No computer that had not experienced the world as we humans had could pass a rigorously administered standard Turing Test. We show that the use of âsubcognitiveâ questions allows the standard Turing Test to indirectly probe the human subcognitive associative concept network built up over a lifetime of experience with the world. Not only can this probing reveal differences in cognitive abilities, but crucially, even differences in _physical aspects_ of the candidates can be detected. Consequently, it is unnecessary to propose even harder versions of the Test in which all physical and behavioral aspects of the two candidates had to be indistinguishable before allowing the machine to pass the Test. Any machine that passed the âsimplerâ symbols- in/symbols-out test as originally proposed by Turing would be intelligent. The problem is that, even in its original form, the Turing Test is already too hard and too anthropocentric for any machine that was not a physical, social, and behavioral carbon copy of ourselves to actually pass it. Consequently, the Turing Test, even in its standard version, is not a reasonable test for general machine intelligence. There is no need for an even stronger version of the Test</div>
<div id='_32_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FREPBT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/french00peeking.html">http://citeseer.ist.psu.edu/french00peeking.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FREPBT",this.href,0);return true;' href="http://www.u-bourgogne.fr/LEAD/people/french/peeking.pdf">http://www.u-bourgogne.fr/LEAD/people/french/peeking.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FREPBT",this.href,0);return true;' href="http://www.informaworld.com/index/24PHYLU4NX08NHQF.pdf">http://www.informaworld.com/index/24PHYLU4NX08NHQF.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FREPBT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/teta/2000/00000012/00000003/art00006">http://www.ingentaconnect.com/content/tandf/teta/2000/00000012/00000003/art00006</a><br></div></div>
</div><!--entry-->

<div id='_33_entry' class='entry'><span ><span class='name'>French, Robert M.</span> (1995). Refocusing the debate on the Turing test: A response.</span> <span class='pub_name'>Behavior and Philosophy</span> 23 (1):59-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18353390315545305342'>Cited by 3</a> | <span class='ll' onclick='$("_33_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Refocusing%20the%20debate%20on%20the%20Turing%20test+author%3AFrench&amp;btnG=Search'>Google</a>)</span><div id='_33_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Response to Jacquette 1993.</div></div>
</div><!--entry-->

<div id='_34_entry' class='entry'><span ><span class='name'>French, Robert M.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("FRESAT",this.href,0);return true;' href='http://philosophy.wisc.edu/shapiro/Phil554/PAPERS/French.pdf'>Subcognition and the limits of the Turing test.</a></span> <span class='pub_name'>Mind</span> 99 (393):53-66. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16736574156284560097'>Cited by 66</a> | <span class='ll' onclick='$("_34_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Subcognition%20and%20the%20limits%20of%20the%20Turing%20test+author%3AFrench&amp;btnG=Search'>Google</a> | <a href='javascript:show("_34_links")'>More links</a>)</span><div id='_34_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The Turing Test is too hard, as it requires not intelligence but human intelligence. Any machine could be unmasked through careful questioning, but this wouldn't mean that the machine was unintelligent.</div></div>
<div id='_34_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRESAT",this.href,0);return true;' href="http://philosophy.wisc.edu/Shapiro/Phil554/PAPERS/French.pdf">http://philosophy.wisc.edu/Shapiro/Phil554/PAPERS/French.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRESAT",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0026-4423(199001)2:99:393&lt;53:SATLOT&gt;2.0.CO;2-E">http://links.jstor.org/sici?sici=0026-4423(199001)2:99:393<53:SATLOT>2.0.CO;2-E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRESAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(199001)2:99:393&lt;53:SATLOT&gt;2.0.CO;2-E">http://www.jstor.org/sici?sici=0026-4423(199001)2:99:393<53:SATLOT>2.0.CO;2-E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRESAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2254890.pdf">http://www.jstor.org/stable/pdfplus/2254890.pdf</a><br></div></div>
</div><!--entry-->

<div id='_35_entry' class='entry'><span ><span class='name'>French, Robert</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("FRETIT",this.href,0);return true;' href='http://psycprints.ecs.soton.ac.uk/archive/00000531/'>The inverted Turing test: How a mindless program could pass it.</a></span> <span class='pub_name'>Psycoloquy</span> 7 (39). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3036785168074977112'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20inverted%20Turing%20test+author%3AFrench&amp;btnG=Search'>Google</a> | <a href='javascript:show("_35_links")'>More links</a>)</span><div id='_35_abstract' class='extra' style='font-size:12px;'>Abstract: This commentary attempts to show that the inverted Turing Test (Watt 1996) could be simulated by a standard Turing test and, most importantly, claims that a very simple program with no intelligence whatsoever could be written that would pass the inverted Turing test. For this reason, the inverted Turing test in its present form must be rejected</div>
<div id='_35_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETIT",this.href,0);return true;' href="http://www.u-bourgogne.fr/LEAD/people/french/invturing.pdf">http://www.u-bourgogne.fr/LEAD/people/french/invturing.pdf</a><br></div></div>
</div><!--entry-->

<div id='_36_entry' class='entry'><span ><span class='name'>French, Robert</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("FRETTT",this.href,0);return true;' href='http://citeseer.ist.psu.edu/326357.html'>The Turing test: The first fifty years.</a></span> <span class='pub_name'>Trends in Cognitive Sciences</span> 4 (3):115-121. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3703699870839603243'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test+author%3AFrench&amp;btnG=Search'>Google</a> | <a href='javascript:show("_36_links")'>More links</a>)</span><div id='_36_abstract' class='extra' style='font-size:12px;'>Abstract: The Turing Test, originally proposed as a simple operational definition of intelligence, has now been with us for exactly half a century. It is safe to say that no other single article in computer science, and few other articles in science in general, have generated so much discussion. The present article chronicles the comments and controversy surrounding Turing's classic article from its publication to the present. The changing perception of the Turing Test over the last fifty years has paralleled the changing attitudes in the scientific community towards artificial intelligence: from the unbridled optimism of 1960's to the current realization of the immense difficulties that still lie ahead. I conclude with the prediction that the Turing Test will remain important, not only as a landmark in the history of the development of intelligent machines, but also with real relevance to future generations of people living in a world in which the cognitive capacities of machines will be vastly greater than they are now</div>
<div id='_36_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETTT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/french00turing.html">http://citeseer.ist.psu.edu/french00turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETTT",this.href,0);return true;' href="http://srsc.ulb.ac.be/cogsci/papers/TICS-French_turing.pdf">http://srsc.ulb.ac.be/cogsci/papers/TICS-French_turing.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETTT",this.href,0);return true;' href="http://www.u-bourgogne.fr/LEAD/people/french/TICS_turing.pdf">http://www.u-bourgogne.fr/LEAD/people/french/TICS_turing.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETTT",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=10689346&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=10689346&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETTT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/13646613/2000/00000004/00000003/art01453">http://www.ingentaconnect.com/content/els/13646613/2000/00000004/00000003/art01453</a><br></div></div>
</div><!--entry-->

<div id='_37_entry' class='entry'><span ><span class='name'>Gunderson, Keith</span> (1964). <a rel="nofollow" class='article_title' onclick='trackclick("GUNTIG",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0026-4423(196404)2:73:290&lt;234:TIG&gt;2.0.CO;2-3'>The imitation game.</a></span> <span class='pub_name'>Mind</span> 73 (April):234-45. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10232170016139983885'>Cited by 13</a> | <span class='ll' onclick='$("_37_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20imitation%20game+author%3AGunderson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_37_links")'>More links</a>)</span><div id='_37_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The Turing test is not broad enough: there's much more to thought than the ability to play the imitation game.</div></div>
<div id='_37_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUNTIG",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(196404)2:73:290&lt;234:TIG&gt;2.0.CO;2-3">http://www.jstor.org/sici?sici=0026-4423(196404)2:73:290<234:TIG>2.0.CO;2-3</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUNTIG",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2251812.pdf">http://www.jstor.org/stable/pdfplus/2251812.pdf</a><br></div></div>
</div><!--entry-->

<div id='_38_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> &amp; <span class='name'>Dror, Itiel</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("HARDCC",this.href,0);return true;' href='http://eprints.soton.ac.uk/40433/'>Distributed cognition: Cognizing, autonomy and the Turing test.</a></span> <span class='pub_name'>Pragmatics and Cognition</span> 14 (2):14. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1934472300868324728'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Distributed%20cognition+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_38_links")'>More links</a>)</span><div id='_38_abstract' class='extra' style='font-size:12px;'>Abstract: Some of the papers in this special issue distribute cognition between what is going on inside individual cognizers' heads and their outside worlds; others distribute cognition among different individual cognizers. Turing's criterion for cognition was individual, autonomous input/output capacity. It is not clear that distributed cognition could pass the Turing Test</div>
<div id='_38_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDCC",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/12368/02/discintro.pdf">http://eprints.ecs.soton.ac.uk/12368/02/discintro.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDCC",this.href,0);return true;' href="http://dialnet.unirioja.es/servlet/articulo?codigo=2196285">http://dialnet.unirioja.es/servlet/articulo?codigo=2196285</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDCC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/jbp/pc/2006/00000014/00000002/art00002">http://www.ingentaconnect.com/content/jbp/pc/2006/00000014/00000002/art00002</a><br></div></div>
</div><!--entry-->

<div id='_39_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("HARDMP",this.href,0);return true;' href='http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad95.mind.robot.html'>Does mind piggyback on robotic and symbolic capacity?</a></span> In H. Morowitz &amp; J. Singer (eds.), <em>The Mind, the Brain, and Complex Adaptive Systems</em>. Addison Wesley. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Does%20mind%20piggyback%20on%20robotic%20and%20symbolic%20capacity%3F+author%3AHarnad&amp;btnG=Search'>Google</a>)</span><div id='_39_abstract' class='extra' style='font-size:12px;'>Abstract: Cognitive science is a form of "reverse engineering" (as Dennett has dubbed it). We are trying to explain the mind by building (or explaining the functional principles of) systems that have minds. A "Turing" hierarchy of empirical constraints can be applied to this task, from t1, toy models that capture only an arbitrary fragment of our performance capacity, to T2, the standard "pen-pal" Turing Test (total symbolic capacity), to T3, the Total Turing Test (total symbolic plus robotic capacity), to T4 (T3 plus internal [neuromolecular] indistinguishability). All scientific theories are underdetermined by data. What is the right level of empirical constraint for cognitive theory? I will argue that T2 is underconstrained (because of the Symbol Grounding Problem and Searle's Chinese Room Argument) and that T4 is overconstrained (because we don't know what neural data, if any, are relevant). T3 is the level at which we solve the "other minds" problem in everyday life, the one at which evolution operates (the Blind Watchmaker is no mind-reader either) and the one at which symbol systems can be grounded in the robotic capacity to name and manipulate the objects their symbols are about. I will illustrate this with a toy model for an important component of T3 -- categorization -- using neural nets that learn category invariance by "warping" similarity space the way it is warped in human categorical perception: within-category similarities are amplified and between-category similarities are attenuated. This analog "shape" constraint is the grounding inherited by the arbitrarily shaped symbol that names the category and by all the symbol combinations it enters into. No matter how tightly one constrains any such model, however, it will always be more underdetermined than normal scientific and engineering theory. This will remain the ineliminable legacy of the mind/body problem</div>
</div><!--entry-->

<div id='_40_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("HARLOF",this.href,0);return true;' href='http://cogprints.org/1591/'>Levels of functional equivalence in reverse bioengineering: The Darwinian Turing test for artificial life.</a></span> <span class='pub_name'>Artificial Life</span> 1 (3):93-301. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16604942953034711458'>Cited by 35</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Levels%20of%20functional%20equivalence%20in%20reverse%20bioengineering+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_40_links")'>More links</a>)</span><div id='_40_abstract' class='extra' style='font-size:12px;'>Abstract: Both Artificial Life and Artificial Mind are branches of what Dennett has called "reverse engineering": Ordinary engineering attempts to build systems to meet certain functional specifications, reverse bioengineering attempts to understand how systems that have already been built by the Blind Watchmaker work. Computational modelling (virtual life) can capture the formal principles of life, perhaps predict and explain it completely, but it can no more be alive than a virtual forest fire can be hot. In itself, a computational model is just an ungrounded symbol system; no matter how closely it matches the properties of what is being modelled, it matches them only formally, with the mediation of an interpretation. Synthetic life is not open to this objection, but it is still an open question how close a functional equivalence is needed in order to capture life. Close enough to fool the Blind Watchmaker is probably close enough, but would that require molecular indistinguishability, and if so, do we really need to go that far?</div>
<div id='_40_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/3363/">http://eprints.resist.ecs.soton.ac.uk/3363/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=188445">http://portal.acm.org/citation.cfm?id=188445</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/91/">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/91/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://mitpress.mit.edu/catalog/item/default.asp?ttype=6&amp;tid=40">http://mitpress.mit.edu/catalog/item/default.asp?ttype=6&tid=40</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad94.artlife2.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad94.artlife2.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad94.artlife2.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad94.artlife2.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003363/02/harnad94.artlife2.html">http://eprints.ecs.soton.ac.uk/archive/00003363/02/harnad94.artlife2.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001591/00/harnad94.artlife2.html">http://cogprints.ecs.soton.ac.uk/archive/00001591/00/harnad94.artlife2.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLOF",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1591">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1591</a><br></div></div>
</div><!--entry-->

<div id='_41_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("HAROBO-2",this.href,0);return true;' href='http://eprints.resist.ecs.soton.ac.uk/3379/'>Other bodies, other minds: A machine incarnation of an old philosophical problem.</a></span> <span class='pub_name'>[Journal (Paginated)]</span> 1 (1):43-54. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16624319899140932614'>Cited by 99</a> | <span class='ll' onclick='$("_41_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Other%20bodies%2C%20other%20minds+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_41_links")'>More links</a>)</span><div id='_41_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the Total Turing Test (full behavioral equivalence) as a test for mind.</div></div><div id='_41_abstract' class='extra' style='font-size:12px;'>Abstract: Explaining the mind by building machines with minds runs into the other-minds problem: How can we tell whether any body other than our own has a mind when the only way to know is by being the other body? In practice we all use some form of Turing Test: If it can do everything a body with a mind can do such that we can't tell them apart, we have no basis for doubting it has a mind. But what is "everything" a body with a mind can do? Turing's original "pen-pal" version (the TT) only tested linguistic capacity, but Searle has shown that a mindless symbol-manipulator could pass the TT undetected. The Total Turing Test (TTT) calls for all of our linguistic and robotic capacities; immune to Searle's argument, it suggests how to ground a symbol manipulating system in the capacity to pick out the objects its symbols refer to. No Turing Test, however, can guarantee that a body has a mind. Worse, nothing in the explanation of its successful performance requires a model to have a mind at all. Minds are hence very different from the unobservables of physics (e.g., superstrings); and Turing Testing, though essential for machine-modeling the mind, can really only yield an explanation of the body</div>
<div id='_41_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003379/">http://eprints.ecs.soton.ac.uk/archive/00003379/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001578/">http://cogprints.ecs.soton.ac.uk/archive/00001578/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=103493.103530">http://portal.acm.org/citation.cfm?id=103493.103530</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://cogprints.org/1578/0/harnad91.otherminds.html">http://cogprints.org/1578/0/harnad91.otherminds.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/78/">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/78/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003379/01/harnad91.otherminds.html">http://eprints.ecs.soton.ac.uk/archive/00003379/01/harnad91.otherminds.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001578/00/harnad91.otherminds.html">http://cogprints.ecs.soton.ac.uk/archive/00001578/00/harnad91.otherminds.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3379">http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3379</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1578">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1578</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://www.springerlink.com/content/t5733025r3t44248/fulltext.pdf">http://www.springerlink.com/content/t5733025r3t44248/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://www.springerlink.com/index/T5733025R3T44248.pdf">http://www.springerlink.com/index/T5733025R3T44248.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAROBO-2",this.href,0);return true;' href="http://cogprints.org/1578/1/harnad91.otherminds.html">http://cogprints.org/1578/1/harnad91.otherminds.html</a><br></div></div>
</div><!--entry-->

<div id='_42_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("HARTAG",this.href,0);return true;' href='http://cogprints.org/3322/'>The annotation game: On Turing (1950) on computing, machinery, and intelligence.</a></span> In Robert Epstein &amp; G. Peters (eds.), <em>[Book Chapter] (in Press)</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5031207198222426766'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20annotation%20game+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_42_links")'>More links</a>)</span><div id='_42_abstract' class='extra' style='font-size:12px;'>Abstract: This quote/commented critique of Turing's classical paper suggests that Turing meant -- or should have meant -- the robotic version of the Turing Test (and not just the email version). Moreover, any dynamic system (that we design and understand) can be a candidate, not just a computational one. Turing also dismisses the other-minds problem and the mind/body problem too quickly. They are at the heart of both the problem he is addressing and the solution he is proposing</div>
<div id='_42_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/12954/">http://eprints.ecs.soton.ac.uk/12954/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/7741/">http://eprints.resist.ecs.soton.ac.uk/7741/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003322/">http://cogprints.ecs.soton.ac.uk/archive/00003322/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/turing.doc">http://www.ecs.soton.ac.uk/~harnad/Temp/turing.doc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/turing.html">http://www.ecs.soton.ac.uk/~harnad/Temp/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00007741/01/turing.html">http://eprints.ecs.soton.ac.uk/archive/00007741/01/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003322/01/turing.html">http://cogprints.ecs.soton.ac.uk/archive/00003322/01/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:7741">http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:7741</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:eprints.ecs.soton.ac.uk:7741">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:eprints.ecs.soton.ac.uk:7741</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://cogprints.org/3322/2/turing.pdf">http://cogprints.org/3322/2/turing.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG",this.href,0);return true;' href="http://cogprints.org/3322/1/turing.html">http://cogprints.org/3322/1/turing.html</a><br></div></div>
</div><!--entry-->

<div id='_43_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("HARTAG-2",this.href,0);return true;' href='http://cogprints.org/3322/'>The annotation game: On Turing (1950) on computing, machinery, and intelligence.</a></span> In Robert Epstein &amp; Grace Peters (eds.), <em>[Book Chapter] (in Press)</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5031207198222426766'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20annotation%20game+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_43_links")'>More links</a>)</span><div id='_43_abstract' class='extra' style='font-size:12px;'>Abstract: This quote/commented critique of Turing's classical paper suggests that Turing meant -- or should have meant -- the robotic version of the Turing Test (and not just the email version). Moreover, any dynamic system (that we design and understand) can be a candidate, not just a computational one. Turing also dismisses the other-minds problem and the mind/body problem too quickly. They are at the heart of both the problem he is addressing and the solution he is proposing</div>
<div id='_43_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/12954/">http://eprints.ecs.soton.ac.uk/12954/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://cogprints.org/3322/1/turing.html">http://cogprints.org/3322/1/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/7741/">http://eprints.resist.ecs.soton.ac.uk/7741/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003322/">http://cogprints.ecs.soton.ac.uk/archive/00003322/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/turing.doc">http://www.ecs.soton.ac.uk/~harnad/Temp/turing.doc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/turing.html">http://www.ecs.soton.ac.uk/~harnad/Temp/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00007741/01/turing.html">http://eprints.ecs.soton.ac.uk/archive/00007741/01/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003322/01/turing.html">http://cogprints.ecs.soton.ac.uk/archive/00003322/01/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:7741">http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:7741</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:eprints.ecs.soton.ac.uk:7741">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:eprints.ecs.soton.ac.uk:7741</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTAG-2",this.href,0);return true;' href="http://cogprints.org/3322/2/turing.pdf">http://cogprints.org/3322/2/turing.pdf</a><br></div></div>
</div><!--entry-->

<div id='_44_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1999). Turing on reverse-engineering the mind.</span> <span class='pub_name'>Journal of Logic, Language, and Information</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=345384329763162389'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%20on%20reverse-engineering%20the%20mind+author%3AHarnad&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_45_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("HARTTT",this.href,0);return true;' href='http://cogprints.org/1584/'>The Turing test is not a trick: Turing indistinguishability is a scientific criterion.</a></span> <span class='pub_name'>[Journal (Paginated)]</span> 3 (4):9-10. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13066625846297527780'>Cited by 44</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test%20is%20not%20a%20trick+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_45_links")'>More links</a>)</span><div id='_45_abstract' class='extra' style='font-size:12px;'>Abstract: It is important to understand that the Turing Test (TT) is not, nor was it intended to be, a trick; how well one can fool someone is not a measure of scientific progress. The TT is an empirical criterion: It sets AI's empirical goal to be to generate human-scale performance capacity. This goal will be met when the candidate's performance is totally indistinguishable from a human's. Until then, the TT simply represents what it is that AI must endeavor eventually to accomplish scientifically</div>
<div id='_45_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/3373/">http://eprints.resist.ecs.soton.ac.uk/3373/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=141420.141422">http://portal.acm.org/citation.cfm?id=141420.141422</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/84/">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/84/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.turing.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:1584">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:1584</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1584">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1584</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://cogprints.org/1584/1/harnad92.turing.html">http://cogprints.org/1584/1/harnad92.turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTTT",this.href,0);return true;' href="http://cogprints.org/1584/0/harnad92.turing.html">http://cogprints.org/1584/0/harnad92.turing.html</a><br></div></div>
</div><!--entry-->

<div id='_46_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("HAULWM",this.href,0);return true;' href='http://www.wutsamada.com/work/lookwhom.htm'>Look who's moving the goal posts now.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (1):41-51. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2554555723834243898'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Look%20who%27s%20moving%20the%20goal%20posts%20now+author%3AHauser&amp;btnG=Search'>Google</a> | <a href='javascript:show("_46_links")'>More links</a>)</span><div id='_46_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The abject failure of Turing's first prediction (of computer success in playing the Imitation Game) confirms the aptness of the Imitation Game test as a test of human level intelligence. It especially belies fears that the test is too easy. At the same time, this failure disconfirms expectations that human level artificial intelligence will be forthcoming any time soon. On the other hand, the success of Turing's second prediction (that acknowledgment of computer thought processes would become commonplace) in practice amply confirms the thought that computers think in some manner and are possessed of some level of intelligence already. This lends ever-growing support to the hypothesis that computers will think at a human level eventually, despite the abject failure of Turing's first prediction</div>
<div id='_46_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAULWM",this.href,0);return true;' href="http://www.springerlink.com/content/p14045502315u372/fulltext.pdf">http://www.springerlink.com/content/p14045502315u372/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAULWM",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319542&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319542&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAULWM",this.href,0);return true;' href="http://www.springerlink.com/index/P14045502315U372.pdf">http://www.springerlink.com/index/P14045502315U372.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAULWM",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319542">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319542</a><br></div></div>
</div><!--entry-->

<div id='_47_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("HAURTW",this.href,0);return true;' href='http://cogprints.org/241/'>Reaping the whirlwind: Reply to Harnad's <em>Other Bodies, Other Minds</em>.</a></span> <span class='pub_name'>Minds and Machines</span> 3 (2):219-37. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17773768264569488065'>Cited by 18</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reaping%20the%20whirlwind+author%3AHauser&amp;btnG=Search'>Google</a> | <a href='javascript:show("_47_links")'>More links</a>)</span><div id='_47_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Harnad''s proposed robotic upgrade of Turing''s Test (TT), from a test of linguistic capacity alone to a Total Turing Test (TTT) of linguisticand sensorimotor capacity, conflicts with his claim that no behavioral test provides even probable warrant for attributions of thought because there is no evidence of consciousness besides private experience. Intuitive, scientific, and philosophical considerations Harnad offers in favor of his proposed upgrade are unconvincing. I agree with Harnad that distinguishing real from as if thought on the basis of (presence or lack of) consciousness (thus rejecting Turing (behavioral) testing as sufficient warrant for mental attribution)has the skeptical consequence Harnad accepts â there is in factno evidence for me that anyone else but me has a mind. I disagree with hisacceptance of it! It would be better to give up the neo-Cartesian faith in private conscious experience underlying Harnad''s allegiance to Searle''s controversial Chinese Room Experiment than give up all claim to know others think. It would be better to allow that (passing) Turing''s Test evidences â evenstrongly evidences â thought</div>
<div id='_47_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAURTW",this.href,0);return true;' href="http://members.aol.com/lshauser/harnad3.html">http://members.aol.com/lshauser/harnad3.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAURTW",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000241/00/reaping.html">http://cogprints.ecs.soton.ac.uk/archive/00000241/00/reaping.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAURTW",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:241">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:241</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAURTW",this.href,0);return true;' href="http://www.springerlink.com/content/h727v843532tp041/fulltext.pdf">http://www.springerlink.com/content/h727v843532tp041/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAURTW",this.href,0);return true;' href="http://www.springerlink.com/index/H727V843532TP041.pdf">http://www.springerlink.com/index/H727V843532TP041.pdf</a><br></div></div>
</div><!--entry-->

<div id='_48_entry' class='entry'><span ><span class='name'>Hayes, Patrick</span> &amp; <span class='name'>Ford, Kenneth M.</span> (1995). Turing test considered harmful.</span> <span class='pub_name'>Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence</span> 1:972-77. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12613228790882625101'>Cited by 26</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%20test%20considered%20harmful+author%3AHayes&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_49_entry' class='entry'><span ><span class='name'>Hernandez-Orallo, Jose</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("HERBTT",this.href,0);return true;' href='http://citeseer.ist.psu.edu/217629.html'>Beyond the Turing test.</a></span> <span class='pub_name'>Journal of Logic, Language and Information</span> 9 (4):447-466. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18031736543989996501'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Beyond%20the%20Turing%20test+author%3AHernandez-Orallo&amp;btnG=Search'>Google</a> | <a href='javascript:show("_49_links")'>More links</a>)</span><div id='_49_abstract' class='extra' style='font-size:12px;'>Abstract:  The main factor of intelligence is defined as the ability tocomprehend, formalising this ability with the help of new constructsbased on descriptional complexity. The result is a comprehension test,or C-test, which is exclusively defined in computational terms. Due toits absolute and non-anthropomorphic character, it is equally applicableto both humans and non-humans. Moreover, it correlates with classicalpsychometric tests, thus establishing the first firm connection betweeninformation theoretical notions and traditional IQ tests. The TuringTest is compared with the C-test and the combination of the two isquestioned. In consequence, the idea of using the Turing Test as apractical test of intelligence should be surpassed, and substituted bycomputational and factorial tests of different cognitive abilities, amuch more useful approach for artificial intelligence progress and formany other intriguing questions that present themselves beyond theTuring Test</div>
<div id='_49_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HERBTT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=595843.595997">http://portal.acm.org/citation.cfm?id=595843.595997</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HERBTT",this.href,0);return true;' href="http://www.dsic.upv.es/~jorallo/escrits/TT-JHdez.ps.gz">http://www.dsic.upv.es/~jorallo/escrits/TT-JHdez.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HERBTT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/hernandez-orallo99beyond.html">http://citeseer.ist.psu.edu/hernandez-orallo99beyond.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HERBTT",this.href,0);return true;' href="http://www.springerlink.com/content/h271n6173ll3773x/fulltext.pdf">http://www.springerlink.com/content/h271n6173ll3773x/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HERBTT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=269489&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=269489&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HERBTT",this.href,0);return true;' href="http://www.springerlink.com/index/H271N6173LL3773X.pdf">http://www.springerlink.com/index/H271N6173LL3773X.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HERBTT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269489">http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269489</a><br></div></div>
</div><!--entry-->

<div id='_50_entry' class='entry'><span ><span class='name'>Hofstadter, Douglas R.</span> (1981). A coffee-house conversation on the Turing test.</span> <span class='pub_name'>Scientific American</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_50_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20coffee-house%20conversation%20on%20the%20Turing%20test+author%3AHofstadter&amp;btnG=Search'>Google</a>)</span><div id='_50_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A dialogue on the Turing test.</div></div>
</div><!--entry-->

<div id='_51_entry' class='entry'><span ><span class='name'>Jacquette, Dale</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("JACATT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(199304)68:264&lt;231:ATTC&gt;2.0.CO;2-L'>A Turing test conversation.</a></span> <span class='pub_name'>Philosophy</span> 68 (264):231-33. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12113573061996436084'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20Turing%20test%20conversation+author%3AJacquette&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_52_entry' class='entry'><span ><span class='name'>Jacquette, Dale</span> (1993). Who's afraid of the Turing test?</span> <span class='pub_name'>Behavior and Philosophy</span> 20 (21):63-74. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_52_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Who%27s%20afraid%20of%20the%20Turing%20test%3F+author%3AJacquette&amp;btnG=Search'>Google</a>)</span><div id='_52_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Defending the Turing test against French 1990. Turing did not intend the test to provide a *necessary* condition for intelligence.</div></div>
</div><!--entry-->

<div id='_53_entry' class='entry'><span ><span class='name'>Karelis, Charles</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("KARROT",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-5914.1986.tb00073.x'>Reflections on the Turing test.</a></span> <span class='pub_name'>Journal for the Theory of Social Behavior</span> 16 (July):161-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12657359925709206531'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reflections%20on%20the%20Turing%20test+author%3AKarelis&amp;btnG=Search'>Google</a> | <a href='javascript:show("_53_links")'>More links</a>)</span>
<div id='_53_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KARROT",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120025387/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120025387/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_54_entry' class='entry'><span ><span class='name'>Klsadlkjfs, Addssdf</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("KLSMT",this.href,0);return true;' href='http://philpapers.org/archive/KLSMT'>mind thing.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=mind%20thing+author%3AKlsadlkjfs&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_55_entry' class='entry'><span ><span class='name'>Lee, E. T.</span> (1996). On the Turing test for artificial intelligence.</span> <span class='pub_name'>Kybernetes</span> 25. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18155623122613280086'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20Turing%20test%20for%20artificial%20intelligence+author%3ALee&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_56_entry' class='entry'><span ><span class='name'>Leiber, Justin</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("LEIOTT",this.href,0);return true;' href='http://www.springerlink.com/content/g6154631rj2612l8/fulltext.pdf'>On Turing's Turing test and why the matter matters.</a></span> <span class='pub_name'>Synthese</span> 104 (1):59-69. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9501491331477387901'>Cited by 6</a> | <span class='ll' onclick='$("_56_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20Turing%27s%20Turing%20test%20and%20why%20the%20matter%20matters+author%3ALeiber&amp;btnG=Search'>Google</a>)</span><div id='_56_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Turing's test is neutral about the structure of the machine that passes it, but it must be practical and reliable (thus excluding Searle's and Block's counterexamples).</div></div>
</div><!--entry-->

<div id='_57_entry' class='entry'><span ><span class='name'>Leiber, Justin</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("LEISOT",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-5914.1989.tb00148.x'>Shanon on the Turing test.</a></span> <span class='pub_name'>Journal of Social Behavior</span> 19 (June):257-259. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7857884051024520272'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Shanon%20on%20the%20Turing%20test+author%3ALeiber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_57_links")'>More links</a>)</span>
<div id='_57_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEISOT",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120004127/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120004127/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_58_entry' class='entry'><span ><span class='name'>Leiber, Justin</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("LEITAT",this.href,0);return true;' href='http://mailer.fsu.edu/~jleiber/Turing and the fragility.pdf'>Turing and the fragility and insubstantiality of evolutionary explanations: A puzzle about the unity of Alan Turing's work with some larger implications.</a></span> <span class='pub_name'>Philosophical Psychology</span> 14 (1):83-94. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%20and%20the%20fragility%20and%20insubstantiality%20of%20evolutionary%20explanations+author%3ALeiber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_58_links")'>More links</a>)</span><div id='_58_abstract' class='extra' style='font-size:12px;'>Abstract: As is well known, Alan Turing drew a line, embodied in the "Turing test," between intellectual and physical abilities, and hence between cognitive and natural sciences. Less familiarly, he proposed that one way to produce a "passer" would be to educate a "child machine," equating the experimenter's improvements in the initial structure of the child machine with genetic mutations, while supposing that the experimenter might achieve improvements more expeditiously than natural selection. On the other hand, in his foundational "On the chemical basis of morphogenesis," Turing insisted that biological explanation clearly confine itself to purely physical and chemical means, eschewing vitalist and teleological talk entirely and hewing to D'Arcy Thompson's line that "evolutionary 'explanations,'" are historical and narrative in character, employing the same intentional and teleological vocabulary we use in doing human history, and hence, while perhaps on occasion of heuristic value, are not part of biology as a natural science. To apply Turing's program to recent issues, the attempt to give foundations to the social and cognitive sciences in the "real science" of evolutionary biology (as opposed to Turing's biology) is neither to give foundations, nor to achieve the unification of the social/cognitive sciences and the natural sciences</div>
<div id='_58_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEITAT",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a713690490~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a713690490~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_59_entry' class='entry'><span ><span class='name'>Leiber, Justin</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("LEITGH",this.href,0);return true;' href='http://mailer.fsu.edu/~jleiber/Turing&#39;sGolden.htm'>Turing's golden: How well Turing's work stands today.</a></span> <span class='pub_name'>Philosophical Psychology</span> 19 (1):13-46. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%27s%20golden+author%3ALeiber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_59_links")'>More links</a>)</span><div id='_59_abstract' class='extra' style='font-size:12px;'>Abstract: A. M. Turing has bequeathed us a conceptulary including 'Turing, or Turing-Church, thesis', 'Turing machine', 'universal Turing machine', 'Turing test' and 'Turing structures', plus other unnamed achievements. These include a proof that any formal language adequate to express arithmetic contains undecidable formulas, as well as achievements in computer science, artificial intelligence, mathematics, biology, and cognitive science. Here it is argued that these achievements hang together and have prospered well in the 50 years since Turing's death</div>
<div id='_59_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEITGH",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a741477282~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a741477282~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEITGH",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/NGH381WR75272U7R.pdf">http://taylorandfrancis.metapress.com/index/NGH381WR75272U7R.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEITGH",this.href,0);return true;' href="http://www.informaworld.com/index/741477282.pdf">http://www.informaworld.com/index/741477282.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEITGH",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2006/00000019/00000001/art00003">http://www.ingentaconnect.com/content/routledg/cphp/2006/00000019/00000001/art00003</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEITGH",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/latest">http://www.ingentaconnect.com/content/routledg/cphp/latest</a><br></div></div>
</div><!--entry-->

<div id='_60_entry' class='entry'><span ><span class='name'>Lockhart, Robert S.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("LOCMCP",this.href,0);return true;' href='http://psycprints.ecs.soton.ac.uk/archive/00000068'>Modularity, cognitive penetrability and the Turing test.</a></span> <span class='pub_name'>Psycoloquy</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3129782407756186128'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modularity%2C%20cognitive%20penetrability%20and%20the%20Turing%20test+author%3ALockhart&amp;btnG=Search'>Google</a> | <a href='javascript:show("_60_links")'>More links</a>)</span><div id='_60_abstract' class='extra' style='font-size:12px;'>Abstract: The Turing Test blurs the distinction between a model and irrelevant) instantiation details. Modeling only functional modules is problematic if these are interconnected and cognitively penetrable</div>
<div id='_60_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LOCMCP",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000068/">http://psycprints.ecs.soton.ac.uk/archive/00000068/</a><br></div></div>
</div><!--entry-->

<div id='_61_entry' class='entry'><span ><span class='name'>Mays, W.</span> (1952). <a rel="nofollow" class='article_title' onclick='trackclick("MAYCMT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(195204)27:101&lt;148:CMT&gt;2.0.CO;2-D'>Can machines think?</a></span> <span class='pub_name'>Philosophy</span> 27 (April):148-62. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16995339974891461590'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20machines%20think%3F+author%3AMays&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_62_entry' class='entry'><span ><span class='name'>Michie, Donald</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("MICTTA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=152186'>Turing's test and conscious thought.</a></span> <span class='pub_name'>Artificial Intelligence</span> 60:1-22. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8413881760235531537'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%27s%20test%20and%20conscious%20thought+author%3AMichie&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_63_entry' class='entry'><span ><span class='name'>Midgley, Mary</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("MIDZAT",this.href,0);return true;' href='http://www.ingentaconnect.com/content/imp/jcs/1995/00000002/00000004/668'>Zombies and the Turing test.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 2 (4):351-352. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Zombies%20and%20the%20Turing%20test+author%3AMidgley&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_64_entry' class='entry'><span ><span class='name'>Millar, P.</span> (1973). <a rel="nofollow" class='article_title' onclick='trackclick("MILOTP",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA177&amp;ots=dLmgNP339B&amp;sig=kc6dFj9Hv7cAPObKmVqQKlXMCIo'>On the point of the imitation game.</a></span> <span class='pub_name'>Mind</span> 82 (October):595-97. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5978809821840527790'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20point%20of%20the%20imitation%20game+author%3AMillar&amp;btnG=Search'>Google</a> | <a href='javascript:show("_64_links")'>More links</a>)</span>
<div id='_64_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MILOTP",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0026-4423(197310)2:82:328&lt;595:OTPOTI&gt;2.0.CO;2-7">http://links.jstor.org/sici?sici=0026-4423(197310)2:82:328<595:OTPOTI>2.0.CO;2-7</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MILOTP",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(197310)2:82:328&lt;595:OTPOTI&gt;2.0.CO;2-7">http://www.jstor.org/sici?sici=0026-4423(197310)2:82:328<595:OTPOTI>2.0.CO;2-7</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MILOTP",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2252214.pdf">http://www.jstor.org/stable/pdfplus/2252214.pdf</a><br></div></div>
</div><!--entry-->

<div id='_65_entry' class='entry'><span ><span class='name'>Mitchell, Robert W.</span> &amp; <span class='name'>Anderson, James R.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("MITPTO",this.href,0);return true;' href='http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=30480&amp;jid=BBS&amp;volumeId=21&amp;issueId=01&amp;aid=30479'>Primate theory of mind is a Turing test.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21 (1):127-128. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Primate%20theory%20of%20mind%20is%20a%20Turing%20test+author%3AMitchell&amp;btnG=Search'>Google</a>)</span><div id='_65_abstract' class='extra' style='font-size:12px;'>Abstract: Heyes's literature review of deception, imitation, and self-recognition is inadequate, misleading, and erroneous. The anaesthetic artifact hypothesis of self-recognition is unsupported by the data she herself examines. Her proposed experiment is tantalizing, indicating that theory of mind is simply a Turing test</div>
</div><!--entry-->

<div id='_66_entry' class='entry'><span ><span class='name'>Moor, James H.</span> (1976). An analysis of Turing's test.</span> <span class='pub_name'>Philosophical Studies</span> 30:249-257. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_66_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=An%20analysis%20of%20Turing%27s%20test+author%3AMoor&amp;btnG=Search'>Google</a>)</span><div id='_66_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The basis of the Turing test is not an operational definition of thinking, but rather an inference to the best explanation.</div></div>
</div><!--entry-->

<div id='_67_entry' class='entry'><span ><span class='name'>Moor, James H.</span> (1976). <a rel="nofollow" class='article_title' onclick='trackclick("MOOAAO-3",this.href,0);return true;' href='http://www.springerlink.com/content/x336q61282151813/fulltext.pdf'>An analysis of the Turing test.</a></span> <span class='pub_name'>Philosophical Studies</span> 30 (4). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=An%20analysis%20of%20the%20Turing%20test+author%3AMoor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_68_entry' class='entry'><span ><span class='name'>Moor, James H.</span> (1978). <a rel="nofollow" class='article_title' onclick='trackclick("MOOECB",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA311&amp;ots=dLmgNP4Z9D&amp;sig=FpK9IjA-y6P_FKixBhB2qyNmkvE'>Explaining computer behavior.</a></span> <span class='pub_name'>Philosophical Studies</span> 34 (October):325-7. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9613504063540588162'>Cited by 9</a> | <span class='ll' onclick='$("_68_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Explaining%20computer%20behavior+author%3AMoor&amp;btnG=Search'>Google</a> | <a href='javascript:show("_68_links")'>More links</a>)</span><div id='_68_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Stalker 1978: Mechanistic and mentalistic explanations are no more incompatible than program-based and physical explanations.</div></div>
<div id='_68_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOECB",this.href,0);return true;' href="http://www.springerlink.com/content/x313g334823725mv/fulltext.pdf">http://www.springerlink.com/content/x313g334823725mv/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOECB",this.href,0);return true;' href="http://www.springerlink.com/index/X313G334823725MV.pdf">http://www.springerlink.com/index/X313G334823725MV.pdf</a><br></div></div>
</div><!--entry-->

<div id='_69_entry' class='entry'><span ><span class='name'>Moor, James H.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("MOOTSA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596908'>The status and future of the Turing test.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (1):77-93. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11997294287052664376'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20status%20and%20future%20of%20the%20Turing%20test+author%3AMoor&amp;btnG=Search'>Google</a> | <a href='javascript:show("_69_links")'>More links</a>)</span><div id='_69_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The standard interpretation of the imitation game is defended over the rival gender interpretation though it is noted that Turing himself proposed several variations of his imitation game. The Turing test is then justified as an inductive test not as an operational definition as commonly suggested. Turing's famous prediction about his test being passed at the 70% level is disconfirmed by the results of the Loebner 2000 contest and the absence of any serious Turing test competitors from AI on the horizon. But, reports of the death of the Turing test and AI are premature. AI continues to flourish and the test continues to play an important philosophical role in AI. Intelligence attribution, methodological, and visionary arguments are given in defense of a continuing role for the Turing test. With regard to Turing's predictions one is disconfirmed, one is confirmed, but another is still outstanding</div>
<div id='_69_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOTSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=RA3-PA197&amp;ots=blQIDolec0&amp;sig=7Zb746qi1B6hBAlr4ehD3tEmgZc">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=RA3-PA197&ots=blQIDolec0&sig=7Zb746qi1B6hBAlr4ehD3tEmgZc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOTSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=5BJaXSedqfIC&amp;oi=fnd&amp;pg=RA3-PA197&amp;ots=rzjaULCgnv&amp;sig=BtFI0p2CUYyifPgOjuKkYI__bFc">http://books.google.com/books?hl=en&lr=&id=5BJaXSedqfIC&oi=fnd&pg=RA3-PA197&ots=rzjaULCgnv&sig=BtFI0p2CUYyifPgOjuKkYI__bFc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOTSA",this.href,0);return true;' href="http://www.springerlink.com/content/ju585836x7571202/fulltext.pdf">http://www.springerlink.com/content/ju585836x7571202/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOTSA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319545&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319545&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOTSA",this.href,0);return true;' href="http://www.springerlink.com/index/JU585836X7571202.pdf">http://www.springerlink.com/index/JU585836X7571202.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MOOTSA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319545">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319545</a><br></div></div>
</div><!--entry-->

<div id='_70_entry' class='entry'><span ><span class='name'>Nichols, Shaun</span> &amp; <span class='name'>Stich, Stephen P.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("NICFP",this.href,0);return true;' href='http://ruccs.rutgers.edu/tech_rpt/folkpsych5.pdf '>Folk psychology.</a></span> <span class='pub_name'>Encyclopedia of Cognitive Science</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5416574873704268713'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20psychology+author%3ANichols&amp;btnG=Search'>Google</a> | <a href='javascript:show("_70_links")'>More links</a>)</span><div id='_70_abstract' class='extra' style='font-size:12px;'>Abstract: For the last 25 years discussions and debates about commonsense psychology (or âfolk psychology,â as it is often called) have been center stage in the philosophy of mind. There have been heated disagreements both about what folk psychology is and about how it is related to the scientific understanding of the mind/brain that is emerging in psychology and the neurosciences. In this chapter we will begin by explaining why folk psychology plays such an important role in the philosophy of mind. Doing that will require a quick look at a bit of the history of philosophical discussions about the mind. Weâll then turn our attention to the lively contemporary discussions aimed at clarifying the philosophical role that folk psychology is expected to play and at using findings in the cognitive sciences to get a clearer understanding of the exact nature of folk psychology</div>
<div id='_70_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://www.blutner.de/philom/Texte/folkpsych5.pdf ">http://www.blutner.de/philom/Texte/folkpsych5.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://www.blutner.de/NeuralNets/Texts/folkpsych5.pdf ">http://www.blutner.de/NeuralNets/Texts/folkpsych5.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://amor.rz.hu-berlin.de/~h0998dgh/philos/Texte/folkpsych5.pdf ">http://amor.rz.hu-berlin.de/~h0998dgh/philos/Texte/folkpsych5.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://amor.cms.hu-berlin.de/~h0998dgh/philos/Texte/folkpsych5.pdf ">http://amor.cms.hu-berlin.de/~h0998dgh/philos/Texte/folkpsych5.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://dingo.sbs.arizona.edu/~snichols/Papers/FolkPsychologyECS.pdf">http://dingo.sbs.arizona.edu/~snichols/Papers/FolkPsychologyECS.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://amor.rz.hu-berlin.de/~h0998dgh/NeuralNets/Texts/folkpsych5.pdf ">http://amor.rz.hu-berlin.de/~h0998dgh/NeuralNets/Texts/folkpsych5.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://www.rci.rutgers.edu/~stich/Publications/Papers/FolkPsychology.pdf">http://www.rci.rutgers.edu/~stich/Publications/Papers/FolkPsychology.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://www.rci.rutgers.edu/~stich/Publications/Papers/FolkPsychology.pdf ">http://www.rci.rutgers.edu/~stich/Publications/Papers/FolkPsychology.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://www-personal.umich.edu/~lormand/phil/teach/mmm/readings/Stich - Cognitive Science and the Appeal to Tacit Theory.rtf ">http://www-personal.umich.edu/~lormand/phil/teach/mmm/readings/Stich - Cognitive Science and the Appeal to Tacit Theory.rtf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFP",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=8039374&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=8039374&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_71_entry' class='entry'><span ><span class='name'>Oppy, Graham</span> &amp; <span class='name'>Dowe, D.</span> (online). The Turing test.</span> <em>Stanford Encyclopedia of Philosophy</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18042499666466145496'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test+author%3AOppy&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_72_entry' class='entry'><span ><span class='name'>Piccinini, Gualtiero</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("PICTRF",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596724.596955'>Turing's rules for the imitation game.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (4):573-582. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14023629074742377387'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%27s%20rules%20for%20the%20imitation%20game+author%3APiccinini&amp;btnG=Search'>Google</a> | <a href='javascript:show("_72_links")'>More links</a>)</span><div id='_72_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In the 1950s, Alan Turing proposed his influential test for machine intelligence, which involved a teletyped dialogue between a human player, a machine, and an interrogator. Two readings of Turing''s rules for the test have been given. According to the standard reading of Turing''s words, the goal of the interrogator was to discover which was the human being and which was the machine, while the goal of the machine was to be indistinguishable from a human being. According to the literal reading, the goal of the machine was to simulate a man imitating a woman, while the interrogator â unaware of the real purpose of the test â was attempting to determine which of the two contestants was the woman and which was the man. The present work offers a study of Turing''s rules for the test in the context of his advocated purpose and his other texts. The conclusion is that there are several independent and mutually reinforcing lines of evidence that support the standard reading, while fitting the literal reading in Turing''s work faces severe interpretative difficulties. So, the controversy over Turing''s rules should be settled in favor of the standard reading</div>
<div id='_72_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICTRF",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=5BJaXSedqfIC&amp;oi=fnd&amp;pg=RA1-PA573&amp;ots=rzj9ZTxlot&amp;sig=sOABQfQAHOiAecLsjc4Dkdn0Kko">http://books.google.com/books?hl=en&lr=&id=5BJaXSedqfIC&oi=fnd&pg=RA1-PA573&ots=rzj9ZTxlot&sig=sOABQfQAHOiAecLsjc4Dkdn0Kko</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICTRF",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=RA1-PA573&amp;ots=blQHIwgjd_&amp;sig=k_FvcCrJGK1pHaGSeZX1ciLb8SM">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=RA1-PA573&ots=blQHIwgjd_&sig=k_FvcCrJGK1pHaGSeZX1ciLb8SM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICTRF",this.href,0);return true;' href="http://www.springerlink.com/content/content/v1k277193084750u/fulltext.pdf">http://www.springerlink.com/content/content/v1k277193084750u/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICTRF",this.href,0);return true;' href="http://www.springerlink.com/content/v1k277193084750u/fulltext.pdf">http://www.springerlink.com/content/v1k277193084750u/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICTRF",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319535&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319535&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICTRF",this.href,0);return true;' href="http://www.springerlink.com/index/V1K277193084750U.pdf">http://www.springerlink.com/index/V1K277193084750U.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICTRF",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319535">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319535</a><br></div></div>
</div><!--entry-->

<div id='_73_entry' class='entry'><span ><span class='name'>Purthill, R.</span> (1971). <a rel="nofollow" class='article_title' onclick='trackclick("PURBTI",this.href,0);return true;' href='http://www.jstor.org/sici?sici=0026-4423(197104)2:80:318&lt;290:BTIG&gt;2.0.CO;2-V'>Beating the imitation game.</a></span> <span class='pub_name'>Mind</span> 80 (April):290-94. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Beating%20the%20imitation%20game+author%3APurthill&amp;btnG=Search'>Google</a> | <a href='javascript:show("_73_links")'>More links</a>)</span>
<div id='_73_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PURBTI",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2252425.pdf">http://www.jstor.org/stable/pdfplus/2252425.pdf</a><br></div></div>
</div><!--entry-->

<div id='_74_entry' class='entry'><span ><span class='name'>Rankin, Terry L.</span> (1987). The Turing paradigm: A critical assessment.</span> <span class='pub_name'>Dialogue</span> 29 (April):50-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14893207474371942461'>Cited by 3</a> | <span class='ll' onclick='$("_74_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20paradigm+author%3ARankin&amp;btnG=Search'>Google</a>)</span><div id='_74_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Some obscure remarks on lying, imitation, and the Turing test.</div></div>
</div><!--entry-->

<div id='_75_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("RAPHTP",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=595998'>How to pass a Turing test: Syntactic semantics, natural-language understanding, and first-person cognition.</a></span> <span class='pub_name'>Journal of Logic, Language, and Information</span> 9 (4):467-490. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11475262290142978380'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20to%20pass%20a%20Turing%20test+author%3ARapaport&amp;btnG=Search'>Google</a> | <a href='javascript:show("_75_links")'>More links</a>)</span>
<div id='_75_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHTP",this.href,0);return true;' href="http://www.cse.buffalo.edu/tech-reports/99-06.ps">http://www.cse.buffalo.edu/tech-reports/99-06.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHTP",this.href,0);return true;' href="http://www.cse.buffalo.edu/tech-reports/99-06.ps.Z">http://www.cse.buffalo.edu/tech-reports/99-06.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHTP",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/turing.pdf">http://www.cse.buffalo.edu/~rapaport/Papers/turing.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHTP",this.href,0);return true;' href="http://historical.ncstrl.org/litesite-data/suny_buffalo_cs/99-06.ps">http://historical.ncstrl.org/litesite-data/suny_buffalo_cs/99-06.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHTP",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=269490&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=269490&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHTP",this.href,0);return true;' href="http://www.springerlink.com/index/JW2371N7T37H2V10.pdf">http://www.springerlink.com/index/JW2371N7T37H2V10.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHTP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269490">http://www.ingentaconnect.com/content/klu/jlli/2000/00000009/00000004/00269490</a><br></div></div>
</div><!--entry-->

<div id='_76_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("RAPHTP-2",this.href,0);return true;' href='http://www.springerlink.com/content/jw2371n7t37h2v10/fulltext.pdf'>How to pass a Turing test.</a></span> <span class='pub_name'>Journal of Logic, Language and Information</span> 9 (4). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20to%20pass%20a%20Turing%20test+author%3ARapaport&amp;btnG=Search'>Google</a>)</span><div id='_76_abstract' class='extra' style='font-size:12px;'>Abstract:  I advocate a theory of syntactic semantics as a way of understanding how computers can think (and how the Chinese-Room-Argument objection to the Turing Test can be overcome): (1) Semantics, considered as the study of relations between symbols and meanings, can be turned into syntax â a study of relations among symbols (including meanings) â and hence syntax (i.e., symbol manipulation) can suffice for the semantical enterprise (contra Searle). (2) Semantics, considered as the process of understanding one domain (by modeling it) in terms of another, can be viewed recursively: The base case of semantic understanding âunderstanding a domain in terms of itself â is syntactic understanding. (3) An internal (or narrow), first-person point of view makes an external (or wide), third-person point of view otiose for purposes of understanding cognition</div>
</div><!--entry-->

<div id='_77_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("RAPRO_",this.href,0);return true;' href='http://www.cse.buffalo.edu/~rapaport/Papers/shieberreview.pdf'>Review of <em>The Turing Test: Verbal Behavior As the Hallmark of Intelligence</em>.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Review%20of%20The%20Turing%20Test+author%3ARapaport&amp;btnG=Search'>Google</a> | <a href='javascript:show("_77_links")'>More links</a>)</span><div id='_77_abstract' class='extra' style='font-size:12px;'>Abstract: Stuart M. Shieberâs name is well known to computational linguists for his research and to computer scientists more generally for his debate on the Loebner Turing Test competition, which appeared a decade earlier in Communications of the ACM (Shieber 1994a, 1994b; Loebner 1994).<sup>1</sup> With this collection, I expect it to become equally well known to philosophers</div>
<div id='_77_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPRO_",this.href,0);return true;' href="http://www.mitpressjournals.org/doi/pdf/10.1162/089120105774321127">http://www.mitpressjournals.org/doi/pdf/10.1162/089120105774321127</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPRO_",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/shieberreview-original.pdf">http://www.cse.buffalo.edu/~rapaport/Papers/shieberreview-original.pdf</a><br></div></div>
</div><!--entry-->

<div id='_78_entry' class='entry'><span ><span class='name'>Ravenscroft, Ian</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("RAVFPA",this.href,0);return true;' href='http://plato.stanford.edu/entries/folkpsych-theory/'>Folk psychology as a theory.</a></span> <em>Stanford Encyclopedia of Philosophy</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4524544867210433784'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20psychology%20as%20a%20theory+author%3ARavenscroft&amp;btnG=Search'>Google</a> | <a href='javascript:show("_78_links")'>More links</a>)</span><div id='_78_abstract' class='extra' style='font-size:12px;'>Abstract: Many philosophers and cognitive scientists claim that our everyday or "folk" understanding of mental states constitutes a theory of mind. That theory is widely called "folk psychology" (sometimes "commonsense" psychology). The terms in which folk psychology is couched are the familiar ones of "belief" and "desire", "hunger", "pain" and so forth. According to many theorists, folk psychology plays a central role in our capacity to predict and explain the behavior of ourselves and others. However, the nature and status of folk psychology remains controversial</div>
<div id='_78_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAVFPA",this.href,0);return true;' href="http://plato.stanford.edu/entries/folkpsych-theory ">http://plato.stanford.edu/entries/folkpsych-theory </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAVFPA",this.href,0);return true;' href="http://plato.stanford.edu/entries/folkpsych-theory/ ">http://plato.stanford.edu/entries/folkpsych-theory/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAVFPA",this.href,0);return true;' href="http://www.seop.leeds.ac.uk/entries/folkpsych-theory/ ">http://www.seop.leeds.ac.uk/entries/folkpsych-theory/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAVFPA",this.href,0);return true;' href="http://www.illc.uva.nl/~seop/entries/folkpsych-theory/ ">http://www.illc.uva.nl/~seop/entries/folkpsych-theory/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAVFPA",this.href,0);return true;' href="http://www.science.uva.nl/~seop/entries/folkpsych-theory/ ">http://www.science.uva.nl/~seop/entries/folkpsych-theory/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAVFPA",this.href,0);return true;' href="http://setis.library.usyd.edu.au/stanford/entries/folkpsych-theory/">http://setis.library.usyd.edu.au/stanford/entries/folkpsych-theory/</a><br></div></div>
</div><!--entry-->

<div id='_79_entry' class='entry'><span ><span class='name'>Rhodes, Kris</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("RHOVOT",this.href,0);return true;' href='http://philpapers.org/archive/RHOVOT'>Vindication of the Rights of Machine.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Vindication%20of%20the%20Rights%20of%20Machine+author%3ARhodes&amp;btnG=Search'>Google</a> | <a href='javascript:show("_79_links")'>More links</a>)</span><div id='_79_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper, I argue that certain Machines can have rights independently of whether they are sentient, or conscious, or whatever you might call it.</div>
<div id='_79_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RHOVOT",this.href,0);return true;' href="http://www.igradeyourpaper.com/VRMv3.doc">http://www.igradeyourpaper.com/VRMv3.doc</a><br></div></div>
</div><!--entry-->

<div id='_80_entry' class='entry'><span ><span class='name'>Richardson, Robert C.</span> (1982). <a rel="nofollow" class='article_title' onclick='trackclick("RICTTF",this.href,0);return true;' href='http://www.springerlink.com/content/g3151345x710l62h/fulltext.pdf'>Turing tests for intelligence: Ned Block's defense of psychologism.</a></span> <span class='pub_name'>Philosophical Studies</span> 41 (May):421-6. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17087407222981991615'>Cited by 4</a> | <span class='ll' onclick='$("_80_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%20tests%20for%20intelligence+author%3ARichardson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_80_links")'>More links</a>)</span><div id='_80_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A weak argument against Block: input/output function doesn't guarantee a capacity to respond sensibly.</div></div>
<div id='_80_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RICTTF",this.href,0);return true;' href="http://www.springerlink.com/index/G3151345X710L62H.pdf">http://www.springerlink.com/index/G3151345X710L62H.pdf</a><br></div></div>
</div><!--entry-->

<div id='_81_entry' class='entry'><span ><span class='name'>Rosenberg, Jay F.</span> (1982). Conversation and intelligence.</span> In B. de Gelder (ed.), <em>Knowledge and Representation</em>. Routledge & Kegan Paul. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Conversation%20and%20intelligence+author%3ARosenberg&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_82_entry' class='entry'><span ><span class='name'>Sampson, Geoffrey</span> (1973). <a rel="nofollow" class='article_title' onclick='trackclick("SAMIDO",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA173&amp;ots=dLmgNP5-9E&amp;sig=-YGWxSw0O_27JVFmNZoM1-8lqh4'>In defence of Turing.</a></span> <span class='pub_name'>Mind</span> 82 (October):592-94. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3342559602261088174'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=In%20defence%20of%20Turing+author%3ASampson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_82_links")'>More links</a>)</span>
<div id='_82_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAMIDO",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0026-4423(197310)2:82:328&lt;592:IDOT&gt;2.0.CO;2-M">http://links.jstor.org/sici?sici=0026-4423(197310)2:82:328<592:IDOT>2.0.CO;2-M</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAMIDO",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(197310)2:82:328&lt;592:IDOT&gt;2.0.CO;2-M">http://www.jstor.org/sici?sici=0026-4423(197310)2:82:328<592:IDOT>2.0.CO;2-M</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAMIDO",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2252213.pdf">http://www.jstor.org/stable/pdfplus/2252213.pdf</a><br></div></div>
</div><!--entry-->

<div id='_83_entry' class='entry'><span ><span class='name'>Sato, Y.</span> &amp; <span class='name'>Ikegami, T.</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("SATUIT",this.href,0);return true;' href='http://citeseer.ist.psu.edu/154152.html'>Undecidability in the imitation game.</a></span> <span class='pub_name'>Minds and Machines</span> 14 (2):133-43. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18106743041300426167'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Undecidability%20in%20the%20imitation%20game+author%3ASato&amp;btnG=Search'>Google</a> | <a href='javascript:show("_83_links")'>More links</a>)</span><div id='_83_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper considers undecidability in the imitation game, the so-called Turing Test. In the Turing Test, a human, a machine, and an interrogator are the players of the game. In our model of the Turing Test, the machine and the interrogator are formalized as Turing machines, allowing us to derive several impossibility results concerning the capabilities of the interrogator. The key issue is that the validity of the Turing test is not attributed to the capability of human or machine, but rather to the capability of the interrogator. In particular, it is shown that no Turing machine can be a perfect interrogator. We also discuss meta-imitation game and imitation game with analog interfaces where both the imitator and the interrogator are mimicked by continuous dynamical systems</div>
<div id='_83_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=976736">http://portal.acm.org/citation.cfm?id=976736</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://www.bdc.brain.riken.jp/publications/internal/jour-Undecidability_in_the_Imitation_Game/uig.pdf">http://www.bdc.brain.riken.jp/publications/internal/jour-Undecidability_in_the_Imitation_Game/uig.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://www.bdc.brain.riken.go.jp/publications/internal/jour-Undecidability_in_the_Imitation_Game/uig.pdf">http://www.bdc.brain.riken.go.jp/publications/internal/jour-Undecidability_in_the_Imitation_Game/uig.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://www.bdc.brain.riken.go.jp/publications/internal/trep-Undecidability_in_the_imitation_game/riken-bsi-bdc-tr2001-04.ps.Z">http://www.bdc.brain.riken.go.jp/publications/internal/trep-Undecidability_in_the_imitation_game/riken-bsi-bdc-tr2001-04.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://www.springerlink.com/content/t2771g8512m67737/fulltext.pdf">http://www.springerlink.com/content/t2771g8512m67737/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5253133&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5253133&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://www.springerlink.com/index/T2771G8512M67737.pdf">http://www.springerlink.com/index/T2771G8512M67737.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SATUIT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000002/05253133">http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000002/05253133</a><br></div></div>
</div><!--entry-->

<div id='_84_entry' class='entry'><span ><span class='name'>Saygin, Ayse P.</span>; <span class='name'>Cicekli, Ilyas</span> &amp; <span class='name'>Akman, Varol</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("SAYTT",this.href,0);return true;' href='http://cogprints.org/1925/'>Turing test: 50 years later.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (4):463-518. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 45 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%20test+author%3ASaygin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_84_links")'>More links</a>)</span><div id='_84_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The Turing Test is one of the most disputed topics in artificial intelligence, philosophy of mind, and cognitive science. This paper is a review of the past 50 years of the Turing Test. Philosophical debates, practical developments and repercussions in related disciplines are all covered. We discuss Turing''s ideas in detail and present the important comments that have been made on them. Within this context, behaviorism, consciousness, the `other minds'' problem, and similar topics in philosophy of mind are discussed. We also cover the sociological and psychological aspects of the Turing Test. Finally, we look at the current situation and analyze programs that have been developed with the aim of passing the Turing Test. We conclude that the Turing Test has been, and will continue to be, an influential and controversial topic</div>
<div id='_84_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/378189.html">http://citeseer.ist.psu.edu/378189.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://crl.ucsd.edu/~saygin/papers/MMTT.pdf">http://crl.ucsd.edu/~saygin/papers/MMTT.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596724.596952">http://portal.acm.org/citation.cfm?id=596724.596952</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001925/00/tt50.ps">http://cogprints.ecs.soton.ac.uk/archive/00001925/00/tt50.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://www.cs.bilkent.edu.tr/~akman/jour-papers/mam/mam2000.pdf">http://www.cs.bilkent.edu.tr/~akman/jour-papers/mam/mam2000.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1925">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1925</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://www.springerlink.com/content/content/ph7275k8w0137245/fulltext.pdf">http://www.springerlink.com/content/content/ph7275k8w0137245/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://www.springerlink.com/content/ph7275k8w0137245/fulltext.pdf">http://www.springerlink.com/content/ph7275k8w0137245/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319526&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319526&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://www.springerlink.com/index/PH7275K8W0137245.pdf">http://www.springerlink.com/index/PH7275K8W0137245.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://cogprints.org/1925/2/tt50.ps">http://cogprints.org/1925/2/tt50.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT",this.href,0);return true;' href="http://cogprints.org/1925/0/tt50.ps">http://cogprints.org/1925/0/tt50.ps</a><br></div></div>
</div><!--entry-->

<div id='_85_entry' class='entry'><span ><span class='name'>Saygin, A. P.</span> &amp; <span class='name'>Cicekli, I.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("SAYTT5",this.href,0);return true;' href='http://cogprints.org/1925/'>Turing test: 50 years later.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (4):463-518. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6365994908222027429'>Cited by 44</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%20test+author%3ASaygin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_85_links")'>More links</a>)</span><div id='_85_abstract' class='extra' style='font-size:12px;'>Abstract: </b>The Turing Test is one of the most disputed topics in artiï¬cial intelligence, philosophy of mind, and cognitive science. This paper is a review of the past 50 years of the Turing Test. Philo- sophical debates, practical developments and repercussions in related disciplines are all covered. We discuss Turingâs ideas in detail and present the important comments that have been made on them. Within this context, behaviorism, consciousness, the âother mindsâ problem, and similar topics in philosophy of mind are discussed. We also cover the sociological and psychological aspects of the Turing Test. Finally, we look at the current situation and analyze programs that have been developed with the aim of passing the Turing Test. We conclude that the Turing Test has been, and will continue to be, an inï¬uential and controversial topic</div>
<div id='_85_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://citeseer.ist.psu.edu/378189.html">http://citeseer.ist.psu.edu/378189.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://crl.ucsd.edu/~saygin/papers/MMTT.pdf">http://crl.ucsd.edu/~saygin/papers/MMTT.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596724.596952">http://portal.acm.org/citation.cfm?id=596724.596952</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001925/00/tt50.ps">http://cogprints.ecs.soton.ac.uk/archive/00001925/00/tt50.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://www.cs.bilkent.edu.tr/~akman/jour-papers/mam/mam2000.pdf">http://www.cs.bilkent.edu.tr/~akman/jour-papers/mam/mam2000.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1925">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1925</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319526&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319526&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://www.springerlink.com/index/PH7275K8W0137245.pdf">http://www.springerlink.com/index/PH7275K8W0137245.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://cogprints.org/1925/2/tt50.ps">http://cogprints.org/1925/2/tt50.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SAYTT5",this.href,0);return true;' href="http://cogprints.org/1925/0/tt50.ps">http://cogprints.org/1925/0/tt50.ps</a><br></div></div>
</div><!--entry-->

<div id='_86_entry' class='entry'><span ><span class='name'>Schweizer, Paul</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("SCHTTT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596709.596774'>The truly total Turing test.</a></span> <span class='pub_name'>Minds and Machines</span> 8 (2):263-272. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16550898653956136526'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20truly%20total%20Turing%20test+author%3ASchweizer&amp;btnG=Search'>Google</a> | <a href='javascript:show("_86_links")'>More links</a>)</span><div id='_86_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The paper examines the nature of the behavioral evidence underlying attributions of intelligence in the case of human beings, and how this might be extended to other kinds of cognitive system, in the spirit of the original Turing Test (TT). I consider Harnad's Total Turing Test (TTT), which involves successful performance of both linguistic and robotic behavior, and which is often thought to incorporate the very same range of empirical data that is available in the human case. However, I argue that the TTT is still too weak, because it only tests the capabilities of particular tokens within a preexisting context of intelligent behavior. What is needed is a test of the cognitive type, as manifested through a number of exemplary tokens, in order to confirm that the cognitive type is able to produce the context of intelligent behavior presupposed by tests such as the TT and TTT</div>
<div id='_86_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTTT",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=371134CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=371134CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTTT",this.href,0);return true;' href="http://www.springerlink.com/content/h51pp233m1h732p0/fulltext.pdf">http://www.springerlink.com/content/h51pp233m1h732p0/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTTT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=150465&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=150465&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTTT",this.href,0);return true;' href="http://www.springerlink.com/index/H51PP233M1H732P0.pdf">http://www.springerlink.com/index/H51PP233M1H732P0.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTTT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000002/00150465">http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000002/00150465</a><br></div></div>
</div><!--entry-->

<div id='_87_entry' class='entry'><span ><span class='name'>Sennett, James F.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("SENTIM",this.href,0);return true;' href='http://www.psych.utoronto.ca/~reingold/courses/ai/cache/iceman.htm'>The ice man cometh: Lt. comander data and the Turing test.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20ice%20man%20cometh+author%3ASennett&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_88_entry' class='entry'><span ><span class='name'>Shanon, Benny</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("SHAASC",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-5914.1989.tb00147.x'>A simple comment regarding the Turing test.</a></span> <span class='pub_name'>Journal for the Theory of Social Behavior</span> 19 (June):249-56. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16273444803515594966'>Cited by 8</a> | <span class='ll' onclick='$("_88_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20simple%20comment%20regarding%20the%20Turing%20test+author%3AShanon&amp;btnG=Search'>Google</a> | <a href='javascript:show("_88_links")'>More links</a>)</span><div id='_88_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The Turing test presupposes a representational/computational framework for cognition. Not all phenomena can be captured in teletype communication.</div></div>
<div id='_88_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHAASC",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120004126/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120004126/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_89_entry' class='entry'><span ><span class='name'>Shah, Huma</span> &amp; <span class='name'>Warwick, Kevin</span> (forthcoming). From the Buzzing in Turingâs Head to Machine Intelligence Contests.</span> <span class='pub_name'>TCIT 2010</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20the%20Buzzing%20in%20Turing%E2%80%99s%20Head%20to%20Machine%20Intelligence%20Contests+author%3AShah&amp;btnG=Search'>Google</a>)</span><div id='_89_abstract' class='extra' style='font-size:12px;'>Abstract: This paper presents an analysis of three major contests for machine intelligence. We conclude that a new era for Turingâs test requires a fillip in the guise of a committed sponsor, not unlike DARPA, funders of the successful 2007 Urban Challenge.</div>
</div><!--entry-->

<div id='_90_entry' class='entry'><span ><span class='name'>Shieber, Stuart M.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("SHILFA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/23200.html'>Lessons from a restricted Turing test.</a></span> <span class='pub_name'>Communications of the Association for Computing Machinery</span> 37:70-82. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1149535998728281145'>Cited by 55</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lessons%20from%20a%20restricted%20Turing%20test+author%3AShieber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_90_links")'>More links</a>)</span>
<div id='_90_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHILFA",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1994cmp.lg....4002S">http://adsabs.harvard.edu/abs/1994cmp.lg....4002S</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHILFA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/shieber93lessons.html">http://citeseer.ist.psu.edu/shieber93lessons.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHILFA",this.href,0);return true;' href="http://www.eecs.harvard.edu/shieber/Biblio/Papers/loebner-rev-html/loebner-rev-html.html">http://www.eecs.harvard.edu/shieber/Biblio/Papers/loebner-rev-html/loebner-rev-html.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHILFA",this.href,0);return true;' href="http://www.eecs.harvard.edu/~shieber/Biblio/Papers/loebner-rev-html/loebner-rev-html.html">http://www.eecs.harvard.edu/~shieber/Biblio/Papers/loebner-rev-html/loebner-rev-html.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHILFA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=175208.175217&amp;dl=GUIDE&amp;dl=ACM&amp;idx=175208&amp;part=periodical&amp;WantType=periodical&amp;title=Communications of the ACM">http://portal.acm.org/citation.cfm?id=175208.175217&dl=GUIDE&dl=ACM&idx=175208&part=periodical&WantType=periodical&title=Communications of the ACM</a><br></div></div>
</div><!--entry-->

<div id='_91_entry' class='entry'><span ><span class='name'>Shieber, Stuart M.</span> (ed.) (2004). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("SHITTT",this.href,0);return true;' href='http://books.google.com/books?id=CEMYUU_HFMAC&amp;printsec=front_cover'>The Turing Test: Verbal Behavior As the Hallmark of Intelligence.</a></span></em></span> MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10998134623561337217'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20Test+author%3AShieber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_91_links")'>More links</a>)</span><div id='_91_abstract' class='extra' style='font-size:12px;'>Abstract: Stuart M. Shieberâs name is well known to computational linguists for his research and to computer scientists more generally for his debate on the Loebner Turing Test competition, which appeared a decade earlier in Communications of the ACM (Shieber 1994a, 1994b; Loebner 1994).<sup>1</sup> With this collection, I expect it to become equally well known to philosophers</div>
<div id='_91_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=993978">http://portal.acm.org/citation.cfm?id=993978</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/shieberreview.pdf">http://www.cse.buffalo.edu/~rapaport/Papers/shieberreview.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT",this.href,0);return true;' href="http://www.mitpressjournals.org/doi/abs/10.1162/089120105774321127">http://www.mitpressjournals.org/doi/abs/10.1162/089120105774321127</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT",this.href,0);return true;' href="http://www.mitpressjournals.org/doi/pdf/10.1162/089120105774321127">http://www.mitpressjournals.org/doi/pdf/10.1162/089120105774321127</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/shieberreview-original.pdf">http://www.cse.buffalo.edu/~rapaport/Papers/shieberreview-original.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT",this.href,0);return true;' href="http://www.mitpressjournals.org/doi/pdfplus/10.1162/089120105774321127">http://www.mitpressjournals.org/doi/pdfplus/10.1162/089120105774321127</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2006018403060CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2006018403060CI</a><br></div></div>
</div><!--entry-->

<div id='_92_entry' class='entry'><span ><span class='name'>Shieber, Stuart M.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("SHITTT-2",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0068.2007.00636.x'>The Turing test as interactive proof.</a></span> <span class='pub_name'>NoÃ»s</span> 41 (4):686&#8211;713. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test%20as%20interactive%20proof+author%3AShieber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_92_links")'>More links</a>)</span>
<div id='_92_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHITTT-2",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/117997259/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/117997259/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_93_entry' class='entry'><span ><span class='name'>Stalker, Douglas F.</span> (1978). <a rel="nofollow" class='article_title' onclick='trackclick("STAWMC",this.href,0);return true;' href='http://www.springerlink.com/content/x101842g87r85027/fulltext.pdf'>Why machines can't think: A reply to James Moor.</a></span> <span class='pub_name'>Philosophical Studies</span> 34 (3):317-20. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2469621780098597866'>Cited by 12</a> | <span class='ll' onclick='$("_93_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20machines%20can%27t%20think+author%3AStalker&amp;btnG=Search'>Google</a> | <a href='javascript:show("_93_links")'>More links</a>)</span><div id='_93_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Contra Moor 1976: The best explanation of computer behavior is mechanistic, not mentalistic.</div></div>
<div id='_93_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STAWMC",this.href,0);return true;' href="http://www.springerlink.com/index/X101842G87R85027.pdf">http://www.springerlink.com/index/X101842G87R85027.pdf</a><br></div></div>
</div><!--entry-->

<div id='_94_entry' class='entry'><span ><span class='name'>Sterrett, Susan G.</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("STENAA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596928'>Nested algorithms and the original imitation game test: A reply to James Moor.</a></span> <span class='pub_name'>Minds and Machines</span> 12 (1):131-136. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16286795411520976980'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Nested%20algorithms%20and%20the%20original%20imitation%20game%20test+author%3ASterrett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_94_links")'>More links</a>)</span>
<div id='_94_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STENAA",this.href,0);return true;' href="http://www.springerlink.com/content/x4225320762736q0/fulltext.pdf">http://www.springerlink.com/content/x4225320762736q0/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STENAA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=391369&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=391369&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STENAA",this.href,0);return true;' href="http://www.springerlink.com/index/X4225320762736Q0.pdf">http://www.springerlink.com/index/X4225320762736Q0.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STENAA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2002/00000012/00000001/00391369">http://www.ingentaconnect.com/content/klu/mind/2002/00000012/00000001/00391369</a><br></div></div>
</div><!--entry-->

<div id='_95_entry' class='entry'><span ><span class='name'>Stevenson, John G.</span> (1976). <a rel="nofollow" class='article_title' onclick='trackclick("STEOTI",this.href,0);return true;' href='http://www.springerlink.com/content/a10m7kw582216882/fulltext.pdf'>On the imitation game.</a></span> <span class='pub_name'>Philosophia</span> 6 (March):131-33. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8221008207537404085'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20imitation%20game+author%3AStevenson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_95_links")'>More links</a>)</span>
<div id='_95_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STEOTI",this.href,0);return true;' href="http://www.springerlink.com/index/A10M7KW582216882.pdf">http://www.springerlink.com/index/A10M7KW582216882.pdf</a><br></div></div>
</div><!--entry-->

<div id='_96_entry' class='entry'><span ><span class='name'>Sterrett, Susan G.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("STETTT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596954'>Turing's two tests for intelligence.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (4):541-559. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15508717710781575043'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%27s%20two%20tests%20for%20intelligence+author%3ASterrett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_96_links")'>More links</a>)</span><div id='_96_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â On a literal reading of `Computing Machinery and Intelligence'', Alan Turing presented not one, but two, practical tests to replace the question `Can machines think?'' He presented them as equivalent. I show here that the first test described in that much-discussed paper is in fact not equivalent to the second one, which has since become known as `the Turing Test''. The two tests can yield different results; it is the first, neglected test that provides the more appropriate indication of intelligence. This is because the features of intelligence upon which it relies are resourcefulness and a critical attitude to one''s habitual responses; thus the test''s applicablity is not restricted to any particular species, nor does it presume any particular capacities. This is more appropriate because the question under consideration is what would count as machine intelligence. The first test realizes a possibility that philosophers have overlooked: a test that uses a human''s linguistic performance in setting an empirical test of intelligence, but does not make behavioral similarity to that performance the criterion of intelligence. Consequently, the first test is immune to many of the philosophical criticisms on the basis of which the (so-called) `Turing Test'' has been dismissed</div>
<div id='_96_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STETTT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=RA1-PA519&amp;ots=blQIDonh93&amp;sig=kpE5iqY7Fjm67XjSS7t2e9XqGDo">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=RA1-PA519&ots=blQIDonh93&sig=kpE5iqY7Fjm67XjSS7t2e9XqGDo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STETTT",this.href,0);return true;' href="http://www.springerlink.com/content/content/k11t54j7821h4230/fulltext.pdf">http://www.springerlink.com/content/content/k11t54j7821h4230/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STETTT",this.href,0);return true;' href="http://www.springerlink.com/content/k11t54j7821h4230/fulltext.pdf">http://www.springerlink.com/content/k11t54j7821h4230/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STETTT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319533&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319533&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STETTT",this.href,0);return true;' href="http://www.springerlink.com/index/K11T54J7821H4230.pdf">http://www.springerlink.com/index/K11T54J7821H4230.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STETTT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319533">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319533</a><br></div></div>
</div><!--entry-->

<div id='_97_entry' class='entry'><span ><span class='name'>Stoica, Cristi</span>, <a rel="nofollow" class='article_title' onclick='trackclick("STOTTE",this.href,0);return true;' href='http://philsci-archive.pitt.edu/archive/00004345/01/TuringTest.pdf'>Turing test, easy to pass; human mind, hard to understand.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%20test%2C%20easy%20to%20pass%3B%20human%20mind%2C%20hard%20to%20understand+author%3AStoica&amp;btnG=Search'>Google</a>)</span><div id='_97_abstract' class='extra' style='font-size:12px;'>Abstract: Under general assumptions, the Turing test can be easily passed by an appropriate algorithm. I show that for any test satisfying several general conditions, we can construct an algorithm that can pass that test, hence, any operational definition is easy to fulfill. I suggest a test complementary to Turing's test, which will measure our understanding of the human mind. The Turing test is required to fix the operational specifications of the algorithm under test; under this constrain, the additional test simply consists in measuring the length of the algorithm</div>
</div><!--entry-->

<div id='_98_entry' class='entry'><span ><span class='name'>Traiger, Saul</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("TRAMTR",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596956'>Making the right identification in the Turing test.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (4):561-572. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9234109336367572617'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Making%20the%20right%20identification%20in%20the%20Turing%20test+author%3ATraiger&amp;btnG=Search'>Google</a> | <a href='javascript:show("_98_links")'>More links</a>)</span><div id='_98_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The test Turing proposed for machine intelligence is usually understood to be a test of whether a computer can fool a human into thinking that the computer is a human. This standard interpretation is rejected in favor of a test based on the Imitation Game introduced by Turing at the beginning of "Computing Machinery and Intelligence."</div>
<div id='_98_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://www.traiger.oxy.edu/publications/making-the-right-identification.pdf">http://www.traiger.oxy.edu/publications/making-the-right-identification.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://faculty.oxy.edu/traiger/publications/making-the-right-identification.pdf">http://faculty.oxy.edu/traiger/publications/making-the-right-identification.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://0-www.faculty.oxy.edu.oasys.lib.oxy.edu/traiger/publications/making-the-right-identification.pdf">http://0-www.faculty.oxy.edu.oasys.lib.oxy.edu/traiger/publications/making-the-right-identification.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=5BJaXSedqfIC&amp;oi=fnd&amp;pg=RA1-PA561&amp;ots=rzjaULFcit&amp;sig=SFxczaJwBF-Ba70js7yMbXB8L6Y">http://books.google.com/books?hl=en&lr=&id=5BJaXSedqfIC&oi=fnd&pg=RA1-PA561&ots=rzjaULFcit&sig=SFxczaJwBF-Ba70js7yMbXB8L6Y</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=RA1-PA561&amp;ots=blQIDooa7_&amp;sig=4ZGzMTB0yiYy62v_qt0Q_DwtyKI">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=RA1-PA561&ots=blQIDooa7_&sig=4ZGzMTB0yiYy62v_qt0Q_DwtyKI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://www.springerlink.com/content/g90h6kqu506lwr75/fulltext.pdf">http://www.springerlink.com/content/g90h6kqu506lwr75/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://www.springerlink.com/index/G90H6KQU506LWR75.pdf">http://www.springerlink.com/index/G90H6KQU506LWR75.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRAMTR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319538">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000004/00319538</a><br></div></div>
</div><!--entry-->

<div id='_99_entry' class='entry'><span ><span class='name'>Turney, Peter</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("TURAST",this.href,0);return true;' href='http://arxiv.org/abs/cs/0212015'>Answering subcognitive Turing test questions: A reply to French.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17588460782459268984'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Answering%20subcognitive%20Turing%20test%20questions+author%3ATurney&amp;btnG=Search'>Google</a> | <a href='javascript:show("_99_links")'>More links</a>)</span><div id='_99_abstract' class='extra' style='font-size:12px;'>Abstract: Robert French has argued that a disembodied computer is incapable of passing a Turing Test that includes subcognitive questions. Subcognitive questions are designed to probe the network of cultural and perceptual associations that humans naturally develop as we live, embodied and embedded in the world. In this paper, I show how it is possible for a disembodied computer to answer subcognitive questions appropriately, contrary to FrenchÂs claim. My approach to answering subcognitive questions is to use statistical information extracted from a very large collection of text. In particular, I show how it is possible to answer a sample of subcognitive questions taken from French, by issuing queries to a search engine that indexes about 350 million Web pages. This simple algorithm may shed light on the nature of human (sub-) cognition, but the scope of this paper is limited to demonstrating that French is mistaken: a disembodied computer can answer subcognitive questions</div>
<div id='_99_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/2002cs.......12015T">http://adsabs.harvard.edu/abs/2002cs.......12015T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://citeseer.ist.psu.edu/turney01answering.html">http://citeseer.ist.psu.edu/turney01answering.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001798/">http://cogprints.ecs.soton.ac.uk/archive/00001798/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://www.extractor.com/download/documents/subcognitive.pdf">http://www.extractor.com/download/documents/subcognitive.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001798/00/subcognitive.pdf">http://cogprints.ecs.soton.ac.uk/archive/00001798/00/subcognitive.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="https://iit-iti.nrc-cnrc.gc.ca/iit-publications-iti/docs/NRC-44898.pdf">https://iit-iti.nrc-cnrc.gc.ca/iit-publications-iti/docs/NRC-44898.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1798">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1798</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/TW3Q03K8NK7UVQJG.pdf">http://taylorandfrancis.metapress.com/index/TW3Q03K8NK7UVQJG.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://www.informaworld.com/index/TW3Q03K8NK7UVQJG.pdf">http://www.informaworld.com/index/TW3Q03K8NK7UVQJG.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/teta/2001/00000013/00000004/art00006">http://www.ingentaconnect.com/content/tandf/teta/2001/00000013/00000004/art00006</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://cogprints.org/1798/1/subcognitive.ps">http://cogprints.org/1798/1/subcognitive.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURAST",this.href,0);return true;' href="http://cogprints.org/1798/0/subcognitive.pdf">http://cogprints.org/1798/0/subcognitive.pdf</a><br></div></div>
</div><!--entry-->

<div id='_100_entry' class='entry'><span ><span class='name'>Turing, Alan M.</span> (1950). <a rel="nofollow" class='article_title' onclick='trackclick("TURCMA",this.href,0);return true;' href='http://cogprints.org/499'>Computing machinery and intelligence.</a></span> <span class='pub_name'>Mind</span> 59 (October):433-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13900598564432406560'>Cited by 9</a> | <span class='ll' onclick='$("_100_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computing%20machinery%20and%20intelligence+author%3ATuring&amp;btnG=Search'>Google</a> | <a href='javascript:show("_100_links")'>More links</a>)</span><div id='_100_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Proposes the Imitation game (Turing test) as a test for intelligence: If a machine can't be told apart from a human in a conversation over a teletype, then that's good enough. With responses to various objections.</div></div><div id='_100_abstract' class='extra' style='font-size:12px;'>Abstract: I propose to consider the question, "Can machines think?" This should begin with definitions of the meaning of the terms "machine" and "think." The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous, If the meaning of the words "machine" and "think" are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, "Can machines think?" is to be sought in a statistical survey such as a Gallup poll. But this is absurd. Instead of attempting such a definition I shall replace the question by another, which is closely related to it and is expressed in relatively unambiguous words. The new form of the problem can be described in terms of a game which we call the 'imitation game." It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart front the other two. The object of the game for the interrogator is to determine which of the other two is the man and which is the woman. He knows them by labels X and Y, and at the end of the game he says either "X is A and Y is B" or "X is B and Y is A." The interrogator is allowed to put questions to A and B. We now ask the question, "What will happen when a machine takes the part of A in this game?" Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, "Can machines think?"</div>
<div id='_100_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://www.ttt.org/ling490/TuringTest.pdf">http://www.ttt.org/ling490/TuringTest.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://www.agent.ai/doc/upload/200302/turi50_1.pdf">http://www.agent.ai/doc/upload/200302/turi50_1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ216711">http://eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ216711</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://www.dcs.gla.ac.uk/~joe/Teaching/ATiCS/FC-TuringAI-intro.pdf">http://www.dcs.gla.ac.uk/~joe/Teaching/ATiCS/FC-TuringAI-intro.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://www.dfki.uni-sb.de/imedia/lidos/bibtex/Collins_a10168-96.html">http://www.dfki.uni-sb.de/imedia/lidos/bibtex/Collins_a10168-96.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://www.marxists.org/reference/subject/philosophy/works/en/turing.htm">http://www.marxists.org/reference/subject/philosophy/works/en/turing.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://lia.deis.unibo.it/corsi/2005-2006/SID-LS-CE/downloads/turing-article.pdf">http://lia.deis.unibo.it/corsi/2005-2006/SID-LS-CE/downloads/turing-article.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:499">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:499</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://twiki.di.uniroma1.it/twiki/viewfile/Users/MarcoBianchi?rev=1.1;filename=TuringComputingMachineryAndIntelligence.pdf">http://twiki.di.uniroma1.it/twiki/viewfile/Users/MarcoBianchi?rev=1.1;filename=TuringComputingMachineryAndIntelligence.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://archive.computerhistory.org/projects/chess/related_materials/text/2-0 and 2-1.Computing_machinery_and_intelligence.turing/2-0 and 2-1.Computing_machinery_and_intelligence.turing-alan.mind-59.1950.062303001.pdf">http://archive.computerhistory.org/projects/chess/related_materials/text/2-0 and 2-1.Computing_machinery_and_intelligence.turing/2-0 and 2-1.Computing_machinery_and_intelligence.turing-alan.mind-59.1950.062303001.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0026-4423(195010)2:59:236&lt;433:CMAI&gt;2.0.CO;2-5">http://links.jstor.org/sici?sici=0026-4423(195010)2:59:236<433:CMAI>2.0.CO;2-5</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(195010)2:59:236&lt;433:CMAI&gt;2.0.CO;2-5">http://www.jstor.org/sici?sici=0026-4423(195010)2:59:236<433:CMAI>2.0.CO;2-5</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://mind.oxfordjournals.org/cgi/reprint/LIX/236/433">http://mind.oxfordjournals.org/cgi/reprint/LIX/236/433</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2251299.pdf">http://www.jstor.org/stable/pdfplus/2251299.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://cogprints.org/499/1/turing.html">http://cogprints.org/499/1/turing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TURCMA",this.href,0);return true;' href="http://cogprints.org/499/0/turing.html">http://cogprints.org/499/0/turing.html</a><br></div></div>
</div><!--entry-->

<div id='_101_entry' class='entry'><span ><span class='name'>Vergauwen, Roger</span> &amp; <span class='name'>GonzÃ¡lez, Rodrigo</span> (2005). On the verisimilitude of artificial intelligence.</span> <span class='pub_name'>Logique Et Analyse-</span> 190 (189):323-350. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20verisimilitude%20of%20artificial%20intelligence+author%3AVergauwen&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_102_entry' class='entry'><span ><span class='name'>Ward, Andrew</span> (1989). Radical interpretation and the Gunderson game.</span> <span class='pub_name'>Dialectica</span> 43 (3):271-280. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Radical%20interpretation%20and%20the%20Gunderson%20game+author%3AWard&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_103_entry' class='entry'><span ><span class='name'>Watt, S.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("WATNPA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/295284.html'>Naive psychology and the inverted Turing test.</a></span> <span class='pub_name'>Psycoloquy</span> 7 (14). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12636542845179401413'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Naive%20psychology%20and%20the%20inverted%20Turing%20test+author%3AWatt&amp;btnG=Search'>Google</a> | <a href='javascript:show("_103_links")'>More links</a>)</span><div id='_103_abstract' class='extra' style='font-size:12px;'>Abstract: This target article argues that the Turing test implicitly rests on a "naive psychology," a naturally evolved psychological faculty which is used to predict and understand the behaviour of others in complex societies. This natural faculty is an important and implicit bias in the observer's tendency to ascribe mentality to the system in the test. The paper analyses the effects of this naive psychology on the Turing test, both from the side of the system and the side of the observer, and then proposes and justifies an inverted version of the test which allows the processes of ascription to be analysed more directly than in the standard version</div>
<div id='_103_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WATNPA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/watt96naive.html">http://citeseer.ist.psu.edu/watt96naive.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WATNPA",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000506/">http://psycprints.ecs.soton.ac.uk/archive/00000506/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WATNPA",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/perl/local/psyc/makedoc?id=506&amp;type=html">http://psycprints.ecs.soton.ac.uk/perl/local/psyc/makedoc?id=506&type=html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WATNPA",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000506/02/psyc.96.7.14.turing-test.1.watt">http://psycprints.ecs.soton.ac.uk/archive/00000506/02/psyc.96.7.14.turing-test.1.watt</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WATNPA",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000506/01/psyc.96.7.14.turing-test.1.watt.xml">http://psycprints.ecs.soton.ac.uk/archive/00000506/01/psyc.96.7.14.turing-test.1.watt.xml</a><br></div></div>
</div><!--entry-->

<div id='_104_entry' class='entry'><span ><span class='name'>Waterman, C.</span> (1995). The Turing test and the argument from analogy for other minds.</span> <span class='pub_name'>Southwest Philosophy Review</span> 11 (1):15-22. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test%20and%20the%20argument%20from%20analogy%20for%20other%20minds+author%3AWaterman&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_105_entry' class='entry'><span ><span class='name'>Whitby, Blay</span> (1996). The Turing test: Ai's biggest blind Alley?</span> In Peter Millican &amp; A. Clark (eds.), <em>Machines and Thought</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14958155716037785676'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20test+author%3AWhitby&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_106_entry' class='entry'><span ><span class='name'>Whitby, Blay</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("WHIWTT",this.href,0);return true;' href='http://www.cogs.susx.ac.uk/users/blayw/tt.html'>Why the Turing test is ai's biggest blind Alley.</a></span> In Peter Millican &amp; A. Clark (eds.), <em>Machines and Thought, The Legacy of Alan Turing</em>. Oup. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20the%20Turing%20test%20is%20ai%27s%20biggest%20blind%20Alley+author%3AWhitby&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_107_entry' class='entry'><span ><span class='name'>Zdenek, Sean</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("ZDEPLT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596719.596907'>Passing loebner's Turing test: A case of conflicting discourse functions.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (1):53-76. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1256356021550730258'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Passing%20loebner%27s%20Turing%20test+author%3AZdenek&amp;btnG=Search'>Google</a> | <a href='javascript:show("_107_links")'>More links</a>)</span><div id='_107_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper argues that the Turing test is based on a fixed and de-contextualized view of communicative competence. According to this view, a machine that passes the test will be able to communicate effectively in a variety of other situations. But the de-contextualized view ignores the relationship between language and social context, or, to put it another way, the extent to which speakers respond dynamically to variations in discourse function, formality level, social distance/solidarity among participants, and participants' relative degrees of power and status (Holmes, 1992). In the case of the Loebner Contest, a present day version of the Turing test, the social context of interaction can be interpreted in conflicting ways. For example, Loebner discourse is defined 1) as a friendly, casual conversation between two strangers of equal power, and 2) as a one-way transaction in which judges control the conversational floor in an attempt to expose contestants that are not human. This conflict in discourse function is irrelevant so long as the goal of the contest is to ensure that only thinking, human entities pass the test. But if the function of Loebner discourse is to encourage the production of software that can pass for human on the level of conversational ability, then the contest designers need to resolve this ambiguity in discourse function, and thus also come to terms with the kind of competence they are trying to measure</div>
<div id='_107_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ZDEPLT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=5BJaXSedqfIC&amp;oi=fnd&amp;pg=RA2-PA53&amp;ots=rzjaULFlks&amp;sig=a-VgtvUjcFyxiSpkIASbwHF4Imk">http://books.google.com/books?hl=en&lr=&id=5BJaXSedqfIC&oi=fnd&pg=RA2-PA53&ots=rzjaULFlks&sig=a-VgtvUjcFyxiSpkIASbwHF4Imk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ZDEPLT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=RA1-PA583&amp;ots=blQIDooj9Z&amp;sig=IxxOEy4OGv0MfwNy7oTRa0j0_9g">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=RA1-PA583&ots=blQIDooj9Z&sig=IxxOEy4OGv0MfwNy7oTRa0j0_9g</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ZDEPLT",this.href,0);return true;' href="http://www.springerlink.com/content/p1572g5485036674/fulltext.pdf">http://www.springerlink.com/content/p1572g5485036674/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ZDEPLT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=319544&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=319544&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ZDEPLT",this.href,0);return true;' href="http://www.springerlink.com/index/P1572G5485036674.pdf">http://www.springerlink.com/index/P1572G5485036674.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ZDEPLT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319544">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000001/00319544</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.1b'></a><a name=''></a><span class='myh3'>6.1b Godelian arguments</span></p>

<div id='cat_6.1b' class='cat_content'>
<div id='__new_entries_6.1b__'></div><div id='__new_entry_6.1b__' class='entry'></div>
<div id='_108_entry' class='entry'><span ><span class='name'>Benacerraf, Paul</span> (1967). God, the devil, and Godel.</span> <span class='pub_name'>The Monist</span> 51 (January):9-32. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_108_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=God%2C%20the%20devil%2C%20and%20Godel+author%3ABenacerraf&amp;btnG=Search'>Google</a>)</span><div id='_108_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Discusses and sharpens Lucas's arguments. Argues that the real consequence is that if we are Turing machines, we can't know which.</div></div>
</div><!--entry-->

<div id='_109_entry' class='entry'><span ><span class='name'>Bojadziev, Damjan</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("BOJGTF",this.href,0);return true;' href='http://nl.ijs.si/~damjan/g-m-c.html'>Mind versus Godel.</a></span> In Matjaz Gams &amp; M. Wu Paprzycki (eds.), <em>Mind Versus Computer</em>. IOS Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12602508672082850484'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%20versus%20Godel+author%3ABojadziev&amp;btnG=Search'>Google</a> | <a href='javascript:show("_109_links")'>More links</a>)</span>
<div id='_109_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOJGTF",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=VHZy4j_Qa-cC&amp;oi=fnd&amp;pg=PA202&amp;dq=+Mind+versus+Godel+Bojadziev&amp;ots=RjBGkflpmk&amp;sig=oyuz5heebVFZdtmfGXFv50bP2zo">http://books.google.com/books?hl=en&lr=&id=VHZy4j_Qa-cC&oi=fnd&pg=PA202&dq=+Mind+versus+Godel+Bojadziev&ots=RjBGkflpmk&sig=oyuz5heebVFZdtmfGXFv50bP2zo</a><br></div></div>
</div><!--entry-->

<div id='_110_entry' class='entry'><span ><span class='name'>Bowie, G. Lee</span> (1982). <a rel="nofollow" class='article_title' onclick='trackclick("BOWLNI",this.href,0);return true;' href='http://www.springerlink.com/content/g54120627174138n/fulltext.pdf'>Lucas' number is finally up.</a></span> <span class='pub_name'>Journal of Philosophy Logic</span> 11 (August):279-85. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2572349558532129814'>Cited by 10</a> | <span class='ll' onclick='$("_110_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lucas%27%20number%20is%20finally%20up+author%3ABowie&amp;btnG=Search'>Google</a> | <a href='javascript:show("_110_links")'>More links</a>)</span><div id='_110_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lucas's very Godelization procedure makes him inconsistent, unless he has an independent way to see if any TM is consistent, which he doesn't.</div></div>
<div id='_110_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOWLNI",this.href,0);return true;' href="http://www.springerlink.com/index/G54120627174138N.pdf">http://www.springerlink.com/index/G54120627174138N.pdf</a><br></div></div>
</div><!--entry-->

<div id='_111_entry' class='entry'><span ><span class='name'>Boyer, David L.</span> (1983). <a rel="nofollow" class='article_title' onclick='trackclick("BOYRLK",this.href,0);return true;' href='http://www.jstor.org/sici?sici=0031-8094(198304)33:131&lt;147:JRLKGA&gt;2.0.CO;2-B'>R. Lucas, Kurt Godel, and Fred astaire.</a></span> <span class='pub_name'>Philosophical Quarterly</span> 33 (April):147-59. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_111_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=R.%20Lucas%2C%20Kurt%20Godel%2C%20and%20Fred%20astaire+author%3ABoyer&amp;btnG=Search'>Google</a> | <a href='javascript:show("_111_links")'>More links</a>)</span><div id='_111_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Remarks on the various ways in which Lucas and a machine might be said to "prove" anything, and the ways in which a machine might simulate Lucas. The argument has all sorts of level confusions, and a bit of circularity.</div></div>
<div id='_111_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOYRLK",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2218741.pdf">http://www.jstor.org/stable/pdfplus/2218741.pdf</a><br></div></div>
</div><!--entry-->

<div id='_112_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> &amp; <span class='name'>Xiao, H.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BRIARO",this.href,0);return true;' href='http://www.rpi.edu/~faheyj2/SB/SELPAP/PENROSE/pen.sel8.pdf'>A refutation of Penrose's new Godelian case against the computational conception of mind.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 12. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20refutation%20of%20Penrose%27s%20new%20Godelian%20case%20against%20the%20computational%20conception%20of%20mind+author%3ABringsjord&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_113_entry' class='entry'><span ><span class='name'>Chari, C. T. K.</span> (1963). <a rel="nofollow" class='article_title' onclick='trackclick("CHAFCO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(196304)38:144&lt;175:FCOMMA&gt;2.0.CO;2-V'>Further comments on minds, machines and Godel.</a></span> <span class='pub_name'>Philosophy</span> 38 (April):175-8. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_113_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Further%20comments%20on%20minds%2C%20machines%20and%20Godel+author%3AChari&amp;btnG=Search'>Google</a>)</span><div id='_113_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Can't reduce the lawless creative process to computation.</div></div>
</div><!--entry-->

<div id='_114_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("CHAMMA",this.href,0);return true;' href='http://consc.net/papers/penrose.html'>Minds, machines, and mathematics.</a></span> <span class='pub_name'>Psyche</span> 2:11-20. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9228240357775967730'>Cited by 17</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%2C%20and%20mathematics+author%3AChalmers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_114_links")'>More links</a>)</span><div id='_114_abstract' class='extra' style='font-size:12px;'>Abstract: In his stimulating book SHADOWS OF THE MIND, Roger Penrose presents arguments, based on GÃ¶del's theorem, for the conclusion that human thought is uncomputable. There are actually two separate arguments in Penrose's book. The second has been widely ignored, but seems to me to be much more interesting and novel than the first. I will address both forms of the argument in some detail. Toward the end, I will also comment on Penrose's proposals for a "new science of consciousness"</div>
<div id='_114_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAMMA",this.href,0);return true;' href="http://www.u.arizona.edu/~chalmers/papers/penrose.html">http://www.u.arizona.edu/~chalmers/papers/penrose.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAMMA",this.href,0);return true;' href="http://psyche.cs.monash.edu.au/v2/psyche-2-09-chalmers.html">http://psyche.cs.monash.edu.au/v2/psyche-2-09-chalmers.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAMMA",this.href,0);return true;' href="http://calculemus.org/MathUniversalis/NS/10/03chalmers.html">http://calculemus.org/MathUniversalis/NS/10/03chalmers.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAMMA",this.href,0);return true;' href="http://psyche.cs.monash.edu.au/volume2-1/psyche-95-2-09-shadows-7-chalmers.html">http://psyche.cs.monash.edu.au/volume2-1/psyche-95-2-09-shadows-7-chalmers.html</a><br></div></div>
</div><!--entry-->

<div id='_115_entry' class='entry'><span ><span class='name'>Chihara, C.</span> (1972). <a rel="nofollow" class='article_title' onclick='trackclick("CHIOAR",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(19720921)69:17&lt;507:OAROMU&gt;2.0.CO;2-9'>On alleged refutations of mechanism using Godel's incompleteness results.</a></span> <span class='pub_name'>Journal of Philosophy</span> 69 (September):507-26. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10795953065151896842'>Cited by 9</a> | <span class='ll' onclick='$("_115_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20alleged%20refutations%20of%20mechanism%20using%20Godel%27s%20incompleteness%20results+author%3AChihara&amp;btnG=Search'>Google</a> | <a href='javascript:show("_115_links")'>More links</a>)</span><div id='_115_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>An analysis of the Lucas/Benacerraf argument. On various senses in which a machine might come to know its own program.</div></div>
<div id='_115_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHIOAR",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(19720921)69:17&lt;507:OAROMU&gt;2.0.CO;2-9">http://www.jstor.org/sici?sici=0022-362X(19720921)69:17<507:OAROMU>2.0.CO;2-9</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHIOAR",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2025144.pdf">http://www.jstor.org/stable/pdfplus/2025144.pdf</a><br></div></div>
</div><!--entry-->

<div id='_116_entry' class='entry'><span ><span class='name'>Coder, David</span> (1969). Godel's theorem and mechanism.</span> <span class='pub_name'>Philosophy</span> 44 (September):234-7. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_116_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Godel%27s%20theorem%20and%20mechanism+author%3ACoder&amp;btnG=Search'>Google</a>)</span><div id='_116_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Only mathematicians understand Godel, so Lucas's argument isn't general; and Turing machines can go wrong. Weak.</div></div>
</div><!--entry-->

<div id='_117_entry' class='entry'><span ><span class='name'>Copeland, Jack</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("COPTOS",this.href,0);return true;' href='http://citeseer.ist.psu.edu/391761.html'>Turing's o-machines, Searle, Penrose, and the brain.</a></span> <span class='pub_name'>Analysis</span> 58 (2):128-138. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6117776153281532366'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Turing%27s%20o-machines%2C%20Searle%2C%20Penrose%2C%20and%20the%20brain+author%3ACopeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_117_links")'>More links</a>)</span><div id='_117_abstract' class='extra' style='font-size:12px;'>Abstract: In his PhD thesis (1938) Turing introduced what he described as 'a new kind of machine'. He called these 'O-machines'. The present paper employs Turing's concept against a number of currently fashionable positions in the philosophy of mind</div>
<div id='_117_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTOS",this.href,0);return true;' href="http://www.alanturing.net/turing_archive/pages/pub/turing1/turing1.pdf">http://www.alanturing.net/turing_archive/pages/pub/turing1/turing1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTOS",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1467-8284.00113">http://www.blackwell-synergy.com/links/doi/10.1111/1467-8284.00113</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTOS",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1467-8284.00113">http://www.blackwell-synergy.com/doi/abs/10.1111/1467-8284.00113</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTOS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/anal/1998/00000058/00000258/art00113">http://www.ingentaconnect.com/content/bpl/anal/1998/00000058/00000258/art00113</a><br></div></div>
</div><!--entry-->

<div id='_118_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("DENMIT",this.href,0);return true;' href='http://ase.tufts.edu/cogstud/papers/penrose.htm'>Murmurs in the cathedral: Review of R. Penrose, <em>The Emperor's New Mind</em>.</a></span> <span class='pub_name'>Times Literary Supplement (September)</span> 29. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4589167920289338505'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Murmurs%20in%20the%20cathedral+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_118_abstract' class='extra' style='font-size:12px;'>Abstract: The idea that a computer could be conscious--or equivalently, that human consciousness is the effect of some complex computation mechanically performed by our brains--strikes some scientists and philosophers as a beautiful idea. They find it initially surprising and unsettling, as all beautiful ideas are, but the inevitable culmination of the scientific advances that have gradually demystified and unified the material world. The ideologues of Artificial Intelligence (AI) have been its most articulate supporters. To others, this idea is deeply repellent: philistine, reductionistic (in some bad sense), as incredible as it is offensive. John Searle's attack on "strong AI" is the best known expression of this view, but others in the same camp, liking Searle's destination better than his route, would dearly love to see a principled, scientific argument showing that strong AI is impossible. Roger Penrose has set out to provide just such an argument</div>
</div><!--entry-->

<div id='_119_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1978). The abilities of men and machines.</span> In <em>Brainstorms</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3119554474488246482'>Cited by 3</a> | <span class='ll' onclick='$("_119_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20abilities%20of%20men%20and%20machines+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_119_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>There is no unique TM which we are -- there could be many.</div></div>
</div><!--entry-->

<div id='_120_entry' class='entry'><span ><span class='name'>Edis, Taner</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("EDIHGT",this.href,0);return true;' href='http://www.springerlink.com/content/content/t36552h6169u6mp8/fulltext.pdf'>How Godel's theorem supports the possibility of machine intelligence.</a></span> <span class='pub_name'>Minds and Machines</span> 8 (2):251-262. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20Godel%27s%20theorem%20supports%20the%20possibility%20of%20machine%20intelligence+author%3AEdis&amp;btnG=Search'>Google</a> | <a href='javascript:show("_120_links")'>More links</a>)</span><div id='_120_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â GÃ¶del's Theorem is often used in arguments against machine intelligence, suggesting humans are not bound by the rules of any formal system. However, GÃ¶delian arguments can be used to support AI, provided we extend our notion of computation to include devices incorporating random number generators. A complete description scheme can be given for integer functions, by which nonalgorithmic functions are shown to be partly random. Not being restricted to algorithms can be accounted for by the availability of an arbitrary random function. Humans, then, might not be rule-bound, but GÃ¶delian arguments also suggest how the relevant sort of nonalgorithmicity may be trivially made available to machines</div>
<div id='_120_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EDIHGT",this.href,0);return true;' href="http://www.springerlink.com/content/t36552h6169u6mp8/fulltext.pdf">http://www.springerlink.com/content/t36552h6169u6mp8/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_121_entry' class='entry'><span ><span class='name'>Feferman, S.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("FEFPGA",this.href,0);return true;' href='http://math.stanford.edu/~feferman/papers/penrose.pdf'>Penrose's Godelian argument.</a></span> <span class='pub_name'>Psyche</span> 2:21-32. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Penrose%27s%20Godelian%20argument+author%3AFeferman&amp;btnG=Search'>Google</a>)</span><div id='_121_abstract' class='extra' style='font-size:12px;'>Abstract: In his book Shadows of the Mind: A search for the missing science of con- sciousness [SM below], Roger Penrose has turned in another bravura perfor- mance, the kind we have come to expect ever since The Emperorâs New Mind [ENM ] appeared. In the service of advancing his deep convictions and daring conjectures about the nature of human thought and consciousness, Penrose has once more drawn a wide swath through such topics as logic, computa- tion, artiï¬cial intelligence, quantum physics and the neuro-physiology of the brain, and has produced along the way many gems of exposition of diï¬cult mathematical and scientiï¬c ideas, without condescension, yet which should be broadly appealing.<sup>1</sup> While the aims and a number of the topics in SM are the same as in ENM , the focus now is much more on the two axes that Pen- rose grinds in earnest. Namely, in the ï¬rst part of SM he argues anew and at great length against computational models of the mind and more speciï¬- cally against any account of mathematical thought in computational terms. Then in the second part, he argues that there must be a scientiï¬c account of consciousness but that will require a (still to be found) non-computational extension or modiï¬cation of present-day quantum physics</div>
</div><!--entry-->

<div id='_122_entry' class='entry'><span ><span class='name'>Gaifman, H.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("GAIWGI",this.href,0);return true;' href='http://www.columbia.edu/~hg17/godel-incomp4.pdf'>What Godel's incompleteness result does and does not show.</a></span> <span class='pub_name'>Journal of Philosophy</span> 97 (8):462-471. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18223272537650897361'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20Godel%27s%20incompleteness%20result%20does%20and%20does%20not%20show+author%3AGaifman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_122_links")'>More links</a>)</span><div id='_122_abstract' class='extra' style='font-size:12px;'>Abstract: In a recent paper S. McCall adds another link to a chain of attempts to enlist GÃ¶delâs incompleteness result as an argument for the thesis that human reasoning cannot be construed as being carried out by a computer.1 McCallâs paper is undermined by a technical oversight. My concern however is not with the technical point. The argument from GÃ¶delâs result to the no-computer thesis can be made without following McCallâs route; it is then straighter and more forceful. Yet the argument fails in an interesting and revealing way. And it leaves a remainder: if some computer does in fact simulate all our mathematical reasoning, then, in principle, we cannot fully grasp how it works. GÃ¶delâs result also points out a certain essential limitation of self-reflection. The resulting picture parallels, not accidentally, Davidsonâs view of psychology, as a science that in principle must remain âimpreciseâ, not fully spelt out. What is intended here by âfully graspâ, and how all this is related to self-reflection, will become clear at the end of this comment</div>
<div id='_122_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAIWGI",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0022-362X(200008)97:8&lt;462:WGIRDA&gt;2.0.CO;2-N">http://links.jstor.org/sici?sici=0022-362X(200008)97:8<462:WGIRDA>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAIWGI",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(200008)97:8&lt;462:WGIRDA&gt;2.0.CO;2-N">http://www.jstor.org/sici?sici=0022-362X(200008)97:8<462:WGIRDA>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAIWGI",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2678427.pdf">http://www.jstor.org/stable/pdfplus/2678427.pdf</a><br></div></div>
</div><!--entry-->

<div id='_123_entry' class='entry'><span ><span class='name'>George, A.</span> &amp; <span class='name'>Velleman, Daniel J.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("GEOLTP",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(200008)97:8&lt;456:LTPFBM&gt;2.0.CO;2-Q'>Leveling the playing field between mind and machine: A reply to McCall.</a></span> <span class='pub_name'>Journal of Philosophy</span> 97 (8):456-452. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15859276070403763328'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Leveling%20the%20playing%20field%20between%20mind%20and%20machine+author%3AGeorge&amp;btnG=Search'>Google</a> | <a href='javascript:show("_123_links")'>More links</a>)</span>
<div id='_123_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GEOLTP",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(200008)97:8&lt;456:LTPFBM&gt;2.0.CO;2-Q">http://www.jstor.org/sici?sici=0022-362X(200008)97:8<456:LTPFBM>2.0.CO;2-Q</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GEOLTP",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2678426.pdf">http://www.jstor.org/stable/pdfplus/2678426.pdf</a><br></div></div>
</div><!--entry-->

<div id='_124_entry' class='entry'><span ><span class='name'>George, F. H.</span> (1962). <a rel="nofollow" class='article_title' onclick='trackclick("GEOMMA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(196201)37:139&lt;62:MMAGAR&gt;2.0.CO;2-H'>Minds, machines and Godel: Another reply to mr. Lucas.</a></span> <span class='pub_name'>Philosophy</span> 37 (January):62-63. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_124_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%20and%20Godel+author%3AGeorge&amp;btnG=Search'>Google</a>)</span><div id='_124_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lucas's argument applies only to deductive machines, not inductive ones.</div></div>
</div><!--entry-->

<div id='_125_entry' class='entry'><span ><span class='name'>Gertler, Brie</span> (2004). Simulation theory on conceptual grounds.</span> <span class='pub_name'>Protosociology</span> 20:261-284. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Simulation%20theory%20on%20conceptual%20grounds+author%3AGertler&amp;btnG=Search'>Google</a>)</span><div id='_125_abstract' class='extra' style='font-size:12px;'>Abstract: I will present a conceptual argument for a simulationist answer to (2). Given that our conception of mental states is employed in attributing mental states to others, a simulationist answer to (2) supports a simulationist answer to (1). I will not address question (3). Answers to (1) and (2) do not yield an answer to (3), since (1) and (2) concern only our actual practices and concepts. For instance, an error theory about (1) and (2) would say that our practices and concepts manifest a mistaken view about the real nature of the mental. Finally, I will not address question (2a), which is an empirical question and so is not immediately relevant to the conceptual argument that is of concern here</div>
</div><!--entry-->

<div id='_126_entry' class='entry'><span ><span class='name'>Good, I. J.</span> (1969). <a rel="nofollow" class='article_title' onclick='trackclick("GOOGTI",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196902)19:4&lt;357:GTIARH&gt;2.0.CO;2-7'>Godel's theorem is a red Herring.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 19 (February):357-8. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13854935076284241469'>Cited by 8</a> | <span class='ll' onclick='$("_126_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Godel%27s%20theorem%20is%20a%20red%20Herring+author%3AGood&amp;btnG=Search'>Google</a> | <a href='javascript:show("_126_links")'>More links</a>)</span><div id='_126_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Rejoinder to Lucas 1967: the role of consistency; non-constructible ordinals.</div></div>
<div id='_126_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOOGTI",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196902)19:4&lt;357:GTIARH&gt;2.0.CO;2-7">http://www.jstor.org/sici?sici=0007-0882(196902)19:4<357:GTIARH>2.0.CO;2-7</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOOGTI",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/19/4/357">http://bjps.oxfordjournals.org/cgi/content/citation/19/4/357</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOOGTI",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/19/4/357">http://bjps.oxfordjournals.org/cgi/reprint/19/4/357</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOOGTI",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686295.pdf">http://www.jstor.org/stable/pdfplus/686295.pdf</a><br></div></div>
</div><!--entry-->

<div id='_127_entry' class='entry'><span ><span class='name'>Good, I. J.</span> (1967). <a rel="nofollow" class='article_title' onclick='trackclick("GOOHAM",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196708)18:2&lt;144:HAML&gt;2.0.CO;2-T'>Human and machine logic.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 18 (August):145-6. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2869958462346213597'>Cited by 7</a> | <span class='ll' onclick='$("_127_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Human%20and%20machine%20logic+author%3AGood&amp;btnG=Search'>Google</a> | <a href='javascript:show("_127_links")'>More links</a>)</span><div id='_127_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Even humans can't Godelize forever. On ordinals and transfinite counting.</div></div>
<div id='_127_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOOHAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/18/2/144">http://bjps.oxfordjournals.org/cgi/content/citation/18/2/144</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOOHAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/18/2/144">http://bjps.oxfordjournals.org/cgi/reprint/18/2/144</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOOHAM",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686582.pdf">http://www.jstor.org/stable/pdfplus/686582.pdf</a><br></div></div>
</div><!--entry-->

<div id='_128_entry' class='entry'><span ><span class='name'>Gordon, Robert M.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("GORFPA",this.href,0);return true;' href='http://plato.stanford.edu/entries/folkpsych-simulation/'>Folk Psychology As Mental Simulation.</a></span> <em>Stanford Encyclopedia of Philosophy</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9500419257569398465'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20Psychology%20As%20Mental%20Simulation+author%3AGordon&amp;btnG=Search'>Google</a>)</span><div id='_128_abstract' class='extra' style='font-size:12px;'>Abstract: by, or is otherwise relevant to the seminar "Folk Psychology vs. Mental Simulation: How Minds Understand Minds," a National</div>
</div><!--entry-->

<div id='_129_entry' class='entry'><span ><span class='name'>Grush, Rick</span> &amp; <span class='name'>Churchland, P.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("GRUGIP",this.href,0);return true;' href='http://mind.ucsd.edu/papers/penrose/penrose.pdf'>Gaps in Penrose's toiling.</a></span> In Thomas Metzinger (ed.), <em>Conscious Experience</em>. Ferdinand Schoningh. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Gaps%20in%20Penrose%27s%20toiling+author%3AGrush&amp;btnG=Search'>Google</a> | <a href='javascript:show("_129_links")'>More links</a>)</span><div id='_129_abstract' class='extra' style='font-size:12px;'>Abstract: Using the GÃ¶del Incompleteness Result for leverage, Roger Penrose has argued that the mechanism for consciousness involves quantum gravitational phenomena, acting through microtubules in neurons. We show that this hypothesis is implausible. First, the GÃ¶del Result does not imply that human thought is in fact non algorithmic. Second, whether or not non algorithmic quantum gravitational phenomena actually exist, and if they did how that could conceivably implicate microtubules, and if microtubules were involved, how that could conceivably implicate consciousness, is entirely speculative. Third, cytoplasmic ions such as calcium and sodium are almost certainly present in the microtubule pore, barring the quantum mechanical effects Penrose envisages. Finally, physiological evidence indicates that consciousness does not directly depend on microtubule properties in any case, rendering doubtful any theory according to which consciousness is generated in the microtubules</div>
<div id='_129_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GRUGIP",this.href,0);return true;' href="http://mind.ucsd.edu/papers/penrose/penrose.rtf">http://mind.ucsd.edu/papers/penrose/penrose.rtf</a><br></div></div>
</div><!--entry-->

<div id='_130_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("HADGLA",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-8640.1987.tb00174.x'>Godel, Lucas, and mechanical models of mind.</a></span> <span class='pub_name'>Computational Intelligence</span> 3:57-63. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11060137655953594272'>Cited by 1</a> | <span class='ll' onclick='$("_130_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Godel%2C%20Lucas%2C%20and%20mechanical%20models%20of%20mind+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_130_links")'>More links</a>)</span><div id='_130_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A nice analysis of Lucas's argument and the circumstances under which a machine might prove another's Godel sentences. There's no reason to believe that machines and humans are different here.</div></div>
<div id='_130_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADGLA",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120022395/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120022395/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_131_entry' class='entry'><span ><span class='name'>Hanson, William H.</span> (1971). <a rel="nofollow" class='article_title' onclick='trackclick("HANMAG",this.href,0);return true;' href='http://www.jstor.org/sici?sici=0007-0882(197102)22:1&lt;9:MAGT&gt;2.0.CO;2-G'>Mechanism and Godel's theorem.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 22 (February):9-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_131_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mechanism%20and%20Godel%27s%20theorem+author%3AHanson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_131_links")'>More links</a>)</span><div id='_131_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>An analysis of Benacerraf 1967. Benacerraf's "paradox" is illusory; there are no strong consequences of Godel's theorem for mechanism.</div></div>
<div id='_131_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HANMAG",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/22/1/9">http://bjps.oxfordjournals.org/cgi/reprint/22/1/9</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HANMAG",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686639.pdf">http://www.jstor.org/stable/pdfplus/686639.pdf</a><br></div></div>
</div><!--entry-->

<div id='_132_entry' class='entry'><span ><span class='name'>Hofstadter, Douglas R.</span> (1979). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HOFGEB",this.href,0);return true;' href='http://www.forum2.org/tal/books/geb.html'>Godel, Escher, Bach: An Eternal Golden Braid.</a></span></em></span> Basic Books. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8543107174324782283'>Cited by 65</a> | <span class='ll' onclick='$("_132_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Godel%2C%20Escher%2C%20Bach+author%3AHofstadter&amp;btnG=Search'>Google</a> | <a href='javascript:show("_132_links")'>More links</a>)</span><div id='_132_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Contra Lucas: we can't Godelize forever; and we're not formal on top level.</div></div>
<div id='_132_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOFGEB",this.href,0);return true;' href="http://www.w3.org/People/Connolly/books_webqcat">http://www.w3.org/People/Connolly/books_webqcat</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOFGEB",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1979geba.book.....H">http://adsabs.harvard.edu/abs/1979geba.book.....H</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOFGEB",this.href,0);return true;' href="http://www.w3.org/hypertext/WWW/People/Connolly/books_webqcat">http://www.w3.org/hypertext/WWW/People/Connolly/books_webqcat</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOFGEB",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=aFcsnUEewLkC&amp;oi=fnd&amp;pg=PA1&amp;sig=k1N3eE1J6IDPURJdAP19PVlW24Q">http://books.google.com/books?hl=en&lr=&id=aFcsnUEewLkC&oi=fnd&pg=PA1&sig=k1N3eE1J6IDPURJdAP19PVlW24Q</a><br></div></div>
</div><!--entry-->

<div id='_133_entry' class='entry'><span ><span class='name'>Hutton, A.</span> (1976). <a rel="nofollow" class='article_title' onclick='trackclick("HUTTGI",this.href,0);return true;' href='http://www.springerlink.com/content/3867746k505t8j83/fulltext.pdf'>This Godel is killing me.</a></span> <span class='pub_name'>Philosophia</span> 3 (March):135-44. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_133_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=This%20Godel%20is%20killing%20me+author%3AHutton&amp;btnG=Search'>Google</a>)</span><div id='_133_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Gives a statistical argument to the effect that we cannot know that we are consistent; so the Lucas argument cannot go through.</div></div>
</div><!--entry-->

<div id='_134_entry' class='entry'><span ><span class='name'>Irvine, Andrew D.</span> (1983). <a rel="nofollow" class='article_title' onclick='trackclick("IRVLLA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(198303)43:2&lt;94:LLAMOM&gt;2.0.CO;2-5'>Lucas, Lewis, and mechanism -- one more time.</a></span> <span class='pub_name'>Analysis</span> 43 (March):94-98. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_134_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lucas%2C%20Lewis%2C%20and%20mechanism%20--%20one%20more%20time+author%3AIrvine&amp;btnG=Search'>Google</a>)</span><div id='_134_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Contra Lewis 1979, Lucas can derive the consistency of M even without the premise that he is M. Hmm.</div></div>
</div><!--entry-->

<div id='_135_entry' class='entry'><span ><span class='name'>Jacquette, Dale</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("JACMCF",this.href,0);return true;' href='http://www.springerlink.com/content/n7273q71p8376195/fulltext.pdf'>Metamathematical criteria for minds and machines.</a></span> <span class='pub_name'>Erkenntnis</span> 27 (July):1-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=902095529376001788'>Cited by 3</a> | <span class='ll' onclick='$("_135_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Metamathematical%20criteria%20for%20minds%20and%20machines+author%3AJacquette&amp;btnG=Search'>Google</a> | <a href='javascript:show("_135_links")'>More links</a>)</span><div id='_135_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A machine will fail a Turing test if it's asked about Godel sentences.</div></div>
<div id='_135_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("JACMCF",this.href,0);return true;' href="http://www.springerlink.com/content/x6832560243n3x6q/fulltext.pdf">http://www.springerlink.com/content/x6832560243n3x6q/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("JACMCF",this.href,0);return true;' href="http://www.springerlink.com/index/N7273Q71P8376195.pdf">http://www.springerlink.com/index/N7273Q71P8376195.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("JACMCF",this.href,0);return true;' href="http://www.springerlink.com/index/X6832560243N3X6Q.pdf">http://www.springerlink.com/index/X6832560243N3X6Q.pdf</a><br></div></div>
</div><!--entry-->

<div id='_136_entry' class='entry'><span ><span class='name'>Ketland, Jeffrey</span> &amp; <span class='name'>Raatikainen, Panu</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("KETTAP",this.href,0);return true;' href='http://www.mv.helsinki.fi/home/praatika/lucas and redhead.pdf'>Truth and provability again.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Truth%20and%20provability%20again+author%3AKetland&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_137_entry' class='entry'><span ><span class='name'>King, D.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("KINITH",this.href,0);return true;' href='http://www.springerlink.com/content/p4761624416hgn82/fulltext.pdf'>Is the human mind a Turing machine?</a></span> <span class='pub_name'>Synthese</span> 108 (3):379-89. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20the%20human%20mind%20a%20Turing%20machine%3F+author%3AKing&amp;btnG=Search'>Google</a> | <a href='javascript:show("_137_links")'>More links</a>)</span><div id='_137_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In this paper I discuss the topics of mechanism and algorithmicity. I emphasise that a characterisation of algorithmicity such as the Turing machine is iterative; and I argue that if the human mind can solve problems that no Turing machine can, the mind must depend on some non-iterative principle â in fact, Cantor's second principle of generation, a principle of the actual infinite rather than the potential infinite of Turing machines. But as there has been theorisation that all physical systems can be represented by Turing machines, I investigate claims that seem to contradict this: specifically, claims that there are noncomputable phenomena. One conclusion I reach is that if it is believed that the human mind is more than a Turing machine, a belief in a kind of Cartesian dualist gulf between the mental and the physical is concomitant</div>
<div id='_137_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KINITH",this.href,0);return true;' href="http://www.springerlink.com/index/P4761624416HGN82.pdf">http://www.springerlink.com/index/P4761624416HGN82.pdf</a><br></div></div>
</div><!--entry-->

<div id='_138_entry' class='entry'><span ><span class='name'>Kirk, Robert E.</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("KIRMMA",this.href,0);return true;' href='http://www.springerlink.com/content/jp103031141743w4/fulltext.pdf'>Mental machinery and Godel.</a></span> <span class='pub_name'>Synthese</span> 66 (March):437-452. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_138_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mental%20machinery%20and%20Godel+author%3AKirk&amp;btnG=Search'>Google</a>)</span><div id='_138_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lucas's argument fails, as theorems by humans don't correspond to outputs of their formal systems.</div></div>
</div><!--entry-->

<div id='_139_entry' class='entry'><span ><span class='name'>Laforte, Geoffrey</span>; <span class='name'>Hayes, Pat</span> &amp; <span class='name'>Ford, Kenneth M.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("LAFWGT",this.href,0);return true;' href='http://www.cs.uwf.edu/~glaforte/papers/whyGodel.ps'>Why Godel's theorem cannot refute computationalism: A reply to Penrose.</a></span> <span class='pub_name'>Artificial Intelligence</span> 104. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20Godel%27s%20theorem%20cannot%20refute%20computationalism+author%3ALaforte&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_140_entry' class='entry'><span ><span class='name'>Leslie, Alan M.</span>; <span class='name'>Nichols, Shaun</span>; <span class='name'>Stich, Stephen P.</span> &amp; <span class='name'>Klein, David B.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("LESVOO",this.href,0);return true;' href='http://ruccs.rutgers.edu/ArchiveFolder/Research Group/Publications/Sim3/sim3.html'>Varieties of off-line simulation.</a></span> In  P. Carruthers &amp;  P. Smith (eds.), <em>Theories of Theories of Mind</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Varieties%20of%20off-line%20simulation+author%3ALeslie&amp;btnG=Search'>Google</a>)</span><div id='_140_abstract' class='extra' style='font-size:12px;'>Abstract: In the last few years, off-line simulation has become an increasingly important alternative to standard explanations in cognitive science. The contemporary debate began with Gordon (1986) and Goldman's (1989) off-line simulation account of our capacity to predict behavior. On their view, in predicting people's behavior we take our own decision making system `off line' and supply it with the `pretend' beliefs and desires of the person whose behavior we are trying to predict; we then let the decision maker reach a decision on the basis of these pretend inputs. Figure 1 offers a `boxological' version of the off-line simulation theory of behavior prediction.(1)</div>
</div><!--entry-->

<div id='_141_entry' class='entry'><span ><span class='name'>Lewis, David</span> (1969). <a rel="nofollow" class='article_title' onclick='trackclick("LEWLAM",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(196907)44:169&lt;231:LAM&gt;2.0.CO;2-2'>Lucas against mechanism.</a></span> <span class='pub_name'>Philosophy</span> 44 (June):231-3. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18029218714637236425'>Cited by 10</a> | <span class='ll' onclick='$("_141_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lucas%20against%20mechanism+author%3ALewis&amp;btnG=Search'>Google</a>)</span><div id='_141_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lucas needs a rule of inference from sentences to their consistency, yielding Lucas arithmetic. No machine can prove all of Lucas arithmetic, but there's no reason to suppose humans can either, as the rule is infinitary.</div></div>
</div><!--entry-->

<div id='_142_entry' class='entry'><span ><span class='name'>Lewis, David</span> (1979). Lucas against mechanism II.</span> <span class='pub_name'>Canadian Journal of Philosophy</span> 9 (June):373-6. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1880128180250584549'>Cited by 7</a> | <span class='ll' onclick='$("_142_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lucas%20against%20mechanism%20II+author%3ALewis&amp;btnG=Search'>Google</a>)</span><div id='_142_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Lucas 1970: the dialectical argument fails, as the human's output depends on the premise that it is the machine (to derive M's consistency). With a similar premise, the machine itself can do equally well.</div></div>
</div><!--entry-->

<div id='_143_entry' class='entry'><span ><span class='name'>Lindstrom, Per</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("LINROP",this.href,0);return true;' href='http://www.springerlink.com/content/fu83655lg7754253/fulltext.pdf'>Remarks on Penrose's new argument.</a></span> <span class='pub_name'>Journal of Philosophical Logic</span> 35 (3):231-237. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Remarks%20on%20Penrose%27s%20new%20argument+author%3ALindstrom&amp;btnG=Search'>Google</a> | <a href='javascript:show("_143_links")'>More links</a>)</span><div id='_143_abstract' class='extra' style='font-size:12px;'>Abstract:  It is commonly agreed that the well-known LucasâPenrose arguments and even Penroseâs ânew argumentâ in [Penrose, R. (1994): Shadows of the Mind, Oxford University Press] are inconclusive. It is, perhaps, less clear exactly why at least the latter is inconclusive. This note continues the discussion in [LindstrÃ¶m, P. (2001): Penroseâs new argument, J. Philos. Logic 30, 241â250; Shapiro, S.(2003): Mechanism, truth, and Penroseâs new argument, J. Philos. Logic 32, 19â42] and elsewhere of this question</div>
<div id='_143_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LINROP",this.href,0);return true;' href="http://www.springerlink.com/index/FU83655LG7754253.pdf">http://www.springerlink.com/index/FU83655LG7754253.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LINROP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/logi/2006/00000035/00000003/00009014">http://www.ingentaconnect.com/content/klu/logi/2006/00000035/00000003/00009014</a><br></div></div>
</div><!--entry-->

<div id='_144_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1967). <a rel="nofollow" class='article_title' onclick='trackclick("LUCHAM",this.href,0);return true;' href='http://users.ox.ac.uk/~jrlucas/Godel/good.html'>Human and machine logic: A rejoinder.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 19 (August):155-6. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=240210670485651472'>Cited by 3</a> | <span class='ll' onclick='$("_144_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Human%20and%20machine%20logic+author%3ALucas&amp;btnG=Search'>Google</a> | <a href='javascript:show("_144_links")'>More links</a>)</span><div id='_144_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Good 1967: a human can trump any given machine, so the human is not the machine, whether or not the human is superior across the board.</div></div><div id='_144_abstract' class='extra' style='font-size:12px;'>Abstract: We can imagine a human operator playing a game of one-upmanship against a programmed computer. If the program is Fn, the human operator can print the theorem Gn, which the programmed computer, or, if you prefer, the program, would never print, if it is consistent. This is true for each whole number n, but the victory is a hollow one since a second computer, loaded with program C, could put the human operator out of a job.... It is useless for the `mentalist' to argue that any given program can always be improves since the process for improving programs can presumably be programmed also; certainly this can be done if the mentalist describes how the improvement is to be made. If he does give such a description, then he has not made a case</div>
<div id='_144_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCHAM",this.href,0);return true;' href="http://www.univ.trieste.it/~etica/2003_1/6_monographica.doc">http://www.univ.trieste.it/~etica/2003_1/6_monographica.doc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCHAM",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0007-0882(196808)19:2&lt;155:HAMLAR&gt;2.0.CO;2-4">http://links.jstor.org/sici?sici=0007-0882(196808)19:2<155:HAMLAR>2.0.CO;2-4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCHAM",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196808)19:2&lt;155:HAMLAR&gt;2.0.CO;2-4">http://www.jstor.org/sici?sici=0007-0882(196808)19:2<155:HAMLAR>2.0.CO;2-4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCHAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/19/2/155">http://bjps.oxfordjournals.org/cgi/content/citation/19/2/155</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCHAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/19/2/155">http://bjps.oxfordjournals.org/cgi/reprint/19/2/155</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCHAM",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686794.pdf">http://www.jstor.org/stable/pdfplus/686794.pdf</a><br></div></div>
</div><!--entry-->

<div id='_145_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1984). Lucas against mechanism II: A rejoinder.</span> <span class='pub_name'>Canadian Journal of Philosophy</span> 14 (June):189-91. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9812583900010111362'>Cited by 2</a> | <span class='ll' onclick='$("_145_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lucas%20against%20mechanism%20II+author%3ALucas&amp;btnG=Search'>Google</a>)</span><div id='_145_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Lewis 1979.</div></div>
</div><!--entry-->

<div id='_146_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1970). <a rel="nofollow" class='article_title' onclick='trackclick("LUCMAR",this.href,0);return true;' href='http://users.ox.ac.uk/~jrlucas/Godel/lewicode.html'>Mechanism: A rejoinder.</a></span> <span class='pub_name'>Philosophy</span> 45 (April):149-51. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_146_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mechanism+author%3ALucas&amp;btnG=Search'>Google</a>)</span><div id='_146_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Response to Lewis 1969 and Coder 1969. Lewis misses the dialectical nature of the argument.</div></div>
</div><!--entry-->

<div id='_147_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1971). <a rel="nofollow" class='article_title' onclick='trackclick("LUCMAT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8248(197106)38:2&lt;310:MATPOM&gt;2.0.CO;2-K'>Metamathematics and the philosophy of mind: A rejoinder.</a></span> <span class='pub_name'>Philosophy of Science</span> 38 (2):310-13. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12164850957531784329'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Metamathematics%20and%20the%20philosophy%20of%20mind+author%3ALucas&amp;btnG=Search'>Google</a> | <a href='javascript:show("_147_links")'>More links</a>)</span>
<div id='_147_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCMAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8248(197106)38:2&lt;310:MATPOM&gt;2.0.CO;2-K">http://www.jstor.org/sici?sici=0031-8248(197106)38:2<310:MATPOM>2.0.CO;2-K</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCMAT",this.href,0);return true;' href="http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288368">http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288368</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCMAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/186792.pdf">http://www.jstor.org/stable/pdfplus/186792.pdf</a><br></div></div>
</div><!--entry-->

<div id='_148_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1961). <a rel="nofollow" class='article_title' onclick='trackclick("LUCMMA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(196104/07)36:137&lt;112:MMAG&gt;2.0.CO;2-I'>Minds, machines and Godel.</a></span> <span class='pub_name'>Philosophy</span> 36 (April-July):112-127. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7011904259034917936'>Cited by 72</a> | <span class='ll' onclick='$("_148_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%20and%20Godel+author%3ALucas&amp;btnG=Search'>Google</a> | <a href='javascript:show("_148_links")'>More links</a>)</span><div id='_148_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Humans can Godelize any given machine, so we're not a machine.</div></div><div id='_148_abstract' class='extra' style='font-size:12px;'>Abstract: Goedel's theorem states that in any consistent system which is strong enough to produce simple arithmetic there are formulae which cannot be proved-in-the-system, but which we can see to be true. Essentially, we consider the formula which says, in effect, "This formula is unprovable-in-the-system". If this formula were provable-in-the-system, we should have a contradiction: for if it were provablein-the-system, then it would not be unprovable-in-the-system, so that "This formula is unprovable-in-the-system" would be false: equally, if it were provable-in-the-system, then it would not be false, but would be true, since in any consistent system nothing false can be provedin-the-system, but only truths. So the formula "This formula is unprovable-in-the-system" is not provable-in-the-system, but unprovablein-the-system. Further, if the formula "This formula is unprovablein- the-system" is unprovable-in-the-system, then it is true that that formula is unprovable-in-the-system, that is, "This formula is unprovable-in-the-system" is true. Goedel's theorem must apply to cybernetical machines, because it is of the essence of being a machine, that it should be a concrete instantiation of a formal system. It follows that given any machine which is consistent and capable of doing simple arithmetic, there is a formula which it is incapable of producing as being true---i.e., the formula is unprovable-in-the-system-but which we can see to be true. It follows that no machine can be a complete or adequate model of the mind, that minds are essentially different from machines</div>
<div id='_148_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCMMA",this.href,0);return true;' href="http://cogprints.org/356/1/lucas.html">http://cogprints.org/356/1/lucas.html</a><br></div></div>
</div><!--entry-->

<div id='_149_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1996). Mind, machines and Godel: A retrospect.</span> In Peter Millican &amp; A. Clark (eds.), <em>Machines and Thought</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_149_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%2C%20machines%20and%20Godel+author%3ALucas&amp;btnG=Search'>Google</a>)</span><div id='_149_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Addresses all the counterarguments. Fun.</div></div>
</div><!--entry-->

<div id='_150_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1968). <a rel="nofollow" class='article_title' onclick='trackclick("LUCSSA",this.href,0);return true;' href='http://users.ox.ac.uk/~jrlucas/Godel/satan.html'>Satan stultified: A rejoinder to Paul Benacerraf.</a></span> <span class='pub_name'>The Monist</span> 52 (1):145-58. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8771674700482945495'>Cited by 10</a> | <span class='ll' onclick='$("_150_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Satan%20stultified+author%3ALucas&amp;btnG=Search'>Google</a>)</span><div id='_150_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Benacerraf 1967 is empty and omega-inconsistent. Reply to arguments based on difficulty of seeing consistency (e.g. Putnam). Fallacious but engaging.</div></div><div id='_150_abstract' class='extra' style='font-size:12px;'>Abstract: The argument is a dialectical one. It is not a direct proof that the mind is something more than a machine, but a schema of disproof for any particular version of mechanism that may be put forward. If the mechanist maintains any specific thesis, I show that [146] a contradiction ensues. But only if. It depends on the mechanist making the first move and putting forward his claim for inspection. I do not think Benacerraf has quite taken the point. He criticizes me both for "failing to notice" that my ability to show that the GÃ¶del sentence of a formal system is true "depends very much on how he is given</div>
</div><!--entry-->

<div id='_151_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> &amp; <span class='name'>Redhead, Michael</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("LUCTAP",this.href,0);return true;' href='http://bjps.oxfordjournals.org/cgi/content/abstract/58/2/331'>Truth and provability.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 58 (2):331-2. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Truth%20and%20provability+author%3ALucas&amp;btnG=Search'>Google</a> | <a href='javascript:show("_151_links")'>More links</a>)</span><div id='_151_abstract' class='extra' style='font-size:12px;'>Abstract: The views of Redhead ([2004]) are defended against the argument by Panu Raatikainen ([2005]). The importance of informal rigour is canvassed, and the argument for the a priori nature of induction is explained. The significance of GÃ¶del's theorem is again rehearsed</div>
<div id='_151_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCTAP",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/full/axm006v1">http://bjps.oxfordjournals.org/cgi/content/full/axm006v1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCTAP",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/58/2/331">http://bjps.oxfordjournals.org/cgi/reprint/58/2/331</a><br></div></div>
</div><!--entry-->

<div id='_152_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1970). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("LUCTFO",this.href,0);return true;' href='http://books.google.com/books?id=B3_ea5WwOx8C&amp;printsec=front_cover'>The Freedom of the Will.</a></span></em></span> Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14714252332266233602'>Cited by 22</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Freedom%20of%20the%20Will+author%3ALucas&amp;btnG=Search'>Google</a>)</span><div id='_152_abstract' class='extra' style='font-size:12px;'>Abstract: It might be the case that absence of constraint is the relevant sense of &#39;
freedom&#39; when we are discussing the freedom of the will, but it needs arguing 
for. ...</div>
</div><!--entry-->

<div id='_153_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("LUCTGA",this.href,0);return true;' href='http://users.ox.ac.uk/~jrlucas/Godel/turn.html'>The Godelian argument: Turn over the page.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2167390478186946868'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Godelian%20argument+author%3ALucas&amp;btnG=Search'>Google</a>)</span><div id='_153_abstract' class='extra' style='font-size:12px;'>Abstract: I have no quarrel with the first two sentences: but the third, though charitable and courteous, is quite untrue. Although there are criticisms which can be levelled against the GÃ¶delian argument, most of the critics have not read either of my, or either of Penrose's, expositions carefully, and seek to refute arguments we never put forward, or else propose as a fatal objection one that had already been considered and countered in our expositions of the argument. Hence my title. The GÃ¶delian Argument uses GÃ¶del's theorem to show that minds cannot be explained in purely mechanist terms. It has been put forward, in different forms, by GÃ¶del himself, by Penrose, and by me</div>
</div><!--entry-->

<div id='_154_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1976). <a rel="nofollow" class='article_title' onclick='trackclick("LUCTGI",this.href,0);return true;' href='http://www.springerlink.com/content/j66633g2800t30q7/fulltext.pdf'>This Godel is killing me: A rejoinder.</a></span> <span class='pub_name'>Philosophia</span> 6 (March):145-8. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_154_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=This%20Godel%20is%20killing%20me+author%3ALucas&amp;btnG=Search'>Google</a>)</span><div id='_154_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Contra Hutton, we know -- even if fallibly -- that we are consistent.</div></div>
</div><!--entry-->

<div id='_155_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("LUCTIO",this.href,0);return true;' href='http://users.ox.ac.uk/~jrlucas/Godel/implic.html'>The implications of Godel's theorem.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20implications%20of%20Godel%27s%20theorem+author%3ALucas&amp;btnG=Search'>Google</a> | <a href='javascript:show("_155_links")'>More links</a>)</span><div id='_155_abstract' class='extra' style='font-size:12px;'>Abstract: In 1931 Kurt GÃ¶del proved two theorems about the completeness and consistency of first-order arithmetic. Their implications for philosophy are profound. Many fashionable tenets are shown to be untenable: many traditional intuitions are vindicated by incontrovertible arguments</div>
<div id='_155_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCTIO",this.href,0);return true;' href="http://users.ox.ac.uk/~jrlucas/Godel/goedhand.html">http://users.ox.ac.uk/~jrlucas/Godel/goedhand.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LUCTIO",this.href,0);return true;' href="http://users.ox.ac.uk/~jrlucas/Godel/implgoed.html">http://users.ox.ac.uk/~jrlucas/Godel/implgoed.html</a><br></div></div>
</div><!--entry-->

<div id='_156_entry' class='entry'><span ><span class='name'>Lyngzeidetson, Albert E.</span> &amp; <span class='name'>Solomon, Martin K.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("LYNACT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(199406)45:2&lt;549:ACTATM&gt;2.0.CO;2-W'>Abstract complexity theory and the mind-machine problem.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 45 (2):549-54. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Abstract%20complexity%20theory%20and%20the%20mind-machine%20problem+author%3ALyngzeidetson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_156_links")'>More links</a>)</span><div id='_156_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper we interpret a characterization of the GÃ¶del speed-up phenomenon as providing support for the âNagel-Newman thesisâ that human theorem recognizers differ from mechanical theorem recognizers in that the former do not seem to be limited by GÃ¶del's incompleteness theorems whereas the latter do seem to be thus limited. However, we also maintain that (currently non-existent) programs which are open systems in that they continuously interact with, and are thus inseparable from, their environment, are not covered by the above (or probably any other recursion-theoretic) argument</div>
<div id='_156_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNACT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(199406)45:2&lt;549:ACTATM&gt;2.0.CO;2-W">http://www.jstor.org/sici?sici=0007-0882(199406)45:2<549:ACTATM>2.0.CO;2-W</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNACT",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/45/2/549">http://bjps.oxfordjournals.org/cgi/content/abstract/45/2/549</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNACT",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/45/2/549">http://bjps.oxfordjournals.org/cgi/reprint/45/2/549</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNACT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/687681.pdf">http://www.jstor.org/stable/pdfplus/687681.pdf</a><br></div></div>
</div><!--entry-->

<div id='_157_entry' class='entry'><span ><span class='name'>Lyngzeidetson, Albert E.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("LYNMPD",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(199003)41:1&lt;121:MPDPAA&gt;2.0.CO;2-E'>Massively parallel distributed processing and a computationalist foundation for cognitive science.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 41 (March):121-127. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_157_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Massively%20parallel%20distributed%20processing%20and%20a%20computationalist%20foundation%20for%20cognitive%20science+author%3ALyngzeidetson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_157_links")'>More links</a>)</span><div id='_157_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A Connection Machine might escape the Lucas argument. Bizarre.</div></div>
<div id='_157_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(199003)41:1&lt;121:MPDPAA&gt;2.0.CO;2-E">http://www.jstor.org/sici?sici=0007-0882(199003)41:1<121:MPDPAA>2.0.CO;2-E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/41/1/121">http://bjps.oxfordjournals.org/cgi/content/abstract/41/1/121</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/41/1/121">http://bjps.oxfordjournals.org/cgi/reprint/41/1/121</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/688006.pdf">http://www.jstor.org/stable/pdfplus/688006.pdf</a><br></div></div>
</div><!--entry-->

<div id='_158_entry' class='entry'><span ><span class='name'>Martin, J.</span> &amp; <span class='name'>Engleman, K.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("MARTMI",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(199010)65:2542.0.CO;2-F'>The mind's I has two eyes.</a></span> <span class='pub_name'>Philosophy</span> 65 (264):510-515. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_158_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20mind%27s%20I%20has%20two%20eyes+author%3AMartin&amp;btnG=Search'>Google</a>)</span><div id='_158_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Contra Hofstadter: Lucas can believe his Whitely sentence.</div></div>
</div><!--entry-->

<div id='_159_entry' class='entry'><span ><span class='name'>Maudlin, Tim</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("MAUBTM",this.href,0);return true;' href='http://calculemus.org/MathUniversalis/NS/10/06maudlin.html'>Between the motion and the act.</a></span> <span class='pub_name'>Psyche</span> 2:40-51. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13245397715175835349'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Between%20the%20motion%20and%20the%20act+author%3AMaudlin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_159_links")'>More links</a>)</span>
<div id='_159_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAUBTM",this.href,0);return true;' href="http://psyche.cs.monash.edu.au/v2/psyche-2-02-maudlin.html">http://psyche.cs.monash.edu.au/v2/psyche-2-02-maudlin.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAUBTM",this.href,0);return true;' href="http://psyche.cs.monash.edu.au/volume2-1/psyche-95-2-02-shadows-1-maudlin.html">http://psyche.cs.monash.edu.au/volume2-1/psyche-95-2-02-shadows-1-maudlin.html</a><br></div></div>
</div><!--entry-->

<div id='_160_entry' class='entry'><span ><span class='name'>McCall, Storrs</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("MCCCAT",this.href,0);return true;' href='http://dialnet.unirioja.es/servlet/articulo?codigo=468225'>Can a Turing machine know that the Godel sentence is true?</a></span> <span class='pub_name'>Journal of Philosophy</span> 96 (10):525-32. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10070253401773961878'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20a%20Turing%20machine%20know%20that%20the%20Godel%20sentence%20is%20true%3F+author%3AMcCall&amp;btnG=Search'>Google</a> | <a href='javascript:show("_160_links")'>More links</a>)</span>
<div id='_160_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCCAT",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0022-362X(199910)96:10&lt;525:CATMKT&gt;2.0.CO;2-2">http://links.jstor.org/sici?sici=0022-362X(199910)96:10<525:CATMKT>2.0.CO;2-2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCCAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(199910)96:10&lt;525:CATMKT&gt;2.0.CO;2-2">http://www.jstor.org/sici?sici=0022-362X(199910)96:10<525:CATMKT>2.0.CO;2-2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCCAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2564612.pdf">http://www.jstor.org/stable/pdfplus/2564612.pdf</a><br></div></div>
</div><!--entry-->

<div id='_161_entry' class='entry'><span ><span class='name'>McCullough, D.</span> (1996). Can humans escape Godel?</span> <span class='pub_name'>Psyche</span> 2:57-65. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20humans%20escape%20Godel%3F+author%3AMcCullough&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_162_entry' class='entry'><span ><span class='name'>McCall, Storrs</span> (2001). On "seeing" the truth of the Godel sentence.</span> <span class='pub_name'>Facta Philosophica</span> 3:25-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20seeing%20the%20truth%20of%20the%20Godel%20sentence+author%3AMcCall&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_163_entry' class='entry'><span ><span class='name'>McDermott, Drew</span> (1996). [Star] Penrose is wrong.</span> <span class='pub_name'>Psyche</span> 2:66-82. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=%5BStar%5D%20Penrose%20is%20wrong+author%3AMcDermott&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_164_entry' class='entry'><span ><span class='name'>Megill, Jason L.</span> (2004). Are we paraconsistent? On the Lucas-Penrose argument and the computational theory of mind.</span> <span class='pub_name'>Auslegung</span> 27 (1):23-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Are%20we%20paraconsistent%3F%20On%20the%20Lucas-Penrose%20argument%20and%20the%20computational%20theory%20of%20mind+author%3AMegill&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_165_entry' class='entry'><span ><span class='name'>Nelson, E.</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("NELMAT",this.href,0);return true;' href='http://citeseer.ist.psu.edu/202585.html'>Mathematics and the mind.</a></span> In Kunio Yasue, Marj Jibu &amp; Tarcisio Della Senta (eds.), <em>No Matter, Never Mind</em>. John Benjamins. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5585997592669436676'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mathematics%20and%20the%20mind+author%3ANelson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_165_links")'>More links</a>)</span>
<div id='_165_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NELMAT",this.href,0);return true;' href="http://www.math.princeton.edu/~nelson/papers/tokyo.pdf">http://www.math.princeton.edu/~nelson/papers/tokyo.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NELMAT",this.href,0);return true;' href="http://www.math.princeton.edu/~nelson/papers/tokyo.ps.gz">http://www.math.princeton.edu/~nelson/papers/tokyo.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NELMAT",this.href,0);return true;' href="http://star.tau.ac.il/~eshel/Bio_complexity/Conceptual Background/Mathematics-mind.pdf">http://star.tau.ac.il/~eshel/Bio_complexity/Conceptual Background/Mathematics-mind.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NELMAT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=eRkooap_j-YC&amp;oi=fnd&amp;pg=PA89&amp;ots=1D3F8NBtaN&amp;sig=L490G6v3TwiKps8crkNSHEMZak4">http://books.google.com/books?hl=en&lr=&id=eRkooap_j-YC&oi=fnd&pg=PA89&ots=1D3F8NBtaN&sig=L490G6v3TwiKps8crkNSHEMZak4</a><br></div></div>
</div><!--entry-->

<div id='_166_entry' class='entry'><span ><span class='name'>Penrose, Roger</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("PENBTD",this.href,0);return true;' href='http://psyche.cs.monash.edu.au/v2/psyche-2-23-penrose.html'>Beyond the doubting of a shadow.</a></span> <span class='pub_name'>Psyche</span> 2:89-129. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14457809600462628309'>Cited by 25</a> | <span class='ll' onclick='$("_166_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Beyond%20the%20doubting%20of%20a%20shadow+author%3APenrose&amp;btnG=Search'>Google</a> | <a href='javascript:show("_166_links")'>More links</a>)</span><div id='_166_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A reply to Chalmers, Feferman, Maudlin, McDermott, etc.</div></div>
<div id='_166_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENBTD",this.href,0);return true;' href="http://calculemus.org/MathUniversalis/NS/10/01penrose.html">http://calculemus.org/MathUniversalis/NS/10/01penrose.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENBTD",this.href,0);return true;' href="http://psyche.csse.monash.edu.au/v2/psyche-2-23-penrose.html">http://psyche.csse.monash.edu.au/v2/psyche-2-23-penrose.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENBTD",this.href,0);return true;' href="http://psyche.cs.monash.edu.au/volume2-1/psyche-96-2-23-shadows-10-penrose.html">http://psyche.cs.monash.edu.au/volume2-1/psyche-96-2-23-shadows-10-penrose.html</a><br></div></div>
</div><!--entry-->

<div id='_167_entry' class='entry'><span ><span class='name'>Penrose, Roger</span> (1990). Precis of the emperor's new mind.</span> <span class='pub_name'>Behavioral and Brain Sciences</span> 13:643-705. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_167_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Precis%20of%20the%20emperor%27s%20new%20mind+author%3APenrose&amp;btnG=Search'>Google</a>)</span><div id='_167_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Much debate over the "non-algorithmic insight" in seeing Godel sentences.</div></div>
</div><!--entry-->

<div id='_168_entry' class='entry'><span ><span class='name'>Penrose, Roger</span> (1994). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("PENSOT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=525243'>Shadows of the Mind.</a></span></em></span> Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8062739552512269460'>Cited by 1412</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Shadows%20of%20the%20Mind+author%3APenrose&amp;btnG=Search'>Google</a> | <a href='javascript:show("_168_links")'>More links</a>)</span>
<div id='_168_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENSOT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=527739">http://portal.acm.org/citation.cfm?id=527739</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENSOT",this.href,0);return true;' href="http://www.fortunecity.com/emachines/e11/86/shadow.html">http://www.fortunecity.com/emachines/e11/86/shadow.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENSOT",this.href,0);return true;' href="http://www.fortunecity.com/emachines/e11/86/shadow1.html">http://www.fortunecity.com/emachines/e11/86/shadow1.html</a><br></div></div>
</div><!--entry-->

<div id='_169_entry' class='entry'><span ><span class='name'>Penrose, Roger</span> (1992). Setting the scene: The claim and the issues.</span> In D. Broadbent (ed.), <em>The Simulation of Human Intelligence</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_169_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Setting%20the%20scene+author%3APenrose&amp;btnG=Search'>Google</a>)</span><div id='_169_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>An argument from the halting problem to the nonalgorithmicity of mathematical thought. Addresses objections: that the algorithm is unknowable, unsound, everchanging, environmental, or random. New physical laws may be involved.</div></div>
</div><!--entry-->

<div id='_170_entry' class='entry'><span ><span class='name'>Penrose, Roger</span> (1989). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("PENTEN",this.href,0);return true;' href='http://www.friesian.com/penrose.htm'>The Emperor's New Mind.</a></span></em></span> Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15916520894334994278'>Cited by 3</a> | <span class='ll' onclick='$("_170_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Emperor%27s%20New%20Mind+author%3APenrose&amp;btnG=Search'>Google</a> | <a href='javascript:show("_170_links")'>More links</a>)</span><div id='_170_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>We are non-algorithmic as we can see Godel sentences of any algorithm.</div></div>
<div id='_170_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://link.aip.org/link/?AJPIAS/58/1214/1">http://link.aip.org/link/?AJPIAS/58/1214/1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=68395">http://portal.acm.org/citation.cfm?id=68395</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1990AmJPh..58.1214P">http://adsabs.harvard.edu/abs/1990AmJPh..58.1214P</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://www.reiters.com/index.cgi?ISBN=0099771705&amp;f=p">http://www.reiters.com/index.cgi?ISBN=0099771705&f=p</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://relativity.livingreviews.org/refdb/record/5936">http://relativity.livingreviews.org/refdb/record/5936</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://www.kokogiak.com/amazon/detpage.asp?asin=018144755X">http://www.kokogiak.com/amazon/detpage.asp?asin=018144755X</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://relativity.livingreviews.org/refdb/unapi?id=lrr-1998-1-PenroseBook&amp;format=bibtex">http://relativity.livingreviews.org/refdb/unapi?id=lrr-1998-1-PenroseBook&format=bibtex</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=RA2-PA1&amp;sig=04UwqLnaAMsFKF2tAizpzMz7rkY">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=RA2-PA1&sig=04UwqLnaAMsFKF2tAizpzMz7rkY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02Tno0-STz&amp;sig=f-ZpKzuvcBwzPzlEUCBmN1m_EbE">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02Tno0-STz&sig=f-ZpKzuvcBwzPzlEUCBmN1m_EbE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02Tnq_-QVA&amp;sig=4JZhl1HlToWmKToz3aXL93fwLxo">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02Tnq_-QVA&sig=4JZhl1HlToWmKToz3aXL93fwLxo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02UkiZZSQx&amp;sig=T9G-BlT6yCiOxYS78zX0RLjfJW0">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02UkiZZSQx&sig=T9G-BlT6yCiOxYS78zX0RLjfJW0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02Tnq_-QQx&amp;sig=EHqvTqlUjD9R-B4QqA8OGU8NUUs">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02Tnq_-QQx&sig=EHqvTqlUjD9R-B4QqA8OGU8NUUs</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02UkiZZRSx&amp;sig=nLDUVLJwJRvnPP9IFUtlt2FLKfo">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02UkiZZRSx&sig=nLDUVLJwJRvnPP9IFUtlt2FLKfo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02Tno0-TPD&amp;sig=ABeb7RU3dzx96MNvKLOi5YoQgV0">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02Tno0-TPD&sig=ABeb7RU3dzx96MNvKLOi5YoQgV0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02UljV1TVC&amp;sig=LbO-NgFr6jmNMkqdEDiXX3SRrqo">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02UljV1TVC&sig=LbO-NgFr6jmNMkqdEDiXX3SRrqo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI0grArWHUMC&amp;oi=fnd&amp;pg=PA1&amp;ots=02UljV2MNE&amp;sig=odNqbL9v6mKh4u4qdpA2fkkbma8">http://books.google.com/books?hl=en&lr=&id=oI0grArWHUMC&oi=fnd&pg=PA1&ots=02UljV2MNE&sig=odNqbL9v6mKh4u4qdpA2fkkbma8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PENTEN",this.href,0);return true;' href="http://orton.catie.ac.cr/cgi-bin/wxis.exe/?IsisScript=IDEA.xis&amp;method=post&amp;formato=2&amp;cantidad=1&amp;expresion=mfn=002295">http://orton.catie.ac.cr/cgi-bin/wxis.exe/?IsisScript=IDEA.xis&method=post&formato=2&cantidad=1&expresion=mfn=002295</a><br></div></div>
</div><!--entry-->

<div id='_171_entry' class='entry'><span ><span class='name'>Piccinini, Gualtiero</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("PICATA",this.href,0);return true;' href='http://www.springerlink.com/content/ul15v486260v8q79/fulltext.pdf'>Alan Turing and the mathematical objection.</a></span> <span class='pub_name'>Minds and Machines</span> 13 (1):23-48. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13691426255804076112'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Alan%20Turing%20and%20the%20mathematical%20objection+author%3APiccinini&amp;btnG=Search'>Google</a> | <a href='javascript:show("_171_links")'>More links</a>)</span><div id='_171_abstract' class='extra' style='font-size:12px;'>Abstract: This paper concerns Alan Turingâs ideas about machines, mathematical methods of proof, and intelligence. By the late 1930s, Kurt GÃ¶del and other logicians, including Turing himself, had shown that no finite set of rules could be used to generate all true mathematical statements. Yet according to Turing, there was no upper bound to the number of mathematical truths provable by intelligent human beings, for they could invent new rules and methods of proof. So, the output of a human mathematician, for Turing, was not a computable sequence (i.e., one that could be generated by a Turing machine). Since computers only contained a finite number of instructions (or programs), one might argue, they could not reproduce human intelligence. Turing called this the âmathematical<br>objectionâ to his view that machines can think. Logico-mathematical reasons, stemming from his own work, helped to convince Turing that it should be possible to reproduce human intelligence, and eventually compete with it, by developing the appropriate kind of digital computer. He felt it<br>should be possible to program a computer so that it could learn or discover new rules, overcoming the limitations imposed by the incompleteness and undecidability results in the same way that human<br>mathematicians presumably do.</div>
<div id='_171_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICATA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5098147&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5098147&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICATA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000001/05098147">http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000001/05098147</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICATA",this.href,0);return true;' href="http://www.springerlink.com/index/UL15V486260V8Q79.pdf">http://www.springerlink.com/index/UL15V486260V8Q79.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICATA",this.href,0);return true;' href="http://www.umsl.edu/~piccininig/Alan_Turing_and_Mathematical_Objection.pdf">http://www.umsl.edu/~piccininig/Alan_Turing_and_Mathematical_Objection.pdf</a><br></div></div>
</div><!--entry-->

<div id='_172_entry' class='entry'><span ><span class='name'>Priest, Graham</span> (1994). Godel's theorem and the mind... Again.</span> In M. Michael &amp; John O'Leary-Hawthorne (eds.), <em>Philosophy in Mind: The Place of Philosophy in the Study of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Godel%27s%20theorem%20and%20the%20mind...%20Again+author%3APriest&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_173_entry' class='entry'><span ><span class='name'>Putnam, Hilary</span> (1995). Review of <em>Shadows of the Mind</em>.</span> <span class='pub_name'>AMS Bulletin</span> 32 (3). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Review%20of%20Shadows%20of%20the%20Mind+author%3APutnam&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_174_entry' class='entry'><span ><span class='name'>Putnam, Hilary</span> (1985). <a rel="nofollow" class='article_title' onclick='trackclick("PUTRR",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=_v5d63lHu0oC&amp;oi=fnd&amp;pg=PA211&amp;ots=1H11LVvgrs&amp;sig=ubbAQ-LWJRyi5wjLU_KeVi5OApE'>Reflexive reflections.</a></span> <span class='pub_name'>Erkenntnis</span> 22 (January):143-153. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9703208763402021389'>Cited by 8</a> | <span class='ll' onclick='$("_174_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reflexive%20reflections+author%3APutnam&amp;btnG=Search'>Google</a> | <a href='javascript:show("_174_links")'>More links</a>)</span><div id='_174_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A generalized Godelian argument: if our prescriptive inductive competence is formalizable, then we could not know that such a formalization is correct.</div></div>
<div id='_174_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUTRR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=8AT_7ZEOFf4C&amp;oi=fnd&amp;pg=RA2-PA143&amp;ots=2yuzpRMYBj&amp;sig=UU2i1OXUpETqyryBJ8N290QLcJc">http://books.google.com/books?hl=en&lr=&id=8AT_7ZEOFf4C&oi=fnd&pg=RA2-PA143&ots=2yuzpRMYBj&sig=UU2i1OXUpETqyryBJ8N290QLcJc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUTRR",this.href,0);return true;' href="http://www.springerlink.com/content/kr0702201813pk58/fulltext.pdf">http://www.springerlink.com/content/kr0702201813pk58/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUTRR",this.href,0);return true;' href="http://www.springerlink.com/index/KR0702201813PK58.pdf">http://www.springerlink.com/index/KR0702201813PK58.pdf</a><br></div></div>
</div><!--entry-->

<div id='_175_entry' class='entry'><span ><span class='name'>Raatikainen, Panu</span>, <a rel="nofollow" class='article_title' onclick='trackclick("RAAMGA",this.href,0);return true;' href='http://www.mv.helsinki.fi/home/praatika/MCCALL.pdf'>McCall's gÃ¶delian argument is invalid.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=McCall%27s%20g%C3%B6delian%20argument%20is%20invalid+author%3ARaatikainen&amp;btnG=Search'>Google</a>)</span><div id='_175_abstract' class='extra' style='font-size:12px;'>Abstract: Storrs McCall continues the tradition of Lucas and Penrose in an attempt to refute mechanism by appealing to GÃ¶delâs incompleteness theorem (McCall 2001). That is, McCall argues that GÃ¶delâs theorem âreveals a sharp dividing line between human and machine thinkingâ. According to McCall, â[h]uman beings are familiar with the distinction between truth and theoremhood, but Turing machines cannot look beyond their own outputâ. However, although McCallâs argumentation is slightly more sophisticated than the earlier GÃ¶delian anti-mechanist arguments, in the end it fails badly, as it is at odds with the logical facts</div>
</div><!--entry-->

<div id='_176_entry' class='entry'><span ><span class='name'>Raatikainen, Panu</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("RAAOTP",this.href,0);return true;' href='http://www.mv.helsinki.fi/home/praatika/Godel.DOC'>On the philosophical relevance of gÃ¶del's incompleteness theorems.</a></span> <span class='pub_name'>Revue Internationale de Philosophie</span> 59 (4):513-534. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20philosophical%20relevance%20of%20g%C3%B6del%27s%20incompleteness%20theorems+author%3ARaatikainen&amp;btnG=Search'>Google</a>)</span><div id='_176_abstract' class='extra' style='font-size:12px;'>Abstract: GÃ¶del began his 1951 Gibbs Lecture by stating: âResearch in the foundations of mathematics during the past few decades has produced some results which seem to me of interest, not only in themselves, but also with regard to their implications for the traditional philosophical problems about the nature of mathematics.â (GÃ¶del 1951) GÃ¶del is referring here especially to his own incompleteness theorems (GÃ¶del 1931). GÃ¶delâs first incompleteness theorem (as improved by Rosser (1936)) says that for any consistent formalized system F, which contains elementary arithmetic, there exists a sentence GF of the language of the system which is true but unprovable in that system. GÃ¶delâs second incompleteness theorem states that no consistent formal system can prove its own consistency</div>
</div><!--entry-->

<div id='_177_entry' class='entry'><span ><span class='name'>Raatikainen, Panu</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("RAATAP",this.href,0);return true;' href='http://www.mv.helsinki.fi/home/praatika/Truth and Proof.pdf'>Truth and provability: A comment on Redhead.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 56 (3):611-613. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Truth%20and%20provability+author%3ARaatikainen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_177_links")'>More links</a>)</span><div id='_177_abstract' class='extra' style='font-size:12px;'>Abstract: Michael Redhead's recent argument aiming to show that humanly certifiable truth outruns provability is critically evaluated. It is argued that the argument is at odds with logical facts and fails</div>
<div id='_177_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAATAP",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/56/3/611">http://bjps.oxfordjournals.org/cgi/content/abstract/56/3/611</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAATAP",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/rapidpdf/axi134v1.pdf">http://bjps.oxfordjournals.org/cgi/rapidpdf/axi134v1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAATAP",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/56/3/611">http://bjps.oxfordjournals.org/cgi/reprint/56/3/611</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAATAP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/oup/phisci/2005/00000056/00000003/art00611">http://www.ingentaconnect.com/content/oup/phisci/2005/00000056/00000003/art00611</a><br></div></div>
</div><!--entry-->

<div id='_178_entry' class='entry'><span ><span class='name'>Raatikainen, Panu</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("RAATAP-2",this.href,0);return true;' href='http://www.mv.helsinki.fi/home/praatika/lucas and redhead.pdf'>Truth and provability again.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Truth%20and%20provability%20again+author%3ARaatikainen&amp;btnG=Search'>Google</a>)</span><div id='_178_abstract' class='extra' style='font-size:12px;'>Abstract: Lucas and Redhead ([2007]) announce that they will defend the views of Redhead ([2004]) against the argument by Panu Raatikainen ([2005]). They certainly re-state the main claims of Redhead ([2004]), but they do not give any real arguments in their favour, and do not provide anything that would save Redheadâs argument from the serious problems pointed out in (Raatikainen [2005]). Instead, Lucas and Redhead make a number of seemingly irrelevant points, perhaps indicating a failure to understand the logico-mathematical points at issue</div>
</div><!--entry-->

<div id='_179_entry' class='entry'><span ><span class='name'>Redhead, M.</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("REDMAT",this.href,0);return true;' href='http://bjps.oxfordjournals.org/cgi/content/abstract/55/4/731'>Mathematics and the mind.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 55 (4):731-737. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7977033910188581670'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mathematics%20and%20the%20mind+author%3ARedhead&amp;btnG=Search'>Google</a> | <a href='javascript:show("_179_links")'>More links</a>)</span><div id='_179_abstract' class='extra' style='font-size:12px;'>Abstract: Granted that truth is valuable we must recognize that certifiable truth is hard to come by, for example in the natural and social sciences. This paper examines the case of mathematics. As a result of the work of GÃ¶del and Tarski we know that truth does not equate with proof. This has been used by Lucas and Penrose to argue that human minds can do things which digital computers can't, viz to know the truth of unprovable arithmetical statements. The argument is given a simple formulation in the context of sorites (Robinson) arithmetic, avoiding the complexities of formulating the GÃ¶del sentence. The pros and cons of the argument are considered in relation to the conception of mathematical truth. * Paper contributed to the Conference entitled The Place of Value in a World of Facts, held at the LSE in October 2003</div>
<div id='_179_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("REDMAT",this.href,0);return true;' href="http://bjps.oupjournals.org/cgi/content/abstract/55/4/731">http://bjps.oupjournals.org/cgi/content/abstract/55/4/731</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("REDMAT",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/55/4/731">http://bjps.oxfordjournals.org/cgi/reprint/55/4/731</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("REDMAT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/oup/phisci/2004/00000055/00000004/art00731">http://www.ingentaconnect.com/content/oup/phisci/2004/00000055/00000004/art00731</a><br></div></div>
</div><!--entry-->

<div id='_180_entry' class='entry'><span ><span class='name'>Robinson, William S.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("ROBPAM",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(199204)52:2&lt;80:PAMA&gt;2.0.CO;2-6'>Penrose and mathematical ability.</a></span> <span class='pub_name'>Analysis</span> 52 (2):80-88. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_180_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Penrose%20and%20mathematical%20ability+author%3ARobinson&amp;btnG=Search'>Google</a>)</span><div id='_180_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Penrose's argument depends on our knowledge of the validity of the algorithm we use, and here he equivocates between conscious and unconscious algorithms.</div></div>
</div><!--entry-->

<div id='_181_entry' class='entry'><span ><span class='name'>Schurz, Gerhard</span> (2002). McCall and Raatikainen on mechanism and incompleteness.</span> <span class='pub_name'>Facta Philosophica</span> 4:171-74. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=McCall%20and%20Raatikainen%20on%20mechanism%20and%20incompleteness+author%3ASchurz&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_182_entry' class='entry'><span ><span class='name'>Seager, William E.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("SEAYAP",this.href,0);return true;' href='http://www.scar.utoronto.ca/~seager/yestalg.pdf'>Yesterday's algorithm: Penrose and the Godel argument.</a></span> <span class='pub_name'>Croatian Journal of Philosophy</span> 3 (9):265-273. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Yesterday%27s%20algorithm+author%3ASeager&amp;btnG=Search'>Google</a>)</span><div id='_182_abstract' class='extra' style='font-size:12px;'>Abstract: Roger Penrose is justly famous for his work in physics and mathematics but he is _notorious_ for his endorsement of the GÃ¶del argument (see his 1989, 1994, 1997). This argument, first advanced by J. R. Lucas (in 1961), attempts to show that GÃ¶delâs (first) incompleteness theorem can be seen to reveal that the human mind transcends all algorithmic models of it<sup>1</sup>. Penrose's version of the argument has been seen to fall victim to the original objections raised against Lucas (see Boolos (1990) and for a particularly intemperate review, Putnam (1994)). Yet I believe that more can and should be said about the argument. Only a brief review is necessary here although I wish to present the argument in a somewhat peculiar form</div>
</div><!--entry-->

<div id='_183_entry' class='entry'><span ><span class='name'>Slezak, Peter</span> (1983). <a rel="nofollow" class='article_title' onclick='trackclick("SLEDDD",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(198303)34:1&lt;13:DDD&gt;2.0.CO;2-P'>Descartes's diagonal deduction.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 34 (March):13-36. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6745035456860044001'>Cited by 13</a> | <span class='ll' onclick='$("_183_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Descartes%27s%20diagonal%20deduction+author%3ASlezak&amp;btnG=Search'>Google</a> | <a href='javascript:show("_183_links")'>More links</a>)</span><div id='_183_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Cogito was a diagonal argument; connection to Godel, Lucas, Minsky, Nagel.</div></div>
<div id='_183_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEDDD",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(198303)34:1&lt;13:DDD&gt;2.0.CO;2-P">http://www.jstor.org/sici?sici=0007-0882(198303)34:1<13:DDD>2.0.CO;2-P</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEDDD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/34/1/13">http://bjps.oxfordjournals.org/cgi/content/citation/34/1/13</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEDDD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/34/1/13">http://bjps.oxfordjournals.org/cgi/reprint/34/1/13</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEDDD",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686931.pdf">http://www.jstor.org/stable/pdfplus/686931.pdf</a><br></div></div>
</div><!--entry-->

<div id='_184_entry' class='entry'><span ><span class='name'>Slezak, Peter</span> (1982). <a rel="nofollow" class='article_title' onclick='trackclick("SLEGTA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(198203)33:1&lt;41:GTATM&gt;2.0.CO;2-W'>Godel's theorem and the mind.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 33 (March):41-52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3276362988202907744'>Cited by 13</a> | <span class='ll' onclick='$("_184_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Godel%27s%20theorem%20and%20the%20mind+author%3ASlezak&amp;btnG=Search'>Google</a> | <a href='javascript:show("_184_links")'>More links</a>)</span><div id='_184_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>General analysis; Lucas commits type/token error; self-ref paradoxes.</div></div>
<div id='_184_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEGTA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(198203)33:1&lt;41:GTATM&gt;2.0.CO;2-W">http://www.jstor.org/sici?sici=0007-0882(198203)33:1<41:GTATM>2.0.CO;2-W</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEGTA",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/33/1/41">http://bjps.oxfordjournals.org/cgi/reprint/33/1/41</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEGTA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/687239.pdf">http://www.jstor.org/stable/pdfplus/687239.pdf</a><br></div></div>
</div><!--entry-->

<div id='_185_entry' class='entry'><span ><span class='name'>Slezak, Peter</span> (1984). <a rel="nofollow" class='article_title' onclick='trackclick("SLEMMA",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1746-8361.1984.tb00835.x'>Minds, machines and self-reference.</a></span> <span class='pub_name'>Dialectica</span> 38:17-34. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16146084609901211382'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%20and%20self-reference+author%3ASlezak&amp;btnG=Search'>Google</a> | <a href='javascript:show("_185_links")'>More links</a>)</span>
<div id='_185_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLEMMA",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120035817/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120035817/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_186_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("SLOTER",this.href,0);return true;' href='http://www.cs.bham.ac.uk/research/cogaff/Aaron.Sloman_Emperor.Real.Mind.pdf'>The emperor's real mind.</a></span> In A.G. Cohn &amp; J.R. Thomas (eds.), <em>Artificial Intelligence and Its Applications</em>. John Wiley and Sons. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20emperor%27s%20real%20mind+author%3ASloman&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_187_entry' class='entry'><span ><span class='name'>Smart, J. J. C.</span> (1961). <a rel="nofollow" class='article_title' onclick='trackclick("SMAGTC",this.href,0);return true;' href='http://www.springerlink.com/content/t5x07627p3785161/fulltext.pdf'>Godel's theorem, church's theorem, and mechanism.</a></span> <span class='pub_name'>Synthese</span> 13 (June):105-10. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_187_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Godel%27s%20theorem%2C%20church%27s%20theorem%2C%20and%20mechanism+author%3ASmart&amp;btnG=Search'>Google</a>)</span><div id='_187_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A machine could escape the Godelian argument by inductively ascertaining its own syntax. With comments on the relevance of ingenuity.</div></div>
</div><!--entry-->

<div id='_188_entry' class='entry'><span ><span class='name'>Stone, Tony</span> &amp; <span class='name'>Davies, Martin</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("STOFPA",this.href,0);return true;' href='http://philrsss.anu.edu.au/~mdavies/papers/simrip.pdf'>Folk psychology and mental simulation.</a></span> <span class='pub_name'>Royal Institute of Philosophy Supplement</span> 43:53-82. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20psychology%20and%20mental%20simulation+author%3AStone&amp;btnG=Search'>Google</a> | <a href='javascript:show("_188_links")'>More links</a>)</span><div id='_188_abstract' class='extra' style='font-size:12px;'>Abstract: This paper is about the contemporary debate concerning folk psychology â the debate between the proponents of the theory theory of folk psychology and the friends of the simulation alternative.<sup>1</sup> At the outset, we need to ask: What should we mean by this term âfolk psychologyâ?</div>
<div id='_188_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STOFPA",this.href,0);return true;' href="http://philrsss.anu.edu.au/~mdavies/papers/simrip.pdf ">http://philrsss.anu.edu.au/~mdavies/papers/simrip.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STOFPA",this.href,0);return true;' href="http://www.nyu.edu/gsas/dept/philo/courses/concepts/folkpsychology.html">http://www.nyu.edu/gsas/dept/philo/courses/concepts/folkpsychology.html</a><br></div></div>
</div><!--entry-->

<div id='_189_entry' class='entry'><span ><span class='name'>Tymoczko, Thomas</span> (1991). Why I am not a Turing machine: Godel's theorem and the philosophy of mind.</span> In Jay L. Garfield (ed.), <em>Foundations of Cognitive Science</em>. Paragon House. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_189_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20I%20am%20not%20a%20Turing%20machine+author%3ATymoczko&amp;btnG=Search'>Google</a>)</span><div id='_189_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Weak defense of Lucas; response to Putnam, Bowie, Dennett.</div></div>
</div><!--entry-->

<div id='_190_entry' class='entry'><span ><span class='name'>Wang, H.</span> (1974). <em><span class='pub_name'>From Mathematics to Philosophy.</span></em></span> London. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11484530503180237562'>Cited by 125</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20Mathematics%20to%20Philosophy+author%3AWang&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_191_entry' class='entry'><span ><span class='name'>Webb, Judson</span> (1968). <a rel="nofollow" class='article_title' onclick='trackclick("WEBMAT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8248(196806)35:2&lt;156:MATPOM&gt;2.0.CO;2-O'>Metamathematics and the philosophy of mind.</a></span> <span class='pub_name'>Philosophy of Science</span> 35 (June):156-78. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5608555197263749078'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Metamathematics%20and%20the%20philosophy%20of%20mind+author%3AWebb&amp;btnG=Search'>Google</a> | <a href='javascript:show("_191_links")'>More links</a>)</span>
<div id='_191_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEBMAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8248(196806)35:2&lt;156:MATPOM&gt;2.0.CO;2-O">http://www.jstor.org/sici?sici=0031-8248(196806)35:2<156:MATPOM>2.0.CO;2-O</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEBMAT",this.href,0);return true;' href="http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288199">http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288199</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEBMAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/186484.pdf">http://www.jstor.org/stable/pdfplus/186484.pdf</a><br></div></div>
</div><!--entry-->

<div id='_192_entry' class='entry'><span ><span class='name'>Webb, Judson</span> (1980). <em><span class='pub_name'>Mechanism, Mentalism and Metamathematics.</span></em></span> Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17440122710044430202'>Cited by 45</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mechanism%2C%20Mentalism%20and%20Metamathematics+author%3AWebb&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_193_entry' class='entry'><span ><span class='name'>Whitely, C.</span> (1962). Minds, machines and Godel: A reply to mr Lucas.</span> <span class='pub_name'>Philosophy</span> 37 (January):61-62. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_193_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%20and%20Godel+author%3AWhitely&amp;btnG=Search'>Google</a>)</span><div id='_193_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Humans get trapped too: "Lucas cannot consistently assert this formula".</div></div>
</div><!--entry-->

<div id='_194_entry' class='entry'><span ><span class='name'>Yu, Q.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("YUCMA",this.href,0);return true;' href='http://www.springerlink.com/content/x073727543g61372/fulltext.pdf'>Consistency, mechanicalness, and the logic of the mind.</a></span> <span class='pub_name'>Synthese</span> 90 (1):145-79. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6824954700753568678'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consistency%2C%20mechanicalness%2C%20and%20the%20logic%20of%20the%20mind+author%3AYu&amp;btnG=Search'>Google</a> | <a href='javascript:show("_194_links")'>More links</a>)</span><div id='_194_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â G. Priest's anti-consistency argument (Priest 1979, 1984, 1987) and J. R. Lucas's anti-mechanist argument (Lucas 1961, 1968, 1970, 1984) both appeal to GÃ¶del incompleteness. By way of refuting them, this paper defends the thesis of quartet compatibility, viz., that the logic of the mind can simultaneously be GÃ¶del incomplete, consistent, mechanical, and recursion complete (capable of all means of recursion). A representational approach is pursued, which owes its origin to works by, among others, J. Myhill (1964), P. Benacerraf (1967), J. Webb (1980, 1983) and M. Arbib (1987). It is shown that the fallacy shared by the two arguments under discussion lies in misidentifying two systems, the one for which the GÃ¶del sentence is constructable and to be proved, and the other in which the GÃ¶del sentence in question is indeed provable. It follows that the logic of the mind can surpass its own GÃ¶delian limitation not by being inconsistent or non-mechanistic, but by being capable of representing stronger systems in itself; and so can a proper machine. The concepts of representational provability, representational maximality, formal system capacity, etc., are discussed</div>
<div id='_194_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("YUCMA",this.href,0);return true;' href="http://www.springerlink.com/index/X073727543G61372.pdf">http://www.springerlink.com/index/X073727543G61372.pdf</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.1c'></a><a name=''></a><span class='myh3'>6.1c The Chinese Room</span></p>

<div id='cat_6.1c' class='cat_content'>
<div id='__new_entries_6.1c__'></div><div id='__new_entry_6.1c__' class='entry'></div>
<div id='_195_entry' class='entry'><span ><span class='name'>Adam, Alison</span> (2003). Cyborgs in the chinese room: Boundaries transgressed and boundaries blurred.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cyborgs%20in%20the%20chinese%20room+author%3AAdam&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_196_entry' class='entry'><span ><span class='name'>Aleksander, Igor L.</span> (2003). Neural depictions of "world" and "self": Bringing computational understanding into the chinese room.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Neural%20depictions%20of%20world%20and%20self+author%3AAleksander&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_197_entry' class='entry'><span ><span class='name'>Anderson, David</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("ANDITC",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(198707)62:241&lt;389:ITCRTR&gt;2.0.CO;2-V'>Is the chinese room the real thing?</a></span> <span class='pub_name'>Philosophy</span> 62 (July):389-93. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3818081639853339868'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20the%20chinese%20room%20the%20real%20thing%3F+author%3AAnderson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_198_entry' class='entry'><span ><span class='name'>Andrews, Kristin</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("ANDOPB",this.href,0);return true;' href='http://www.bu.edu/wcp/Papers/Mind/MindAndr.htm'>On predicting behavior.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20predicting%20behavior+author%3AAndrews&amp;btnG=Search'>Google</a>)</span><div id='_198_abstract' class='extra' style='font-size:12px;'>Abstract: I argue that the behavior of other agents is insufficiently described in current debates as a dichotomy between tacit theory (attributing beliefs and desires to predict behavior) and simulation theory (imagining what one would do in similar circumstances in order to predict behavior). I introduce two questions about the foundation and development of our ability both to attribute belief and to simulate it. I then propose that there is one additional method used to predict behavior, namely, an inductive strategy</div>
</div><!--entry-->

<div id='_199_entry' class='entry'><span ><span class='name'>Atlas, Jay David</span>, <a rel="nofollow" class='article_title' onclick='trackclick("ATLWII",this.href,0);return true;' href='http://pages.pomona.edu/~jda14747/Atlas_WHAT IS IT LIKE TO BE A CHINESE ROOM_1995.pdf'>What is it like to be a chinese room?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20it%20like%20to%20be%20a%20chinese%20room%3F+author%3AAtlas&amp;btnG=Search'>Google</a> | <a href='javascript:show("_199_links")'>More links</a>)</span><div id='_199_abstract' class='extra' style='font-size:12px;'>Abstract: When philosophers think about mental phenomena, they focus on several features of human experience: (1) the existence of consciousness, (2) the intentionality of mental states, that property by which beliefs, desires, anger, etc. are directed at, are about, or refer to objects and states of affairs, (3) subjectivity, characterized by my feeling my pains but not yours, by my experiencing the world and myself from my point of view and not yours, (4) mental causation, that thoughts and feelings have physical effects on the world: I decide to raise my arm and my arm rises. In a world described by theories of physics and chemistry, what place in that physical description do descriptions of the mental have?</div>
<div id='_199_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ATLWII",this.href,0);return true;' href="http://pages.pomona.edu/~jda14747/Atlas_WHAT%20IS%20IT%20LIKE%20TO%20BE%20A%20CHINESE%20ROOM_1995.pdf">http://pages.pomona.edu/~jda14747/Atlas_WHAT%20IS%20IT%20LIKE%20TO%20BE%20A%20CHINESE%20ROOM_1995.pdf</a><br></div></div>
</div><!--entry-->

<div id='_200_entry' class='entry'><span ><span class='name'>Ben-Yami, Hanoch</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("BENANO",this.href,0);return true;' href='http://www.springerlink.com/content/k1nx461746n57467/fulltext.pdf'>A note on the chinese room.</a></span> <span class='pub_name'>Synthese</span> 95 (2):169-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10934812639637501126'>Cited by 3</a> | <span class='ll' onclick='$("_200_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20note%20on%20the%20chinese%20room+author%3ABen-Yami&amp;btnG=Search'>Google</a> | <a href='javascript:show("_200_links")'>More links</a>)</span><div id='_200_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A fully functional Chinese room is impossible, as it (for instance) could not say what the time is.</div></div><div id='_200_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Searle's Chinese Room was supposed to prove that computers can't understand: the man in the room, following, like a computer, syntactical rules alone, though indistinguishable from a genuine Chinese speaker, doesn't understand a word. But such a room is impossible: the man won't be able to respond correctly to questions like What is the time?, even though such an ability is indispensable for a genuine Chinese speaker. Several ways to provide the room with the required ability are considered, and it is concluded that for each of these the room will have understanding. Hence, Searle's argument is invalid</div>
<div id='_200_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BENANO",this.href,0);return true;' href="http://www.springerlink.com/index/K1NX461746N57467.pdf">http://www.springerlink.com/index/K1NX461746N57467.pdf</a><br></div></div>
</div><!--entry-->

<div id='_201_entry' class='entry'><span ><span class='name'>Block, Ned</span> (2003). Searle's arguments against cognitive science.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11695290948813046600'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20arguments%20against%20cognitive%20science+author%3ABlock&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_202_entry' class='entry'><span ><span class='name'>Boden, Margaret A.</span> (1988). Escaping from the chinese room.</span> In <em>Computer Models of Mind</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14947610009102835480'>Cited by 21</a> | <span class='ll' onclick='$("_202_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Escaping%20from%20the%20chinese%20room+author%3ABoden&amp;btnG=Search'>Google</a>)</span><div id='_202_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A procedural account of how computers might have understanding and semantics.</div></div>
</div><!--entry-->

<div id='_203_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> &amp; <span class='name'>Noel, Ron</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("BRIRRA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/380566.html'>Real robots and the missing thought-experiment in the chinese room dialectic.</a></span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Real%20robots%20and%20the%20missing%20thought-experiment%20in%20the%20chinese%20room%20dialectic+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_203_links")'>More links</a>)</span>
<div id='_203_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIRRA",this.href,0);return true;' href="http://kryten.mm.rpi.edu/searlebook1.pdf">http://kryten.mm.rpi.edu/searlebook1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIRRA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/bringsjord99real.html">http://citeseer.ist.psu.edu/bringsjord99real.html</a><br></div></div>
</div><!--entry-->

<div id='_204_entry' class='entry'><span ><span class='name'>Brown, Steven Ravett</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BROPAF",this.href,0);return true;' href='http://cogprints.org/1002/'>Peirce and formalization of thought: The chinese room argument.</a></span> <span class='pub_name'>Journal of Mind and Behavior</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Peirce%20and%20formalization%20of%20thought+author%3ABrown&amp;btnG=Search'>Google</a> | <a href='javascript:show("_204_links")'>More links</a>)</span><div id='_204_abstract' class='extra' style='font-size:12px;'>Abstract: Whether human thinking can be formalized and whether machines can think in a human sense are questions that have been addressed by both Peirce and Searle. Peirce came to roughly the same conclusion as Searle, that the digital computer would not be able to perform human thinking or possess human understanding. However, his rationale and Searle's differ on several important points. Searle approaches the problem from the standpoint of traditional analytic philosophy, where the strict separation of syntax and semantics renders understanding impossible for a purely syntactical device. Peirce disagreed with that analysis, but argued that the computer would only be able to achieve algorithmic thinking, which he considered the simplest type. Although their approaches were radically dissimilar, their conclusions were not. I will compare and analyze the arguments of both Peirce and Searle on this issue, and outline some implications of their conclusions for the field of Artificial Intelligence</div>
<div id='_204_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROPAF",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001002/">http://cogprints.ecs.soton.ac.uk/archive/00001002/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROPAF",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/10/02/">http://cogprints.soton.ac.uk/documents/disk0/00/00/10/02/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROPAF",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001002/00/Peirce_Paper.html">http://cogprints.ecs.soton.ac.uk/archive/00001002/00/Peirce_Paper.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROPAF",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1002">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1002</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROPAF",this.href,0);return true;' href="http://cogprints.org/1002/1/Peirce_Paper.html">http://cogprints.org/1002/1/Peirce_Paper.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROPAF",this.href,0);return true;' href="http://cogprints.org/1002/0/Peirce_Paper.html">http://cogprints.org/1002/0/Peirce_Paper.html</a><br></div></div>
</div><!--entry-->

<div id='_205_entry' class='entry'><span ><span class='name'>Button, Graham</span>; <span class='name'>Coutler, Jeff</span> &amp; <span class='name'>Lee, John R. E.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BUTRTC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596715.596858'>Re-entering the chinese room: A reply to Gottfried and Traiger.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (1):145-148. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Re-entering%20the%20chinese%20room+author%3AButton&amp;btnG=Search'>Google</a> | <a href='javascript:show("_205_links")'>More links</a>)</span>
<div id='_205_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTRTC",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=238829&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=238829&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTRTC",this.href,0);return true;' href="http://www.springerlink.com/index/JQ41061085707655.pdf">http://www.springerlink.com/index/JQ41061085707655.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTRTC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000001/00238829">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000001/00238829</a><br></div></div>
</div><!--entry-->

<div id='_206_entry' class='entry'><span ><span class='name'>Bynum, Terrell Ward</span> (1985). <a rel="nofollow" class='article_title' onclick='trackclick("BYNAIB",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-9973.1985.tb00183.x'>Artificial intelligence, biology, and intentional states.</a></span> <span class='pub_name'>Metaphilosophy</span> 16 (October):355-77. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2560823770573013183'>Cited by 9</a> | <span class='ll' onclick='$("_206_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence%2C%20biology%2C%20and%20intentional%20states+author%3ABynum&amp;btnG=Search'>Google</a> | <a href='javascript:show("_206_links")'>More links</a>)</span><div id='_206_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A chess-playing machine embodied as a robot could have intentional states. Reference requires input/output, computation, and context.</div></div>
<div id='_206_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BYNAIB",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120031491/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120031491/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_207_entry' class='entry'><span ><span class='name'>Cam, Philip</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("CAMSOS",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a739199028~fulltext=713240930'>Searle on strong AI.</a></span> <span class='pub_name'>Australasian Journal of Philosophy</span> 68 (1):103-8. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=605672049221983358'>Cited by 2</a> | <span class='ll' onclick='$("_207_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%20on%20strong%20AI+author%3ACam&amp;btnG=Search'>Google</a> | <a href='javascript:show("_207_links")'>More links</a>)</span><div id='_207_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Criticizes Searle's "conclusion" that brains are needed for intentionality, notes that even a homunculus has intentional states. A misinterpretation.</div></div>
<div id='_207_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMSOS",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/X701829J6248U835.pdf">http://taylorandfrancis.metapress.com/index/X701829J6248U835.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMSOS",this.href,0);return true;' href="http://www.informaworld.com/index/739199028.pdf">http://www.informaworld.com/index/739199028.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMSOS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/ajphil/1990/00000068/00000001/art00007">http://www.ingentaconnect.com/content/routledg/ajphil/1990/00000068/00000001/art00007</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMSOS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/tajp/1990/00000068/00000001/art00007">http://www.ingentaconnect.com/content/tandf/tajp/1990/00000068/00000001/art00007</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMSOS",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a739199028~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a739199028~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_208_entry' class='entry'><span ><span class='name'>Carleton, Lawrence Richard</span> (1984). <a rel="nofollow" class='article_title' onclick='trackclick("CARPLU",this.href,0);return true;' href='http://www.springerlink.com/content/q24263234455051l/fulltext.pdf'>Programs, language understanding, and Searle.</a></span> <span class='pub_name'>Synthese</span> 59 (May):219-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16423821245566644283'>Cited by 8</a> | <span class='ll' onclick='$("_208_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Programs%2C%20language%20understanding%2C%20and%20Searle+author%3ACarleton&amp;btnG=Search'>Google</a> | <a href='javascript:show("_208_links")'>More links</a>)</span><div id='_208_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Arguing against Searle on a number of fronts, somewhat unconvincingly.</div></div>
<div id='_208_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CARPLU",this.href,0);return true;' href="http://www.springerlink.com/index/Q24263234455051L.pdf">http://www.springerlink.com/index/Q24263234455051L.pdf</a><br></div></div>
</div><!--entry-->

<div id='_209_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("CHASCA-2",this.href,0);return true;' href='http://citeseer.ist.psu.edu/53863.html'>Subsymbolic computation and the chinese room.</a></span> In J. Dinsmore (ed.), <em>The Symbolic and Connectionist Paradigms: Closing the Gap</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2654225510692069431'>Cited by 29</a> | <span class='ll' onclick='$("_209_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Subsymbolic%20computation%20and%20the%20chinese%20room+author%3AChalmers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_209_links")'>More links</a>)</span><div id='_209_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Gives an account of symbolic vs. subsymbolic computation, and argues that the latter is less vulnerable to the Chinese-room intuition, as representations there are not computational tokens.</div></div><div id='_209_abstract' class='extra' style='font-size:12px;'>Abstract: More than a decade ago, philosopher John Searle started a long-running controversy with his paper âMinds, Brains, and Programsâ (Searle, 1980a), an attack on the ambitious claims of artificial intelligence (AI). With his now famous _Chinese Room_ argument, Searle claimed to show that despite the best efforts of AI researchers, a computer could never recreate such vital properties of human mentality as intentionality, subjectivity, and understanding. The AI research program is based on the underlying assumption that all important aspects of human cognition may in principle be captured in a computational model. This assumption stems from the belief that beyond a certain level, implementational details are irrelevant to cognition. According to this belief, neurons, and biological wetware in general, have no preferred status as the substrate for a mind. As it happens, the best examples of minds we have at present have arisen from a carbon-based substrate, but this is due to constraints of evolution and possibly historical accidents, rather than to an absolute metaphysical necessity. As a result of this belief, many cognitive scientists have chosen to focus not on the biological substrate of the mind, but instead on the abstract causal structure_ _that the mind embodies (at an appropriate level of abstraction). The view that it is abstract causal structure that is essential to mentality has been an implicit assumption of the AI research program since Turing (1950), but was first articulated explicitly, in various forms, by Putnam (1960), Armstrong (1970) and Lewis (1970), and has become known as _functionalism_. From here, it is a very short step to _computationalism_, the view that computational structure is what is important in capturing the essence of mentality. This step follows from a belief that any abstract causal structure can be captured computationally: a belief made plausible by the ChurchâTuring Thesis, which articulates the power</div>
<div id='_209_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASCA-2",this.href,0);return true;' href="http://consc.net/papers/subsymbolic.pdf">http://consc.net/papers/subsymbolic.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASCA-2",this.href,0);return true;' href="http://citeseer.ist.psu.edu/chalmers92subsymbolic.html">http://citeseer.ist.psu.edu/chalmers92subsymbolic.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASCA-2",this.href,0);return true;' href="http://www.u.arizona.edu/~chalmers/papers/subsymbolic.pdf">http://www.u.arizona.edu/~chalmers/papers/subsymbolic.pdf</a><br></div></div>
</div><!--entry-->

<div id='_210_entry' class='entry'><span ><span class='name'>Churchland, Paul M.</span> &amp; <span class='name'>Churchland, Patricia S.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("CHUCAM",this.href,0);return true;' href='http://www.osti.gov/energycitations/product.biblio.jsp?osti_id=5305075'>Could a machine think?</a></span> <span class='pub_name'>Scientific American</span> 262 (1):32-37. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11088041765824108867'>Cited by 102</a> | <span class='ll' onclick='$("_210_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20a%20machine%20think%3F+author%3AChurchland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_210_links")'>More links</a>)</span><div id='_210_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Artificial mentality is possible, not through classical AI but through brain-like AI. Argues the syntax/semantics point using an analogy with electromagnetism and luminance.</div></div>
<div id='_210_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHUCAM",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=2294584&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=2294584&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_211_entry' class='entry'><span ><span class='name'>Cohen, L. Jonathan</span> (1986). What sorts of machines can understand the symbols they use?</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 60:81-96. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20sorts%20of%20machines%20can%20understand%20the%20symbols%20they%20use%3F+author%3ACohen&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_212_entry' class='entry'><span ><span class='name'>Cole, David J.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("COLAIA",this.href,0);return true;' href='http://www.d.umn.edu/~dcole/aipiabs.htm'>Artificial intelligence and personal identity.</a></span> <span class='pub_name'>Synthese</span> 88 (September):399-417. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5164703230637539126'>Cited by 18</a> | <span class='ll' onclick='$("_212_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence%20and%20personal%20identity+author%3ACole&amp;btnG=Search'>Google</a> | <a href='javascript:show("_212_links")'>More links</a>)</span><div id='_212_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>In the Chinese room, neither the person nor the system understands: a virtual person does. This person isn't the system, just as a normal person isn't a body. Follows from the "Kornese" room, which has two distinct understanders.</div></div><div id='_212_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Considerations of personal identity bear on John Searle's Chinese Room argument, and on the opposed position that a computer itself could really understand a natural language. In this paper I develop the notion of a virtual person, modelled on the concept of virtual machines familiar in computer science. I show how Searle's argument, and J. Maloney's attempt to defend it, fail. I conclude that Searle is correct in holding that no digital machine could understand language, but wrong in holding that artificial minds are impossible: minds and persons are not the same as the machines, biological or electronic, that realize them</div>
<div id='_212_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLAIA",this.href,0);return true;' href="http://www.springerlink.com/content/t130331427116747/fulltext.pdf">http://www.springerlink.com/content/t130331427116747/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLAIA",this.href,0);return true;' href="http://www.springerlink.com/index/T130331427116747.pdf">http://www.springerlink.com/index/T130331427116747.pdf</a><br></div></div>
</div><!--entry-->

<div id='_213_entry' class='entry'><span ><span class='name'>Cole, David J.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("COLAMC",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a739199915~fulltext=713240930'>Artificial minds: Cam on Searle.</a></span> <span class='pub_name'>Australasian Journal of Philosophy</span> 69 (September):329-33. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6199673251284872616'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20minds+author%3ACole&amp;btnG=Search'>Google</a> | <a href='javascript:show("_213_links")'>More links</a>)</span>
<div id='_213_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLAMC",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/X06438UX20015555.pdf">http://taylorandfrancis.metapress.com/index/X06438UX20015555.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLAMC",this.href,0);return true;' href="http://www.informaworld.com/index/X06438UX20015555.pdf">http://www.informaworld.com/index/X06438UX20015555.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLAMC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/ajphil/1991/00000069/00000003/art00006">http://www.ingentaconnect.com/content/routledg/ajphil/1991/00000069/00000003/art00006</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLAMC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/tajp/1991/00000069/00000003/art00006">http://www.ingentaconnect.com/content/tandf/tajp/1991/00000069/00000003/art00006</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLAMC",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a739199915~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a739199915~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_214_entry' class='entry'><span ><span class='name'>Cole, David J.</span> (1984). <a rel="nofollow" class='article_title' onclick='trackclick("COLTAT",this.href,0);return true;' href='http://www.springerlink.com/content/j009m56335341362/fulltext.pdf'>Thought and thought experiments.</a></span> <span class='pub_name'>Philosophical Studies</span> 45 (May):431-44. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17354610140073214075'>Cited by 15</a> | <span class='ll' onclick='$("_214_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Thought%20and%20thought%20experiments+author%3ACole&amp;btnG=Search'>Google</a> | <a href='javascript:show("_214_links")'>More links</a>)</span><div id='_214_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lots of thought experiments like Searle's, against Searle. Searle's argument is like Leibniz's "mill" argument, with similar level confusions. Nice but patchy.</div></div>
<div id='_214_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLTAT",this.href,0);return true;' href="http://www.springerlink.com/index/J009M56335341362.pdf">http://www.springerlink.com/index/J009M56335341362.pdf</a><br></div></div>
</div><!--entry-->

<div id='_215_entry' class='entry'><span ><span class='name'>Cole, David J.</span> (1994). The causal powers of CPUs.</span> In Eric Dietrich (ed.), <em>Thinking Computers and Virtual Persons</em>. Academic Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17327570341526867673'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20causal%20powers%20of%20CPUs+author%3ACole&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_216_entry' class='entry'><span ><span class='name'>Cole, David</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("COLTCR",this.href,0);return true;' href='http://plato.stanford.edu/entries/chinese-room/'>The chinese room argument.</a></span> <em>Stanford Encyclopedia of Philosophy</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20argument+author%3ACole&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_217_entry' class='entry'><span ><span class='name'>Copeland, B. Jack</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("COPTCC",this.href,0);return true;' href='http://citeseer.ist.psu.edu/388877.html'>The curious case of the chinese gym.</a></span> <span class='pub_name'>Synthese</span> 95 (2):173-86. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16781782574193027230'>Cited by 12</a> | <span class='ll' onclick='$("_217_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20curious%20case%20of%20the%20chinese%20gym+author%3ACopeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_217_links")'>More links</a>)</span><div id='_217_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Advocates the systems reply, and criticizes Searle's "Chinese Gym" response to connectionism: Searle (like those he accuses) confuses a simulation with the thing being simulated. Nice.</div></div><div id='_217_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Searle has recently used two adaptations of his Chinese room argument in an attack on connectionism. I show that these new forms of the argument are fallacious. First I give an exposition of and rebuttal to the original Chinese room argument, and then a brief introduction to the essentials of connectionism</div>
<div id='_217_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTCC",this.href,0);return true;' href="http://home.swipnet.se/drofe/chincym.pdf">http://home.swipnet.se/drofe/chincym.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTCC",this.href,0);return true;' href="http://www.alanturing.net/turing_archive/pages/pub/chincym/chincym.pdf">http://www.alanturing.net/turing_archive/pages/pub/chincym/chincym.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTCC",this.href,0);return true;' href="http://www.springerlink.com/content/ut111604435042jn/fulltext.pdf">http://www.springerlink.com/content/ut111604435042jn/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPTCC",this.href,0);return true;' href="http://www.springerlink.com/index/UT111604435042JN.pdf">http://www.springerlink.com/index/UT111604435042JN.pdf</a><br></div></div>
</div><!--entry-->

<div id='_218_entry' class='entry'><span ><span class='name'>Copeland, B. Jack</span> (2003). The chinese room from a logical point of view.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13730166743692250462'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20from%20a%20logical%20point%20of%20view+author%3ACopeland&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_219_entry' class='entry'><span ><span class='name'>Coulter, Jeff</span> &amp; <span class='name'>Sharrock, S.</span> (2003). The hinterland of the chinese room.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20hinterland%20of%20the%20chinese%20room+author%3ACoulter&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_220_entry' class='entry'><span ><span class='name'>Cutrona, Jr</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("CUTZIS",this.href,0);return true;' href='http://cogprints.org/4636/1/TR-05-002.pdf'>Zombies in Searle's chinese room: Putting the Turing test to bed.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Zombies%20in%20Searle%27s%20chinese%20room+author%3ACutrona%2C%20Jr&amp;btnG=Search'>Google</a> | <a href='javascript:show("_220_links")'>More links</a>)</span><div id='_220_abstract' class='extra' style='font-size:12px;'>Abstract: Searleâs discussions over the years 1980-2004 of the implications of his âChinese Roomâ Gedanken experiment are frustrating because they proceed from a correct assertion: (1) âInstantiating a computer program is never by itself a sufficient condition of intentionality;â and an incorrect assertion: (2) âThe explanation of how the brain produces intentionality cannot be that it does it by instantiating a computer program.â In this article, I describe how to construct a Gedanken zombie Chinese Room program that will pass the Turing test and at the same time unambiguously demonstrates the correctness of (1). I then describe how to construct a Gedanken Chinese brain program that will pass the Turing test, has a mind, and understands Chinese, thus demonstrating that (2) is incorrect. Searleâs instantiation of this program can and does produce intentionality. Searleâs longstanding ignorance of Chinese is simply irrelevant and always has been. I propose a truce and a plan for further exploration</div>
<div id='_220_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CUTZIS",this.href,0);return true;' href="http://cogprints.org/4636/1/TR%2D05%2D002.pdf">http://cogprints.org/4636/1/TR%2D05%2D002.pdf</a><br></div></div>
</div><!--entry-->

<div id='_221_entry' class='entry'><span ><span class='name'>Damper, Robert I.</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("DAMTCR",this.href,0);return true;' href='http://eprints.ecs.soton.ac.uk/9561/'>The chinese room argument--dead but not yet buried.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 11 (5-6):159-169. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6322691398264401239'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20argument--dead%20but%20not%20yet%20buried+author%3ADamper&amp;btnG=Search'>Google</a> | <a href='javascript:show("_221_links")'>More links</a>)</span>
<div id='_221_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAMTCR",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/9561/">http://eprints.resist.ecs.soton.ac.uk/9561/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAMTCR",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/9561/01/damper.pdf">http://eprints.ecs.soton.ac.uk/9561/01/damper.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAMTCR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2004/00000011/F0020005/art00010">http://www.ingentaconnect.com/content/imp/jcs/2004/00000011/F0020005/art00010</a><br></div></div>
</div><!--entry-->

<div id='_222_entry' class='entry'><span ><span class='name'>Damper, Robert I.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("DAMTLO",this.href,0);return true;' href='http://www.springerlink.com/content/4m402680547056t3/fulltext.pdf'>The logic of Searle's chinese room argument.</a></span> <span class='pub_name'>Minds and Machines</span> 16 (2):163-183. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20logic%20of%20Searle%27s%20chinese%20room%20argument+author%3ADamper&amp;btnG=Search'>Google</a> | <a href='javascript:show("_222_links")'>More links</a>)</span><div id='_222_abstract' class='extra' style='font-size:12px;'>Abstract:  John Searleâs Chinese room argument (CRA) is a celebrated thought experiment designed to refute the hypothesis, popular among artificial intelligence (AI) scientists and philosophers of mind, that âthe appropriately programmed computer really is a mindâ. Since its publication in 1980, the CRA has evoked an enormous amount of debate about its implications for machine intelligence, the functionalist philosophy of mind, theories of consciousness, etc. Although the general consensus among commentators is that the CRA is flawed, and not withstanding the popularity of the systems reply in some quarters, there is remarkably little agreement on exactly how and why it is flawed. A newcomer to the controversy could be forgiven for thinking that the bewildering collection of diverse replies to Searle betrays a tendency to unprincipled, ad hoc argumentation and, thereby, a weakness in the oppositionâs case. In this paper, treating the CRA as a prototypical example of a âdestructiveâ thought experiment, I attempt to set it in a logical framework (due to Sorensen), which allows us to systematise and classify the various objections. Since thought experiments are always posed in narrative form, formal logic by itself cannot fully capture the controversy. On the contrary, much also hinges on how one translates between the informal everyday language in which the CRA was initially framed and formal logic and, in particular, on the specific conception(s) of possibility that one reads into the logical formalism</div>
<div id='_222_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAMTLO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2006/00000016/00000002/00009031">http://www.ingentaconnect.com/content/klu/mind/2006/00000016/00000002/00009031</a><br></div></div>
</div><!--entry-->

<div id='_223_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1987). Fast thinking.</span> In <em>The Intentional Stance</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5164111903249622803'>Cited by 12</a> | <span class='ll' onclick='$("_223_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Fast%20thinking+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_223_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues with Searle on many points. A little weak.</div></div>
</div><!--entry-->

<div id='_224_entry' class='entry'><span ><span class='name'>Double, Richard</span> (1984). Reply to C.A. Field's <em>Double on Searle's Chinese Room</em>.</span> <span class='pub_name'>Nature and System</span> 6 (March):55-58. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reply%20to%20C.A.%20Field%27s%20Double%20on%20Searle%27s%20Chinese%20Room+author%3ADouble&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_225_entry' class='entry'><span ><span class='name'>Double, Richard</span> (1983). Searle, programs and functionalism.</span> <span class='pub_name'>Nature and System</span> 5 (March-June):107-14. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17091864932468178620'>Cited by 3</a> | <span class='ll' onclick='$("_225_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%2C%20programs%20and%20functionalism+author%3ADouble&amp;btnG=Search'>Google</a>)</span><div id='_225_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The homunculus doesn't have access to the system's intentionality. The syntax/semantics relation is like the neurophysiology/mind relation.</div></div>
</div><!--entry-->

<div id='_226_entry' class='entry'><span ><span class='name'>Dyer, Michael G.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("DYEFLM",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=95660'>Finding lost minds.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 2:329-39. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6877856439955048963'>Cited by 3</a> | <span class='ll' onclick='$("_226_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Finding%20lost%20minds+author%3ADyer&amp;btnG=Search'>Google</a> | <a href='javascript:show("_226_links")'>More links</a>)</span><div id='_226_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Harnad 1990: symbols, other minds, physically embodied algorithms.</div></div>
<div id='_226_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DYEFLM",this.href,0);return true;' href="http://www.informaworld.com/index/777957611.pdf">http://www.informaworld.com/index/777957611.pdf</a><br></div></div>
</div><!--entry-->

<div id='_227_entry' class='entry'><span ><span class='name'>Dyer, Michael G.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("DYEIAC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=95646.95657'>Intentionality and computationalism: Minds, machines, Searle and Harnad.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 2:303-19. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7595359163004966126'>Cited by 23</a> | <span class='ll' onclick='$("_227_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intentionality%20and%20computationalism+author%3ADyer&amp;btnG=Search'>Google</a> | <a href='javascript:show("_227_links")'>More links</a>)</span><div id='_227_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Searle/Harnad: systems reply, level confusions, etc.</div></div>
<div id='_227_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DYEIAC",this.href,0);return true;' href="http://www.informaworld.com/index/777957609.pdf">http://www.informaworld.com/index/777957609.pdf</a><br></div></div>
</div><!--entry-->

<div id='_228_entry' class='entry'><span ><span class='name'>Fields, Christopher A.</span> (1984). Double on Searle's chinese room.</span> <span class='pub_name'>Nature and System</span> 6 (March):51-54. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_228_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Double%20on%20Searle%27s%20chinese%20room+author%3AFields&amp;btnG=Search'>Google</a>)</span><div id='_228_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Double's argument implies that the brain isn't the basis of intentionality.</div></div>
</div><!--entry-->

<div id='_229_entry' class='entry'><span ><span class='name'>Fisher, Justin C.</span> (1988). The wrong stuff: Chinese rooms and the nature of understanding.</span> <span class='pub_name'>Philosophical Investigations</span> 11 (October):279-99. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11289459999177807597'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20wrong%20stuff+author%3AFisher&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_230_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> (1991). Yin and Yang in the chinese room.</span> In D. Rosenthal (ed.), <em>The Nature of Mind</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11803014526968087310'>Cited by 5</a> | <span class='ll' onclick='$("_230_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Yin%20and%20Yang%20in%20the%20chinese%20room+author%3AFodor&amp;btnG=Search'>Google</a>)</span><div id='_230_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The Chinese room isn't even implementing a Turing machine, because it doesn't use proximal causation. With a reply by Searle.</div></div>
</div><!--entry-->

<div id='_231_entry' class='entry'><span ><span class='name'>Fulda, Joseph S.</span> (2006). A Plea for Automated Language-to-Logical-Form Converters.</span> <span class='pub_name'>RASK: Internationalt tidsskrift for sprog og kommuinkation</span> 24 (--):87-102. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20Plea%20for%20Automated%20Language-to-Logical-Form%20Converters+author%3AFulda&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_232_entry' class='entry'><span ><span class='name'>Millikan, Ruth G.</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("GARSRO",this.href,0);return true;' href='http://www.philosophy.uconn.edu/department/millikan/imitatio.pdf'>Some reflections on the theory theory - simulation theory discussion.</a></span> In  Susan Hurley &amp;  Nick Chater (eds.), <em>Perspectives on Imitation: From Mirror Neurons to Memes, Vol II</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Some%20reflections%20on%20the%20theory%20theory%20-%20simulation%20theory%20discussion+author%3AMillikan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_233_entry' class='entry'><span ><span class='name'>Globus, Gordon G.</span> (1991). Deconstructing the chinese room.</span> <span class='pub_name'>Journal of Mind and Behavior</span> 12 (3):377-91. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9375969821941010443'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Deconstructing%20the%20chinese%20room+author%3AGlobus&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_234_entry' class='entry'><span ><span class='name'>Gozzano, Simone</span> (1995). Consciousness and understanding in the chinese room.</span> <span class='pub_name'>Informatica</span> 19:653-56. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17281686936172739812'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20and%20understanding%20in%20the%20chinese%20room+author%3AGozzano&amp;btnG=Search'>Google</a>)</span><div id='_234_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper I submit that the âChinese roomâ argument rests on the assumption that understanding a sentence necessarily implies being conscious of its content. However, this assumption can be challenged by showing that two notions of consciousness come into play, one to be found in AI, the other in Searleâs argument, and that the former is an essential condition for the notion used by Searle. If Searle discards the first, he not only has trouble explaining how we can learn a language but finds the validity of his own argument in jeopardy</div>
</div><!--entry-->

<div id='_235_entry' class='entry'><span ><span class='name'>Gozzano, Simone</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("GOZTCR",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=294079'>The chinese room argument: Consciousness and understanding.</a></span> In Matjaz Gams, M. Paprzycki &amp; X. Wu (eds.), <em>Mind Versus Computer: Were Dreyfus and Winograd Right?</em> Amsterdam: IOS Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20argument+author%3AGozzano&amp;btnG=Search'>Google</a> | <a href='javascript:show("_235_links")'>More links</a>)</span>
<div id='_235_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOZTCR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=VHZy4j_Qa-cC&amp;oi=fnd&amp;pg=PA231&amp;ots=RjBGkheslj&amp;sig=o6qlThOEXlScQeLhIvbrclE6lQc">http://books.google.com/books?hl=en&lr=&id=VHZy4j_Qa-cC&oi=fnd&pg=PA231&ots=RjBGkheslj&sig=o6qlThOEXlScQeLhIvbrclE6lQc</a><br></div></div>
</div><!--entry-->

<div id='_236_entry' class='entry'><span ><span class='name'>Hanna, Patricia</span> (1985). <a rel="nofollow" class='article_title' onclick='trackclick("HANCPA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0026-4423(198501)2:94:373&lt;53:CPAC&gt;2.0.CO;2-9'>Causal powers and cognition.</a></span> <span class='pub_name'>Mind</span> 94 (373):53-63. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15623975909157791666'>Cited by 2</a> | <span class='ll' onclick='$("_236_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Causal%20powers%20and%20cognition+author%3AHanna&amp;btnG=Search'>Google</a> | <a href='javascript:show("_236_links")'>More links</a>)</span><div id='_236_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that Searle is confused, and underestimates computers. Weak.</div></div>
<div id='_236_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HANCPA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(198501)2:94:373&lt;53:CPAC&gt;2.0.CO;2-9">http://www.jstor.org/sici?sici=0026-4423(198501)2:94:373<53:CPAC>2.0.CO;2-9</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HANCPA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2254697.pdf">http://www.jstor.org/stable/pdfplus/2254697.pdf</a><br></div></div>
</div><!--entry-->

<div id='_237_entry' class='entry'><span ><span class='name'>Harrison, David</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("HARCHT",this.href,0);return true;' href='http://www.open.ac.uk/Arts/connex/Connexions_1.pdf'>Connectionism hits the chinese gym.</a></span> <span class='pub_name'>Connexions</span> 1. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20hits%20the%20chinese%20gym+author%3AHarrison&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_238_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("HARLIT",this.href,0);return true;' href='http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad90.dyer.crit.html'>Lost in the hermeneutic hall of mirrors.</a></span> <span class='pub_name'>[Journal (Paginated)]</span> 2:321-27. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_238_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lost%20in%20the%20hermeneutic%20hall%20of%20mirrors+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_238_links")'>More links</a>)</span><div id='_238_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Dyer 1990: on the differences between real and as-if intentionality.</div></div><div id='_238_abstract' class='extra' style='font-size:12px;'>Abstract: Critique of Computationalism as merely projecting hermeneutics (i.e., meaning originating from the mind of an external interpreter) onto otherwise intrinsically meaningless symbols. Projecting an interpretation onto a symbol system results in its being reflected back, in a spuriously self-confirming way</div>
<div id='_238_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLIT",this.href,0);return true;' href="http://cogprints.org/1577/1/harnad90.dyer.crit.html">http://cogprints.org/1577/1/harnad90.dyer.crit.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARLIT",this.href,0);return true;' href="http://cogprints.org/1577/0/harnad90.dyer.crit.html">http://cogprints.org/1577/0/harnad90.dyer.crit.html</a><br></div></div>
</div><!--entry-->

<div id='_239_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("HARMMA-3",this.href,0);return true;' href='http://cogprints.org/1573/'>Minds, machines and Searle.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 1 (4):5-25. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7405660321207937873'>Cited by 113</a> | <span class='ll' onclick='$("_239_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%20and%20Searle+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_239_links")'>More links</a>)</span><div id='_239_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Non-symbolic function is necessary for mentality. Trying hard to work out a theory of why the Chinese Room shows what it does. Nice but wrong.</div></div><div id='_239_abstract' class='extra' style='font-size:12px;'>Abstract: Searle's celebrated Chinese Room Argument has shaken the foundations of Artificial Intelligence. Many refutations have been attempted, but none seem convincing. This paper is an attempt to sort out explicitly the assumptions and the logical, methodological and empirical points of disagreement. Searle is shown to have underestimated some features of computer modeling, but the heart of the issue turns out to be an empirical question about the scope and limits of the purely symbolic (computational) model of the mind. Nonsymbolic modeling turns out to be immune to the Chinese Room Argument. The issues discussed include the Total Turing Test, modularity, neural modeling, robotics, causality and the symbol-grounding problem</div>
<div id='_239_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.org/1573/ ">http://cogprints.org/1573/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/1891/">http://eprints.ecs.soton.ac.uk/1891/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/1891/">http://eprints.resist.ecs.soton.ac.uk/1891/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://citeseer.ist.psu.edu/harnad89minds.html">http://citeseer.ist.psu.edu/harnad89minds.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.org/1573/00/harnad89.searle.html">http://cogprints.org/1573/00/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001573/">http://cogprints.ecs.soton.ac.uk/archive/00001573/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001622/">http://cogprints.ecs.soton.ac.uk/archive/00001622/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/73/">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/73/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/73/ ">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/73/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/1891/01/harnad89.searle.html">http://eprints.ecs.soton.ac.uk/1891/01/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/5942/01/harnad00.searle.html">http://eprints.ecs.soton.ac.uk/5942/01/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/1891/01/harnad89.searle.html ">http://eprints.ecs.soton.ac.uk/1891/01/harnad89.searle.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad89.searle.html">http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad89.searle.html ">http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad89.searle.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad89.searle.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad89.searle.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad89.searle.html ">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad89.searle.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00005942/01/harnad00.searle.html">http://eprints.ecs.soton.ac.uk/archive/00005942/01/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001622/00/harnad00.searle.html">http://cogprints.ecs.soton.ac.uk/archive/00001622/00/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001573/00/harnad89.searle.html">http://cogprints.ecs.soton.ac.uk/archive/00001573/00/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001573/00/harnad89.searle.html ">http://cogprints.ecs.soton.ac.uk/archive/00001573/00/harnad89.searle.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1573">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1573</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2229271CI ">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2229271CI </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1573 ">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1573 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://web.comlab.ox.ac.uk/oucl/research/areas/ieg/e-library/sources/harnad89_searle.pdf ">http://web.comlab.ox.ac.uk/oucl/research/areas/ieg/e-library/sources/harnad89_searle.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://www.informaworld.com/index/777580727.pdf">http://www.informaworld.com/index/777580727.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/%7Eharnad/Papers/Harnad/harnad89.searle.html">http://www.ecs.soton.ac.uk/%7Eharnad/Papers/Harnad/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.org/1573/1/harnad89.searle.html">http://cogprints.org/1573/1/harnad89.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-3",this.href,0);return true;' href="http://cogprints.org/1573/0/harnad89.searle.html">http://cogprints.org/1573/0/harnad89.searle.html</a><br></div></div>
</div><!--entry-->

<div id='_240_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("HARMMA-4",this.href,0);return true;' href='http://cogprints.ecs.soton.ac.uk/archive/00001622/'>Minds, machines, and Searle 2: What's right and wrong about the chinese room argument.</a></span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6287626490712955056'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%2C%20and%20Searle%202+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_240_links")'>More links</a>)</span><div id='_240_abstract' class='extra' style='font-size:12px;'>Abstract: When in 1979 Zenon Pylyshyn, associate editor of Behavioral and Brain Sciences (BBS, a peer commentary journal which I edit) informed me that he had secured a paper by John Searle with the unprepossessing title of [XXXX], I cannot say that I was especially impressed; nor did a quick reading of the brief manuscript -- which seemed to be yet another tedious "Granny Objection"[1] about why/how we are not computers -- do anything to upgrade that impression</div>
<div id='_240_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-4",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/5942/01/harnad00.searle.html">http://eprints.ecs.soton.ac.uk/5942/01/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-4",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-4",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-4",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00005942/01/harnad00.searle.html">http://eprints.ecs.soton.ac.uk/archive/00005942/01/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARMMA-4",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001622/00/harnad00.searle.html">http://cogprints.ecs.soton.ac.uk/archive/00001622/00/harnad00.searle.html</a><br></div></div>
</div><!--entry-->

<div id='_241_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("HARRAW",this.href,0);return true;' href='http://cogprints.ecs.soton.ac.uk/archive/00001622/'>Rights and wrongs of Searle's chinese room argument.</a></span> In  M. Bishop &amp;  J. Preston (eds.), <em>Essays on Searle's Chinese Room Argument</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rights%20and%20wrongs%20of%20Searle%27s%20chinese%20room%20argument+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_241_links")'>More links</a>)</span><div id='_241_abstract' class='extra' style='font-size:12px;'>Abstract: "in an academic generation a little overaddicted to "politesse," it may be worth saying that violent destruction is not necessarily worthless and futile. Even though it leaves doubt about the right road for London, it helps if someone rips up, however violently, a</div>
<div id='_241_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARRAW",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/5942/01/harnad00.searle.html">http://eprints.ecs.soton.ac.uk/5942/01/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARRAW",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARRAW",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad00.searle.html</a><br></div></div>
</div><!--entry-->

<div id='_242_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span>, <a rel="nofollow" class='article_title' onclick='trackclick("HARSCR",this.href,0);return true;' href='http://eprints.ecs.soton.ac.uk/10424/01/chineseroom.html'>Searle's chinese room argument.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20chinese%20room%20argument+author%3AHarnad&amp;btnG=Search'>Google</a>)</span><div id='_242_abstract' class='extra' style='font-size:12px;'>Abstract: Computationalism. According to computationalism, to explain how the mind works, cognitive science needs to find out what the right computations are -- the same ones that the brain performs in order to generate the mind and its capacities. Once we know that, then every system that performs those computations will have those mental states: Every computer that runs the mind's program will have a mind, because computation is hardware independent : Any hardware that is running the right program has the right computational states</div>
</div><!--entry-->

<div id='_243_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("HARWWA",this.href,0);return true;' href='http://cogprints.org/1622/'>What's wrong and right about Searle's chinese room argument?</a></span> In Michael A. Bishop &amp; John M. Preston (eds.), <em>[Book Chapter] (in Press)</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13441516570252491390'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%27s%20wrong%20and%20right%20about%20Searle%27s%20chinese%20room%20argument%3F+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_243_links")'>More links</a>)</span><div id='_243_abstract' class='extra' style='font-size:12px;'>Abstract: Searle's Chinese Room Argument showed a fatal flaw in computationalism (the idea that mental states are just computational states) and helped usher in the era of situated robotics and symbol grounding (although Searle himself thought neuroscience was the only correct way to understand the mind)</div>
<div id='_243_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARWWA",this.href,0);return true;' href="http://cogprints.org/4023/1/searlbook.htm">http://cogprints.org/4023/1/searlbook.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARWWA",this.href,0);return true;' href="http://cogprints.org/1622/0/harnad00.searle.html">http://cogprints.org/1622/0/harnad00.searle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARWWA",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/16/22/">http://cogprints.soton.ac.uk/documents/disk0/00/00/16/22/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARWWA",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:1622">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:1622</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARWWA",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1622">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1622</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARWWA",this.href,0);return true;' href="http://cogprints.org/1622/1/harnad00.searle.html">http://cogprints.org/1622/1/harnad00.searle.html</a><br></div></div>
</div><!--entry-->

<div id='_244_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("HAUCRA",this.href,0);return true;' href='http://www.iep.utm.edu/c/chineser.htm'>Chinese room argument.</a></span> <em>Internet Encyclopedia of Philosophy</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Chinese%20room%20argument+author%3AHauser&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_245_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("HAUNGT",this.href,0);return true;' href='http://www.wutsamada.com/work/nixgoes6.htm'>Nixin' goes to china.</a></span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16275028307506227923'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Nixin%27%20goes%20to%20china+author%3AHauser&amp;btnG=Search'>Google</a>)</span><div id='_245_abstract' class='extra' style='font-size:12px;'>Abstract: The intelligent-seeming deeds of computers are what occasion philosophical debate about artificial intelligence (AI) in the first place. Since evidence of AI is not bad, arguments against seem called for. John Searle's Chinese Room Argument (1980a, 1984, 1990, 1994) is among the most famous and long-running would-be answers to the call. Surprisingly, both the original thought experiment (1980a) and Searle's later would-be formalizations of the embedding argument (1984, 1990) are quite unavailing against AI proper (claims that computers do or someday will think ). Searle lately even styles it a "misunderstanding" (1994, p. 547) to think the argument was ever so directed! The Chinese room is now advertised to target Computationalism (claims that computation is what thought essentially is ) exclusively. Despite its renown, the Chinese Room Argument is totally ineffective even against this target</div>
</div><!--entry-->

<div id='_246_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (1993). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HAUSCB",this.href,0);return true;' href='http://members.aol.com/wutsamada/disserta.html'>Searle's Chinese Box: The Chinese Room Argument and Artificial Intelligence.</a></span></em></span> Dissertation, University of Michigan <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 11 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20Chinese%20Box+author%3AHauser&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_247_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href='http://cogprints.org/240/'>Searle's chinese box: Debunking the chinese room argument.</a></span> <span class='pub_name'>[Journal (Paginated)]</span> 7 (2):199-226. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18055555563999984880'>Cited by 17</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20chinese%20box+author%3AHauser&amp;btnG=Search'>Google</a> | <a href='javascript:show("_247_links")'>More links</a>)</span><div id='_247_abstract' class='extra' style='font-size:12px;'>Abstract: John Searle's Chinese room argument is perhaps the most influential and widely cited argument against artificial intelligence (AI). Understood as targeting AI proper -- claims that computers can think or do think -- Searle's argument, despite its rhetorical flash, is logically and scientifically a dud. Advertised as effective against AI proper, the argument, in its main outlines, is an ignoratio elenchi. It musters persuasive force fallaciously by indirection fostered by equivocal deployment of the phrase "strong AI" and reinforced by equivocation on the phrase "causal powers (at least) equal to those of brains." On a more carefully crafted understanding -- understood just to target metaphysical identification of thought with computation ("Functionalism" or "Computationalism") and not AI proper -- the argument is still unsound, though more interestingly so. It's unsound in ways difficult for high church -- "someday my prince of an AI program will come" -- believers in AI to acknowledge without undermining their high church beliefs. The ad hominem bite of Searle's argument against the high church persuasions of so many cognitive scientists, I suggest, largely explains the undeserved repute this really quite disreputable argument enjoys among them</div>
<div id='_247_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://cogprints.org/240/00/199802002.html ">http://cogprints.org/240/00/199802002.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://members.aol.com/lshauser/chiboxab.html">http://members.aol.com/lshauser/chiboxab.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://members.aol.com/lshauser2/chinabox.html">http://members.aol.com/lshauser2/chinabox.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://members.aol.com/wutsamada/disserta.html">http://members.aol.com/wutsamada/disserta.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://members.aol.com/lshauser/chiboxab.html ">http://members.aol.com/lshauser/chiboxab.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://members.aol.com/wutsamada/contents.html">http://members.aol.com/wutsamada/contents.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://members.aol.com/lshauser2/chinabox.html ">http://members.aol.com/lshauser2/chinabox.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000240/">http://cogprints.ecs.soton.ac.uk/archive/00000240/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596705.596737">http://portal.acm.org/citation.cfm?id=596705.596737</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/02/40/">http://cogprints.soton.ac.uk/documents/disk0/00/00/02/40/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/02/40/ ">http://cogprints.soton.ac.uk/documents/disk0/00/00/02/40/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000240/00/199802002.html ">http://cogprints.ecs.soton.ac.uk/archive/00000240/00/199802002.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:240">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:240</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:240 ">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:240 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=322378CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=322378CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=322378CI ">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=322378CI </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.springerlink.com/content/kx8r435770352167/fulltext.pdf">http://www.springerlink.com/content/kx8r435770352167/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=120195&amp;PDF=1 ">http://www.kluweronline.com/article.asp?PIPS=120195&PDF=1 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=120195&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=120195&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.springerlink.com/index/KX8R435770352167.pdf ">http://www.springerlink.com/index/KX8R435770352167.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.springerlink.com/index/KX8R435770352167.pdf">http://www.springerlink.com/index/KX8R435770352167.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000002/00120195">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000002/00120195</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://cogprints.org/240/1/199802002.html">http://cogprints.org/240/1/199802002.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUSCB-2",this.href,0);return true;' href="http://cogprints.org/240/0/199802002.html">http://cogprints.org/240/0/199802002.html</a><br></div></div>
</div><!--entry-->

<div id='_248_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("HAUSCR",this.href,0);return true;' href='http://host.uniroma3.it/progetti/kant/field/chinese.html'>Searle's chinese room argument.</a></span> <em>Field Guide to the Philosophy of Mind</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20chinese%20room%20argument+author%3AHauser&amp;btnG=Search'>Google</a>)</span><div id='_248_abstract' class='extra' style='font-size:12px;'>Abstract: John Searle's 1980a) thought experiment and associated 1984a) argument is one of the best known and widely credited counters to claims of artificial intelligence (AI), i.e., to claims that computers _do_ or at least _can_ (roughly, someday will) think. According to Searle's original presentation, the argument is based on two truths: _brains cause minds_ , and _syntax doesn't suffice_ _for semantics_ . Its target, Searle dubs "strong AI": "according to strong AI," according to Searle, "the computer is not merely a tool in the study of the mind, rather the appropriately programmed computer really _is_ a mind in the sense that computers given the right programs can be literally said to _understand_ and have other cognitive states" 1980a, p. 417). Searle contrasts "strong AI" to "weak AI". According to weak AI, according to Searle, computers just</div>
</div><!--entry-->

<div id='_249_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("HAUTCR",this.href,0);return true;' href='http://www.utm.edu/research/iep/c/chineser.htm'>The chinese room argument.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3714359935738620225'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20argument+author%3AHauser&amp;btnG=Search'>Google</a>)</span><div id='_249_abstract' class='extra' style='font-size:12px;'>Abstract: _The Chinese room argument_ - John Searle's (1980a) thought experiment and associated (1984) derivation - is one of the best known and widely credited counters to claims of artificial intelligence (AI), i.e., to claims that computers _do_ or at least _can_ (someday might) think. According to Searle's original presentation, the argument is based on two truths: _brains cause minds_ , and _syntax doesn't_ _suffice for semantics_ . Its target, Searle dubs "strong AI": "according to strong AI," according to Searle, "the computer is not merely a tool in the study of the mind, rather the appropriately programmed computer really _is_ a mind in the sense that computers given the right programs can be literally said to _understand_ and have other cognitive states" (1980a, p. 417). Searle contrasts "strong AI" to "weak AI". According to weak AI, according to Searle, computers just</div>
</div><!--entry-->

<div id='_250_entry' class='entry'><span ><span class='name'>Hayes, Patrick</span>; <span class='name'>Harnad, Stevan</span>; <span class='name'>Perlis, Donald R.</span> &amp; <span class='name'>Block, Ned</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href='http://cogprints.org/1585/'>Virtual symposium on virtual mind.</a></span> <span class='pub_name'>[Journal (Paginated)]</span> 2 (3):217-238. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9887073176691005699'>Cited by 21</a> | <span class='ll' onclick='$("_250_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Virtual%20symposium%20on%20virtual%20mind+author%3AHayes&amp;btnG=Search'>Google</a> | <a href='javascript:show("_250_links")'>More links</a>)</span><div id='_250_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A discussion about the Chinese room, symbol grounding, and so on.</div></div><div id='_250_abstract' class='extra' style='font-size:12px;'>Abstract: When certain formal symbol systems (e.g., computer programs) are implemented as dynamic physical symbol systems (e.g., when they are run on a computer) their activity can be interpreted at higher levels (e.g., binary code can be interpreted as LISP, LISP code can be interpreted as English, and English can be interpreted as a meaningful conversation). These higher levels of interpretability are called "virtual" systems. If such a virtual system is interpretable as if it had a mind, is such a "virtual mind" real? This is the question addressed in this "virtual" symposium, originally conducted electronically among four cognitive scientists: Donald Perlis, a computer scientist, argues that according to the computationalist thesis, virtual minds are real and hence Searle's Chinese Room Argument fails, because if Searle memorized and executed a program that could pass the Turing Test in Chinese he would have a second, virtual, Chinese-understanding mind of which he was unaware (as in multiple personality). Stevan Harnad, a psychologist, argues that Searle's Argument is valid, virtual minds are just hermeneutic overinterpretations, and symbols must be grounded in the real world of objects, not just the virtual world of interpretations. Computer scientist Patrick Hayes argues that Searle's Argument fails, but because Searle does not really implement the program: A real implementation must not be homuncular but mindless and mechanical, like a computer. Only then can it give rise to a mind at the virtual level. Philosopher Ned Block suggests that there is no reason a mindful implementation would not be a real one</div>
<div id='_250_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/3371/">http://eprints.resist.ecs.soton.ac.uk/3371/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003371/">http://eprints.ecs.soton.ac.uk/archive/00003371/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003371/ ">http://eprints.ecs.soton.ac.uk/archive/00003371/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogprints.org/1585/00/harnad92.virtualmind.html ">http://cogprints.org/1585/00/harnad92.virtualmind.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/85/">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/85/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/85/ ">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/85/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad92.virtualmind.html">http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad92.virtualmind.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad92.virtualmind.html ">http://cogsci.soton.ac.uk/harnad/Papers/Harnad/harnad92.virtualmind.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html ">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html ">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.virtualmind.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003371/02/harnad92.virtualmind.html">http://eprints.ecs.soton.ac.uk/archive/00003371/02/harnad92.virtualmind.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001585/00/harnad92.virtualmind.html">http://cogprints.ecs.soton.ac.uk/archive/00001585/00/harnad92.virtualmind.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001585/00/harnad92.virtualmind.html ">http://cogprints.ecs.soton.ac.uk/archive/00001585/00/harnad92.virtualmind.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3371 ">http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3371 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1585">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1585</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1585 ">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1585 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://www.springerlink.com/content/g2063372459ww766/fulltext.pdf">http://www.springerlink.com/content/g2063372459ww766/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://www.springerlink.com/index/G2063372459WW766.pdf">http://www.springerlink.com/index/G2063372459WW766.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogprints.org/1585/1/harnad92.virtualmind.html">http://cogprints.org/1585/1/harnad92.virtualmind.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYVSO-2",this.href,0);return true;' href="http://cogprints.org/1585/0/harnad92.virtualmind.html">http://cogprints.org/1585/0/harnad92.virtualmind.html</a><br></div></div>
</div><!--entry-->

<div id='_251_entry' class='entry'><span ><span class='name'>Hofstadter, Douglas R.</span> (1981). Reflections on Searle.</span> In Douglas R. Hofstadter &amp; Daniel C. Dennett (eds.), <em>The Mind's I</em>. Basic Books. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1579993768229768369'>Cited by 1</a> | <span class='ll' onclick='$("_251_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reflections%20on%20Searle+author%3AHofstadter&amp;btnG=Search'>Google</a>)</span><div id='_251_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Searle is committing a level confusion, and understates the complexity of the case. We can move from the CR to a brain (with a demon) by twiddling knobs, and the systems reply should work equally well in both cases.</div></div>
</div><!--entry-->

<div id='_252_entry' class='entry'><span ><span class='name'>Jacquette, Dale</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("JACAIT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8205(198906)49:4&lt;605:AITCR&gt;2.0.CO;2-1'>Adventures in the chinese room.</a></span> <span class='pub_name'>Philosophy and Phenomenological Research</span> 49 (June):605-23. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3996025529386638414'>Cited by 5</a> | <span class='ll' onclick='$("_252_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Adventures%20in%20the%20chinese%20room+author%3AJacquette&amp;btnG=Search'>Google</a> | <a href='javascript:show("_252_links")'>More links</a>)</span><div id='_252_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>If we had microfunctional correspondence, the CR argument would fail. With points about the status of abstract/biological intentionality. A bit weak.</div></div>
<div id='_252_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("JACAIT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8205(198906)49:4&lt;605:AITCR&gt;2.0.CO;2-1">http://www.jstor.org/sici?sici=0031-8205(198906)49:4<605:AITCR>2.0.CO;2-1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("JACAIT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2107850.pdf">http://www.jstor.org/stable/pdfplus/2107850.pdf</a><br></div></div>
</div><!--entry-->

<div id='_253_entry' class='entry'><span ><span class='name'>Jacquette, Dale</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("JACFAL",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793914468~fulltext=713240930'>Fear and loathing (and other intentional states) in Searle's chinese room.</a></span> <span class='pub_name'>Philosophical Psychology</span> 3 (2 & 3):287-304. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_253_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Fear%20and%20loathing%20%28and%20other%20intentional%20states%29%20in%20Searle%27s%20chinese%20room+author%3AJacquette&amp;btnG=Search'>Google</a>)</span><div id='_253_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Searle on CR, central control, biological intentionality & dualism.</div></div><div id='_253_abstract' class='extra' style='font-size:12px;'>Abstract: John R. Searle's problem of the Chinese Room poses an important philosophical challenge to the foundations of strong artificial intelligence, and functionalist, cognitivist, and computationalist theories of mind. Searle has recently responded to three categories of criticisms of the Chinese Room and the consequences he attempts to conclude from it, redescribing the essential features of the problem, and offering new arguments about the syntax-semantics gap it is intended to demonstrate. Despite Searle's defense, the Chinese Room remains ineffective as a counterexample, and poses no real threat to artificial intelligence or mechanist philosophy of mind. The thesis that intentionality is a primitive irreducible relation exemplified by biological phenomena is preferred in opposition to Searle's contrary claim that intentionality is a biological phenomenon exhibiting abstract properties</div>
</div><!--entry-->

<div id='_254_entry' class='entry'><span ><span class='name'>Jacquette, Dale</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("JACSIT",this.href,0);return true;' href='http://www.springerlink.com/content/jq02542uq70q1130/fulltext.pdf'>Searle's intentionality thesis.</a></span> <span class='pub_name'>Synthese</span> 80 (August):267-75. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1691655193607494172'>Cited by 1</a> | <span class='ll' onclick='$("_254_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20intentionality%20thesis+author%3AJacquette&amp;btnG=Search'>Google</a> | <a href='javascript:show("_254_links")'>More links</a>)</span><div id='_254_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Searle's view implies that intentional causation is not efficient causation.</div></div>
<div id='_254_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("JACSIT",this.href,0);return true;' href="http://www.springerlink.com/index/JQ02542UQ70Q1130.pdf">http://www.springerlink.com/index/JQ02542UQ70Q1130.pdf</a><br></div></div>
</div><!--entry-->

<div id='_255_entry' class='entry'><span ><span class='name'>Jahren, Neal</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("JAHCSB",this.href,0);return true;' href='http://www.springerlink.com/content/g7140m0r11437051/fulltext.pdf'>Can semantics be syntactic?</a></span> <span class='pub_name'>Synthese</span> 82 (3):309-28. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5882667440900723893'>Cited by 3</a> | <span class='ll' onclick='$("_255_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20semantics%20be%20syntactic%3F+author%3AJahren&amp;btnG=Search'>Google</a> | <a href='javascript:show("_255_links")'>More links</a>)</span><div id='_255_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Against Rapaport's Korean Room argument -- syntax isn't enough.</div></div><div id='_255_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The author defends John R. Searle's Chinese Room argument against a particular objection made by William J. Rapaport called the Korean Room. Foundational issues such as the relationship of strong AI to human mentality and the adequacy of the Turing Test are discussed. Through undertaking a Gedankenexperiment similar to Searle's but which meets new specifications given by Rapaport for an AI system, the author argues that Rapaport's objection to Searle does not stand and that Rapaport's arguments seem convincing only because they assume the foundations of strong AI at the outset</div>
<div id='_255_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("JAHCSB",this.href,0);return true;' href="http://www.springerlink.com/index/G7140M0R11437051.pdf">http://www.springerlink.com/index/G7140M0R11437051.pdf</a><br></div></div>
</div><!--entry-->

<div id='_256_entry' class='entry'><span ><span class='name'>Kaernbach, C.</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("KAENVM",this.href,0);return true;' href='http://fechner.uni-graz.at/team/kaernbach/publications/2005_kae_jcs.pdf'>No virtual mind in the chinese room.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 12 (11):31-42. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=No%20virtual%20mind%20in%20the%20chinese%20room+author%3AKaernbach&amp;btnG=Search'>Google</a> | <a href='javascript:show("_256_links")'>More links</a>)</span>
<div id='_256_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KAENVM",this.href,0);return true;' href="http://www.psychologie.uni-kiel.de/emotion/team/kaernbach/publications/2005_kae_jcs.pdf">http://www.psychologie.uni-kiel.de/emotion/team/kaernbach/publications/2005_kae_jcs.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KAENVM",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2005/00000012/00000011/art00002">http://www.ingentaconnect.com/content/imp/jcs/2005/00000012/00000011/art00002</a><br></div></div>
</div><!--entry-->

<div id='_257_entry' class='entry'><span ><span class='name'>Kentridge, Robert W.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("KENCCA",this.href,0);return true;' href='http://psycprints.ecs.soton.ac.uk/archive/00000179/'>Computation, chaos and non-deterministic symbolic computation: The chinese room problem solved?</a></span> <span class='pub_name'>Psycoloquy</span> 12 (50). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14911501082969219640'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computation%2C%20chaos%20and%20non-deterministic%20symbolic%20computation+author%3AKentridge&amp;btnG=Search'>Google</a> | <a href='javascript:show("_257_links")'>More links</a>)</span>
<div id='_257_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KENCCA",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Temp/Think/kentridg.htm">http://cogsci.soton.ac.uk/~harnad/Temp/Think/kentridg.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KENCCA",this.href,0);return true;' href="http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?article=12.050">http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?article=12.050</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KENCCA",this.href,0);return true;' href="http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?symbolism-connectionism.17">http://www.cogsci.ecs.soton.ac.uk/cgi/psyc/newpsy?symbolism-connectionism.17</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KENCCA",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.kentridge.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.kentridge.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KENCCA",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.kentridge.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.kentridge.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KENCCA",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000179/02/psyc.01.12.050.symbolism-connectionism.17.kentridge">http://psycprints.ecs.soton.ac.uk/archive/00000179/02/psyc.01.12.050.symbolism-connectionism.17.kentridge</a><br></div></div>
</div><!--entry-->

<div id='_258_entry' class='entry'><span ><span class='name'>King, D.</span> (2001). Entering the chinese room with Castaneda's principle (p).</span> <span class='pub_name'>Philosophy Today</span> 45 (2):168-174. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Entering%20the%20chinese%20room%20with%20Castaneda%27s%20principle%20%28p%29+author%3AKing&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_259_entry' class='entry'><span ><span class='name'>Kober, Michael</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("KOBKMT",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a713788476~fulltext=713240930'>Kripkenstein meets the chinese room: Looking for the place of meaning from a natural point of view.</a></span> <span class='pub_name'>Inquiry</span> 41 (3):317-332. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17838185696734620581'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Kripkenstein%20meets%20the%20chinese%20room+author%3AKober&amp;btnG=Search'>Google</a> | <a href='javascript:show("_259_links")'>More links</a>)</span><div id='_259_abstract' class='extra' style='font-size:12px;'>Abstract: The discussion between Searle and the Churchlands over whether or not symbolmanipulating computers generate semantics will be confronted both with the rulesceptical considerations of Kripke/Wittgenstein and with Wittgenstein's privatelanguage argument in order to show that the discussion focuses on the wrong place: meaning does not emerge in the brain. That a symbol means something should rather be conceived as a social fact, depending on a mutual imputation of linguistic competence of the participants of a linguistic practice to one another. The alternative picture will finally be applied to small children, animals, and computers as well</div>
<div id='_259_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KOBKMT",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/NRA0050818Y5C6GA.pdf">http://taylorandfrancis.metapress.com/index/NRA0050818Y5C6GA.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KOBKMT",this.href,0);return true;' href="http://www.informaworld.com/index/NRA0050818Y5C6GA.pdf">http://www.informaworld.com/index/NRA0050818Y5C6GA.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KOBKMT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/sinq/1998/00000041/00000003/art00004">http://www.ingentaconnect.com/content/routledg/sinq/1998/00000041/00000003/art00004</a><br></div></div>
</div><!--entry-->

<div id='_260_entry' class='entry'><span ><span class='name'>Korb, Kevin B.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("KORSAP",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=124208'>Searle's AI program.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 3:283-96. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8549199980068768702'>Cited by 6</a> | <span class='ll' onclick='$("_260_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20AI%20program+author%3AKorb&amp;btnG=Search'>Google</a> | <a href='javascript:show("_260_links")'>More links</a>)</span><div id='_260_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The Chinese room doesn't succeed as an argument about semantics. At best it might succeed as an argument about consciousness.</div></div>
<div id='_260_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KORSAP",this.href,0);return true;' href="http://www.informaworld.com/index/776648442.pdf">http://www.informaworld.com/index/776648442.pdf</a><br></div></div>
</div><!--entry-->

<div id='_261_entry' class='entry'><span ><span class='name'>Kugel, Peter</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("KUGTCR",this.href,0);return true;' href='http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=242546&amp;jid=BBS&amp;volumeId=27&amp;issueId=01&amp;aid=242545'>The chinese room is a trick.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 27 (1):153-154. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20is%20a%20trick+author%3AKugel&amp;btnG=Search'>Google</a>)</span><div id='_261_abstract' class='extra' style='font-size:12px;'>Abstract: To convince us that computers cannot have mental states, Searle (1980) imagines a âChinese roomâ that simulates a computer that âspeaksâ Chinese and asks us to find the understanding in the room. It's a trick. There is no understanding in the room, not because computers can't have it, but because the room's computer-simulation is defective. Fix it and understanding appears. Abracadabra!</div>
</div><!--entry-->

<div id='_262_entry' class='entry'><span ><span class='name'>Law, Diane</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("LAWSSF",this.href,0);return true;' href='http://citeseer.ist.psu.edu/181740.html'>Searle, subsymbolic functionalism, and synthetic intelligence.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11777053227442107038'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%2C%20subsymbolic%20functionalism%2C%20and%20synthetic%20intelligence+author%3ALaw&amp;btnG=Search'>Google</a> | <a href='javascript:show("_262_links")'>More links</a>)</span>
<div id='_262_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAWSSF",this.href,0);return true;' href="http://nn.cs.utexas.edu/downloads/papers/law.synthetic.pdf">http://nn.cs.utexas.edu/downloads/papers/law.synthetic.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAWSSF",this.href,0);return true;' href="http://nn.cs.utexas.edu/downloads/papers/law.synthetic.ps.gz">http://nn.cs.utexas.edu/downloads/papers/law.synthetic.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAWSSF",this.href,0);return true;' href="http://www.cs.utexas.edu/users/nn/downloads/papers/law.synthetic.pdf">http://www.cs.utexas.edu/users/nn/downloads/papers/law.synthetic.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAWSSF",this.href,0);return true;' href="http://www.cs.utexas.edu/ftp/pub/neural-nets/papers/law.synthetic.pdf">http://www.cs.utexas.edu/ftp/pub/neural-nets/papers/law.synthetic.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAWSSF",this.href,0);return true;' href="http://www.let.rug.nl/~nerbonne/teach/neuro/kleiweg/law.synthetic.ps.gz">http://www.let.rug.nl/~nerbonne/teach/neuro/kleiweg/law.synthetic.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAWSSF",this.href,0);return true;' href="http://odur.let.rug.nl/~nerbonne/teach/neuro/kleiweg/law.synthetic.ps.gz">http://odur.let.rug.nl/~nerbonne/teach/neuro/kleiweg/law.synthetic.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAWSSF",this.href,0);return true;' href="http://historical.ncstrl.org/litesite-data/utexas_cs/UT-AI-TR-94-222.ps.Z">http://historical.ncstrl.org/litesite-data/utexas_cs/UT-AI-TR-94-222.ps.Z</a><br></div></div>
</div><!--entry-->

<div id='_263_entry' class='entry'><span ><span class='name'>Leslie, Alan M.</span> &amp; <span class='name'>Scholl, Brian J.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("LESMDA",this.href,0);return true;' href='http://www.cs.colorado.edu/~ctg/classes/lib/cogsci/scholl.pdf '>Modularity, development and 'theory of mind'.</a></span> <span class='pub_name'>Mind and Language</span> 14 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modularity%2C%20development%20and%20%27theory%20of%20mind%27+author%3ALeslie&amp;btnG=Search'>Google</a> | <a href='javascript:show("_263_links")'>More links</a>)</span><div id='_263_abstract' class='extra' style='font-size:12px;'>Abstract: Psychologists and philosophers have recently been exploring whether the mechanisms which underlie the acquisition of âtheory of mindâ (ToM) are best charac- terized as cognitive modules or as developing theories. In this paper, we attempt to clarify what a modular account of ToM entails, and why it is an attractive type of explanation. Intuitions and arguments in this debate often turn on the role of develop- ment: traditional research on ToM focuses on various developmental sequences, whereas cognitive modules are thought to be static and âanti-developmentalâ. We suggest that this mistaken view relies on an overly limited notion of modularity, and we explore how ToM might be grounded in a cognitive module and yet still afford development. Modules must âcome on-lineâ, and even fully developed modules may still develop internally, based on their constrained input. We make these points con- crete by focusing on a recent proposal to capture the development of ToM in a module via parameterization</div>
<div id='_263_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LESMDA",this.href,0);return true;' href="http://l3d.cs.colorado.edu/~ctg/classes/lib/cogsci/scholl.pdf ">http://l3d.cs.colorado.edu/~ctg/classes/lib/cogsci/scholl.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LESMDA",this.href,0);return true;' href="http://ruccs.rutgers.edu/~aleslie/99-Scholl-Leslie-MindLang.pdf">http://ruccs.rutgers.edu/~aleslie/99-Scholl-Leslie-MindLang.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LESMDA",this.href,0);return true;' href="http://ruccs.rutgers.edu/~aleslie/99-Scholl-Leslie-MindLang.pdf ">http://ruccs.rutgers.edu/~aleslie/99-Scholl-Leslie-MindLang.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LESMDA",this.href,0);return true;' href="http://www.cs.colorado.edu/~duck/ctg/classes/lib/cogsci/scholl.pdf ">http://www.cs.colorado.edu/~duck/ctg/classes/lib/cogsci/scholl.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LESMDA",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00106?favorite=add ">http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00106?favorite=add </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LESMDA",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00106">http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00106</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LESMDA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1999/00000014/00000001/art00106">http://www.ingentaconnect.com/content/bpl/mila/1999/00000014/00000001/art00106</a><br></div></div>
</div><!--entry-->

<div id='_264_entry' class='entry'><span ><span class='name'>Maloney, J. Christopher</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("MALTRS",this.href,0);return true;' href='http://www.springerlink.com/content/l1w0183h2384xg26/fulltext.pdf'>The right stuff.</a></span> <span class='pub_name'>Synthese</span> 70 (March):349-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13814838437138585065'>Cited by 13</a> | <span class='ll' onclick='$("_264_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20right%20stuff+author%3AMaloney&amp;btnG=Search'>Google</a> | <a href='javascript:show("_264_links")'>More links</a>)</span><div id='_264_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Defends Searle against all kinds of objections.</div></div>
<div id='_264_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MALTRS",this.href,0);return true;' href="http://www.springerlink.com/index/L1W0183H2384XG26.pdf">http://www.springerlink.com/index/L1W0183H2384XG26.pdf</a><br></div></div>
</div><!--entry-->

<div id='_265_entry' class='entry'><span ><span class='name'>McCarthy, John</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("MCCJSC",this.href,0);return true;' href='http://www-formal.stanford.edu/jmc/chinese.html'>John Searle's chinese room argument.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=John%20Searle%27s%20chinese%20room%20argument+author%3AMcCarthy&amp;btnG=Search'>Google</a>)</span><div id='_265_abstract' class='extra' style='font-size:12px;'>Abstract: John Searle begins his (1990) ``Consciousness, Explanatory Inversion and Cognitive Science'' with <blockquote> ``Ten years ago in this journal I published an article (Searle, 1980a and 1980b) criticising what I call Strong<br> AI, the view that for a system to have mental states it is sufficient for the system to implement the right sort of<br> program with right inputs and outputs. Strong AI is rather easy to refute and the basic argument can be<br> summarized in one sentence: {it a system, me for example, could implement a program for understanding<br> Chinese, for example, without understanding any Chinese at all.} This idea, when developed, became<br> known as the Chinese Room Argument.'' </blockquote> The Chinese Room Argument can be refuted in one sentence</div>
</div><!--entry-->

<div id='_266_entry' class='entry'><span ><span class='name'>Melnyk, Andrew</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("MELSAA-2",this.href,0);return true;' href='http://www.springerlink.com/content/v404x74w610n4umx/fulltext.pdf'>Searle's abstract argument against strong AI.</a></span> <span class='pub_name'>Synthese</span> 108 (3):391-419. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16527602857771837283'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20abstract%20argument%20against%20strong%20AI+author%3AMelnyk&amp;btnG=Search'>Google</a> | <a href='javascript:show("_266_links")'>More links</a>)</span><div id='_266_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Discussion of Searle's case against strong AI has usually focused upon his Chinese Room thought-experiment. In this paper, however, I expound and then try to refute what I call his abstract argument against strong AI, an argument which turns upon quite general considerations concerning programs, syntax, and semantics, and which seems not to depend on intuitions about the Chinese Room. I claim that this argument fails, since it assumes one particular account of what a program is. I suggest an alternative account which, however, cannot play a role in a Searle-type argument, and argue that Searle gives no good reason for favoring his account, which allows the abstract argument to work, over the alternative, which doesn't. This response to Searle's abstract argument also, incidentally, enables the Robot Reply to the Chinese Room to defend itself against objections Searle makes to it</div>
<div id='_266_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MELSAA-2",this.href,0);return true;' href="http://www.springerlink.com/index/V404X74W610N4UMX.pdf">http://www.springerlink.com/index/V404X74W610N4UMX.pdf</a><br></div></div>
</div><!--entry-->

<div id='_267_entry' class='entry'><span ><span class='name'>Mitchell, Ethan</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("MITTRC",this.href,0);return true;' href='http://www.philica.com/display_article.php?article_id=125'>The real Chinese Room.</a></span> <span class='pub_name'>Philica</span> 125. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20real%20Chinese%20Room+author%3AMitchell&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_268_entry' class='entry'><span ><span class='name'>Moor, James H.</span> (1988). The pseudorealization fallacy and the chinese room argument.</span> In James H. Fetzer (ed.), <em>Aspects of AI</em>. D. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10105002502633564371'>Cited by 5</a> | <span class='ll' onclick='$("_268_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20pseudorealization%20fallacy%20and%20the%20chinese%20room%20argument+author%3AMoor&amp;btnG=Search'>Google</a>)</span><div id='_268_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Computational systems must also meet performance criteria.</div></div>
</div><!--entry-->

<div id='_269_entry' class='entry'><span ><span class='name'>Moural, Josef</span> (2003). The chinese room argument.</span> In <em>John Searle</em>. Cambridge: Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5640882494000613252'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20argument+author%3AMoural&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_270_entry' class='entry'><span ><span class='name'>Narayanan, Ajit</span> (1991). The chinese room argument.</span> In <em>Logical Foundations</em>. New York: St Martin's Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20argument+author%3ANarayanan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_271_entry' class='entry'><span ><span class='name'>Newton, Natika</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("NEWMUA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793919346~fulltext=713240930'>Machine understanding and the chinese room.</a></span> <span class='pub_name'>Philosophical Psychology</span> 2 (2):207-15. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17913334607431078773'>Cited by 2</a> | <span class='ll' onclick='$("_271_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20understanding%20and%20the%20chinese%20room+author%3ANewton&amp;btnG=Search'>Google</a>)</span><div id='_271_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A program can possess intentionality, even if not consciousness.</div></div><div id='_271_abstract' class='extra' style='font-size:12px;'>Abstract: John Searle has argued that one can imagine embodying a machine running any computer program without understanding the symbols, and hence that purely computational processes do not yield understanding. The disagreement this argument has generated stems, I hold, from ambiguity in talk of 'understanding'. The concept is analysed as a relation between subjects and symbols having two components: a formal and an intentional. The central question, then becomes whether a machine could possess the intentional component with or without the formal component. I argue that the intentional state of a symbol's being meaningful to a subject is a functionally definable relation between the symbol and certain past and present states of the subject, and that a machine could bear this relation to a symbol. I sketch a machine which could be said to possess, in primitive form, the intentional component of understanding. Even if the machine, in lacking consciousness, lacks full understanding, it contributes to a theory of understanding and constitutes a counterexample to the Chinese Room argument</div>
</div><!--entry-->

<div id='_272_entry' class='entry'><span ><span class='name'>Obermeier, K. K.</span> (1983). <a rel="nofollow" class='article_title' onclick='trackclick("OBEWOL",this.href,0);return true;' href='http://www.springerlink.com/content/r725636t3l54x366/fulltext.pdf'>Wittgenstein on language and artificial intelligence: The chinese-room thought-experiment revisited.</a></span> <span class='pub_name'>Synthese</span> 56 (September):339-50. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10658357509622459340'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Wittgenstein%20on%20language%20and%20artificial%20intelligence+author%3AObermeier&amp;btnG=Search'>Google</a> | <a href='javascript:show("_272_links")'>More links</a>)</span>
<div id='_272_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBEWOL",this.href,0);return true;' href="http://www.springerlink.com/index/R725636T3L54X366.pdf">http://www.springerlink.com/index/R725636T3L54X366.pdf</a><br></div></div>
</div><!--entry-->

<div id='_273_entry' class='entry'><span ><span class='name'>Penrose, Roger</span> (2003). Consciousness, computation, and the chinese room.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2722318680184370481'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%2C%20computation%2C%20and%20the%20chinese%20room+author%3APenrose&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_274_entry' class='entry'><span ><span class='name'>Pfeifer, Karl</span> (1992). Searle, strong, and two ways of sorting cucumbers.</span> <span class='pub_name'>Journal of Philosophical Research</span> 17:347-50. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8128898754763167854'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%2C%20strong%2C%20and%20two%20ways%20of%20sorting%20cucumbers+author%3APfeifer&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_275_entry' class='entry'><span ><span class='name'>Preston, John M.</span> &amp; <span class='name'>Bishop, Michael A.</span> (eds.) (2002). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("PREVIT",this.href,0);return true;' href='http://books.google.com/books?id=0V6PwUrH2aYC&amp;printsec=front_cover'>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence.</a></span></em></span> Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4320502136809945437'>Cited by 21</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Views%20Into%20the%20Chinese%20Room+author%3APreston&amp;btnG=Search'>Google</a>)</span><div id='_275_abstract' class='extra' style='font-size:12px;'>Abstract: The most famous challenge to computational cognitive science and artificial intelligence is the philosopher John Searle&#39;s &quot;Chinese Room&quot; argument.</div>
</div><!--entry-->

<div id='_276_entry' class='entry'><span ><span class='name'>Proudfoot, Diane</span> (2003). Wittgenstein's anticipation of the chinese room.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Wittgenstein%27s%20anticipation%20of%20the%20chinese%20room+author%3AProudfoot&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_277_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("RAPHHK",this.href,0);return true;' href='http://www.cse.buffalo.edu/~rapaport/Papers/helenkeller.pdf'>How Helen Keller used syntactic semantics to escape from a chinese room.</a></span> <span class='pub_name'>Minds and Machines</span> 16 (4). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20Helen%20Keller%20used%20syntactic%20semantics%20to%20escape%20from%20a%20chinese%20room+author%3ARapaport&amp;btnG=Search'>Google</a> | <a href='javascript:show("_277_links")'>More links</a>)</span><div id='_277_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â A computer can come to understand natural language the same way Helen Keller did: by using âsyntactic semanticsââa theory of how syntax can suffice for semantics, i.e., how semantics for natural language can be provided by means of computational symbol manipulation. This essay considers real-life approximations of Chinese Rooms, focusing on Helen Kellerâs experiences growing up deaf and blind, locked in a sort of Chinese Room yet learning how to communicate with the outside world. Using the SNePS computational knowledge-representation system, the essay analyzes Kellerâs belief that learning that âeverything has a nameâ was the key to her success, enabling her to âpartitionâ her mental concepts into mental representations of: words, objects, and the naming relations between them. It next looks at Herbert Terraceâs theory of naming, which is akin to Kellerâs, and which only humans are supposed to be capable of. The essay suggests that computers at least, and perhaps non-human primates, are also capable of this kind of naming</div>
<div id='_277_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPHHK",this.href,0);return true;' href="http://www.springerlink.com/content/601p84g288756774/fulltext.pdf">http://www.springerlink.com/content/601p84g288756774/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_278_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (1984). <a rel="nofollow" class='article_title' onclick='trackclick("RAPSEW",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8248(198606)53:2&lt;271:SEWT&gt;2.0.CO;2-5'>Searle's experiments with thought.</a></span> <span class='pub_name'>Philosophy of Science</span> 53 (June):271-9. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17484036473242208103'>Cited by 14</a> | <span class='ll' onclick='$("_278_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20experiments%20with%20thought+author%3ARapaport&amp;btnG=Search'>Google</a> | <a href='javascript:show("_278_links")'>More links</a>)</span><div id='_278_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Comments on Cole, and some general material on syntax and semantics.</div></div>
<div id='_278_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPSEW",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8248(198606)53:2&lt;271:SEWT&gt;2.0.CO;2-5">http://www.jstor.org/sici?sici=0031-8248(198606)53:2<271:SEWT>2.0.CO;2-5</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPSEW",this.href,0);return true;' href="http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/289312">http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/289312</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPSEW",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/187697.pdf">http://www.jstor.org/stable/pdfplus/187697.pdf</a><br></div></div>
</div><!--entry-->

<div id='_279_entry' class='entry'><span ><span class='name'>Rey, Georges</span> (2003). Searle's misunderstandings of functionalism and strong AI.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20misunderstandings%20of%20functionalism%20and%20strong%20AI+author%3ARey&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_280_entry' class='entry'><span ><span class='name'>Rey, Georges</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("REYWRG",this.href,0);return true;' href='http://www.springerlink.com/content/p4j2378205330137/fulltext.pdf'>What's really going on in Searle's 'chinese room'.</a></span> <span class='pub_name'>Philosophical Studies</span> 50 (September):169-85. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14643785515627964330'>Cited by 17</a> | <span class='ll' onclick='$("_280_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%27s%20really%20going%20on%20in%20Searle%27s%20%27chinese%20room%27+author%3ARey&amp;btnG=Search'>Google</a> | <a href='javascript:show("_280_links")'>More links</a>)</span><div id='_280_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Recommends the systems reply, and a causal account of semantics. Discusses the relevance of wide and narrow notions of content, and the tension between Searle's positive and negative proposals.</div></div>
<div id='_280_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("REYWRG",this.href,0);return true;' href="http://www.springerlink.com/index/P4J2378205330137.pdf">http://www.springerlink.com/index/P4J2378205330137.pdf</a><br></div></div>
</div><!--entry-->

<div id='_281_entry' class='entry'><span ><span class='name'>Roberts, Lawrence D.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("ROBSEO",this.href,0);return true;' href='http://www.informaworld.com/index/777913234.pdf'>Searle's extension of the chinese room to connectionist machines.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 2:185-7. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8348360413984789476'>Cited by 4</a> | <span class='ll' onclick='$("_281_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%27s%20extension%20of%20the%20chinese%20room%20to%20connectionist%20machines+author%3ARoberts&amp;btnG=Search'>Google</a>)</span><div id='_281_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>In arguing against the relevance of the serial/parallel distinction to mental states, Searle becomes a formalist. A nice point.</div></div>
</div><!--entry-->

<div id='_282_entry' class='entry'><span ><span class='name'>Rodych, Victor</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("RODSFO",this.href,0);return true;' href='http://www.springerlink.com/content/h82mp6r2l10h0745/fulltext.pdf'>Searle Freed of every flaw.</a></span> <span class='pub_name'>Acta Analytica</span> 18 (30-31):161-175. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%20Freed%20of%20every%20flaw+author%3ARodych&amp;btnG=Search'>Google</a> | <a href='javascript:show("_282_links")'>More links</a>)</span><div id='_282_abstract' class='extra' style='font-size:12px;'>Abstract: Strong Al presupposes (1) that Super-Searle (henceforth âSearleâ) comes to know that the symbols he manipulates are meaningful , and (2) that there cannot be two or more semantical interpretations for the system of symbols that Searle manipulates such that the set of rules constitutes a language comprehension program for each interpretation. In this paper, I show that Strong Al is false and that presupposition #1 is false, on the assumption that presupposition #2 is true. The main argument of the paper constructs a second program, isomorphic to Searleâs, to show that if someone, say Dan, runs this isomorphic program, he cannot possibly come to know what its mentioned symbols mean because they do not mean anything to anybody. Since Dan and Searle do exactly the same thing, except that the symbols they manipulate are different, neither Dan nor Searle can possibly know whether the symbols they manipulate are meaningful (let alone what they mean, if they are meaningful). The remainder of the paper responds to an anticipated Strong Al rejoinder, which, I believe, is a necessary extension of Strong Al</div>
<div id='_282_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RODSFO",this.href,0);return true;' href="http://transactionpub.metapress.com/index/H82MP6R2L10H0745.pdf">http://transactionpub.metapress.com/index/H82MP6R2L10H0745.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RODSFO",this.href,0);return true;' href="http://www.springerlink.com/index/H82MP6R2L10H0745.pdf">http://www.springerlink.com/index/H82MP6R2L10H0745.pdf</a><br></div></div>
</div><!--entry-->

<div id='_283_entry' class='entry'><span ><span class='name'>Russow, L-M.</span> (1984). Unlocking the chinese room.</span> <span class='pub_name'>Nature and System</span> 6 (December):221-8. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12006477542440201392'>Cited by 4</a> | <span class='ll' onclick='$("_283_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Unlocking%20the%20chinese%20room+author%3ARussow&amp;btnG=Search'>Google</a>)</span><div id='_283_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Searle's presence in the room destroys the integrity of the system, so that it is no longer a proper implementation of the program.</div></div>
</div><!--entry-->

<div id='_284_entry' class='entry'><span ><span class='name'>Searle, John R.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("SEAITB",this.href,0);return true;' href='http://www.osti.gov/energycitations/product.biblio.jsp?osti_id=5305098'>Is the brain's mind a computer program?</a></span> <span class='pub_name'>Scientific American</span> 262 (1):26-31. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5930569329536421779'>Cited by 178</a> | <span class='ll' onclick='$("_284_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20the%20brain%27s%20mind%20a%20computer%20program%3F+author%3ASearle&amp;btnG=Search'>Google</a> | <a href='javascript:show("_284_links")'>More links</a>)</span><div id='_284_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the status of the Chinese Room argument, ten years on.</div></div>
<div id='_284_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAITB",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=hQCzOmaGeVYC&amp;oi=fnd&amp;pg=PA264&amp;ots=j6aih-FnAo&amp;sig=S9z08wWdwwt3psKgZPsRfS-1bXE">http://books.google.com/books?hl=en&lr=&id=hQCzOmaGeVYC&oi=fnd&pg=PA264&ots=j6aih-FnAo&sig=S9z08wWdwwt3psKgZPsRfS-1bXE</a><br></div></div>
</div><!--entry-->

<div id='_285_entry' class='entry'><span ><span class='name'>Searle, John R.</span> (1987). Minds and brains without programs.</span> In Colin Blakemore (ed.), <em>Mindwaves</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9307036590716437453'>Cited by 27</a> | <span class='ll' onclick='$("_285_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%20and%20brains%20without%20programs+author%3ASearle&amp;btnG=Search'>Google</a>)</span><div id='_285_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>More on the arguments against AI, e.g. the Chinese room and considerations about syntax and semantics. Mind is a high-level physical property of brain.</div></div>
</div><!--entry-->

<div id='_286_entry' class='entry'><span ><span class='name'>Searle, John R.</span> (1980). <a rel="nofollow" class='article_title' onclick='trackclick("SEAMBA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=42463'>Minds, brains and programs.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 3:417-57. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4721814261581197628'>Cited by 1532</a> | <span class='ll' onclick='$("_286_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20brains%20and%20programs+author%3ASearle&amp;btnG=Search'>Google</a> | <a href='javascript:show("_286_links")'>More links</a>)</span><div id='_286_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Implementing a program is not sufficient for mentality, as someone could e.g. implement a "Chinese-speaking" program without understanding Chinese. So strong AI is false, and no program is sufficient for consciousness.</div></div><div id='_286_abstract' class='extra' style='font-size:12px;'>Abstract: What psychological and philosophical significance should we attach to recent efforts at computer simulations of human cognitive capacities? In answering this question, I find it useful to distinguish what I will call "strong" AI from "weak" or "cautious" AI (artificial intelligence). According to weak AI, the principal value of the computer in the study of the mind is that it gives us a very powerful tool. For example, it enables us to formulate and test hypotheses in a more rigorous and precise fashion. But according to strong AI, the computer is not merely a tool in the study of the mind; rather, the appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to..</div>
<div id='_286_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://courses.washington.edu/info300/searle.pdf">http://courses.washington.edu/info300/searle.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://pami.uwaterloo.ca/tizhoosh/docs/Searle.pdf">http://pami.uwaterloo.ca/tizhoosh/docs/Searle.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://www.ifispan.waw.pl/~rpilat/john_searle.pdf">http://www.ifispan.waw.pl/~rpilat/john_searle.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html">http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://www.bbsonline.org/Preprints/OldArchive/bbs.searle2.html">http://www.bbsonline.org/Preprints/OldArchive/bbs.searle2.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html">http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdcPQ709B&amp;sig=IAV-tI3UMUrdII-jhXVCiE5EiNY">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdcPQ709B&sig=IAV-tI3UMUrdII-jhXVCiE5EiNY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dLmgQW13bB&amp;sig=e696dd_RJUp-z7nJq_VUVkJ6Vco">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dLmgQW13bB&sig=e696dd_RJUp-z7nJq_VUVkJ6Vco</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdgLT5-bF&amp;sig=WhrAW9GsnXpijAGLjoTnMSl83U4">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdgLT5-bF&sig=WhrAW9GsnXpijAGLjoTnMSl83U4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdeTS616J&amp;sig=Gup1URzClmw94-tEdiKkRv8oo_E">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdeTS616J&sig=Gup1URzClmw94-tEdiKkRv8oo_E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdfPT1-fI&amp;sig=NuhA3CnAPDnsWqo8Ta8-RX2cCEY">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdfPT1-fI&sig=NuhA3CnAPDnsWqo8Ta8-RX2cCEY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dLmgLS63cA&amp;sig=lNvUnhfC6Xi8TMG19ynGzF7-UrE">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dLmgLS63cA&sig=lNvUnhfC6Xi8TMG19ynGzF7-UrE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdeNS1ZcF&amp;sig=6EzNiu7H_1bXLA0zJ16b39NuIVQ">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdeNS1ZcF&sig=6EzNiu7H_1bXLA0zJ16b39NuIVQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdiPV7_dJ&amp;sig=xzN-ebbJvEML3FULifpKsvbJ4B0">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdiPV7_dJ&sig=xzN-ebbJvEML3FULifpKsvbJ4B0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dLmgOW03aF&amp;sig=v25MYgLHP7PRb5D3u6V0j21p3Os">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dLmgOW03aF&sig=v25MYgLHP7PRb5D3u6V0j21p3Os</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdhTV4ZdG&amp;sig=_xvxtHTY2CziSv0BQSRuTeAcVyE">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdhTV4ZdG&sig=_xvxtHTY2CziSv0BQSRuTeAcVyE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMddRR63eF&amp;sig=LYLLmE8CSwbq9blXRhOQWNiQKBo">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMddRR63eF&sig=LYLLmE8CSwbq9blXRhOQWNiQKBo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMddLR2XfE&amp;sig=hPqWXhv4YdFnGCjtMhQpRctFDz8">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMddLR2XfE&sig=hPqWXhv4YdFnGCjtMhQpRctFDz8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdgRU01eJ&amp;sig=PuxfSwx103nfQfLP8luU4Z-hgSc">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdgRU01eJ&sig=PuxfSwx103nfQfLP8luU4Z-hgSc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEAMBA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=CEMYUU_HFMAC&amp;oi=fnd&amp;pg=PA201&amp;ots=dMdhNV0_7I&amp;sig=JxSMo440evbsIv2dv4QpEJVAC4A">http://books.google.com/books?hl=en&lr=&id=CEMYUU_HFMAC&oi=fnd&pg=PA201&ots=dMdhNV0_7I&sig=JxSMo440evbsIv2dv4QpEJVAC4A</a><br></div></div>
</div><!--entry-->

<div id='_287_entry' class='entry'><span ><span class='name'>Searle, John R.</span> (1984). <em><span class='pub_name'>Minds, Brains and Science.</span></em></span> Harvard University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13447460711936408561'>Cited by 515</a> | <span class='ll' onclick='$("_287_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20Brains%20and%20Science+author%3ASearle&amp;btnG=Search'>Google</a>)</span><div id='_287_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Axiomatizes the argument: Syntax isn't sufficient for semantics, programs are syntactic, minds are semantic, so no program is sufficient for mind.</div></div>
</div><!--entry-->

<div id='_288_entry' class='entry'><span ><span class='name'>Searle, John R.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("SEARTJ",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8205(198906)49:4&lt;701:RTJ&gt;2.0.CO;2-Y'>Reply to Jacquette.</a></span> <span class='pub_name'>Philosophy and Phenomenological Research</span> 49 (4):701-8. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8975316544102035365'>Cited by 4</a> | <span class='ll' onclick='$("_288_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reply%20to%20Jacquette+author%3ASearle&amp;btnG=Search'>Google</a> | <a href='javascript:show("_288_links")'>More links</a>)</span><div id='_288_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Jacquette misses the point of the argument. Also, biological and abstract intentionality are quite compatible.</div></div>
<div id='_288_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEARTJ",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8205(198906)49:4&lt;701:RTJ&gt;2.0.CO;2-Y">http://www.jstor.org/sici?sici=0031-8205(198906)49:4<701:RTJ>2.0.CO;2-Y</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SEARTJ",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2107856.pdf">http://www.jstor.org/stable/pdfplus/2107856.pdf</a><br></div></div>
</div><!--entry-->

<div id='_289_entry' class='entry'><span ><span class='name'>Searle, John R.</span> (1989). Reply to Jacquette's adventures in the chinese room.</span> <span class='pub_name'>Philosophy and Phenomenological Research</span> 49 (June):701-707. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reply%20to%20Jacquette%27s%20adventures%20in%20the%20chinese%20room+author%3ASearle&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_290_entry' class='entry'><span ><span class='name'>Searle, John R.</span> (2002). Twenty-one years in the chinese room.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6734266705724442637'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Twenty-one%20years%20in%20the%20chinese%20room+author%3ASearle&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_291_entry' class='entry'><span ><span class='name'>Seidel, Asher</span> (1989). Chinese rooms a, B and C.</span> <span class='pub_name'>Pacific Philosophical Quarterly</span> 20 (June):167-73. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4008427045732399513'>Cited by 1</a> | <span class='ll' onclick='$("_291_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Chinese%20rooms%20a%2C%20B%20and%20C+author%3ASeidel&amp;btnG=Search'>Google</a>)</span><div id='_291_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A person running the program, with interpretations at hand, would understand. Point-missing.</div></div>
</div><!--entry-->

<div id='_292_entry' class='entry'><span ><span class='name'>Seidel, Asher</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("SEISOT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(198801)48:1&lt;26:SOTBBO&gt;2.0.CO;2-E'>Searle on the biological basis of cognition.</a></span> <span class='pub_name'>Analysis</span> 48 (January):26-28. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%20on%20the%20biological%20basis%20of%20cognition+author%3ASeidel&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_293_entry' class='entry'><span ><span class='name'>Shaffer, Michael J.</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("SHAALH",this.href,0);return true;' href='http://www.springerlink.com/content/q482p7054700q742/fulltext.pdf'>A logical hole in the chinese room.</a></span> <span class='pub_name'>Minds and Machines</span> 19 (2):229-235. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20logical%20hole%20in%20the%20chinese%20room+author%3AShaffer&amp;btnG=Search'>Google</a>)</span><div id='_293_abstract' class='extra' style='font-size:12px;'>Abstract: Searleâs Chinese Room Argument (CRA) has been the object of great interest in the philosophy of mind, artificial intelligence and cognitive science since its initial presentation in âMinds, Brains and Programsâ in 1980. It is by no means an overstatement to assert that it has been a main focus of attention for philosophers and computer scientists of many stripes. It is then especially interesting to note that relatively little has been said about the detailed logic of the argument, whatever significance Searle intended CRA to have. The problem with the CRA is that it involves a very strong modal claim, the truth of which is both unproved and highly questionable. So it will be argued here that the CRA does not prove what it was intended to prove</div>
</div><!--entry-->

<div id='_294_entry' class='entry'><span ><span class='name'>Sharvy, Richard</span> (1985). Searle on programs and intentionality.</span> <span class='pub_name'>Canadian Journal of Philosophy</span> 11:39-54. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_294_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%20on%20programs%20and%20intentionality+author%3ASharvy&amp;btnG=Search'>Google</a>)</span><div id='_294_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues against Searle, but misses the point for the most part.</div></div>
</div><!--entry-->

<div id='_295_entry' class='entry'><span ><span class='name'>Simon, Herbert A.</span> &amp; <span class='name'>Eisenstadt, Stuart A.</span> (2003). A chinese room that understands.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17908113736747703762'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20chinese%20room%20that%20understands+author%3ASimon&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_296_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("SLODSA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=26560'>Did Searle attack strong strong AI or weak strong AI?</a></span> In <em>Artificial Intelligence and its Applications</em>. Chichester. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4717426363542322623'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Did%20Searle%20attack%20strong%20strong%20AI%20or%20weak%20strong%20AI%3F+author%3ASloman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_296_links")'>More links</a>)</span>
<div id='_296_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLODSA",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/cogaff/sloman.searle.85.text">http://www.cs.bham.ac.uk/research/cogaff/sloman.searle.85.text</a><br></div></div>
</div><!--entry-->

<div id='_297_entry' class='entry'><span ><span class='name'>Sprevak, Mark D.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("SPRAAT",this.href,0);return true;' href='http://users.ox.ac.uk/~gradconf/Selected_papers(PROGRAM2)/Algorithms_and_the_chinese.rtf'>Algorithms and the chinese room.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Algorithms%20and%20the%20chinese%20room+author%3ASprevak&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_298_entry' class='entry'><span ><span class='name'>Suits, David B.</span> (1989). Out of the chinese room.</span> <span class='pub_name'>Computing and Philosophy Newsletter</span> 4:1-7. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7191733891242203915'>Cited by 2</a> | <span class='ll' onclick='$("_298_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Out%20of%20the%20chinese%20room+author%3ASuits&amp;btnG=Search'>Google</a>)</span><div id='_298_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Story about homunculi within homunculi. Fun.</div></div>
</div><!--entry-->

<div id='_299_entry' class='entry'><span ><span class='name'>Tanaka, Koji</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("TANMPA",this.href,0);return true;' href='http://www.springerlink.com/content/w5020557682u6247/fulltext.pdf'>Minds, programs, and chinese philosophers: A chinese perspective on the chinese room.</a></span> <span class='pub_name'>Sophia</span> 43 (1):61-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20programs%2C%20and%20chinese%20philosophers+author%3ATanaka&amp;btnG=Search'>Google</a>)</span><div id='_299_abstract' class='extra' style='font-size:12px;'>Abstract:  The paper is concerned with John Searleâs famous Chinese room argument. Despite being objected to by some, Searleâs Chinese room argument appears very appealing. This is because Searleâs argument is based on an intuition about the mind that âweâ all seem to share. Ironically, however, Chinese philosophers donât seem to share this same intuition. The paper begins by first analysing Searleâs Chinee room argument. It then introduces what can be seen as the (implicit) Chinese view of the mind. Lastly, it demonstrates a conceptual difference between Chinese and Western philosophy with respect to the notion of mind. Thus, it is shown that one must carefully attend to the presuppositions underlying Chinese philosophising in interpreting Chinese philosophers</div>
</div><!--entry-->

<div id='_300_entry' class='entry'><span ><span class='name'>Taylor, John G.</span> (2003). Do virtual actions avoid the chinese room?</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11472296823905851425'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Do%20virtual%20actions%20avoid%20the%20chinese%20room%3F+author%3ATaylor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_301_entry' class='entry'><span ><span class='name'>Teng, Norman Y.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("TENACA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a713690443~fulltext=713240930'>A cognitive analysis of the chinese room argument.</a></span> <span class='pub_name'>Philosophical Psychology</span> 13 (3):313-24. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14595594244568114984'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20cognitive%20analysis%20of%20the%20chinese%20room%20argument+author%3ATeng&amp;btnG=Search'>Google</a> | <a href='javascript:show("_301_links")'>More links</a>)</span><div id='_301_abstract' class='extra' style='font-size:12px;'>Abstract: Searle's Chinese room argument is analyzed from a cognitive point of view. The analysis is based on a newly developed model of conceptual integration, the many space model proposed by Fauconnier and Turner. The main point of the analysis is that the central inference constructed in the Chinese room scenario is a result of a dynamic, cognitive activity of conceptual blending, with metaphor defining the basic features of the blending. Two important consequences follow: (1) Searle's recent contention that syntax is not intrinsic to physics turns out to be a slightly modified version of the old Chinese room argument; and (2) the argument itself is still open to debate. It is persuasive but not conclusive, and at bottom it is a topological mismatch in the metaphoric conceptual integration that is responsible for the non-conclusive character of the Chinese room argument</div>
<div id='_301_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TENACA",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/PAHW8YBYRV4EF93P.pdf">http://taylorandfrancis.metapress.com/index/PAHW8YBYRV4EF93P.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TENACA",this.href,0);return true;' href="http://www.informaworld.com/index/PAHW8YBYRV4EF93P.pdf">http://www.informaworld.com/index/PAHW8YBYRV4EF93P.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TENACA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000003/art00003">http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000003/art00003</a><br></div></div>
</div><!--entry-->

<div id='_302_entry' class='entry'><span ><span class='name'>Thagard, Paul R.</span> (1986). The emergence of meaning: An escape from Searle's chinese room.</span> <span class='pub_name'>Behaviorism</span> 14 (3):139-46. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11544884316346518064'>Cited by 5</a> | <span class='ll' onclick='$("_302_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20emergence%20of%20meaning+author%3AThagard&amp;btnG=Search'>Google</a>)</span><div id='_302_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Get semantics computationally via induction and functional roles.</div></div>
</div><!--entry-->

<div id='_303_entry' class='entry'><span ><span class='name'>Wakefield, Jerome C.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("WAKTCR",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=641443'>The chinese room argument reconsidered: Essentialism, indeterminacy, and strong AI.</a></span> <span class='pub_name'>Minds and Machines</span> 13 (2):285-319. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1697274773412748414'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chinese%20room%20argument%20reconsidered+author%3AWakefield&amp;btnG=Search'>Google</a> | <a href='javascript:show("_303_links")'>More links</a>)</span><div id='_303_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â I argue that John Searle's (1980) influential Chinese room argument (CRA) against computationalism and strong AI survives existing objections, including Block's (1998) internalized systems reply, Fodor's (1991b) deviant causal chain reply, and Hauser's (1997) unconscious content reply. However, a new ``essentialist'' reply I construct shows that the CRA as presented by Searle is an unsound argument that relies on a question-begging appeal to intuition. My diagnosis of the CRA relies on an interpretation of computationalism as a scientific theory about the essential nature of intentional content; such theories often yield non-intuitive results in non-standard cases, and so cannot be judged by such intuitions. However, I further argue that the CRA can be transformed into a potentially valid argument against computationalism simply by reinterpreting it as an indeterminacy argument that shows that computationalism cannot explain the ordinary distinction between semantic content and sheer syntactic manipulation, and thus cannot be an adequate account of content. This conclusion admittedly rests on the arguable but plausible assumption that thought content is interestingly determinate. I conclude that the viability of computationalism and strong AI depends on their addressing the indeterminacy objection, but that it is currently unclear how this objection can be successfully addressed</div>
<div id='_303_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WAKTCR",this.href,0);return true;' href="http://www.springerlink.com/content/q76u712262711110/fulltext.pdf">http://www.springerlink.com/content/q76u712262711110/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WAKTCR",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5115346&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5115346&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WAKTCR",this.href,0);return true;' href="http://www.springerlink.com/index/Q76U712262711110.pdf">http://www.springerlink.com/index/Q76U712262711110.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WAKTCR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000002/05115346">http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000002/05115346</a><br></div></div>
</div><!--entry-->

<div id='_304_entry' class='entry'><span ><span class='name'>Warwick, Kevin</span> (2002). Alien encounters.</span> In <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford: Clarendon Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Alien%20encounters+author%3AWarwick&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_305_entry' class='entry'><span ><span class='name'>Weiss, Timothy</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("WEICTC",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-9329.1990.tb00022.x'>Closing the chinese room.</a></span> <span class='pub_name'>Ratio</span> 3 (2):165-81. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17114908371826831263'>Cited by 6</a> | <span class='ll' onclick='$("_305_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Closing%20the%20chinese%20room+author%3AWeiss&amp;btnG=Search'>Google</a> | <a href='javascript:show("_305_links")'>More links</a>)</span><div id='_305_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Searle-in-the-room isn't in a position to know about the system's first-person states. Intrinsic intentionality is an incoherent notion.</div></div>
<div id='_305_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEICTC",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119373604/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119373604/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_306_entry' class='entry'><span ><span class='name'>Wheeler, M.</span> (2003). Changes in the rules: Computers, dynamic systems, and Searle.</span> In John M. Preston &amp; Michael A. Bishop (eds.), <em>Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Changes%20in%20the%20rules+author%3AWheeler&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_307_entry' class='entry'><span ><span class='name'>Whitmer, J. M.</span> (1983). Intentionality, artificial intelligence, and the causal powers of the brain.</span> <span class='pub_name'>Auslegung</span> 10:194-210. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_307_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intentionality%2C%20artificial%20intelligence%2C%20and%20the%20causal%20powers%20of%20the%20brain+author%3AWhitmer&amp;btnG=Search'>Google</a>)</span><div id='_307_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Defending Searle's position, with remarks on the "causal powers" argument.</div></div>
</div><!--entry-->
</div>
<p><a name='.6.1d'></a><a name=''></a><span class='myh3'>6.1d Machine Consciousness</span></p>

<div id='cat_6.1d' class='cat_content'>
<div id='__new_entries_6.1d__'></div><div id='__new_entry_6.1d__' class='entry'></div>
<div id='_308_entry' class='entry'><span ><span class='name'>Tson, M. E.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("ABE",this.href,0);return true;' href='http://philpapers.org/archive/ABE'>A Brief Explanation of Consciousness.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20Brief%20Explanation%20of%20Consciousness+author%3ATson&amp;btnG=Search'>Google</a>)</span><div id='_308_abstract' class='extra' style='font-size:12px;'>Abstract: This short paper (4 pages) demonstrates how subjective experience, language, and consciousness can be explained in terms of abilities we share with the simplest of creatures, specifically the ability to detect, react to, and associate various aspects of the world.</div>
</div><!--entry-->

<div id='_309_entry' class='entry'><span ><span class='name'>Adams, William Y.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("ADAITA",this.href,0);return true;' href='http://members.bainbridge.net/~bill.adams/artificial.htm'>Intersubjective transparency and artificial consciousness.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intersubjective%20transparency%20and%20artificial%20consciousness+author%3AAdams&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_310_entry' class='entry'><span ><span class='name'>Adams, William Y.</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("ADAMCP",this.href,0);return true;' href='http://www.ingentaconnect.com/content/imp/jcs/2004/00000011/00000009/art00003'>Machine consciousness: Plausible idea or semantic distortion?</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 11 (9):46-56. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16777493185124590859'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20consciousness+author%3AAdams&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_311_entry' class='entry'><span ><span class='name'>Aleksander, Igor L.</span> &amp; <span class='name'>Dunmall, B.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("ALEAAT",this.href,0);return true;' href='http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1343'>Axioms and tests for the presence of minimal consciousness in agents I: Preamble.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4):7-18. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15430230570512869971'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Axioms%20and%20tests%20for%20the%20presence%20of%20minimal%20consciousness%20in%20agents%20I+author%3AAleksander&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_312_entry' class='entry'><span ><span class='name'>Aleksander, Igor L.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("ALEMC",this.href,0);return true;' href='http://imprint.co.uk/jcs_10_4-5.html'>Machine consciousness.</a></span> In Max Velmans &amp; Susan Schneider (eds.), <em>The Blackwell Companion to Consciousness</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18189007450924263853'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20consciousness+author%3AAleksander&amp;btnG=Search'>Google</a> | <a href='javascript:show("_312_links")'>More links</a>)</span>
<div id='_312_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALEMC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=YHGacGKyVbYC&amp;oi=fnd&amp;pg=PA99&amp;ots=SSSQPkbxBS&amp;sig=LmbDUzP5IccBZCh8TG02TqZZL28">http://books.google.com/books?hl=en&lr=&id=YHGacGKyVbYC&oi=fnd&pg=PA99&ots=SSSQPkbxBS&sig=LmbDUzP5IccBZCh8TG02TqZZL28</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALEMC",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=16186018&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=16186018&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALEMC",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;uid=16186018&amp;cmd=showdetailview&amp;indexed=google">http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&uid=16186018&cmd=showdetailview&indexed=google</a><br></div></div>
</div><!--entry-->

<div id='_313_entry' class='entry'><span ><span class='name'>Aleksander, Igor L.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("ALEMC-2",this.href,0);return true;' href='http://imprint.co.uk/jcs_10_4-5.html'>Machine consciousness.</a></span> In Steven Laureys (ed.), <em>Boundaries of Consciousness</em>. Elsevier. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18189007450924263853'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20consciousness+author%3AAleksander&amp;btnG=Search'>Google</a> | <a href='javascript:show("_313_links")'>More links</a>)</span>
<div id='_313_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALEMC-2",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=YHGacGKyVbYC&amp;oi=fnd&amp;pg=PA99&amp;ots=SSSQPkbzBY&amp;sig=dSV8_pheTWTgsxz7NiRaIDipYNs">http://books.google.com/books?hl=en&lr=&id=YHGacGKyVbYC&oi=fnd&pg=PA99&ots=SSSQPkbzBY&sig=dSV8_pheTWTgsxz7NiRaIDipYNs</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALEMC-2",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=16186018&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=16186018&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALEMC-2",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;uid=16186018&amp;cmd=showdetailview&amp;indexed=google">http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&uid=16186018&cmd=showdetailview&indexed=google</a><br></div></div>
</div><!--entry-->

<div id='_314_entry' class='entry'><span ><span class='name'>Amoroso, Richard L.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("AMOTTF",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=294062'>The theoretical foundations for engineering a conscious quantum computer.</a></span> In M. Gams, M. Paprzycki &amp; X. Wu (eds.), <em>Mind Versus Computer: Were Dreyfus and Winograd Right?</em> Amsterdam: IOS Press. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 5 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20theoretical%20foundations%20for%20engineering%20a%20conscious%20quantum%20computer+author%3AAmoroso&amp;btnG=Search'>Google</a> | <a href='javascript:show("_314_links")'>More links</a>)</span>
<div id='_314_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AMOTTF",this.href,0);return true;' href="http://www.mindspring.com/~noetic.advanced.studies/Amoroso19.pdf">http://www.mindspring.com/~noetic.advanced.studies/Amoroso19.pdf</a><br></div></div>
</div><!--entry-->

<div id='_315_entry' class='entry'><span ><span class='name'>Angel, Leonard</span> (1994). Am I a computer?</span> In Eric Dietrich (ed.), <em>Thinking Computers and Virtual Persons</em>. Academic Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Am%20I%20a%20computer%3F+author%3AAngel&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_316_entry' class='entry'><span ><span class='name'>Angel, Leonard</span> (1989). <em><span class='pub_name'>How to Build a Conscious Machine.</span></em></span> Westview Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10246836607038703514'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20to%20Build%20a%20Conscious%20Machine+author%3AAngel&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_317_entry' class='entry'><span ><span class='name'>Arrabales, R.</span> &amp; <span class='name'>Sanchis, A.</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("ARRAMC",this.href,0);return true;' href='http://dx.doi.org/10.1016/j.patrec.2007.09.002'>Applying machine consciousness models in autonomous situated agents.</a></span> <span class='pub_name'>Pattern Recognition Letters</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Applying%20machine%20consciousness%20models%20in%20autonomous%20situated%20agents+author%3AArrabales&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_318_entry' class='entry'><span ><span class='name'>Arrington, Robert L.</span> (1999). Machines, consciousness, and thought.</span> <span class='pub_name'>Idealistic Studies</span> 29 (3):231-243. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machines%2C%20consciousness%2C%20and%20thought+author%3AArrington&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_319_entry' class='entry'><span ><span class='name'>Arrabales, R.</span>; <span class='name'>Ledezma, A.</span> &amp; <span class='name'>Sanchis, A.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("ARRMCF",this.href,0);return true;' href='http://www.springerlink.com/content/268726763156562w/'>Modelling consciousness for autonomous robot exploration.</a></span> <em>Lecture Notes in Computer Science</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modelling%20consciousness%20for%20autonomous%20robot%20exploration+author%3AArrabales&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_320_entry' class='entry'><span ><span class='name'>Aydede, Murat</span> &amp; <span class='name'>Guzeldere, Guven</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("AYDCIA",this.href,0);return true;' href='http://www.informaworld.com/index/VPWRVGNM0MR1XRJ3.pdf'>Consciousness, intentionality, and intelligence: Some foundational issues for artificial intelligence.</a></span> <span class='pub_name'>Journal Of Experimental and Theoretical Artificial Intelligence</span> 12 (3):263-277. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10383985781586754812'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%2C%20intentionality%2C%20and%20intelligence+author%3AAydede&amp;btnG=Search'>Google</a> | <a href='javascript:show("_320_links")'>More links</a>)</span>
<div id='_320_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AYDCIA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/teta/2000/00000012/00000003/art00003">http://www.ingentaconnect.com/content/tandf/teta/2000/00000012/00000003/art00003</a><br></div></div>
</div><!--entry-->

<div id='_321_entry' class='entry'><span ><span class='name'>Bair, Puran K.</span> (1981). Computer metaphors for consciousness.</span> In <em>The Metaphors Of Consciousness</em>. New York: Plenum Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computer%20metaphors%20for%20consciousness+author%3ABair&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_322_entry' class='entry'><span ><span class='name'>Barnes, E.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("BARTCH",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(199106)88:6&lt;304:TCHOCA&gt;2.0.CO;2-1'>The causal history of computational activity: Maudlin and olympia.</a></span> <span class='pub_name'>Journal of Philosophy</span> 88 (6):304-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7777719769439460618'>Cited by 5</a> | <span class='ll' onclick='$("_322_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20causal%20history%20of%20computational%20activity+author%3ABarnes&amp;btnG=Search'>Google</a> | <a href='javascript:show("_322_links")'>More links</a>)</span><div id='_322_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Response to Maudlin 1989. True computation needs active, not passive causation, so Maudlin's machine isn't really computing.</div></div>
<div id='_322_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BARTCH",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(199106)88:6&lt;304:TCHOCA&gt;2.0.CO;2-1">http://www.jstor.org/sici?sici=0022-362X(199106)88:6<304:TCHOCA>2.0.CO;2-1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BARTCH",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2026687.pdf">http://www.jstor.org/stable/pdfplus/2026687.pdf</a><br></div></div>
</div><!--entry-->

<div id='_323_entry' class='entry'><span ><span class='name'>Bell, John L.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("BELAAC",this.href,0);return true;' href='http://publish.uwo.ca/~jbell/Algorithmicity and Consciousness.pdf'>Algorithmicity and consciousness.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Algorithmicity%20and%20consciousness+author%3ABell&amp;btnG=Search'>Google</a>)</span><div id='_323_abstract' class='extra' style='font-size:12px;'>Abstract: Why should one believe that conscious awareness is solely the result of organizational complexity? What is the connection between consciousness and combinatorics: transformation of quantity into quality? The claim that the former is reducible to the other seems unconvincingâas unlike as chalk and cheese! In his book1 Penrose is at least attempting to compare like with like: the enigma of consciousness with the progress of physics</div>
</div><!--entry-->

<div id='_324_entry' class='entry'><span ><span class='name'>Birnbacher, Dieter</span> (1995). Artificial consciousness.</span> In Thomas Metzinger (ed.), <em>Conscious Experience</em>. Ferdinand Schoningh. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20consciousness+author%3ABirnbacher&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_325_entry' class='entry'><span ><span class='name'>Bonzon, Pierre</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("BONCBT",this.href,0);return true;' href='http://philpapers.org/archive/BONCBT'>Conscious Behavior through Reflexive Dialogs.</a></span> In A. GÃ¼nter, R. Kruse &amp; B. Neumann (eds.), <em>Lectures Notes in Artificial Intelligence</em>. Springer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Conscious%20Behavior%20through%20Reflexive%20Dialogs+author%3ABonzon&amp;btnG=Search'>Google</a>)</span><div id='_325_abstract' class='extra' style='font-size:12px;'>Abstract: We consider the problem of executing conscious behavior i.e., of driving an agentâs actions and of allowing it, at the same time, to run concurrent processes reflecting on these actions. Toward this end, we express a single agentâs plans as reflexive dialogs in a multi-agent system defined by a virtual machine. We extend this machineâs planning language by introducing two specific operators for reflexive dialogs i.e., conscious and caught for monitoring beliefs and actions, respectively. The possibility to use the same language both to drive a machine and to establish a reflexive communication within the machine itself stands as a key feature of our model.</div>
</div><!--entry-->

<div id='_326_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("BRICHC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=216365'>Could, how could we tell if, and should - androids have inner lives?</a></span> In Kenneth M. Ford, C. Glymour &amp; Patrick Hayes (eds.), <em>Android Epistemology</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13976469920032481126'>Cited by 16</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%2C%20how%20could%20we%20tell%20if%2C%20and%20should%20-%20androids%20have%20inner%20lives%3F+author%3ABringsjord&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_327_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("BRIOBR",this.href,0);return true;' href='http://kryten.mm.rpi.edu/bringsjord.on.zlatev.pdf'>On building robot persons: Response to Zlatev.</a></span> <span class='pub_name'>Minds and Machines</span> 14 (3):381-385. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20building%20robot%20persons+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_327_links")'>More links</a>)</span><div id='_327_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Zlatev offers surprisingly weak reasoning in support of his view that robots with the right kind of developmental histories can have meaning. We ought nonetheless to praise Zlatev for an impressionistic account of how attending to the psychology of human development can help us build robots that appear to have intentionality</div>
<div id='_327_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIOBR",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=1011949.1011965">http://portal.acm.org/citation.cfm?id=1011949.1011965</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIOBR",this.href,0);return true;' href="http://www.cogs.indiana.edu/cogx/robotperson_Zlatev_response.pdf">http://www.cogs.indiana.edu/cogx/robotperson_Zlatev_response.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIOBR",this.href,0);return true;' href="http://www.springerlink.com/content/w83402573w376q55/fulltext.pdf">http://www.springerlink.com/content/w83402573w376q55/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIOBR",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5274048&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5274048&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIOBR",this.href,0);return true;' href="http://www.springerlink.com/index/W83402573W376Q55.pdf">http://www.springerlink.com/index/W83402573W376Q55.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIOBR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000003/05274048">http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000003/05274048</a><br></div></div>
</div><!--entry-->

<div id='_328_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("BRIOOB",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/jcs/2007/00000014/00000007/art00002'>Offer: One billion dollars for a conscious robot; if you're honest, you must decline.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 14 (7):28-43. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=387752126156249499'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Offer+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_328_links")'>More links</a>)</span><div id='_328_abstract' class='extra' style='font-size:12px;'>Abstract: You are offered one billion dollars to 'simply' produce a proof-of-concept robot that has phenomenal consciousness -- in fact, you can receive a deliciously large portion of the money up front, by simply starting a three-year work plan in good faith. Should you take the money and commence? No. I explain why this refusal is in order, now and into the foreseeable future</div>
<div id='_328_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIOOB",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00002">http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00002</a><br></div></div>
</div><!--entry-->

<div id='_329_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (1992). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("BRIWRC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=531168'>What Robots Can and Can't Be.</a></span></em></span> Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8943756322369026005'>Cited by 85</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20Robots%20Can%20and%20Can%27t%20Be+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_329_links")'>More links</a>)</span>
<div id='_329_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIWRC",this.href,0);return true;' href="http://www.rpi.edu/~brings/precis.wrccb.2.html">http://www.rpi.edu/~brings/precis.wrccb.2.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIWRC",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000418/">http://psycprints.ecs.soton.ac.uk/archive/00000418/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIWRC",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/perl/local/psyc/makedoc?id=418&amp;type=html">http://psycprints.ecs.soton.ac.uk/perl/local/psyc/makedoc?id=418&type=html</a><br></div></div>
</div><!--entry-->

<div id='_330_entry' class='entry'><span ><span class='name'>Brockmeier, Scott</span> (1997). Computational architecture and the creation of consciousness.</span> <span class='pub_name'>The Dualist</span> 4. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17241489871006453498'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computational%20architecture%20and%20the%20creation%20of%20consciousness+author%3ABrockmeier&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_331_entry' class='entry'><span ><span class='name'>Brown, Geoffrey</span> (1989). <em><span class='pub_name'>Minds, Brains And Machines.</span></em></span> St Martin's Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12639082683711530570'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20Brains%20And%20Machines+author%3ABrown&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_332_entry' class='entry'><span ><span class='name'>Buttazzo, G.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("BUTACU",this.href,0);return true;' href='http://ict.udlap.mx/people/anibal/r7024.pdf'>Artificial consciousness: Utopia or real possibility?</a></span> <span class='pub_name'>Computer</span> 34:24-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2912605416639859362'>Cited by 17</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20consciousness+author%3AButtazzo&amp;btnG=Search'>Google</a> | <a href='javascript:show("_332_links")'>More links</a>)</span>
<div id='_332_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTACU",this.href,0);return true;' href="http://feanor.sssup.it/~giorgio/paps/2001/ieeecm01.pdf">http://feanor.sssup.it/~giorgio/paps/2001/ieeecm01.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTACU",this.href,0);return true;' href="http://csdl.computer.org/comp/mags/co/2001/07/r7024abs.htm">http://csdl.computer.org/comp/mags/co/2001/07/r7024abs.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTACU",this.href,0);return true;' href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=933500">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=933500</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTACU",this.href,0);return true;' href="http://www.das.ufsc.br/~rabelo/Ensino/DAS6607/Artigos-Gerais/ArtificialConsciousness.pdf">http://www.das.ufsc.br/~rabelo/Ensino/DAS6607/Artigos-Gerais/ArtificialConsciousness.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTACU",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=20061053096677MT&amp;recid=20061090133720CI&amp;recid=20061023229829EA">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=20061053096677MT&recid=20061090133720CI&recid=20061023229829EA</a><br></div></div>
</div><!--entry-->

<div id='_333_entry' class='entry'><span ><span class='name'>Caplain, G.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("CAPICA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=294029.294067'>Is consciousness a computational property?</a></span> <span class='pub_name'>Informatica</span> 19:615-19. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12915758302902689456'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20consciousness%20a%20computational%20property%3F+author%3ACaplain&amp;btnG=Search'>Google</a> | <a href='javascript:show("_333_links")'>More links</a>)</span>
<div id='_333_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAPICA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=VHZy4j_Qa-cC&amp;oi=fnd&amp;pg=PA190&amp;ots=RjBGledukl&amp;sig=Oa-FArSWce_2jXSLqmlPHTdqlZc">http://books.google.com/books?hl=en&lr=&id=VHZy4j_Qa-cC&oi=fnd&pg=PA190&ots=RjBGledukl&sig=Oa-FArSWce_2jXSLqmlPHTdqlZc</a><br></div></div>
</div><!--entry-->

<div id='_334_entry' class='entry'><span ><span class='name'>Caws, Peter</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("CAWSIT",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-5914.1988.tb00128.x'>Subjectivity in the machine.</a></span> <span class='pub_name'>Journal for the Theory of Social Behaviour</span> 18 (September):291-308. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Subjectivity%20in%20the%20machine+author%3ACaws&amp;btnG=Search'>Google</a> | <a href='javascript:show("_334_links")'>More links</a>)</span>
<div id='_334_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAWSIT",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120012886/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120012886/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_335_entry' class='entry'><span ><span class='name'>Chandler, Keith A.</span> (2002). Artificial intelligence and artificial consciousness.</span> <span class='pub_name'>Philosophia</span> 31 (1):32-46. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence%20and%20artificial%20consciousness+author%3AChandler&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_336_entry' class='entry'><span ><span class='name'>Chella, Antonio</span> &amp; <span class='name'>Manzotti, Riccardo</span> (2007). <em><span class='pub_name'>Artificial Consciousness.</span></em></span> Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 1 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Consciousness+author%3AChella&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_337_entry' class='entry'><span ><span class='name'>Cherry, Christopher</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("CHERPO",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a794256895~fulltext=713240930'>Reply--the possibility of computers becoming persons: A response to Dolby.</a></span> <span class='pub_name'>Social Epistemology</span> 3 (4):337-348. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reply--the%20possibility%20of%20computers%20becoming%20persons+author%3ACherry&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_338_entry' class='entry'><span ><span class='name'>Clack, Robert J.</span> (1968). The myth of the conscious robot.</span> <span class='pub_name'>Personalist</span> 49:351-369. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20myth%20of%20the%20conscious%20robot+author%3AClack&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_339_entry' class='entry'><span ><span class='name'>Coles, L. S.</span> (1993). Engineering machine consciousness.</span> <span class='pub_name'>AI Expert</span> 8:34-41. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Engineering%20machine%20consciousness+author%3AColes&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_340_entry' class='entry'><span ><span class='name'>Cotterill, Rodney M. J.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("COTCAS",this.href,0);return true;' href='http://forskningsbasen.deff.dk/ddf/rec.external?id=dtu22502'>Cyberchild: A simulation test-bed for consciousness studies.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4):31-45. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5379397949626086408'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cyberchild+author%3ACotterill&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_341_entry' class='entry'><span ><span class='name'>Danto, Arthur C.</span> (1960). On consciousness in machines.</span> In Sidney Hook (ed.), <em>Dimensions of Mind</em>. New York University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17058958398334415614'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20consciousness%20in%20machines+author%3ADanto&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_342_entry' class='entry'><span ><span class='name'>D'Aquili, Eugene G.</span> &amp; <span class='name'>Newberg, Andrew B.</span> (1996). Consciousness and the machine.</span> <span class='pub_name'>Zygon</span> 31 (2):235-52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5053512421926096741'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20and%20the%20machine+author%3AD%27Aquili&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_343_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("DENCIH-2",this.href,0);return true;' href='http://cogprints.org/429/'>Consciousness in Human and Robot Minds.</a></span> In M. Ito, Y. Miyashita &amp; Edmund T. Rolls (eds.), <em>Cognition, Computation and Consciousness</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6671031696801665966'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20in%20Human%20and%20Robot%20Minds+author%3ADennett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_343_links")'>More links</a>)</span><div id='_343_abstract' class='extra' style='font-size:12px;'>Abstract: The best reason for believing that robots might some day become conscious is that we human beings are conscious, and we are a sort of robot ourselves. That is, we are extraordinarily complex self-controlling, self-sustaining physical mechanisms, designed over the eons by natural selection, and operating according to the same well-understood principles that govern all the other physical processes in living things: digestive and metabolic processes, self-repair and reproductive processes, for instance. It may be wildly over-ambitious to suppose that human artificers can repeat Nature's triumph, with variations in material, form, and design process, but this is not a deep objection. It is not as if a conscious machine contradicted any fundamental laws of nature, the way a perpetual motion machine does. Still, many skeptics believe--or in any event want to believe--that it will never be done. I wouldn't wager against them, but my reasons for skepticism are mundane, economic reasons, not theoretical reasons</div>
<div id='_343_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCIH-2",this.href,0);return true;' href="http://ase.tufts.edu/cogstud/papers/concrobt.htm">http://ase.tufts.edu/cogstud/papers/concrobt.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCIH-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000429/">http://cogprints.ecs.soton.ac.uk/archive/00000429/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCIH-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000429/00/concrobt.htm">http://cogprints.ecs.soton.ac.uk/archive/00000429/00/concrobt.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCIH-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:429">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:429</a><br></div></div>
</div><!--entry-->

<div id='_344_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("DENTPR",this.href,0);return true;' href='http://ase.tufts.edu/cogstud/papers/practic.htm'>The practical requirements for making a conscious robot.</a></span> <span class='pub_name'>Philosophical Transactions of the Royal Society</span> 349:133-46. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9450548439813306455'>Cited by 25</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20practical%20requirements%20for%20making%20a%20conscious%20robot+author%3ADennett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_344_links")'>More links</a>)</span><div id='_344_abstract' class='extra' style='font-size:12px;'>Abstract: Arguments about whether a robot could ever be conscious have been conducted up to now in the factually impoverished arena of what is possible "in principle." A team at MIT of which I am a part is now embarking on a longterm project to design and build a humanoid robot, Cog, whose cognitive talents will include speech, eye-coordinated manipulation of objects, and a host of self-protective, self-regulatory and self-exploring activities. The aim of the project is not to make a conscious robot, but to make a robot that can interact with human beings in a robust and versatile manner in real time, take care of itself, and tell its designers things about itself that would otherwise be extremely difficult if not impossible to determine by examination. Many of the details of Cog's "neural" organization will parallel what is known (or presumed known) about their counterparts in the human brain, but the intended realism of Cog as a model is relatively coarse-grained, varying opportunistically as a function of what we think we know, what we think we can build, and what we think doesn't matter. Much of what we think will of course prove to be mistaken; that is one advantage of real experiments over thought experiments</div>
<div id='_344_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENTPR",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1994RSPTA.349..133D">http://adsabs.harvard.edu/abs/1994RSPTA.349..133D</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENTPR",this.href,0);return true;' href="http://www.journals.royalsoc.ac.uk/index/L62130158Q786731.pdf">http://www.journals.royalsoc.ac.uk/index/L62130158Q786731.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENTPR",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Py104/dennett.rob.html">http://cogsci.soton.ac.uk/~harnad/Papers/Py104/dennett.rob.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENTPR",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0962-8428(19941015)349:1689&lt;133:TPRFMA&gt;2.0.CO;2-1">http://links.jstor.org/sici?sici=0962-8428(19941015)349:1689<133:TPRFMA>2.0.CO;2-1</a><br></div></div>
</div><!--entry-->

<div id='_345_entry' class='entry'><span ><span class='name'>Duch, WÅodzisÅaw</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("DUCBCC",this.href,0);return true;' href='http://cogprints.org/3319'>Brain-inspired conscious computing architecture.</a></span> <span class='pub_name'>Journal of Mind and Behavior</span> 26 (1-2):1-21. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14679664870573609267'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Brain-inspired%20conscious%20computing%20architecture+author%3ADuch&amp;btnG=Search'>Google</a> | <a href='javascript:show("_345_links")'>More links</a>)</span><div id='_345_abstract' class='extra' style='font-size:12px;'>Abstract: What type of artificial systems will claim to be conscious and will claim to experience qualia? The ability to comment upon physical states of a brain-like dynamical system coupled with its environment seems to be sufficient to make claims. The flow of internal states in such system, guided and limited by associative memory, is similar to the stream of consciousness. Minimal requirements for an artificial system that will claim to be conscious were given in form of specific architecture named articon. Nonverbal discrimination of the working memory states of the articon gives it the ability to experience different qualities of internal states. Analysis of the inner state flows of such a system during typical behavioral process shows that qualia are inseparable from perception and action. The role of consciousness in learning of skills, when conscious information processing is replaced by subconscious, is elucidated. Arguments confirming that phenomenal experience is a result of cognitive processes are presented. Possible philosophical objections based on the Chinese room and other arguments are discussed, but they are insufficient to refute claims articonâs claims. Conditions for genuine understanding that go beyond the Turing test are presented. Articons may fulfill such conditions and in principle the structure of their experiences may be arbitrarily close to human</div>
<div id='_345_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DUCBCC",this.href,0);return true;' href="http://citeseer.ist.psu.edu/duch05braininspired.html">http://citeseer.ist.psu.edu/duch05braininspired.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DUCBCC",this.href,0);return true;' href="http://www.phys.uni.torun.pl/publications/kmk/03-Brainins.pdf">http://www.phys.uni.torun.pl/publications/kmk/03-Brainins.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DUCBCC",this.href,0);return true;' href="http://www.phys.uni.torun.pl/publications/kmk/03-Brainins.html">http://www.phys.uni.torun.pl/publications/kmk/03-Brainins.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DUCBCC",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003319/01/03-Brainins.pdf">http://cogprints.ecs.soton.ac.uk/archive/00003319/01/03-Brainins.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DUCBCC",this.href,0);return true;' href="http://cogprints.org/3319/1/03-Brainins.pdf">http://cogprints.org/3319/1/03-Brainins.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DUCBCC",this.href,0);return true;' href="http://cogprints.org/3319/1/03%2DBrainins.pdf">http://cogprints.org/3319/1/03%2DBrainins.pdf</a><br></div></div>
</div><!--entry-->

<div id='_346_entry' class='entry'><span ><span class='name'>Ettinger, R. C. W.</span> (2004). To be or not to be: The zombie in the computer.</span> In Nick Bostrom, R.C.W. Ettinger &amp; Charles Tandy (eds.), <em>Death and Anti-Death, Volume 2: Two Hundred Years After Kant, Fifty Years After Turing</em>. Palo Alto: Ria University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=To%20be%20or%20not%20to%20be+author%3AEttinger&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_347_entry' class='entry'><span ><span class='name'>Farrell, B. A.</span> (1970). <a rel="nofollow" class='article_title' onclick='trackclick("FAROTD",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0026-4423(197007)2:79:315&lt;321:OTDOAC&gt;2.0.CO;2-0'>On the design of a conscious device.</a></span> <span class='pub_name'>Mind</span> 79 (July):321-346. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5955674133565394211'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20design%20of%20a%20conscious%20device+author%3AFarrell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_347_links")'>More links</a>)</span>
<div id='_347_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FAROTD",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(197007)2:79:315&lt;321:OTDOAC&gt;2.0.CO;2-0">http://www.jstor.org/sici?sici=0026-4423(197007)2:79:315<321:OTDOAC>2.0.CO;2-0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FAROTD",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2252823.pdf">http://www.jstor.org/stable/pdfplus/2252823.pdf</a><br></div></div>
</div><!--entry-->

<div id='_348_entry' class='entry'><span ><span class='name'>Farleigh, Peter</span> (2007). The ensemble and the single mind.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20ensemble%20and%20the%20single%20mind+author%3AFarleigh&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_349_entry' class='entry'><span ><span class='name'>Franklin, Stan</span> (2003). A conscious artifact?</span> <span class='pub_name'>Journal of Consciousness Studies</span> 10. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20conscious%20artifact%3F+author%3AFranklin&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_350_entry' class='entry'><span ><span class='name'>Franklin, Stan</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("FRAIAC",this.href,0);return true;' href='http://ccrg.cs.memphis.edu/assets/papers/IDA-ConsciousArtifact.pdf'>Ida: A conscious artifact?</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4):47-66. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3102944719727910355'>Cited by 40</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Ida+author%3AFranklin&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_351_entry' class='entry'><span ><span class='name'>Gunderson, Keith</span> (1969). <a rel="nofollow" class='article_title' onclick='trackclick("GUNCAM",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a902031643~fulltext=713240930'>Cybernetics and mind-body problems.</a></span> <span class='pub_name'>Inquiry</span> 12 (1-4):406-19. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cybernetics%20and%20mind-body%20problems+author%3AGunderson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_352_entry' class='entry'><span ><span class='name'>Gunderson, Keith</span> (1971). <em><span class='pub_name'>Mentality and Machines.</span></em></span> Doubleday. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2813132086301272343'>Cited by 29</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentality%20and%20Machines+author%3AGunderson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_353_entry' class='entry'><span ><span class='name'>Gunderson, Keith</span> (1968). <a rel="nofollow" class='article_title' onclick='trackclick("GUNRCA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196808)19:2&lt;109:RCAPB&gt;2.0.CO;2-M'>Robots, consciousness and programmed behaviour.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 19 (August):109-22. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots%2C%20consciousness%20and%20programmed%20behaviour+author%3AGunderson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_353_links")'>More links</a>)</span>
<div id='_353_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUNRCA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196808)19:2&lt;109:RCAPB&gt;2.0.CO;2-M">http://www.jstor.org/sici?sici=0007-0882(196808)19:2<109:RCAPB>2.0.CO;2-M</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUNRCA",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/19/2/109">http://bjps.oxfordjournals.org/cgi/reprint/19/2/109</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUNRCA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686790.pdf">http://www.jstor.org/stable/pdfplus/686790.pdf</a><br></div></div>
</div><!--entry-->

<div id='_354_entry' class='entry'><span ><span class='name'>Haikonen, Pentti O. A.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("HAIEIO",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/jcs/2007/00000014/00000007/art00005'>Essential issues of conscious machines.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 14 (7):72-84. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Essential%20issues%20of%20conscious%20machines+author%3AHaikonen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_354_links")'>More links</a>)</span><div id='_354_abstract' class='extra' style='font-size:12px;'>Abstract: The development of conscious machines faces a number of difficult issues such as the apparent immateriality of mind, qualia and self-awareness. Also consciousness-related cognitive processes such as perception, imagination, motivation and inner speech are a technical challenge. It is foreseen that the development of machine consciousness would call for a system approach; the developer of conscious machines should consider complete systems that integrate the cognitive processes seamlessly and process information in a transparent way with representational and non-representational information-processing modes. An overview of the main issues is given and some possible solutions are outlined</div>
<div id='_354_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAIEIO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00005">http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00005</a><br></div></div>
</div><!--entry-->

<div id='_355_entry' class='entry'><span ><span class='name'>Haikonen, </span> &amp; <span class='name'>Pentti, O.</span> (2007). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HAIRBC",this.href,0);return true;' href='http://books.google.com/books?id=4MoBoHhYCpkC&amp;printsec=front_cover'>Robot Brains: Circuits and Systems for Conscious Machines.</a></span></em></span> Wiley-Interscience. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robot%20Brains+author%3AHaikonen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_355_links")'>More links</a>)</span>
<div id='_355_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAIRBC",this.href,0);return true;' href="http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470062045.html">http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470062045.html</a><br></div></div>
</div><!--entry-->

<div id='_356_entry' class='entry'><span ><span class='name'>Haikonen, Pentti O. A.</span> (2003). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HAITCA",this.href,0);return true;' href='http://books.google.com/books?id=Zsh6-Nz2k1cC&amp;printsec=front_cover'>The Cognitive Approach to Conscious Machines.</a></span></em></span> Thorverton UK: Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10186918043043953644'>Cited by 20</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Cognitive%20Approach%20to%20Conscious%20Machines+author%3AHaikonen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_356_links")'>More links</a>)</span>
<div id='_356_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAITCA",this.href,0);return true;' href="http://imprint.co.uk/books/haikonen.html">http://imprint.co.uk/books/haikonen.html</a><br></div></div>
</div><!--entry-->

<div id='_357_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("HARCAM",this.href,0);return true;' href='http://cogprints.org/5330/'>Can a machine be conscious? How?</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4):67-75. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8144093798669560296'>Cited by 16</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20a%20machine%20be%20conscious%3F%20How%3F+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_357_links")'>More links</a>)</span><div id='_357_abstract' class='extra' style='font-size:12px;'>Abstract: A "machine" is any causal physical system, hence we are machines, hence machines can be conscious. The question is: which kinds of machines can be conscious? Chances are that robots that can pass the Turing Test -- completely indistinguishable from us in their behavioral capacities -- can be conscious (i.e. feel), but we can never be sure (because of the "other-minds" problem). And we can never know HOW they have minds, because of the "mind/body" problem. We can only know how they pass the Turing Test, but not how, why or whether that makes them feel</div>
<div id='_357_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://cogprints.org/2460/">http://cogprints.org/2460/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/7718">http://eprints.ecs.soton.ac.uk/7718</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://cogprints.org/5330/1/machine.htm">http://cogprints.org/5330/1/machine.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://cogprints.org/2460/1/machine.htm">http://cogprints.org/2460/1/machine.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/7718/">http://eprints.resist.ecs.soton.ac.uk/7718/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00007718/">http://eprints.ecs.soton.ac.uk/archive/00007718/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Temp/machine.htm">http://cogsci.soton.ac.uk/~harnad/Temp/machine.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00002460/">http://cogprints.ecs.soton.ac.uk/archive/00002460/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/machine.htm">http://www.ecs.soton.ac.uk/~harnad/Temp/machine.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://users.ecs.soton.ac.uk/~harnad/Temp/machine.htm">http://users.ecs.soton.ac.uk/~harnad/Temp/machine.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00002460/01/machine.htm">http://cogprints.ecs.soton.ac.uk/archive/00002460/01/machine.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:2460">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:2460</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:2460">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:2460</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1347">http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1347</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCAM",this.href,0);return true;' href="http://users.ecs.soton.ac.uk/%7Eharnad/Temp/machine.htm">http://users.ecs.soton.ac.uk/%7Eharnad/Temp/machine.htm</a><br></div></div>
</div><!--entry-->

<div id='_358_entry' class='entry'><span ><span class='name'>Henley, Tracy B.</span> (1991). Consciousness and aI: A reconsideration of Shanon.</span> <span class='pub_name'>Journal of Mind and Behavior</span> 12 (3):367-370. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20and%20aI+author%3AHenley&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_359_entry' class='entry'><span ><span class='name'>Hillis, D.</span> (1998). Can a machine be conscious?</span> In Stuart R. Hameroff, Alfred W. Kaszniak &amp; A. C. Scott (eds.), <em>Toward a Science of Consciousness II</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20a%20machine%20be%20conscious%3F+author%3AHillis&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_360_entry' class='entry'><span ><span class='name'>Holland, Owen</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("HOLASE",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/jcs/2007/00000014/00000007/art00007'>A strongly embodied approach to machine consciousness.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 14 (7):97-110. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5153087098232083193'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20strongly%20embodied%20approach%20to%20machine%20consciousness+author%3AHolland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_360_links")'>More links</a>)</span><div id='_360_abstract' class='extra' style='font-size:12px;'>Abstract: Over sixty years ago, Kenneth Craik noted that, if an organism (or an artificial agent) carried 'a small-scale model of external reality and of its own possible actions within its head', it could use the model to behave intelligently. This paper argues that the possible actions might best be represented by interactions between a model of reality and a model of the agent, and that, in such an arrangement, the internal model of the agent might be a transparent model of the sort recently discussed by Metzinger, and so might offer a useful analogue of a conscious entity. The CRONOS project has built a robot functionally similar to a human that has been provided with an internal model of itself and of the world to be used in the way suggested by Craik; when the system is completed, it will be possible to study its operation from the perspective not only of artificial intelligence, but also of machine consciousness</div>
<div id='_360_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOLASE",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00007">http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00007</a><br></div></div>
</div><!--entry-->

<div id='_361_entry' class='entry'><span ><span class='name'>Holland, Owen</span> (ed.) (2003). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HOLMC",this.href,0);return true;' href='http://books.google.com/books?id=k-M8B5rzokIC&amp;printsec=front_cover'>Machine Consciousness.</a></span></em></span> Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17887062314419983989'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20Consciousness+author%3AHolland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_361_links")'>More links</a>)</span><div id='_361_abstract' class='extra' style='font-size:12px;'>Abstract: In this collection of essays we hear from an international array of computer and brain scientists who are actively working from both the machine and human ends...</div>
<div id='_361_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOLMC",this.href,0);return true;' href="http://imprint.co.uk/books/holland.html">http://imprint.co.uk/books/holland.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOLMC",this.href,0);return true;' href="http://mentalhelp.net/books/books.php?type=de&amp;id=2305">http://mentalhelp.net/books/books.php?type=de&id=2305</a><br></div></div>
</div><!--entry-->

<div id='_362_entry' class='entry'><span ><span class='name'>Holland, Owen</span> &amp; <span class='name'>Goodman, Russell B.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("HOLRWI",this.href,0);return true;' href='http://www.rodgoodman.ws/pdf/RG.Paper.JA46.pdf'>Robots with internal models: A route to machine consciousness?</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4):77-109. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12246066617239933326'>Cited by 20</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots%20with%20internal%20models+author%3AHolland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_362_links")'>More links</a>)</span>
<div id='_362_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOLRWI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1348">http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1348</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOLRWI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1342">http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1342</a><br></div></div>
</div><!--entry-->

<div id='_363_entry' class='entry'><span ><span class='name'>Holland, Owen</span>; <span class='name'>Knight, Rob</span> &amp; <span class='name'>Newcombe, Richard</span> (2007). The role of the self process in embodied machine consciousness.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20role%20of%20the%20self%20process%20in%20embodied%20machine%20consciousness+author%3AHolland&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_364_entry' class='entry'><span ><span class='name'>Joy, Glenn C.</span> (1989). Gunderson and Searle: A common error about artificial intelligence.</span> <span class='pub_name'>Southwest Philosophical Studies</span> 28:28-34. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Gunderson%20and%20Searle+author%3AJoy&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_365_entry' class='entry'><span ><span class='name'>Kirk, Robert E.</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("KIRSCA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a739196855~fulltext=713240930'>Sentience, causation and some robots.</a></span> <span class='pub_name'>Australasian Journal of Philosophy</span> 64 (September):308-21. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18352158639944100086'>Cited by 1</a> | <span class='ll' onclick='$("_365_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Sentience%2C%20causation%20and%20some%20robots+author%3AKirk&amp;btnG=Search'>Google</a> | <a href='javascript:show("_365_links")'>More links</a>)</span><div id='_365_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>One could model brain states with monadic states and appropriate connections. But surely that's not intelligent -- the causation has the wrong form. Nice.</div></div>
<div id='_365_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIRSCA",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/K370525M56161703.pdf">http://taylorandfrancis.metapress.com/index/K370525M56161703.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIRSCA",this.href,0);return true;' href="http://www.informaworld.com/index/739196855.pdf">http://www.informaworld.com/index/739196855.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIRSCA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/ajphil/1986/00000064/00000003/art00006">http://www.ingentaconnect.com/content/routledg/ajphil/1986/00000064/00000003/art00006</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIRSCA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/tajp/1986/00000064/00000003/art00006">http://www.ingentaconnect.com/content/tandf/tajp/1986/00000064/00000003/art00006</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIRSCA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a739196855~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a739196855~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_366_entry' class='entry'><span ><span class='name'>Kiverstein, Julian</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("KIVCAR",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/jcs/2007/00000014/00000007/art00009'>Could a robot have a subjective point of view?</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 14 (7):127-139. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18229131561759822499'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20a%20robot%20have%20a%20subjective%20point%20of%20view%3F+author%3AKiverstein&amp;btnG=Search'>Google</a> | <a href='javascript:show("_366_links")'>More links</a>)</span><div id='_366_abstract' class='extra' style='font-size:12px;'>Abstract: Scepticism about the possibility of machine consciousness comes in at least two forms. Some argue that our neurobiology is special, and only something sharing our neurobiology could be a subject of experience. Others argue that a machine couldn't be anything else but a zombie: there could never be something it is like to be a machine. I advance a dynamic sensorimotor account of consciousness which argues against both these varieties of scepticism</div>
<div id='_366_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIVCAR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00009">http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00009</a><br></div></div>
</div><!--entry-->

<div id='_367_entry' class='entry'><span ><span class='name'>Levy, Donald</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("LEVHTP",this.href,0);return true;' href='http://www.springerlink.com/content/u6t815g723r22382/fulltext.pdf'>How to psychoanalyze a robot: Unconscious cognition and the evolution of intentionality.</a></span> <span class='pub_name'>Minds and Machines</span> 13 (2):203-212. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20to%20psychoanalyze%20a%20robot+author%3ALevy&amp;btnG=Search'>Google</a> | <a href='javascript:show("_367_links")'>More links</a>)</span><div id='_367_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â According to a common philosophical distinction, the `original' intentionality, or `aboutness' possessed by our thoughts, beliefs and desires, is categorically different from the `derived' intentionality manifested in some of our artifacts â- our words, books and pictures, for example. Those making the distinction claim that the intentionality of our artifacts is `parasitic' on the `genuine' intentionality to be found in members of the former class of things. In Kinds of Minds: Toward an Understanding of Consciousness, Daniel Dennett criticizes that claim and the distinction it rests on, and seeks to show that ``metaphysically original intentionality'' is illusory by working out the implications he sees in the practical possibility of a certain type of robot, i.e., one that generates `utterances' which are `inscrutable to the robot's designers' so that we, and they, must consult the robot to discover the meaning of its utterances. I argue that the implications Dennett finds are erroneous, regardless of whether such a robot is possible, and therefore that the real existence of metaphysically original intentionality has not been undermined by the possibility of the robot Dennett describes</div>
<div id='_367_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEVHTP",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5115347&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5115347&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEVHTP",this.href,0);return true;' href="http://www.springerlink.com/index/U6T815G723R22382.pdf">http://www.springerlink.com/index/U6T815G723R22382.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LEVHTP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000002/05115347">http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000002/05115347</a><br></div></div>
</div><!--entry-->

<div id='_368_entry' class='entry'><span ><span class='name'>Lucas, John R.</span> (1994). A view of one's own (conscious machines).</span> <span class='pub_name'>Philosophical Transactions of the Royal Society, Series A</span> 349:147-52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20view%20of%20one%27s%20own%20%28conscious%20machines%29+author%3ALucas&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_369_entry' class='entry'><span ><span class='name'>Lycan, William G.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("LYCQEI",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=oXmTuWBOn_AC&amp;oi=fnd&amp;pg=PA171&amp;dq=+Qualitative+experience+in+machines+Lycan&amp;ots=OYYy2y0CW8&amp;sig=S-_pCp3LAkNCtt55kenfcmHond8'>Qualitative experience in machines.</a></span> In Terrell Ward Bynum &amp; James H. Moor (eds.), <em>How Computers Are Changing Philosophy</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Qualitative%20experience%20in%20machines+author%3ALycan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_370_entry' class='entry'><span ><span class='name'>Mackay, Donald M.</span> (1963). <a rel="nofollow" class='article_title' onclick='trackclick("MACCAM",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196308)14:54&lt;157:CAMART&gt;2.0.CO;2-D'>Consciousness and mechanism: A reply to miss Fozzy.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 14 (August):157-159. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20and%20mechanism+author%3AMackay&amp;btnG=Search'>Google</a> | <a href='javascript:show("_370_links")'>More links</a>)</span>
<div id='_370_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACCAM",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196308)14:54&lt;157:CAMART&gt;2.0.CO;2-D">http://www.jstor.org/sici?sici=0007-0882(196308)14:54<157:CAMART>2.0.CO;2-D</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACCAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/XIV/54/157">http://bjps.oxfordjournals.org/cgi/content/citation/XIV/54/157</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACCAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/XIV/54/157">http://bjps.oxfordjournals.org/cgi/reprint/XIV/54/157</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACCAM",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685435.pdf">http://www.jstor.org/stable/pdfplus/685435.pdf</a><br></div></div>
</div><!--entry-->

<div id='_371_entry' class='entry'><span ><span class='name'>Mackay, Donald M.</span> (1985). Machines, brains, and persons.</span> <span class='pub_name'>Zygon</span> 20 (December):401-412. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machines%2C%20brains%2C%20and%20persons+author%3AMackay&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_372_entry' class='entry'><span ><span class='name'>Manzotti, Riccardo</span> (2007). From artificial intelligence to artificial consciousness.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20artificial%20intelligence%20to%20artificial%20consciousness+author%3AManzotti&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_373_entry' class='entry'><span ><span class='name'>Margolis, Joseph</span> (1974). Ascribing actions to machines.</span> <span class='pub_name'>Behaviorism</span> 2:85-93. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Ascribing%20actions%20to%20machines+author%3AMargolis&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_374_entry' class='entry'><span ><span class='name'>Marras, Ausonio</span> (1993). Pollock on how to build a person.</span> <span class='pub_name'>Dialogue</span> 32 (3):595-605. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9590943233470194174'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Pollock%20on%20how%20to%20build%20a%20person+author%3AMarras&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_375_entry' class='entry'><span ><span class='name'>Maudlin, Tim</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("MAUCAC",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(198908)86:8&lt;407:CAC&gt;2.0.CO;2-A'>Computation and consciousness.</a></span> <span class='pub_name'>Journal of Philosophy</span> 86 (August):407-32. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13284087395705893310'>Cited by 24</a> | <span class='ll' onclick='$("_375_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computation%20and%20consciousness+author%3AMaudlin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_375_links")'>More links</a>)</span><div id='_375_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Computational state is not sufficient for consciousness, as it can be instantiated by a mostly inert object. A nice thought-experiment, raising questions about the relevance of counterfactuals to consciousness.</div></div>
<div id='_375_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAUCAC",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(198908)86:8&lt;407:CAC&gt;2.0.CO;2-A">http://www.jstor.org/sici?sici=0022-362X(198908)86:8<407:CAC>2.0.CO;2-A</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAUCAC",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2026650.pdf">http://www.jstor.org/stable/pdfplus/2026650.pdf</a><br></div></div>
</div><!--entry-->

<div id='_376_entry' class='entry'><span ><span class='name'>Mayberry, Thomas C.</span> (1970). Consciousness and robots.</span> <span class='pub_name'>Personalist</span> 51:222-236. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20and%20robots+author%3AMayberry&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_377_entry' class='entry'><span ><span class='name'>McCann, Hugh J.</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("MCCIAA",this.href,0);return true;' href='http://www.unc.edu/~knobe/McCann.pdf'>Intentional action and intending: Recent empirical studies.</a></span> <span class='pub_name'>Philosophical Psychology</span> 18 (6):737-748. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10876638420084561380'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intentional%20action%20and%20intending+author%3AMcCann&amp;btnG=Search'>Google</a> | <a href='javascript:show("_377_links")'>More links</a>)</span><div id='_377_abstract' class='extra' style='font-size:12px;'>Abstract: Recent empirical work calls into question the so-called Simple View that an agent who Aâs intentionally intends to A. In experimental studies, ordinary speakers frequently assent to claims that, in certain cases, agents who knowingly behave wrongly intentionally bring about the harm they do; yet the speakers tend to deny that it was the intention of those agents to cause the harm. This paper reports two additional studies that at first appear to support the original ones, but argues that in fact, the evidence of all the studies considered is best understood in terms of the Simple View.</div>
<div id='_377_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCIAA",this.href,0);return true;' href="http://instruct1.cit.cornell.edu/courses/phi663/knobe McCann.pdf ">http://instruct1.cit.cornell.edu/courses/phi663/knobe McCann.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCIAA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a727334015~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a727334015~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCIAA",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/RP912503N228W554.pdf">http://taylorandfrancis.metapress.com/index/RP912503N228W554.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCIAA",this.href,0);return true;' href="http://www.informaworld.com/index/727334015.pdf">http://www.informaworld.com/index/727334015.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCIAA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2005/00000018/00000006/art00005">http://www.ingentaconnect.com/content/routledg/cphp/2005/00000018/00000006/art00005</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCIAA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a727334015~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a727334015~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_378_entry' class='entry'><span ><span class='name'>McCarthy, John</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("MCCMRC",this.href,0);return true;' href='http://cogprints.org/422/'>Making robots conscious of their mental states.</a></span> In S. Muggleton (ed.), <em>Machine Intelligence 15</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11318807839444023476'>Cited by 68</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Making%20robots%20conscious%20of%20their%20mental%20states+author%3AMcCarthy&amp;btnG=Search'>Google</a> | <a href='javascript:show("_378_links")'>More links</a>)</span><div id='_378_abstract' class='extra' style='font-size:12px;'>Abstract: In AI, consciousness of self consists in a program having certain kinds of facts about its own mental processes and state of mind. We discuss what consciousness of its own mental structures a robot will need in order to operate in the common sense world and accomplish the tasks humans will give it. It's quite a lot. Many features of human consciousness will be wanted, some will not, and some abilities not possessed by humans have already been found feasible and useful in limited contexts. We give preliminary fragments of a logical language a robot can use to represent information about its own state of mind. A robot will often have to conclude that it cannot decide a question on the basis of the information in memory and therefore must seek information externally. GÃ¶del's idea of relative consistency is used to formalize non-knowledge. Programs with the kind of consciousness discussed in this article do not yet exist, although programs with some components of it exist. Thinking about consciousness with a view to designing it provides a new approach to some of the problems of consciousness studied by philosophers. One advantage is that it focusses on the aspects of consciousness important for intelligent behavior</div>
<div id='_378_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCMRC",this.href,0);return true;' href="http://citeseer.ist.psu.edu/81449.html">http://citeseer.ist.psu.edu/81449.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCMRC",this.href,0);return true;' href="http://citeseer.ist.psu.edu/mccarthy95making.html">http://citeseer.ist.psu.edu/mccarthy95making.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCMRC",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000422/">http://cogprints.ecs.soton.ac.uk/archive/00000422/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCMRC",this.href,0);return true;' href="http://www-formal.stanford.edu/jmc/consciousness.ps">http://www-formal.stanford.edu/jmc/consciousness.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCMRC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=647636.733058">http://portal.acm.org/citation.cfm?id=647636.733058</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCMRC",this.href,0);return true;' href="http://www-formal.stanford.edu/jmc/consciousness/consciousness.html">http://www-formal.stanford.edu/jmc/consciousness/consciousness.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCMRC",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:422">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:422</a><br></div></div>
</div><!--entry-->

<div id='_379_entry' class='entry'><span ><span class='name'>McDermott, Drew</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("MCDAIA",this.href,0);return true;' href='http://www.cs.yale.edu/homes/dvm/papers/conscioushb.pdf'>Artificial intelligence and consciousness.</a></span> In Philip David Zelazo, Morris Moscovitch &amp; Evan Thompson (eds.), <em>The Cambridge Handbook of Consciousness</em>. Cambridge. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence%20and%20consciousness+author%3AMcDermott&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_380_entry' class='entry'><span ><span class='name'>McGinn, Colin</span> (1987). Could a machine be conscious?</span> In Colin Blakemore &amp; Susan A. Greenfield (eds.), <em>Mindwaves</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15563912907953085102'>Cited by 1</a> | <span class='ll' onclick='$("_380_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20a%20machine%20be%20conscious%3F+author%3AMcGinn&amp;btnG=Search'>Google</a>)</span><div id='_380_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Of course, as we are machines. But what sort of machines are conscious, and in virtue of what properties? Remarks on artefacts, life, functionalism, and computationalism. So far, we don't know what makes the brain conscious.</div></div>
</div><!--entry-->

<div id='_381_entry' class='entry'><span ><span class='name'>Mele, Alfred R.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("MELTFC",this.href,0);return true;' href='http://www.unc.edu/~knobe/MeleJCC.pdf'>The folk concept of intentional action: A commentary.</a></span> <span class='pub_name'>Journal of Cognition and Culture</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9728414519863756026'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20folk%20concept%20of%20intentional%20action+author%3AMele&amp;btnG=Search'>Google</a> | <a href='javascript:show("_381_links")'>More links</a>)</span><div id='_381_abstract' class='extra' style='font-size:12px;'>Abstract: In this commentary, I discuss the three main articles in this volume that present survey data relevant to a search for something that might merit the label âthe folk concept of intentional actionâ â the articles by Joshua Knobe and Arudra Burra, Bertram Malle, and Thomas Nadelhoffer. My guiding question is this: What shape might we find in an analysis of intentional action that takes at face value the results of all of the relevant surveys about vignettes discussed in these three articles?1 To simplify exposition, I assume that there is something that merits the label I mentioned</div>
<div id='_381_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MELTFC",this.href,0);return true;' href="http://www.unc.edu/~knobe/MeleJCC.pdf ">http://www.unc.edu/~knobe/MeleJCC.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MELTFC",this.href,0);return true;' href="http://www.springerlink.com/index/0P30736376436T04.pdf">http://www.springerlink.com/index/0P30736376436T04.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MELTFC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/brill/jocc/2006/00000006/F0020001/art00016">http://www.ingentaconnect.com/content/brill/jocc/2006/00000006/F0020001/art00016</a><br></div></div>
</div><!--entry-->

<div id='_382_entry' class='entry'><span ><span class='name'>Menant, Christophe</span>, <a rel="nofollow" class='article_title' onclick='trackclick("MENPFA",this.href,0);return true;' href='http://crmenant.free.fr/AAAI-2007/FS01MenantCh20070905074007.pdf'>Proposal for an approach to artificial consciousness based on self-consciousness.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Proposal%20for%20an%20approach%20to%20artificial%20consciousness%20based%20on%20self-consciousness+author%3AMenant&amp;btnG=Search'>Google</a> | <a href='javascript:show("_382_links")'>More links</a>)</span><div id='_382_abstract' class='extra' style='font-size:12px;'>Abstract: Current research on artificial consciousness is focused on phenomenal consciousness and on functional consciousness. We propose to shift the focus to self-consciousness in order to open new areas of investigation. We use an existing scenario where self-consciousness is considered as the result of an evolution of representations. Application of the scenario to the possible build up of a conscious robot also introduces questions relative to emotions in robots. Areas of investigation are proposed as a continuation of this approach</div>
<div id='_382_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENPFA",this.href,0);return true;' href="http://cogprints.org/6013/">http://cogprints.org/6013/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENPFA",this.href,0);return true;' href="http://cogprints.org/6013/1/FS01MenantCh20070905074007.pdf">http://cogprints.org/6013/1/FS01MenantCh20070905074007.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENPFA",this.href,0);return true;' href="http://www.aaai.org/Papers/Symposia/Fall/2007/FS-07-01/FS07-01-020.pdf">http://www.aaai.org/Papers/Symposia/Fall/2007/FS-07-01/FS07-01-020.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENPFA",this.href,0);return true;' href="http://cogprints.org/5866/3/FS01MenantCh20070905074007.pdf">http://cogprints.org/5866/3/FS01MenantCh20070905074007.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENPFA",this.href,0);return true;' href="http://cogprints.org/5999/1/FS01MenantCh20070905074007.pdf">http://cogprints.org/5999/1/FS01MenantCh20070905074007.pdf</a><br></div></div>
</div><!--entry-->

<div id='_383_entry' class='entry'><span ><span class='name'>Minsky, Marvin L.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("MINCM",this.href,0);return true;' href='http://kuoi.asui.uidaho.edu/~kamikaze/documents/minsky.html'>Conscious machines.</a></span> In <em>Machinery of Consciousness</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Conscious%20machines+author%3AMinsky&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_384_entry' class='entry'><span ><span class='name'>Moffett, Marc A.</span> &amp; <span class='name'>Cole Wright, Jennifer</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("MOFTFO",this.href,0);return true;' href='http://www.uwyo.edu/moffett/research/folkintellectualism.pdf'>The folk on know-how: Why radical intellectualism does not over-intellectualize.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20folk%20on%20know-how+author%3AMoffett&amp;btnG=Search'>Google</a>)</span><div id='_384_abstract' class='extra' style='font-size:12px;'>Abstract: Philosophical discussion of the nature of know-how has focused on the relation between know-how and ability. Broadly speaking, neo-Ryleans attempt to identify know-how with a certain type of ability,1 while, traditionally, intellectualists attempt to reduce it to some form of propositional knowledge. For our purposes, however, this characterization of the debate is too crude. Instead, we prefer the following more explicit taxonomy. Anti-intellectualists, as we will use the term, maintain that knowing how to ? entails the ability to ?. Dispositionalists maintain that the ability to ? is sufficient (modulo some fairly innocuous constraints) for knowing how to ?. Intellectualists, as we will use the term, deny the anti-intellectualist claim. Finally, radical intellectualists deny both the anti-intellectualist and dispositionalist claims. Pace neo-Ryleans (who in our taxonomy are those who accept both dispositionalism and anti-intellectualism), radical intellectualists maintain that the ability to ? is neither necessary nor sufficient for knowing how to ?</div>
</div><!--entry-->

<div id='_385_entry' class='entry'><span ><span class='name'>Nichols, Shaun</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("NICFCA",this.href,0);return true;' href='http://dingo.sbs.arizona.edu/~snichols/Papers/FolkConcepts.pdf'>Folk concepts and intuitions: From philosophy to cognitive science.</a></span> <span class='pub_name'>Trends in Cognitive Sciences</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=906049876249544939'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20concepts%20and%20intuitions+author%3ANichols&amp;btnG=Search'>Google</a> | <a href='javascript:show("_385_links")'>More links</a>)</span><div id='_385_abstract' class='extra' style='font-size:12px;'>Abstract: Analytic philosophers have long used a priori methods to characterize folk concepts like knowledge, belief, and wrongness. Recently, researchers have begun to exploit social scientific methodologies to characterize such folk concepts. One line of work has explored folk intuitions on cases that are disputed within philosophy. A second approach, with potentially more radical implications, applies the methods of cross-cultural psychology to philosophical intuitions. Recent work suggests that people in different cultures have systematically different intuitions surrounding folk concepts like wrong, knows, and refers. A third strand of research explores the emergence and character of folk concepts in children. These approaches to characterizing folk concepts provide important resources that will supplement, and perhaps sometimes displace, a priori approaches</div>
<div id='_385_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFCA",this.href,0);return true;' href="http://dingo.sbs.arizona.edu/~snichols/Papers/FolkConcepts.pdf ">http://dingo.sbs.arizona.edu/~snichols/Papers/FolkConcepts.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFCA",this.href,0);return true;' href="http://matrix.aklab.psych.ubc.ca/uploads/Christine_FolkPhilosophy_TICS.pdf">http://matrix.aklab.psych.ubc.ca/uploads/Christine_FolkPhilosophy_TICS.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFCA",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=15491906&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=15491906&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFCA",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;uid=15491906&amp;cmd=showdetailview&amp;indexed=google">http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&uid=15491906&cmd=showdetailview&indexed=google</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NICFCA",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S1364661304002360">http://linkinghub.elsevier.com/retrieve/pii/S1364661304002360</a><br></div></div>
</div><!--entry-->

<div id='_386_entry' class='entry'><span ><span class='name'>Pinker, Steven</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("PINCAC",this.href,0);return true;' href='http://pinker.wjh.harvard.edu/articles/media/1997_08_18_usnewsworldreport.html'>Could a computer ever be conscious?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20a%20computer%20ever%20be%20conscious%3F+author%3APinker&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_387_entry' class='entry'><span ><span class='name'>Prinz, Jesse J.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("PRILMA",this.href,0);return true;' href='http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1349'>Level-headed mysterianism and artificial experience.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4-5):111-132. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7958271402001055296'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Level-headed%20mysterianism%20and%20artificial%20experience+author%3APrinz&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_388_entry' class='entry'><span ><span class='name'>Puccetti, Roland</span> (1975). God and the robots: A philosophical fable.</span> <span class='pub_name'>Personalist</span> 56:29-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=God%20and%20the%20robots+author%3APuccetti&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_389_entry' class='entry'><span ><span class='name'>Puccetti, Roland</span> (1967). <a rel="nofollow" class='article_title' onclick='trackclick("PUCOTM",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196705)18:1&lt;39:OTMAFM&gt;2.0.CO;2-K'>On thinking machines and feeling machines.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 18 (May):39-51. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13771930334297081229'>Cited by 3</a> | <span class='ll' onclick='$("_389_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20thinking%20machines%20and%20feeling%20machines+author%3APuccetti&amp;btnG=Search'>Google</a> | <a href='javascript:show("_389_links")'>More links</a>)</span><div id='_389_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Machines can think but can't feel, so aren't persons.</div></div>
<div id='_389_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUCOTM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/18/1/39">http://bjps.oxfordjournals.org/cgi/content/citation/18/1/39</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUCOTM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/18/1/39">http://bjps.oxfordjournals.org/cgi/reprint/18/1/39</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUCOTM",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686888.pdf">http://www.jstor.org/stable/pdfplus/686888.pdf</a><br></div></div>
</div><!--entry-->

<div id='_390_entry' class='entry'><span ><span class='name'>Putnam, Hilary</span> (1964). Robots: Machines or artificially created life?</span> <span class='pub_name'>Journal of Philosophy</span> 61 (November):668-91. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_390_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots+author%3APutnam&amp;btnG=Search'>Google</a>)</span><div id='_390_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Various arguments and counter-arguments re machine consciousness and civil liberties. Problems of machine consciousness are analogous to problems of human consciousness. The structural basis of the two may well be the same.</div></div>
</div><!--entry-->

<div id='_391_entry' class='entry'><span ><span class='name'>Rhodes, Kris</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("RHOVOT",this.href,0);return true;' href='http://philpapers.org/archive/RHOVOT'>Vindication of the Rights of Machine.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Vindication%20of%20the%20Rights%20of%20Machine+author%3ARhodes&amp;btnG=Search'>Google</a> | <a href='javascript:show("_391_links")'>More links</a>)</span><div id='_391_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper, I argue that certain Machines can have rights independently of whether they are sentient, or conscious, or whatever you might call it.</div>
<div id='_391_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RHOVOT",this.href,0);return true;' href="http://www.igradeyourpaper.com/VRMv3.doc">http://www.igradeyourpaper.com/VRMv3.doc</a><br></div></div>
</div><!--entry-->

<div id='_392_entry' class='entry'><span ><span class='name'>Robinson, William S.</span> (1998). Could a robot be qualitatively conscious?</span> <span class='pub_name'>Aisb</span> 99:13-18. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20a%20robot%20be%20qualitatively%20conscious%3F+author%3ARobinson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_393_entry' class='entry'><span ><span class='name'>Sanz, Ricardo</span>; <span class='name'>LÃ³pez, Ignacio</span> &amp; <span class='name'>Bermejo-Alonso, Julita</span> (2007). A rationale and vision for machine consciousness in complex controllers.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20rationale%20and%20vision%20for%20machine%20consciousness%20in%20complex%20controllers+author%3ASanz&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_394_entry' class='entry'><span ><span class='name'>Schlagel, Richard H.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("SCHWNA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596830'>Why not artificial consciousness or thought?</a></span> <span class='pub_name'>Minds and Machines</span> 9 (1):3-28. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=735418801220759185'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20not%20artificial%20consciousness%20or%20thought%3F+author%3ASchlagel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_394_links")'>More links</a>)</span><div id='_394_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The purpose of this article is to show why consciousness and thought are not manifested in digital computers. Analyzing the rationale for claiming that the formal manipulation of physical symbols in Turing machines would emulate human thought, the article attempts to show why this proved false. This is because the reinterpretation of designation and meaning to accommodate physical symbol manipulation eliminated their crucial functions in human discourse. Words have denotations and intensional meanings because the brain transforms the physical stimuli received from the microworld into a qualitative, macroscopic representation for consciousness. Lacking this capacity as programmed machines, computers have no representations for their symbols to designate and mean. Unlike human beings in which consciousness and thought, with their inherent content, have emerged because of their organic natures, serial processing computers or parallel distributed processing systems, as programmed electrical machines, lack these causal capacities</div>
<div id='_394_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHWNA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=467237CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=467237CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHWNA",this.href,0);return true;' href="http://www.springerlink.com/content/k248165u513p4746/fulltext.pdf">http://www.springerlink.com/content/k248165u513p4746/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHWNA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=187743&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=187743&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHWNA",this.href,0);return true;' href="http://www.springerlink.com/index/K248165U513P4746.pdf">http://www.springerlink.com/index/K248165U513P4746.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHWNA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1998/00000009/00000001/00187743">http://www.ingentaconnect.com/content/klu/mind/1998/00000009/00000001/00187743</a><br></div></div>
</div><!--entry-->

<div id='_395_entry' class='entry'><span ><span class='name'>Scriven, Michael</span> (1953). <a rel="nofollow" class='article_title' onclick='trackclick("SCRTMC",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0026-4423(195304)2:62:246&lt;230:TMCOM&gt;2.0.CO;2-2'>The mechanical concept of mind.</a></span> <span class='pub_name'>Mind</span> 62 (April):230-240. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8841918247845151323'>Cited by 12</a> | <span class='ll' onclick='$("_395_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20mechanical%20concept%20of%20mind+author%3AScriven&amp;btnG=Search'>Google</a> | <a href='javascript:show("_395_links")'>More links</a>)</span><div id='_395_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>To speak of a conscious machine is to commit a semantic mistake. Consciousness presupposes life and non-mechanism. Later retracted.</div></div>
<div id='_395_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCRTMC",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(195304)2:62:246&lt;230:TMCOM&gt;2.0.CO;2-2">http://www.jstor.org/sici?sici=0026-4423(195304)2:62:246<230:TMCOM>2.0.CO;2-2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCRTMC",this.href,0);return true;' href="http://mind.oxfordjournals.org/cgi/reprint/LXII/246/230">http://mind.oxfordjournals.org/cgi/reprint/LXII/246/230</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCRTMC",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2251386.pdf">http://www.jstor.org/stable/pdfplus/2251386.pdf</a><br></div></div>
</div><!--entry-->

<div id='_396_entry' class='entry'><span ><span class='name'>Shanon, Benny</span> (1991). Consciousness and the computer: A reply to Henley.</span> <span class='pub_name'>Journal of Mind and Behavior</span> 12 (3):371-375. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20and%20the%20computer+author%3AShanon&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_397_entry' class='entry'><span ><span class='name'>Sharlow, Mark F.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("SHACMH",this.href,0);return true;' href='http://www.eskimo.com/~msharlow/firstper.htm'>Can machines have first-person properties?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20machines%20have%20first-person%20properties%3F+author%3ASharlow&amp;btnG=Search'>Google</a>)</span><div id='_397_abstract' class='extra' style='font-size:12px;'>Abstract: One of the most important ongoing debates in the philosophy of mind is the debate over the reality of the first-person character of consciousness.[1] Philosophers on one side of this debate hold that some features of experience are accessible only from a first-person standpoint. Some members of this camp, notably Frank Jackson, have maintained that epiphenomenal properties play roles in consciousness [2]; others, notably John R. Searle, have rejected dualism and regarded mental phenomena as entirely biological.[3] In the opposite camp are philosophers who hold that all mental capacities are in some sense computational - or, more broadly, explainable in terms of features of information processing systems.[4] Consistent with this explanatory agenda, members of this camp normally deny that any aspect of mind is accessible solely from a first-person standpoint. This denial sometimes goes very far - even as far as Dennett's claim that the phenomenology of conscious experience does not really exist</div>
</div><!--entry-->

<div id='_398_entry' class='entry'><span ><span class='name'>Simon, Michael A.</span> (1969). Could there be a conscious automaton?</span> <span class='pub_name'>American Philosophical Quarterly</span> 6 (January):71-78. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20there%20be%20a%20conscious%20automaton%3F+author%3ASimon&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_399_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> &amp; <span class='name'>Chrisley, Ronald L.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("SLOVMA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/519904.html'>Virtual machines and consciousness.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4-5):133-172. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1396750238194514532'>Cited by 26</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Virtual%20machines%20and%20consciousness+author%3ASloman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_399_links")'>More links</a>)</span>
<div id='_399_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOVMA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/sloman02virtual.html">http://citeseer.ist.psu.edu/sloman02virtual.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOVMA",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/cogaff/sloman-chrisley-jcs.pdf">http://www.cs.bham.ac.uk/research/cogaff/sloman-chrisley-jcs.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOVMA",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/cogaff/sloman-chrisley-jcs03.pdf">http://www.cs.bham.ac.uk/research/cogaff/sloman-chrisley-jcs03.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOVMA",this.href,0);return true;' href="http://www.cs.memphis.edu/~franklin/documents/sloman-chrisley-jcs.pdf">http://www.cs.memphis.edu/~franklin/documents/sloman-chrisley-jcs.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOVMA",this.href,0);return true;' href="http://www.msci.memphis.edu/~franklin/documents/sloman-chrisley-jcs.pdf">http://www.msci.memphis.edu/~franklin/documents/sloman-chrisley-jcs.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOVMA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1350">http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1350</a><br></div></div>
</div><!--entry-->

<div id='_400_entry' class='entry'><span ><span class='name'>Smart, J. J. C.</span> (1959). <a rel="nofollow" class='article_title' onclick='trackclick("SMAPZO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(195904)19:5&lt;117:PZOR&gt;2.0.CO;2-Q'>Professor Ziff on robots.</a></span> <span class='pub_name'>Analysis</span> 19 (April):117-118. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13387504973800044696'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Professor%20Ziff%20on%20robots+author%3ASmart&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_401_entry' class='entry'><span ><span class='name'>Smart, Ninian</span> (1959). <a rel="nofollow" class='article_title' onclick='trackclick("SMARI",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(195904)19:5&lt;119:RI&gt;2.0.CO;2-U'>Robots incorporated.</a></span> <span class='pub_name'>Analysis</span> 19 (April):119-120. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18118996956370765068'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots%20incorporated+author%3ASmart&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_402_entry' class='entry'><span ><span class='name'>Stuart, Susan A. J.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("STUMCC",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/jcs/2007/00000014/00000007/art00010'>Machine consciousness: Cognitive and kinaesthetic imagination.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 14 (7):141-153. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1564060652031147083'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20consciousness+author%3AStuart&amp;btnG=Search'>Google</a> | <a href='javascript:show("_402_links")'>More links</a>)</span><div id='_402_abstract' class='extra' style='font-size:12px;'>Abstract: Machine consciousness exists already in organic systems and it is only a matter of time -- and some agreement -- before it will be realised in reverse-engineered organic systems and forward- engineered inorganic systems. The agreement must be over the preconditions that must first be met if the enterprise is to be successful, and it is these preconditions, for instance, being a socially-embedded, structurally-coupled and dynamic, goal-directed entity that organises its perceptual input and enacts its world through the application of both a cognitive and kinaesthetic imagination, that I shall concentrate on presenting in this paper. It will become clear that these preconditions will present engineers with a tall order, but not, I will argue, an impossible one. After all, we might agree with Freeman and NÃºÃ±ez's claim that the machine metaphor has restricted the expectations of the cognitive sciences (Freeman & NÃºÃ±ez, 1999); but it is a double-edged sword, since our limited expectations about machines also narrow the potential of our cognitive science</div>
<div id='_402_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STUMCC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00010">http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00010</a><br></div></div>
</div><!--entry-->

<div id='_403_entry' class='entry'><span ><span class='name'>Stubenberg, Leopold</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("STUWII",this.href,0);return true;' href='http://www.springerlink.com/content/m60825350x345117/fulltext.pdf'>What is it like to be Oscar?</a></span> <span class='pub_name'>Synthese</span> 90 (1):1-26. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2083356193713608359'>Cited by 1</a> | <span class='ll' onclick='$("_403_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20it%20like%20to%20be%20Oscar%3F+author%3AStubenberg&amp;btnG=Search'>Google</a> | <a href='javascript:show("_403_links")'>More links</a>)</span><div id='_403_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that AI systems like Pollock's Oscar needn't be conscious. Blindsight tells us that complex perceptual processing can go on unconsciously.</div></div><div id='_403_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Oscar is going to be the first artificial person â at any rate, he is going to be the first artificial person to be built in Tucson's Philosophy Department. Oscar's creator, John Pollock, maintains that once Oscar is complete he will experience qualia, will be self-conscious, will have desires, fears, intentions, and a full range of mental states (Pollock 1989, pp. ixâx). In this paper I focus on what seems to me to be the most problematical of these claims, viz., that Oscar will experience qualia. I argue that we have not been given sufficient reasons to believe this bold claim. I doubt that Oscar will enjoy qualitative conscious phenomena and I maintain that it will be like nothing to be Oscar</div>
<div id='_403_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STUWII",this.href,0);return true;' href="http://www.springerlink.com/index/M60825350X345117.pdf">http://www.springerlink.com/index/M60825350X345117.pdf</a><br></div></div>
</div><!--entry-->

<div id='_404_entry' class='entry'><span ><span class='name'>Tagliasco, Vincenzo</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("TAGACA",this.href,0);return true;' href='http://www.consciousness.it/manzotti/On Line Papers/artificial-2520consciousness.pdf'>Artificial consciousness: A technological discipline.</a></span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20consciousness+author%3ATagliasco&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_405_entry' class='entry'><span ><span class='name'>Taylor, John G.</span> (2007). Through machine attention to machine consciousness.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Through%20machine%20attention%20to%20machine%20consciousness+author%3ATaylor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_406_entry' class='entry'><span ><span class='name'>Thompson, David L.</span> (1965). <a rel="nofollow" class='article_title' onclick='trackclick("THOCAM",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196505)16:61&lt;33:CAMBC&gt;2.0.CO;2-T'>Can a machine be conscious?</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 16 (May):33-43. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_406_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20a%20machine%20be%20conscious%3F+author%3AThompson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_406_links")'>More links</a>)</span><div id='_406_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Accepting machine consciousness would have few philosophical consequences, whereas rejecting it would tend to commit one to epiphenomenalism.</div></div>
<div id='_406_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOCAM",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196505)16:61&lt;33:CAMBC&gt;2.0.CO;2-T">http://www.jstor.org/sici?sici=0007-0882(196505)16:61<33:CAMBC>2.0.CO;2-T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOCAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/XVI/61/33">http://bjps.oxfordjournals.org/cgi/content/citation/XVI/61/33</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOCAM",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/XVI/61/33">http://bjps.oxfordjournals.org/cgi/reprint/XVI/61/33</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOCAM",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686137.pdf">http://www.jstor.org/stable/pdfplus/686137.pdf</a><br></div></div>
</div><!--entry-->

<div id='_407_entry' class='entry'><span ><span class='name'>Thompson, William I.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("THOTBO",this.href,0);return true;' href='http://imprint.co.uk/pdf/WI_Thompson.pdf'>The Borg or Borges?</a></span> In Owen Holland (ed.), <em>Machine Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13723835170213213415'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Borg%20or%20Borges%3F+author%3AThompson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_407_links")'>More links</a>)</span>
<div id='_407_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOTBO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1352">http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1352</a><br></div></div>
</div><!--entry-->

<div id='_408_entry' class='entry'><span ><span class='name'>Torrance, Steve</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("TORTCO-2",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/jcs/2007/00000014/00000007/art00011'>Two conceptions of machine phenomenality.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 14 (7):154-166. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=23337006900530965'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Two%20conceptions%20of%20machine%20phenomenality+author%3ATorrance&amp;btnG=Search'>Google</a> | <a href='javascript:show("_408_links")'>More links</a>)</span><div id='_408_abstract' class='extra' style='font-size:12px;'>Abstract: Current approaches to machine consciousness (MC) tend to offer a range of characteristic responses to critics of the enterprise. Many of these responses seem to marginalize phenomenal consciousness, by presupposing a 'thin' conception of phenomenality. This conception is, we will argue, largely shared by anti- computationalist critics of MC. On the thin conception, physiological or neural or functional or organizational features are secondary accompaniments to consciousness rather than primary components of consciousness itself. We outline an alternative, 'thick' conception of phenomenality. This shows some signposts in the direction of a more adequate approach to MC</div>
<div id='_408_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TORTCO-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00011">http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00011</a><br></div></div>
</div><!--entry-->

<div id='_409_entry' class='entry'><span ><span class='name'>Tson, M. E.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("TSOFDT",this.href,0);return true;' href='http://philpapers.org/archive/TSOFDT'>From Dust to Descartes: A Mechanical and Evolutionary Explanation of Consciousness and Self-Awareness.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20Dust%20to%20Descartes+author%3ATson&amp;btnG=Search'>Google</a>)</span><div id='_409_abstract' class='extra' style='font-size:12px;'>Abstract:       Beginning with physical reactions as simple and mechanical as rust, From Dust to Descartes goes step by evolutionary step to explore how the most remarkable and personal aspects of consciousness have arisen, how our awareness of the world of ourselves differs from that of other species, and whether machines could ever become self-aware.   
     Part I addresses a newbornâs innate abilities.  Part II shows how with these and experience, we can form expectations about the world.  Parts III concentrates on the essential role that others play in the formation of self-awareness.  Part IV then explores what follows from this explanation of human consciousness, touching on topics such as free will, personality, intelligence, and color perception which are often associated with self-awareness and the philosophy of mind.

</div>
</div><!--entry-->

<div id='_410_entry' class='entry'><span ><span class='name'>van de Vete, D.</span> (1971). The problem of robot consciousness.</span> <span class='pub_name'>Philosophy and Phenomenological Research</span> 32:149-65. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20problem%20of%20robot%20consciousness+author%3Avan%20de%20Vete&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_411_entry' class='entry'><span ><span class='name'>Wallace, Rodrick</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("WALPIB",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/mm/2006/00000004/00000001/art00004'>Pitfalls in biological computing: Canonical and idiosyncratic dysfunction of conscious machines.</a></span> <span class='pub_name'>Mind and Matter</span> 4 (1):91-113. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2010803715944641283'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Pitfalls%20in%20biological%20computing+author%3AWallace&amp;btnG=Search'>Google</a> | <a href='javascript:show("_411_links")'>More links</a>)</span><div id='_411_abstract' class='extra' style='font-size:12px;'>Abstract: The central paradigm of arti?cial intelligence is rapidly shifting toward biological models for both robotic devices and systems performing such critical tasks as network management, vehicle navigation, and process control. Here we use a recent mathematical analysis of the necessary conditions for consciousness in humans to explore likely failure modes inherent to a broad class of biologically inspired computing machines. Analogs to developmental psychopathology, in which regulatory mechanisms for consciousness fail progressively and subtly understress, and toinattentional blindness, where a narrow 'syntactic band pass' de?ned by the rate distortion manifold of conscious attention results in pathological ?xation, seem inevitable. Similar problems are likely to confront other possible architectures, although their mathematical description may be far less straightforward. Computing devices constructed on biological paradigms will inevitably lack the elaborate, but poorly understood, system of control mechanisms which has evolved over the last few hundred million years to stabilize consciousness in higher animals. This will make such machines prone to insidious degradation, and, ultimately, catastrophic failure</div>
<div id='_411_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WALPIB",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/mm/2006/00000004/00000001/art00004">http://www.ingentaconnect.com/content/imp/mm/2006/00000004/00000001/art00004</a><br></div></div>
</div><!--entry-->

<div id='_412_entry' class='entry'><span ><span class='name'>Ziff, P.</span> (1959). <a rel="nofollow" class='article_title' onclick='trackclick("ZIFTFO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(195901)19:3&lt;64:TFOR&gt;2.0.CO;2-Z'>The feelings of robots.</a></span> <span class='pub_name'>Analysis</span> 19 (January):64-68. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2578816124654208197'>Cited by 11</a> | <span class='ll' onclick='$("_412_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20feelings%20of%20robots+author%3AZiff&amp;btnG=Search'>Google</a>)</span><div id='_412_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Of course robots can't think: they're not alive, so this gives us good reason not to rely on behavior. With replies by J.J.C. Smart, N. Smart.</div></div>
</div><!--entry-->
</div>
<p><a name='.6.1e'></a><a name=''></a><span class='myh3'>6.1e Machine Mentality, Misc</span></p>

<div id='cat_6.1e' class='cat_content'>
<div id='__new_entries_6.1e__'></div><div id='__new_entry_6.1e__' class='entry'></div>
<div id='_413_entry' class='entry'><span ><span class='name'>Albritton, Rogers</span> (1964). Comments on Hilary Putnam's robots: Machines or artificially created life.</span> <span class='pub_name'>Journal of Philosophy</span> 61 (November):691-694. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Comments%20on%20Hilary%20Putnam%27s%20robots+author%3AAlbritton&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_414_entry' class='entry'><span ><span class='name'>Ashby, W. R.</span> (1947). <a rel="nofollow" class='article_title' onclick='trackclick("ASHTNS",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0026-4423(194701)2:56:221&lt;44:TNSAPM&gt;2.0.CO;2-U'>The nervous system as physical machine: With special reference to the origin of adaptive behaviour.</a></span> <span class='pub_name'>Mind</span> 56 (January):44-59. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5626733018218957934'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20nervous%20system%20as%20physical%20machine+author%3AAshby&amp;btnG=Search'>Google</a> | <a href='javascript:show("_414_links")'>More links</a>)</span>
<div id='_414_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ASHTNS",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(194701)2:56:221&lt;44:TNSAPM&gt;2.0.CO;2-U">http://www.jstor.org/sici?sici=0026-4423(194701)2:56:221<44:TNSAPM>2.0.CO;2-U</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ASHTNS",this.href,0);return true;' href="http://mind.oxfordjournals.org/cgi/reprint/LVI/221/44">http://mind.oxfordjournals.org/cgi/reprint/LVI/221/44</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ASHTNS",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2250675.pdf">http://www.jstor.org/stable/pdfplus/2250675.pdf</a><br></div></div>
</div><!--entry-->

<div id='_415_entry' class='entry'><span ><span class='name'>Beisecker, David</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("BEIDOO",this.href,0);return true;' href='http://www.springerlink.com/content/3m13835807176130/fulltext.pdf'>Dennett's overlooked originality.</a></span> <span class='pub_name'>Minds and Machines</span> 16 (1):43-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dennett%27s%20overlooked%20originality+author%3ABeisecker&amp;btnG=Search'>Google</a> | <a href='javascript:show("_415_links")'>More links</a>)</span><div id='_415_abstract' class='extra' style='font-size:12px;'>Abstract:  No philosopher has worked harder than Dan Dennett to set the possibility of machine mentality on firm philosophical footing. Dennettâs defense of this possibility has both a positive and a negative thrust. On the positive side, he has developed an account of mental activity that is tailor-made for the attribution of intentional states to purely mechanical contrivances, while on the negative side, he pillories as mystery mongering and skyhook grasping any attempts to erect barriers to the conception of machine mentality by excavating gulfs to keep us âbona fideâ thinkers apart from the rest of creation. While I think heâs âwonâ the rhetorical tilts with his philosophical adversaries, I worry that Dennettâs negative side sometimes gets the better of him, and that this obscures advances that can be made on the positive side of his program. In this paper, I show that Dennett is much too dismissive of original intentionality in particular, and that this notion can be put to good theoretical use after all. Though deployed to distinguish different grades of mentality, it can (and should) be incorporated into a philosophical account of the mind that is recognizably Dennettian in spirit</div>
<div id='_415_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BEIDOO",this.href,0);return true;' href="http://www.springerlink.com/index/3M13835807176130.pdf">http://www.springerlink.com/index/3M13835807176130.pdf</a><br></div></div>
</div><!--entry-->

<div id='_416_entry' class='entry'><span ><span class='name'>Beloff, John</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("BELMOM",this.href,0);return true;' href='http://www.leaderu.com/truth/2truth04.html'>Minds or machines.</a></span> <span class='pub_name'>Truth Journal</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10945736459434181551'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%20or%20machines+author%3ABeloff&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_417_entry' class='entry'><span ><span class='name'>Boden, Margaret A.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("BODCAR",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=216361'>Could a robot be creative--and would we know?</a></span> In <em>Android Epistemology</em>. Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=166156227431996660'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20a%20robot%20be%20creative--and%20would%20we%20know%3F+author%3ABoden&amp;btnG=Search'>Google</a> | <a href='javascript:show("_417_links")'>More links</a>)</span>
<div id='_417_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BODCAR",this.href,0);return true;' href="http://kogs-www.informatik.uni-hamburg.de/~neumann/Denkmaschinen-SS-2005/Vortrag-14.6.05.pdf">http://kogs-www.informatik.uni-hamburg.de/~neumann/Denkmaschinen-SS-2005/Vortrag-14.6.05.pdf</a><br></div></div>
</div><!--entry-->

<div id='_418_entry' class='entry'><span ><span class='name'>Boden, Margaret A.</span> (1969). <a rel="nofollow" class='article_title' onclick='trackclick("BODMP",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8094(196901)19:74&lt;33:MP&gt;2.0.CO;2-L'>Machine perception.</a></span> <span class='pub_name'>Philosophical Quarterly</span> 19 (January):33-45. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11967379126579408327'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20perception+author%3ABoden&amp;btnG=Search'>Google</a> | <a href='javascript:show("_418_links")'>More links</a>)</span>
<div id='_418_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BODMP",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8094(196901)19:74&lt;33:MP&gt;2.0.CO;2-L">http://www.jstor.org/sici?sici=0031-8094(196901)19:74<33:MP>2.0.CO;2-L</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BODMP",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2218186.pdf">http://www.jstor.org/stable/pdfplus/2218186.pdf</a><br></div></div>
</div><!--entry-->

<div id='_419_entry' class='entry'><span ><span class='name'>Bostrom, Nick</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("BOSTIM",this.href,0);return true;' href='http://www.nickbostrom.com/2050/reply.html'>Taking intelligent machines seriously: Reply to critics.</a></span> <span class='pub_name'>Futures</span> 35 (8):901-906. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Taking%20intelligent%20machines%20seriously+author%3ABostrom&amp;btnG=Search'>Google</a> | <a href='javascript:show("_419_links")'>More links</a>)</span><div id='_419_abstract' class='extra' style='font-size:12px;'>Abstract: In an earlier paper in this journal[1], I sought to defend the claims that (1) substantial probability should be assigned to the hypothesis that machines will outsmart humans within 50 years, (2) such an event would have immense ramifications for many important areas of human concern, and that consequently (3) serious attention should be given to this scenario. Here, I will address a number of points made by several commentators</div>
<div id='_419_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSTIM",this.href,0);return true;' href="http://www.questia.com/PM.qst?a=o&amp;se=gglsc&amp;d=5002030442">http://www.questia.com/PM.qst?a=o&se=gglsc&d=5002030442</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSTIM",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S0016328703000466">http://linkinghub.elsevier.com/retrieve/pii/S0016328703000466</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSTIM",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/00163287/2003/00000035/00000008/art00046">http://www.ingentaconnect.com/content/els/00163287/2003/00000035/00000008/art00046</a><br></div></div>
</div><!--entry-->

<div id='_420_entry' class='entry'><span ><span class='name'>Brey, Philip</span> (2001). Hubert Dreyfus: Humans versus computers.</span> In <em>American Philosophy of Technology: The Empirical Turn</em>. Bloomington: Indiana University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6694011902874191704'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Hubert%20Dreyfus+author%3ABrey&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_421_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("BRICIN",this.href,0);return true;' href='http://citeseer.ist.psu.edu/23981.html'>Cognition is not computation: The argument from irreversibility.</a></span> <span class='pub_name'>Synthese</span> 113 (2):285-320. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14357442720678845790'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognition%20is%20not%20computation+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_421_links")'>More links</a>)</span><div id='_421_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The dominant scientific and philosophical view of the mind â according to which, put starkly, cognition is computation â is refuted herein, via specification and defense of the following new argument: Computation is reversible; cognition isn't; ergo, cognition isn't computation. After presenting a sustained dialectic arising from this defense, we conclude with a brief preview of the view we would put in place of the cognition-is-computation doctrine</div>
<div id='_421_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICIN",this.href,0);return true;' href="http://www.rpi.edu/~brings/SELPAP/irr.ps">http://www.rpi.edu/~brings/SELPAP/irr.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICIN",this.href,0);return true;' href="http://www.rpi.edu/~brings/SELPAP/irr.pdf">http://www.rpi.edu/~brings/SELPAP/irr.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICIN",this.href,0);return true;' href="http://citeseer.ist.psu.edu/bringsjord96cognition.html">http://citeseer.ist.psu.edu/bringsjord96cognition.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICIN",this.href,0);return true;' href="http://www.springerlink.com/content/n887505850j434ur/fulltext.pdf">http://www.springerlink.com/content/n887505850j434ur/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICIN",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=152330&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=152330&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICIN",this.href,0);return true;' href="http://www.springerlink.com/index/N887505850J434UR.pdf">http://www.springerlink.com/index/N887505850J434UR.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRICIN",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/synt/1997/00000113/00000002/00152330">http://www.ingentaconnect.com/content/klu/synt/1997/00000113/00000002/00152330</a><br></div></div>
</div><!--entry-->

<div id='_422_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("BRIPO_",this.href,0);return true;' href='http://www.rpi.edu/~brings/precis.wrccb.html'>Precis of <em>What Robots Can and Can't Be</em>.</a></span> <span class='pub_name'>Psycholoquy</span> 5 (59). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3592823210063849857'>Cited by 22</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Precis%20of%20What%20Robots%20Can%20and%20Can%27t%20Be+author%3ABringsjord&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_423_entry' class='entry'><span ><span class='name'>Bunge, Mario</span> (1956). <a rel="nofollow" class='article_title' onclick='trackclick("BUNDCT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(195608)7:26&lt;139:DCT(&gt;2.0.CO;2-T'>Do computers think? (I).</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 7 (26):139-148. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 1 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Do%20computers%20think%3F%20%28I%29+author%3ABunge&amp;btnG=Search'>Google</a> | <a href='javascript:show("_423_links")'>More links</a>)</span>
<div id='_423_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(195608)7:26&lt;139:DCT(&gt;2.0.CO;2-T">http://www.jstor.org/sici?sici=0007-0882(195608)7:26<139:DCT(>2.0.CO;2-T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(195611)7:27&lt;212:DCT(&gt;2.0.CO;2-N">http://www.jstor.org/sici?sici=0007-0882(195611)7:27<212:DCT(>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/VII/26/139">http://bjps.oxfordjournals.org/cgi/reprint/VII/26/139</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685697.pdf">http://www.jstor.org/stable/pdfplus/685697.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685873.pdf">http://www.jstor.org/stable/pdfplus/685873.pdf</a><br></div></div>
</div><!--entry-->

<div id='_424_entry' class='entry'><span ><span class='name'>Bunge, Mario</span> (1956). <a rel="nofollow" class='article_title' onclick='trackclick("BUNDCT-2",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(195611)7:27&lt;212:DCT(&gt;2.0.CO;2-N'>Do computers think? (II).</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 7 (27):212-219. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Do%20computers%20think%3F%20%28II%29+author%3ABunge&amp;btnG=Search'>Google</a> | <a href='javascript:show("_424_links")'>More links</a>)</span>
<div id='_424_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT-2",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(195608)7:26&lt;139:DCT(&gt;2.0.CO;2-T">http://www.jstor.org/sici?sici=0007-0882(195608)7:26<139:DCT(>2.0.CO;2-T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT-2",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(195611)7:27&lt;212:DCT(&gt;2.0.CO;2-N">http://www.jstor.org/sici?sici=0007-0882(195611)7:27<212:DCT(>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT-2",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/VII/27/212">http://bjps.oxfordjournals.org/cgi/reprint/VII/27/212</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT-2",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685697.pdf">http://www.jstor.org/stable/pdfplus/685697.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUNDCT-2",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685873.pdf">http://www.jstor.org/stable/pdfplus/685873.pdf</a><br></div></div>
</div><!--entry-->

<div id='_425_entry' class='entry'><span ><span class='name'>Burks, Arthur W.</span> (1973). <a rel="nofollow" class='article_title' onclick='trackclick("BURLCA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0065-972X(1972/1973)46&lt;39:LCAM&gt;2.0.CO;2-G'>Logic, computers, and men.</a></span> <span class='pub_name'>Proceedings and Addresses of the American Philosophical Association</span> 46:39-57. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16604405491622123609'>Cited by 4</a> | <span class='ll' onclick='$("_425_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Logic%2C%20computers%2C%20and%20men+author%3ABurks&amp;btnG=Search'>Google</a>)</span><div id='_425_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Arguing that a finite deterministic automaton can perform all natural human functions. With remarks on the logical organization of computers.</div></div>
</div><!--entry-->

<div id='_426_entry' class='entry'><span ><span class='name'>Campbell, Richmond M.</span> &amp; <span class='name'>Rosenberg, Alexander</span> (1973). <a rel="nofollow" class='article_title' onclick='trackclick("CAMAPA-2",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8248(197312)40:4&lt;547:APACAT&gt;2.0.CO;2-S'>Action, purpose, and consciousness among the computers.</a></span> <span class='pub_name'>Philosophy of Science</span> 40 (December):547-557. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Action%2C%20purpose%2C%20and%20consciousness%20among%20the%20computers+author%3ACampbell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_426_links")'>More links</a>)</span>
<div id='_426_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMAPA-2",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8248(197312)40:4&lt;547:APACAT&gt;2.0.CO;2-S">http://www.jstor.org/sici?sici=0031-8248(197312)40:4<547:APACAT>2.0.CO;2-S</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMAPA-2",this.href,0);return true;' href="http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288564">http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288564</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CAMAPA-2",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/186287.pdf">http://www.jstor.org/stable/pdfplus/186287.pdf</a><br></div></div>
</div><!--entry-->

<div id='_427_entry' class='entry'><span ><span class='name'>Casey, Gerard</span> (1992). Minds and machines.</span> <span class='pub_name'>American Catholic Philosophical Quarterly</span> 66 (1):57-80. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7060153700866399172'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%20and%20machines+author%3ACasey&amp;btnG=Search'>Google</a>)</span><div id='_427_abstract' class='extra' style='font-size:12px;'>Abstract: The emergence of electronic computers in the last thirty years has given rise to many interesting questions. Many of these questions are technical, relating to a machineâs ability to perform complex operations in a variety of circumstances. While some of these questions are not without philosophical interest, the one question which above all others has stimulated philosophical interest is explicitly non-technical and it can be expressed crudely as follows: Can a machine be said to think and, if so, in what sense? The issue has received much attention in the scholarly journals with articles and arguments appearing in great profusion, some resolutely answering this question in the affirmative, some, equally resolutely, answering this question in the negative, and others manifesting modified rapture. While the ramifications of the question are enormous I believe that the issue at the heart of the matter has gradually emerged from the forest of complications</div>
</div><!--entry-->

<div id='_428_entry' class='entry'><span ><span class='name'>Cherry, Christopher</span> (1991). Machines as persons? - I.</span> In <em>Human Beings</em>. New York: Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machines%20as%20persons%3F%20-%20I+author%3ACherry&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_429_entry' class='entry'><span ><span class='name'>Cohen, L. Jonathan</span> (1955). <a rel="nofollow" class='article_title' onclick='trackclick("COHCTB",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(195512)16:2&lt;36:CTBAM&gt;2.0.CO;2-O'>Can there be artificial minds?</a></span> <span class='pub_name'>Analysis</span> 16 (December):36-41. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15081195989274167692'>Cited by 3</a> | <span class='ll' onclick='$("_429_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20there%20be%20artificial%20minds%3F+author%3ACohen&amp;btnG=Search'>Google</a>)</span><div id='_429_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Subservience to known or knowable rules is incompatible with mentality.</div></div>
</div><!--entry-->

<div id='_430_entry' class='entry'><span ><span class='name'>Collins, Harry M.</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("COLRTS",this.href,0);return true;' href='http://www.springerlink.com/content/w6vp1135100t4555/fulltext.pdf'>Response to Selinger on Dreyfus.</a></span> <span class='pub_name'>Phenomenology and the Cognitive Sciences</span> 7 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Response%20to%20Selinger%20on%20Dreyfus+author%3ACollins&amp;btnG=Search'>Google</a> | <a href='javascript:show("_430_links")'>More links</a>)</span><div id='_430_abstract' class='extra' style='font-size:12px;'>Abstract: My claim is clear and unambiguous: no machine will pass a well-designed Turing Test unless we find some means of embedding it in lived social life. We have no idea how to do this but my argument, and all our evidence, suggests that it will not be a necessary condition that the machine have more than a minimal body. Exactly how minimal is still being worked out</div>
<div id='_430_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLRTS",this.href,0);return true;' href="http://www.springerlink.com/index/w6vp1135100t4555.pdf">http://www.springerlink.com/index/w6vp1135100t4555.pdf</a><br></div></div>
</div><!--entry-->

<div id='_431_entry' class='entry'><span ><span class='name'>Copeland, B. Jack</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("COPNVW",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(200001)97:1&lt;5:NVWMIA&gt;2.0.CO;2-U'>Narrow versus wide mechanism: Including a re-examination of Turing's views on the mind-machine issue.</a></span> <span class='pub_name'>Journal of Philosophy</span> 97 (1):5-33. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=425311566655771641'>Cited by 42</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Narrow%20versus%20wide%20mechanism+author%3ACopeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_431_links")'>More links</a>)</span>
<div id='_431_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPNVW",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(200001)97:1&lt;5:NVWMIA&gt;2.0.CO;2-U">http://www.jstor.org/sici?sici=0022-362X(200001)97:1<5:NVWMIA>2.0.CO;2-U</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPNVW",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2678472.pdf">http://www.jstor.org/stable/pdfplus/2678472.pdf</a><br></div></div>
</div><!--entry-->

<div id='_432_entry' class='entry'><span ><span class='name'>Dayre, Kenneth M.</span> (1968). Intelligence, bodies, and digital computers.</span> <span class='pub_name'>Review of Metaphysics</span> 21 (June):714-723. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intelligence%2C%20bodies%2C%20and%20digital%20computers+author%3ADayre&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_433_entry' class='entry'><span ><span class='name'>Dembski, William A.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("DEMAWS",this.href,0);return true;' href='http://www.designinference.com/documents/1999.10.spiritual_machines.htm'>Are we spiritual machines?</a></span> <span class='pub_name'>First Things</span> 96:25-31. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Are%20we%20spiritual%20machines%3F+author%3ADembski&amp;btnG=Search'>Google</a>)</span><div id='_433_abstract' class='extra' style='font-size:12px;'>Abstract: For two hundred years materialist philosophers have argued that man is some sort of machine. The claim began with French materialists of the Enlightenment such as Pierre Cabanis, Julien La Mettrie, and Baron dâHolbach (La Mettrie even wrote a book titled Man the Machine). Likewise contemporary materialists like Marvin Minsky, Daniel Dennett, and Patricia Churchland claim that the motions and modifications of matter are sufficient to account for all human experiences, even our interior and cognitive ones. Whereas the Enlightenment philosophes might have thought of humans in terms of gear mechanisms and fluid flows, contemporary materialists think of humans in terms of neurological systems and computational devices. The idiom has been updated, but the underlying impulse to reduce mind to matter remains unchanged</div>
</div><!--entry-->

<div id='_434_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1984). Can machines think?</span> In M. G. Shafto (ed.), <em>How We Know</em>. Harper & Row. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4590289152323472424'>Cited by 24</a> | <span class='ll' onclick='$("_434_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20machines%20think%3F+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_434_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Defending the Turing test as a good test for intelligence.</div></div>
</div><!--entry-->

<div id='_435_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("DENDHC",this.href,0);return true;' href='http://ase.tufts.edu/cogstud/papers/didhal.htm'>Did Hal committ murder?</a></span> In D. Stork (ed.), <em>Hal's Legacy: 2001's Computer As Dream and Reality</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Did%20Hal%20committ%20murder%3F+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_435_abstract' class='extra' style='font-size:12px;'>Abstract: The first robot homicide was committed in 1981, according to my files. I have a yellowed clipping dated 12/9/81 from the Philadelphia Inquirer--not the National Enquirer--with the headline: Robot killed repairman, Japan reports The story was an anti-climax: at the Kawasaki Heavy Industries plant in Akashi, a malfunctioning robotic arm pushed a repairman against a gearwheel-milling machine, crushing him to death. The repairman had failed to follow proper instructions for shutting down the arm before entering the workspace. Why, indeed, had this industrial accident in Japan been reported in a Philadelphia newspaper? Every day somewhere in the world a human worker is killed by one machine or another. The difference, of course, was that in the public imagination at least, this was no ordinary machine; this was a robot, a machine that might have a mind, might have evil intentions, might be capable not just of homicide but of murder</div>
</div><!--entry-->

<div id='_436_entry' class='entry'><span ><span class='name'>Dretske, Fred</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("DRECIB",this.href,0);return true;' href='http://www.jstor.org/stable/4320430'>Can intelligence be artificial?</a></span> <span class='pub_name'>Philosophical Studies</span> 71 (2):201-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5548240408407354458'>Cited by 3</a> | <span class='ll' onclick='$("_436_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20intelligence%20be%20artificial%3F+author%3ADretske&amp;btnG=Search'>Google</a> | <a href='javascript:show("_436_links")'>More links</a>)</span><div id='_436_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Intelligence requires not just action or thought, but the governance of action by thought, which requires a history. "Wired-up" systems lack the explanatory connection between thought and action, so are not intelligent.</div></div>
<div id='_436_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DRECIB",this.href,0);return true;' href="http://www.springerlink.com/index/X3345068024H5002.pdf">http://www.springerlink.com/index/X3345068024H5002.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DRECIB",this.href,0);return true;' href="http://www.springerlink.com/content/x3345068024h5002/fulltext.pdf">http://www.springerlink.com/content/x3345068024h5002/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_437_entry' class='entry'><span ><span class='name'>Dretske, Fred</span> (1985). <a rel="nofollow" class='article_title' onclick='trackclick("DREMAT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0065-972X(198509)59:1&lt;23:MATM&gt;2.0.CO;2-2'>Machines and the mental.</a></span> <span class='pub_name'>Proceedings and Addresses of the American Philosophical Association</span> 59 (1):23-33. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11085149857954219227'>Cited by 27</a> | <span class='ll' onclick='$("_437_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machines%20and%20the%20mental+author%3ADretske&amp;btnG=Search'>Google</a>)</span><div id='_437_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Machines can't even add, let alone think, as the symbols they use aren't meaningful to them. They would need real information based on perceptual embodiment, and conceptual capacities, for meaning to play a real role.</div></div>
</div><!--entry-->

<div id='_438_entry' class='entry'><span ><span class='name'>Drexler, Eric</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("DRETM",this.href,0);return true;' href='http://www.kurzweilai.net/articles/art0122.html?printable=1'>Thinking machines.</a></span> In <em>Engines of Creation</em>. Fourth Estate. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1866707711737175902'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Thinking%20machines+author%3ADrexler&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_439_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> (1972). <em><span class='pub_name'>What Computers Can't Do.</span></em></span> Harper and Row. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13222673920320623828'>Cited by 847</a> | <span class='ll' onclick='$("_439_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20Computers%20Can%27t%20Do+author%3ADreyfus&amp;btnG=Search'>Google</a>)</span><div id='_439_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Computers follow rules, people don't.</div></div>
</div><!--entry-->

<div id='_440_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> (1967). Why computers must have bodies in order to be intelligent.</span> <span class='pub_name'>Review of Metaphysics</span> 21 (September):13-32. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7543539869596777001'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20computers%20must%20have%20bodies%20in%20order%20to%20be%20intelligent+author%3ADreyfus&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_441_entry' class='entry'><span ><span class='name'>Drozdek, Adam</span> (1993). Computers and the mind-body problem: On ontological and epistemological dualism.</span> <span class='pub_name'>Idealistic Studies</span> 23 (1):39-48. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computers%20and%20the%20mind-body%20problem+author%3ADrozdek&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_442_entry' class='entry'><span ><span class='name'>Endicott, Ronald P.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("ENDSSA",this.href,0);return true;' href='http://philpapers.org/archive/ENDSSA'>Searle, syntax, and observer-relativity.</a></span> <span class='pub_name'>Canadian Journal of Philosophy</span> 26 (1):101-22. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=745211723075385633'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searle%2C%20syntax%2C%20and%20observer-relativity+author%3AEndicott&amp;btnG=Search'>Google</a>)</span><div id='_442_abstract' class='extra' style='font-size:12px;'>Abstract: I critically examine some provocative arguments that John Searle presents in his book The Rediscovery of Mind to support the claim that the syntactic states of a classical computational system are &quot;observer relative&quot; or &quot;mind dependent&quot; or otherwise less than fully and objectively real. I begin by explaining how this claim differs from Searle's earlier and more well-known claim that the physical states of a machine, including the syntactic states, are insufficient to determine its semantics. In contrast, his more recent claim concerns the syntax, in particular, whether a machine actually has symbols to underlie its semantics. I then present and respond to a number of arguments that Searle offers to support this claim, including whether machine symbols are observer relative because the assignment of syntax is arbitrary, or linked to universal realizability, or linked to the sub-personal interpretive acts of a homunculus, or linked to a person's consciousness. I conclude that a realist about the computational model need not be troubled by such arguments. Their key premises need further support.</div>
</div><!--entry-->

<div id='_443_entry' class='entry'><span ><span class='name'>Fisher, Mark</span> (1983). <a rel="nofollow" class='article_title' onclick='trackclick("FISANO",this.href,0);return true;' href='http://www.springerlink.com/content/657443w258453806/fulltext.pdf'>A note on free will and artificial intelligence.</a></span> <span class='pub_name'>Philosophia</span> 13 (September):75-80. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20note%20on%20free%20will%20and%20artificial%20intelligence+author%3AFisher&amp;btnG=Search'>Google</a> | <a href='javascript:show("_443_links")'>More links</a>)</span>
<div id='_443_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FISANO",this.href,0);return true;' href="http://www.springerlink.com/index/657443W258453806.pdf">http://www.springerlink.com/index/657443W258453806.pdf</a><br></div></div>
</div><!--entry-->

<div id='_444_entry' class='entry'><span ><span class='name'>Fozzy, P. J.</span> (1963). <a rel="nofollow" class='article_title' onclick='trackclick("FOZPMO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196308)14:54&lt;154:PMOM&gt;2.0.CO;2-6'>Professor MacKay on machines.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 14 (August):154-156. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Professor%20MacKay%20on%20machines+author%3AFozzy&amp;btnG=Search'>Google</a> | <a href='javascript:show("_444_links")'>More links</a>)</span>
<div id='_444_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FOZPMO",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196308)14:54&lt;154:PMOM&gt;2.0.CO;2-6">http://www.jstor.org/sici?sici=0007-0882(196308)14:54<154:PMOM>2.0.CO;2-6</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FOZPMO",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/XIV/54/154">http://bjps.oxfordjournals.org/cgi/content/citation/XIV/54/154</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FOZPMO",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/XIV/54/154">http://bjps.oxfordjournals.org/cgi/reprint/XIV/54/154</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FOZPMO",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685434.pdf">http://www.jstor.org/stable/pdfplus/685434.pdf</a><br></div></div>
</div><!--entry-->

<div id='_445_entry' class='entry'><span ><span class='name'>Friedland, Julian</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("FRIWAT",this.href,0);return true;' href='http://www.blackwell-synergy.com/links/doi/10.1111/j.1467-9205.2005.00250.x/abs/'>Wittgenstein and the aesthetic robot's handicap.</a></span> <span class='pub_name'>Philosophical Investigations</span> 28 (2):177-192. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Wittgenstein%20and%20the%20aesthetic%20robot%27s%20handicap+author%3AFriedland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_445_links")'>More links</a>)</span>
<div id='_445_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRIWAT",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-9205.2005.00250.x">http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-9205.2005.00250.x</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRIWAT",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/118651665/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/118651665/PDFSTART</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRIWAT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/phin/2005/00000028/00000002/art00004">http://www.ingentaconnect.com/content/bpl/phin/2005/00000028/00000002/art00004</a><br></div></div>
</div><!--entry-->

<div id='_446_entry' class='entry'><span ><span class='name'>Fulton, James S.</span> (1957). Computing machines and minds.</span> <span class='pub_name'>Personalist</span> 38:62-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computing%20machines%20and%20minds+author%3AFulton&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_447_entry' class='entry'><span ><span class='name'>Gaglio, Salvatore</span> (2007). Intelligent artificial systems.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intelligent%20artificial%20systems+author%3AGaglio&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_448_entry' class='entry'><span ><span class='name'>Gams, Matjaz</span> (ed.) (1997). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("GAMMVC",this.href,0);return true;' href='http://books.google.com/books?id=VHZy4j_Qa-cC&amp;printsec=front_cover'>Mind Versus Computer: Were Dreyfus and Winograd Right?</a></span></em></span> Amsterdam: IOS Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14330898748231259632'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%20Versus%20Computer+author%3AGams&amp;btnG=Search'>Google</a> | <a href='javascript:show("_448_links")'>More links</a>)</span>
<div id='_448_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAMMVC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=294029">http://portal.acm.org/citation.cfm?id=294029</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAMMVC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=SERIES9545.294029">http://portal.acm.org/citation.cfm?id=SERIES9545.294029</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAMMVC",this.href,0);return true;' href="http://ai.ijs.si/mezi/kopija231/STARI_PC/USR/INFORM/Vol21/Book/BOOK_97.PS">http://ai.ijs.si/mezi/kopija231/STARI_PC/USR/INFORM/Vol21/Book/BOOK_97.PS</a><br></div></div>
</div><!--entry-->

<div id='_449_entry' class='entry'><span ><span class='name'>Gauld, Alan</span> (1966). <a rel="nofollow" class='article_title' onclick='trackclick("GAUCAM",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196605)17:1&lt;44:CAMP&gt;2.0.CO;2-K'>Could a machine perceive?</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 17 (May):44-58. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3415530415804551221'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20a%20machine%20perceive%3F+author%3AGauld&amp;btnG=Search'>Google</a> | <a href='javascript:show("_449_links")'>More links</a>)</span>
<div id='_449_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAUCAM",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196605)17:1&lt;44:CAMP&gt;2.0.CO;2-K">http://www.jstor.org/sici?sici=0007-0882(196605)17:1<44:CAMP>2.0.CO;2-K</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAUCAM",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686403.pdf">http://www.jstor.org/stable/pdfplus/686403.pdf</a><br></div></div>
</div><!--entry-->

<div id='_450_entry' class='entry'><span ><span class='name'>Gogol, Daniel</span> (1970). <a rel="nofollow" class='article_title' onclick='trackclick("GOGDAT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8205(197003)30:3&lt;455:DATPM&gt;2.0.CO;2-C'>Determinism and the predicting machine.</a></span> <span class='pub_name'>Philosophy and Phenomenological Research</span> 30 (March):455-456. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Determinism%20and%20the%20predicting%20machine+author%3AGogol&amp;btnG=Search'>Google</a> | <a href='javascript:show("_450_links")'>More links</a>)</span>
<div id='_450_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOGDAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8205(197003)30:3&lt;455:DATPM&gt;2.0.CO;2-C">http://www.jstor.org/sici?sici=0031-8205(197003)30:3<455:DATPM>2.0.CO;2-C</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOGDAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2105612.pdf">http://www.jstor.org/stable/pdfplus/2105612.pdf</a><br></div></div>
</div><!--entry-->

<div id='_451_entry' class='entry'><span ><span class='name'>Goldkind, Stuart</span> (1982). Machines and mistakes.</span> <span class='pub_name'>Ratio</span> 24 (December):173-184. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=52024094058007409'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machines%20and%20mistakes+author%3AGoldkind&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_452_entry' class='entry'><span ><span class='name'>Goldberg, Sanford C.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("GOLTVI",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596707.596762'>The very idea of computer self-knowledge and self-deception.</a></span> <span class='pub_name'>Minds and Machines</span> 7 (4):515-529. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12899995901298028914'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20very%20idea%20of%20computer%20self-knowledge%20and%20self-deception+author%3AGoldberg&amp;btnG=Search'>Google</a> | <a href='javascript:show("_452_links")'>More links</a>)</span><div id='_452_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Do computers have beliefs? I argue that anyone who answers in the affirmative holds a view that is incompatible with what I shall call the commonsense approach to the propositional attitudes. My claims shall be two. First,the commonsense view places important constraints on what can be acknowledged as a case of having a belief. Second, computers â at least those for which having a belief would be conceived as having a sentence in a belief box â fail to satisfy some of these constraints. This second claim can best be brought out in the context of an examination of the idea of computer self-knowledge and self-deception, but the conclusion is perfectly general: the idea that computers are believers, like the idea that computers could have self-knowledge or be self-deceived, is incompatible with the commonsense view. The significance of the argument lies in the choice it forces on us: whether to revise our notion of belief so as to accommodate the claim that computers are believers, or to give up on that claim so as to preserve our pretheoretic notion of the attitudes. We cannot have it both ways</div>
<div id='_452_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOLTVI",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=316238CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=316238CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOLTVI",this.href,0);return true;' href="http://www.springerlink.com/content/x67006n334r1n383/fulltext.pdf">http://www.springerlink.com/content/x67006n334r1n383/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOLTVI",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=136245&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=136245&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOLTVI",this.href,0);return true;' href="http://www.springerlink.com/index/X67006N334R1N383.pdf">http://www.springerlink.com/index/X67006N334R1N383.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GOLTVI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00136245">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00136245</a><br></div></div>
</div><!--entry-->

<div id='_453_entry' class='entry'><span ><span class='name'>Gomila, Antoni</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("GOMFCS",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=216364'>From cognitive systems to persons.</a></span> In <em>Android Epistemology</em>. Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5533820511861731180'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20cognitive%20systems%20to%20persons+author%3AGomila&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_454_entry' class='entry'><span ><span class='name'>Gunderson, Keith</span> (1963). <a rel="nofollow" class='article_title' onclick='trackclick("GUNIWA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(196306)23:6&lt;136:IWAR&gt;2.0.CO;2-R'>Interview with a robot.</a></span> <span class='pub_name'>Analysis</span> 23 (June):136-142. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6731970387666805995'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Interview%20with%20a%20robot+author%3AGunderson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_455_entry' class='entry'><span ><span class='name'>Gunderson, Keith</span> (1985). <em><span class='pub_name'>Mentality And Machines, Second Edition.</span></em></span> Minneapolis: University Minnesota Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentality%20And%20Machines%2C%20Second%20Edition+author%3AGunderson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_456_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("HAUTSO",this.href,0);return true;' href='http://www.springerlink.com/content/h68x032616766137/fulltext.pdf'>The sense of thinking.</a></span> <span class='pub_name'>Minds and Machines</span> 3 (1):21-29. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9540260034904918605'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20sense%20of%20thinking+author%3AHauser&amp;btnG=Search'>Google</a> | <a href='javascript:show("_456_links")'>More links</a>)</span><div id='_456_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â It will be found that the great majority, given the premiss that thought is not distinct from corporeal motion, take a much more rational line and maintain that thought is the same in the brutes as in us, since they observe all sorts of corporeal motions in them, just as in us. And they will add that the difference, which is merely one of degree, does not imply any essential difference; from this they will be quite justified in concluding that, although there may be a smaller degree of reason in the beasts than there is in us, the beasts possess minds which are of exactly the same type as ours. (Descartes 1642: 288â289.)</div>
<div id='_456_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUTSO",this.href,0);return true;' href="http://www.springerlink.com/index/H68X032616766137.pdf">http://www.springerlink.com/index/H68X032616766137.pdf</a><br></div></div>
</div><!--entry-->

<div id='_457_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("HAUWIM",this.href,0);return true;' href='http://cogprints.org/242/'>Why isn't my pocket calculator a thinking thing?</a></span> <span class='pub_name'>Minds and Machines</span> 3 (1):3-10. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12512116875701451940'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20isn%27t%20my%20pocket%20calculator%20a%20thinking%20thing%3F+author%3AHauser&amp;btnG=Search'>Google</a> | <a href='javascript:show("_457_links")'>More links</a>)</span><div id='_457_abstract' class='extra' style='font-size:12px;'>Abstract: My pocket calculator (Cal) has certain arithmetical abilities: it seems Cal calculates. That calculating is thinking seems equally untendentious. Yet these two claims together provide premises for a seemingly valid syllogism whose conclusion -- Cal thinks -- most would deny. I consider several ways to avoid this conclusion, and find them mostly wanting. Either we ourselves can't be said to think or calculate if our calculation-like performances are judged by the standards proposed to rule out Cal; or the standards -- e.g., autonomy and self-consciousness -- make it impossible to verify whether anything or anyone (save myself) meets them. While appeals to the intentionality of thought or the unity of minds provide more credible lines of resistance, available accounts of intentionality and mental unity are insufficiently clear and warranted to provide very substantial arguments against Cal's title to be called a thinking thing. Indeed, considerations favoring granting that title are more formidable than generally appreciated</div>
<div id='_457_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://cogprints.org/242/00/wimpcatt.html">http://cogprints.org/242/00/wimpcatt.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://members.aol.com/lshauser/wimpcatt.html">http://members.aol.com/lshauser/wimpcatt.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000242/">http://cogprints.ecs.soton.ac.uk/archive/00000242/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000242/00/wimpcatt.html">http://cogprints.ecs.soton.ac.uk/archive/00000242/00/wimpcatt.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:242">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:242</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:242">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:242</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://www.springerlink.com/content/t46235328605618l/fulltext.pdf">http://www.springerlink.com/content/t46235328605618l/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://www.springerlink.com/content/k5383t2m586208l4/fulltext.pdf">http://www.springerlink.com/content/k5383t2m586208l4/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://www.springerlink.com/index/T46235328605618L.pdf">http://www.springerlink.com/index/T46235328605618L.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://www.springerlink.com/index/K5383T2M586208L4.pdf">http://www.springerlink.com/index/K5383T2M586208L4.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://cogprints.org/242/1/wimpcatt.html">http://cogprints.org/242/1/wimpcatt.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUWIM",this.href,0);return true;' href="http://cogprints.org/242/0/wimpcatt.html">http://cogprints.org/242/0/wimpcatt.html</a><br></div></div>
</div><!--entry-->

<div id='_458_entry' class='entry'><span ><span class='name'>Heffernan, James D.</span> (1978). <a rel="nofollow" class='article_title' onclick='trackclick("HEFSDA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8248(197812)45:4&lt;638:SDA&quot;MA&gt;2.0.CO;2-0'>Some doubts about Turing machine arguments.</a></span> <span class='pub_name'>Philosophy of Science</span> 45 (December):638-647. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Some%20doubts%20about%20Turing%20machine%20arguments+author%3AHeffernan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_458_links")'>More links</a>)</span>
<div id='_458_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HEFSDA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8248(197812)45:4&lt;638:SDA&quot;MA&gt;2.0.CO;2-0">http://www.jstor.org/sici?sici=0031-8248(197812)45:4<638:SDA"MA>2.0.CO;2-0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HEFSDA",this.href,0);return true;' href="http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288843">http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/288843</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HEFSDA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/186977.pdf">http://www.jstor.org/stable/pdfplus/186977.pdf</a><br></div></div>
</div><!--entry-->

<div id='_459_entry' class='entry'><span ><span class='name'>Henley, Tracy B.</span> (1990). Natural problems and artificial intelligence.</span> <span class='pub_name'>Behavior and Philosophy</span> 18:43-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16783274278486503819'>Cited by 4</a> | <span class='ll' onclick='$("_459_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Natural%20problems%20and%20artificial%20intelligence+author%3AHenley&amp;btnG=Search'>Google</a>)</span><div id='_459_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the philosophical importance of criteria for intelligence. With remarks on Searle, the Turing test, attitudes to AI, and ethical considerations.</div></div>
</div><!--entry-->

<div id='_460_entry' class='entry'><span ><span class='name'>Joske, W. D.</span> (1972). Deliberating machines.</span> <span class='pub_name'>Philosophical Papers</span> 1 (October):57-66. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Deliberating%20machines+author%3AJoske&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_461_entry' class='entry'><span ><span class='name'>Kary, Michael</span> &amp; <span class='name'>Mahner, Martin</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("KARHWY",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596927'>How would you know if you synthesized a thinking thing?</a></span> <span class='pub_name'>Minds and Machines</span> 12 (1):61-86. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12858950381066710209'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20would%20you%20know%20if%20you%20synthesized%20a%20thinking%20thing%3F+author%3AKary&amp;btnG=Search'>Google</a> | <a href='javascript:show("_461_links")'>More links</a>)</span><div id='_461_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â We confront the following popular views: that mind or life are algorithms; that thinking, or more generally any process other than computation, is computation; that anything other than a working brain can have thoughts; that anything other than a biological organism can be alive; that form and function are independent of matter; that sufficiently accurate simulations are just as genuine as the real things they imitate; and that the Turing test is either a necessary or sufficient or scientific procedure for evaluating whether or not an entity is intelligent. Drawing on the distinction between activities and tasks, and the fundamental scientific principles of ontological lawfulness, epistemological realism, and methodological skepticism, we argue for traditional scientific materialism of the emergentist kind in opposition to the functionalism, behaviourism, tacit idealism, and merely decorative materialism of the artificial intelligence and artificial life communities</div>
<div id='_461_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KARHWY",this.href,0);return true;' href="http://www.springerlink.com/content/h8731k7036822314/fulltext.pdf">http://www.springerlink.com/content/h8731k7036822314/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KARHWY",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=390424&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=390424&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KARHWY",this.href,0);return true;' href="http://www.springerlink.com/index/H8731K7036822314.pdf">http://www.springerlink.com/index/H8731K7036822314.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KARHWY",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2002/00000012/00000001/00390424">http://www.ingentaconnect.com/content/klu/mind/2002/00000012/00000001/00390424</a><br></div></div>
</div><!--entry-->

<div id='_462_entry' class='entry'><span ><span class='name'>Kearns, John T.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("KEATMS",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596705.596736'>Thinking machines: Some fundamental confusions.</a></span> <span class='pub_name'>Minds and Machines</span> 7 (2):269-87. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13998173335617024251'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Thinking%20machines+author%3AKearns&amp;btnG=Search'>Google</a> | <a href='javascript:show("_462_links")'>More links</a>)</span><div id='_462_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper explores Church's Thesis and related claims madeby Turing. Church's Thesis concerns computable numerical functions, whileTuring's claims concern both procedures for manipulating uninterpreted marksand machines that generate the results that these procedures would yield. Itis argued that Turing's claims are true, and that they support (the truth of)Church's Thesis. It is further argued that the truth of Turing's and Church'sTheses has no interesting consequences for human cognition or cognitiveabilities. The Theses don't even mean that computers can do as much as peoplecan when it comes to carrying out effective procedures. For carrying out aprocedure is a purposive, intentional activity. No actual machine does, orcan do, as much</div>
<div id='_462_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KEATMS",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=322375CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=322375CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KEATMS",this.href,0);return true;' href="http://www.springerlink.com/content/p457647356006413/fulltext.pdf">http://www.springerlink.com/content/p457647356006413/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KEATMS",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=116417&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=116417&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KEATMS",this.href,0);return true;' href="http://www.springerlink.com/index/P457647356006413.pdf">http://www.springerlink.com/index/P457647356006413.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KEATMS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000002/00116417">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000002/00116417</a><br></div></div>
</div><!--entry-->

<div id='_463_entry' class='entry'><span ><span class='name'>Krishna, Daya</span> (1961). <a rel="nofollow" class='article_title' onclick='trackclick("KRILTC",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196108)12:46&lt;146:&#39;ATCR&gt;2.0.CO;2-3'>"Lying" and the compleat robot.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 12 (August):146-149. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3437349203340695779'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lying%20and%20the%20compleat%20robot+author%3AKrishna&amp;btnG=Search'>Google</a> | <a href='javascript:show("_463_links")'>More links</a>)</span>
<div id='_463_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KRILTC",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196108)12:46&lt;146:&#39;ATCR&gt;2.0.CO;2-3">http://www.jstor.org/sici?sici=0007-0882(196108)12:46<146:'ATCR>2.0.CO;2-3</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KRILTC",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/XII/46/146">http://bjps.oxfordjournals.org/cgi/content/citation/XII/46/146</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KRILTC",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/XII/46/146">http://bjps.oxfordjournals.org/cgi/reprint/XII/46/146</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KRILTC",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685493.pdf">http://www.jstor.org/stable/pdfplus/685493.pdf</a><br></div></div>
</div><!--entry-->

<div id='_464_entry' class='entry'><span ><span class='name'>Kugel, Peter</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("KUGCMC-2",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=585459'>Computing machines can't be intelligent (...And Turing said so).</a></span> <span class='pub_name'>Minds and Machines</span> 12 (4):563-579. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9813446716836810157'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computing%20machines%20can%27t%20be%20intelligent%20%28...And%20Turing%20said%20so%29+author%3AKugel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_464_links")'>More links</a>)</span><div id='_464_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â According to the conventional wisdom, Turing (1950) said that computing machines can be intelligent. I don''t believe it. I think that what Turing really said was that computing machines â- computers limited to computing â- can only fake intelligence. If we want computers to become genuinelyintelligent, we will have to give them enough initiative (Turing, 1948, p. 21) to do more than compute. In this paper, I want to try to develop this idea. I want to explain how giving computers more ``initiative'''' can allow them to do more than compute. And I want to say why I believe (and believe that Turing believed) that they will have to go beyond computation before they can become genuinely intelligent</div>
<div id='_464_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KUGCMC-2",this.href,0);return true;' href="http://www.cs.bc.edu/~kugel/Publications/Hyper.pdf">http://www.cs.bc.edu/~kugel/Publications/Hyper.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KUGCMC-2",this.href,0);return true;' href="http://www.cs.queensu.ca/home/akl/cisc879/papers/PAPERS_FROM_MINDS_AND_MACHINES/VOLUME_12_NO_4/P8T30NK152182338.pdf">http://www.cs.queensu.ca/home/akl/cisc879/papers/PAPERS_FROM_MINDS_AND_MACHINES/VOLUME_12_NO_4/P8T30NK152182338.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KUGCMC-2",this.href,0);return true;' href="http://www.springerlink.com/content/p8t30nk152182338/fulltext.pdf">http://www.springerlink.com/content/p8t30nk152182338/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KUGCMC-2",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5098145&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5098145&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KUGCMC-2",this.href,0);return true;' href="http://www.springerlink.com/index/P8T30NK152182338.pdf">http://www.springerlink.com/index/P8T30NK152182338.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KUGCMC-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2002/00000012/00000004/05098145">http://www.ingentaconnect.com/content/klu/mind/2002/00000012/00000004/05098145</a><br></div></div>
</div><!--entry-->

<div id='_465_entry' class='entry'><span ><span class='name'>Lanier, Jaron</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("LANMTE",this.href,0);return true;' href='http://www.jaronlanier.com/aichapter.html'>Mindless thought experiments (a critique of machine intelligence).</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mindless%20thought%20experiments%20%28a%20critique%20of%20machine%20intelligence%29+author%3ALanier&amp;btnG=Search'>Google</a>)</span><div id='_465_abstract' class='extra' style='font-size:12px;'>Abstract: Since there isn't a computer that seems conscious at this time, the idea of machine consciousness is supported by thought experiments. Here's one old chestnut: "What if you replaced your neurons one by one with neuron sized and shaped substitutes made of silicon chips that perfectly mimicked the chemical and electric functions of the originals? If you just replaced one single neuron, surely you'd feel the same. As you proceed, as more and more neurons are replaced, you'd stay conscious. Why wouldn't you still be conscious at the end of the process, when you'd reside in a brain shaped glob of silicon? And why couldn't the resulting replacement brain have been manufactured by some other means?"</div>
</div><!--entry-->

<div id='_466_entry' class='entry'><span ><span class='name'>Lanier, Jaron</span> (1998). Three objections to the idea of artificial intelligence.</span> In Stuart R. Hameroff, Alfred W. Kaszniak &amp; A. C. Scott (eds.), <em>Toward a Science of Consciousness II</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Three%20objections%20to%20the%20idea%20of%20artificial%20intelligence+author%3ALanier&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_467_entry' class='entry'><span ><span class='name'>Laymon, Ronald E.</span> (1988). Some computers can add (even if the IBM 1620 couldn't): Defending eniac's accumulators against Dretske.</span> <span class='pub_name'>Behaviorism</span> 16:1-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Some%20computers%20can%20add%20%28even%20if%20the%20IBM%201620%20couldn%27t%29+author%3ALaymon&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_468_entry' class='entry'><span ><span class='name'>Lind, Richard W.</span> (1986). The priority of attention: Intentionality for automata.</span> <span class='pub_name'>The Monist</span> 69 (October):609-619. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8806147600124050093'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20priority%20of%20attention+author%3ALind&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_469_entry' class='entry'><span ><span class='name'>Long, Douglas C.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("LONWMC",this.href,0);return true;' href='http://www.unc.edu/~dlong/WhyMachines_pages_inserted.DOC'>Why Machines Can Neither Think nor Feel.</a></span> In Dale W. Jamieson (ed.), <em>Language, Mind and Art</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7585245001835173948'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20Machines%20Can%20Neither%20Think%20nor%20Feel+author%3ALong&amp;btnG=Search'>Google</a>)</span><div id='_469_abstract' class='extra' style='font-size:12px;'>Abstract: Over three decades ago, in a brief but provocative essay, Paul Ziff argued for the thesis that robots cannot have feelings because they are "mechanisms, not organisms, not living creatures. There could be a broken-down robot but not a dead one. Only living creatures can literally have feelings."[i] Since machines are not living things they cannot have feelings</div>
</div><!--entry-->

<div id='_470_entry' class='entry'><span ><span class='name'>Mackay, Donald M.</span> (1951). <a rel="nofollow" class='article_title' onclick='trackclick("MACMBI",this.href,0);return true;' href='http://www.jstor.org/sici?sici=0007-0882(195108)2:6&lt;105:MBIA&gt;2.0.CO;2-I'>Mind-life behavior in artifacts.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 2 (August):105-21. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind-life%20behavior%20in%20artifacts+author%3AMackay&amp;btnG=Search'>Google</a> | <a href='javascript:show("_470_links")'>More links</a>)</span>
<div id='_470_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACMBI",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/II/6/105">http://bjps.oxfordjournals.org/cgi/reprint/II/6/105</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACMBI",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685505.pdf">http://www.jstor.org/stable/pdfplus/685505.pdf</a><br></div></div>
</div><!--entry-->

<div id='_471_entry' class='entry'><span ><span class='name'>Mackay, Donald M.</span> (1952). Mentality in machines.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 26:61-86. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1612635100910341530'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentality%20in%20machines+author%3AMackay&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_472_entry' class='entry'><span ><span class='name'>Mackay, Donald M.</span> (1952). Mentality in machines, part III.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 61:61-86. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentality%20in%20machines%2C%20part%20III+author%3AMackay&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_473_entry' class='entry'><span ><span class='name'>Mackay, Donald M.</span> (1962). <a rel="nofollow" class='article_title' onclick='trackclick("MACTUO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196208)13:50&lt;89:TUOBLT&gt;2.0.CO;2-O'>The use of behavioural language to refer to mechanical processes.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 13 (August):89-103. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14629186539537911199'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20use%20of%20behavioural%20language%20to%20refer%20to%20mechanical%20processes+author%3AMackay&amp;btnG=Search'>Google</a> | <a href='javascript:show("_473_links")'>More links</a>)</span>
<div id='_473_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACTUO",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196208)13:50&lt;89:TUOBLT&gt;2.0.CO;2-O">http://www.jstor.org/sici?sici=0007-0882(196208)13:50<89:TUOBLT>2.0.CO;2-O</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACTUO",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/XIII/50/89">http://bjps.oxfordjournals.org/cgi/content/citation/XIII/50/89</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACTUO",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/XIII/50/89">http://bjps.oxfordjournals.org/cgi/reprint/XIII/50/89</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MACTUO",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685963.pdf">http://www.jstor.org/stable/pdfplus/685963.pdf</a><br></div></div>
</div><!--entry-->

<div id='_474_entry' class='entry'><span ><span class='name'>Manning, Rita C.</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("MANWSH",this.href,0);return true;' href='http://www.springerlink.com/content/nxq656054557584r/fulltext.pdf'>Why Sherlock Holmes can't be replaced by an expert system.</a></span> <span class='pub_name'>Philosophical Studies</span> 51 (January):19-28. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3958070376237228063'>Cited by 3</a> | <span class='ll' onclick='$("_474_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20Sherlock%20Holmes%20can%27t%20be%20replaced%20by%20an%20expert%20system+author%3AManning&amp;btnG=Search'>Google</a> | <a href='javascript:show("_474_links")'>More links</a>)</span><div id='_474_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>An expert system would lack Holmes' ability to raise the right questions, sort out relevant data, and determine what data are in need of explanation.</div></div>
<div id='_474_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANWSH",this.href,0);return true;' href="http://www.springerlink.com/index/NXQ656054557584R.pdf">http://www.springerlink.com/index/NXQ656054557584R.pdf</a><br></div></div>
</div><!--entry-->

<div id='_475_entry' class='entry'><span ><span class='name'>Mays, W.</span> (1952). <a rel="nofollow" class='article_title' onclick='trackclick("MAYCMT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8191(195204)27:101&lt;148:CMT&gt;2.0.CO;2-D'>Can machines think?</a></span> <span class='pub_name'>Philosophy</span> 27 (April):148-62. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16995339974891461590'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20machines%20think%3F+author%3AMays&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_476_entry' class='entry'><span ><span class='name'>McCarthy, John</span> (1979). <a rel="nofollow" class='article_title' onclick='trackclick("MCCAMQ",this.href,0);return true;' href='http://cogprints.org/416/'>Ascribing mental qualities to machines.</a></span> In Martin Ringle (ed.), <em>Philosophical Perspectives in Artificial Intelligence</em>. Humanities Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2750173829749683232'>Cited by 168</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Ascribing%20mental%20qualities%20to%20machines+author%3AMcCarthy&amp;btnG=Search'>Google</a> | <a href='javascript:show("_476_links")'>More links</a>)</span><div id='_476_abstract' class='extra' style='font-size:12px;'>Abstract: Ascribing mental qualities like beliefs, intentions and wants to a machine is sometimes correct if done conservatively and is sometimes necessary to express what is known about its state. We propose some new definitional tools for this: definitions relative to an approximate theory and second order structural definitions</div>
<div id='_476_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCAMQ",this.href,0);return true;' href="http://www-formal.stanford.edu/jmc/ascribing.ps">http://www-formal.stanford.edu/jmc/ascribing.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCAMQ",this.href,0);return true;' href="http://www-formal.stanford.edu/jmc/ascribing.pdf">http://www-formal.stanford.edu/jmc/ascribing.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCAMQ",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000416/00/ascribing.ps">http://cogprints.ecs.soton.ac.uk/archive/00000416/00/ascribing.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCAMQ",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:416">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:416</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCAMQ",this.href,0);return true;' href="http://stinet.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA071423">http://stinet.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA071423</a><br></div></div>
</div><!--entry-->

<div id='_477_entry' class='entry'><span ><span class='name'>McNamara, Paul</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("MCNCOC",this.href,0);return true;' href='http://www.springerlink.com/content/v4u3146226676203/fulltext.pdf'>Comments on can intelligence be artificial?</a></span> <span class='pub_name'>Philosophical Studies</span> 71 (2):217-222. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Comments%20on%20can%20intelligence%20be%20artificial%3F+author%3AMcNamara&amp;btnG=Search'>Google</a> | <a href='javascript:show("_477_links")'>More links</a>)</span>
<div id='_477_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCNCOC",this.href,0);return true;' href="http://www.springerlink.com/index/V4U3146226676203.pdf">http://www.springerlink.com/index/V4U3146226676203.pdf</a><br></div></div>
</div><!--entry-->

<div id='_478_entry' class='entry'><span ><span class='name'>Minsky, Marvin L.</span> (1968). <a rel="nofollow" class='article_title' onclick='trackclick("MINMMM",this.href,0);return true;' href='http://groups.csail.mit.edu/medg/people/doyle/gallery/minsky/mmm.html'>Matter, minds, models.</a></span> In Marvin L. Minsky (ed.), <em>Semantic Information Processing</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9755843958461624484'>Cited by 18</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Matter%2C%20minds%2C%20models+author%3AMinsky&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_479_entry' class='entry'><span ><span class='name'>Minsky, Marvin L.</span> (1982). <a rel="nofollow" class='article_title' onclick='trackclick("MINWPT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=107368.108513'>Why people think computers can't.</a></span> <span class='pub_name'>AI Magazine Fall</span> 1982. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8089881172046686428'>Cited by 32</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20people%20think%20computers%20can%27t+author%3AMinsky&amp;btnG=Search'>Google</a> | <a href='javascript:show("_479_links")'>More links</a>)</span><div id='_479_abstract' class='extra' style='font-size:12px;'>Abstract: Most people think computers will never be able to think. That is, really think. Not now or ever. To be sure, most people also agree that computers can do many things that a person would have to be thinking to do. Then how could a machine seem to think but not actually think? Well, setting aside the question of what thinking actually is, I think that most of us would answer that by saying that in these cases, what the computer is doing is merely a superficial imitation of human intelligence. It has been designed to obey certain simple commands, and then it has been provided with programs composed of those commands. Because of this, the computer has to obey those commands, but without any idea of what's happening</div>
<div id='_479_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWPT",this.href,0);return true;' href="http://web.media.mit.edu/~minsky/papers/ComputersCantThink.txt">http://web.media.mit.edu/~minsky/papers/ComputersCantThink.txt</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWPT",this.href,0);return true;' href="http://www.cogsci.northwestern.edu/courses/cg207/readings/AIMag03-04-001.pdf">http://www.cogsci.northwestern.edu/courses/cg207/readings/AIMag03-04-001.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWPT",this.href,0);return true;' href="http://cs.clarku.edu/~jbreecher/public/2005_Can_Computers_Think/Minsky-WhyPeopleThinkComputersCant.pdf">http://cs.clarku.edu/~jbreecher/public/2005_Can_Computers_Think/Minsky-WhyPeopleThinkComputersCant.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWPT",this.href,0);return true;' href="http://aleph0.clarku.edu/~jbreecher/public/2005_Can_Computers_Think/Minsky-WhyPeopleThinkComputersCant.pdf">http://aleph0.clarku.edu/~jbreecher/public/2005_Can_Computers_Think/Minsky-WhyPeopleThinkComputersCant.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWPT",this.href,0);return true;' href="http://act-r.psy.cmu.edu/~douglass/Douglass/Agents/TopicPapers/~TopCandidates~/State-of-AI/AIMag03-04-001.pdf">http://act-r.psy.cmu.edu/~douglass/Douglass/Agents/TopicPapers/~TopCandidates~/State-of-AI/AIMag03-04-001.pdf</a><br></div></div>
</div><!--entry-->

<div id='_480_entry' class='entry'><span ><span class='name'>Nanay, Bence</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("NANSBT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1145458.1145459'>Symmetry between the intentionality of minds and machines? The biological plausibility of Dennett's position.</a></span> <span class='pub_name'>Minds and Machines</span> 16 (1):57-71. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Symmetry%20between%20the%20intentionality%20of%20minds%20and%20machines%3F%20The%20biological%20plausibility%20of%20Dennett%27s%20position+author%3ANanay&amp;btnG=Search'>Google</a> | <a href='javascript:show("_480_links")'>More links</a>)</span><div id='_480_abstract' class='extra' style='font-size:12px;'>Abstract:  One of the most influential arguments against the claim that computers can think is that while our intentionality is intrinsic, that of computers is derived: it is parasitic on the intentionality of the programmer who designed the computer-program. Daniel Dennett chose a surprising strategy for arguing against this asymmetry: instead of denying that the intentionality of computers is derived, he endeavours to argue that human intentionality is derived too. I intend to examine that biological plausibility of Dennettâs suggestion and show that Dennettâs argument for the claim that human intentionality is derived because it was designed by natural selection is based on the misunderstanding of how natural selection works</div>
<div id='_480_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NANSBT",this.href,0);return true;' href="http://www.springerlink.com/content/a44653240255k3g2/fulltext.pdf">http://www.springerlink.com/content/a44653240255k3g2/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NANSBT",this.href,0);return true;' href="http://www.springerlink.com/index/A44653240255K3G2.pdf">http://www.springerlink.com/index/A44653240255K3G2.pdf</a><br></div></div>
</div><!--entry-->

<div id='_481_entry' class='entry'><span ><span class='name'>Negley, Glenn</span> (1951). <a rel="nofollow" class='article_title' onclick='trackclick("NEGCAT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(19510913)48:19&lt;574:CATOM&gt;2.0.CO;2-T'>Cybernetics and theories of mind.</a></span> <span class='pub_name'>Journal of Philosophy</span> 48 (September):574-82. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=435182804486461709'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cybernetics%20and%20theories%20of%20mind+author%3ANegley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_481_links")'>More links</a>)</span>
<div id='_481_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEGCAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(19510913)48:19&lt;574:CATOM&gt;2.0.CO;2-T">http://www.jstor.org/sici?sici=0022-362X(19510913)48:19<574:CATOM>2.0.CO;2-T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEGCAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2020606.pdf">http://www.jstor.org/stable/pdfplus/2020606.pdf</a><br></div></div>
</div><!--entry-->

<div id='_482_entry' class='entry'><span ><span class='name'>Pinsky, Leonard</span> (1951). <a rel="nofollow" class='article_title' onclick='trackclick("PINDMT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0026-4423(195107)2:60:239&lt;397:DMTAMT&gt;2.0.CO;2-7'>Do machines think about machines thinking?</a></span> <span class='pub_name'>Mind</span> 60 (July):397-398. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Do%20machines%20think%20about%20machines%20thinking%3F+author%3APinsky&amp;btnG=Search'>Google</a> | <a href='javascript:show("_482_links")'>More links</a>)</span>
<div id='_482_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINDMT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0026-4423(195107)2:60:239&lt;397:DMTAMT&gt;2.0.CO;2-7">http://www.jstor.org/sici?sici=0026-4423(195107)2:60:239<397:DMTAMT>2.0.CO;2-7</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINDMT",this.href,0);return true;' href="http://mind.oxfordjournals.org/cgi/reprint/LX/239/397">http://mind.oxfordjournals.org/cgi/reprint/LX/239/397</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINDMT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2251326.pdf">http://www.jstor.org/stable/pdfplus/2251326.pdf</a><br></div></div>
</div><!--entry-->

<div id='_483_entry' class='entry'><span ><span class='name'>Preston, Beth</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("PRETOA",this.href,0);return true;' href='http://www.springerlink.com/content/u36t1v40250183j7/fulltext.pdf'>The ontological argument against the mind-machine hypothesis.</a></span> <span class='pub_name'>Philosophical Studies</span> 80 (2):131-57. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_483_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20ontological%20argument%20against%20the%20mind-machine%20hypothesis+author%3APreston&amp;btnG=Search'>Google</a> | <a href='javascript:show("_483_links")'>More links</a>)</span><div id='_483_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lucas, Searle, and Penrose all fall prey to "dual-description" fallacies.</div></div>
<div id='_483_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PRETOA",this.href,0);return true;' href="http://www.springerlink.com/index/U36T1V40250183J7.pdf">http://www.springerlink.com/index/U36T1V40250183J7.pdf</a><br></div></div>
</div><!--entry-->

<div id='_484_entry' class='entry'><span ><span class='name'>Proudfoot, Diane</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("PROTIO",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1011963'>The implications of an externalist theory of rule-following behavior for robot cognition.</a></span> <span class='pub_name'>Minds and Machines</span> 14 (3):283-308. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20implications%20of%20an%20externalist%20theory%20of%20rule-following%20behavior%20for%20robot%20cognition+author%3AProudfoot&amp;btnG=Search'>Google</a> | <a href='javascript:show("_484_links")'>More links</a>)</span><div id='_484_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Given (1) Wittgensteins externalist analysis of the distinction between following a rule and behaving in accordance with a rule, (2) prima facie connections between rule-following and psychological capacities, and (3) pragmatic issues about training, it follows that most, even all, future artificially intelligent computers and robots will not use language, possess concepts, or reason. This argument suggests that AIs traditional aim of building machines with minds, exemplified in current work on cognitive robotics, is in need of substantial revision</div>
<div id='_484_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PROTIO",this.href,0);return true;' href="http://www.springerlink.com/content/v3gpx4k76m46705k/fulltext.pdf">http://www.springerlink.com/content/v3gpx4k76m46705k/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PROTIO",this.href,0);return true;' href="http://www.springerlink.com/index/V3GPX4K76M46705K.pdf">http://www.springerlink.com/index/V3GPX4K76M46705K.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PROTIO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000003/05268464">http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000003/05268464</a><br></div></div>
</div><!--entry-->

<div id='_485_entry' class='entry'><span ><span class='name'>Puccetti, Roland</span> (1966). Can humans think?</span> <span class='pub_name'>Analysis</span> 26 (June):198-202. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20humans%20think%3F+author%3APuccetti&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_486_entry' class='entry'><span ><span class='name'>Putnam, Hilary</span> (1967). The mental life of some machines.</span> In Hector-Neri Castaneda (ed.), <em>Intentionality, Minds and Perception</em>. Wayne State University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6579735072696699587'>Cited by 37</a> | <span class='ll' onclick='$("_486_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20mental%20life%20of%20some%20machines+author%3APutnam&amp;btnG=Search'>Google</a>)</span><div id='_486_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On explaining behavior via TM states, e.g. explaining preference via utility functions. Logical behaviorism assumes rational preference functions. Functional organization is what matters, not physical make-up.</div></div>
</div><!--entry-->

<div id='_487_entry' class='entry'><span ><span class='name'>Pylyshyn, Zenon W.</span> (1975). <a rel="nofollow" class='article_title' onclick='trackclick("PYLMMA",this.href,0);return true;' href='http://eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ125190'>Minds, machines and phenomenology: Some reflections on Dreyfus' <em>What Computers Can't Do</em>.</a></span> <span class='pub_name'>Cognition</span> 3:57-77. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14534896851800934946'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20machines%20and%20phenomenology+author%3APylyshyn&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_488_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("RAPBMC",this.href,0);return true;' href='http://www.springerlink.com/content/l1vhlv44122w0014/fulltext.pdf'>Because mere calculating isn't thinking: Comments on Hauser's <em>Why Isn't My Pocket Calculator a Thinking Thing?</em>.</a></span> <span class='pub_name'>Minds and Machines</span> 3 (1):11-20. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15982738645786615225'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Because%20mere%20calculating%20isn%27t%20thinking+author%3ARapaport&amp;btnG=Search'>Google</a> | <a href='javascript:show("_488_links")'>More links</a>)</span>
<div id='_488_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPBMC",this.href,0);return true;' href="http://www.springerlink.com/index/L1VHLV44122W0014.pdf">http://www.springerlink.com/index/L1VHLV44122W0014.pdf</a><br></div></div>
</div><!--entry-->

<div id='_489_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("RAPCPA",this.href,0);return true;' href='http://www.cs.buffalo.edu/tech-reports/90-13.ps '>Computer processes and virtual persons: Comments on Cole's "artificial intelligence and personal identity".</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15126066552065920604'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computer%20processes%20and%20virtual%20persons+author%3ARapaport&amp;btnG=Search'>Google</a> | <a href='javascript:show("_489_links")'>More links</a>)</span><div id='_489_abstract' class='extra' style='font-size:12px;'>Abstract: This is a draft of the written version of comments on a paper by David Cole, presented orally at the American Philosophical Association Central Division meeting in New Orleans, 27 April 1990. Following the written comments are 2 appendices: One contains a letter to Cole updating these comments. The other is the handout from the oral presentation</div>
<div id='_489_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPCPA",this.href,0);return true;' href="http://www.cse.buffalo.edu/tech-reports/90-13.ps ">http://www.cse.buffalo.edu/tech-reports/90-13.ps </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPCPA",this.href,0);return true;' href="http://www.cse.buffalo.edu/tech-reports/90-13.ps.Z">http://www.cse.buffalo.edu/tech-reports/90-13.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPCPA",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/cole.tr.17my90.pdf">http://www.cse.buffalo.edu/~rapaport/Papers/cole.tr.17my90.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPCPA",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/cole.tr.17my90.pdf ">http://www.cse.buffalo.edu/~rapaport/Papers/cole.tr.17my90.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPCPA",this.href,0);return true;' href="http://historical.ncstrl.org/litesite-data/suny_buffalo_cs/90-13.ps.Z">http://historical.ncstrl.org/litesite-data/suny_buffalo_cs/90-13.ps.Z</a><br></div></div>
</div><!--entry-->

<div id='_490_entry' class='entry'><span ><span class='name'>Ritchie, Graeme</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("RITSEC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1285561.1285574'>Some empirical criteria for attributing creativity to a computer program.</a></span> <span class='pub_name'>Minds and Machines</span> 17 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Some%20empirical%20criteria%20for%20attributing%20creativity%20to%20a%20computer%20program+author%3ARitchie&amp;btnG=Search'>Google</a> | <a href='javascript:show("_490_links")'>More links</a>)</span><div id='_490_abstract' class='extra' style='font-size:12px;'>Abstract: Over recent decades there has been a growing interest in the question of whether computer programs are capable of genuinely creative activity. Although this notion can be explored as a purely philosophical debate, an alternative perspective is to consider what aspects of the behaviour of a program might be noted or measured in order to arrive at an empirically supported judgement that creativity has occurred. We sketch out, in general abstract terms, what goes on when a potentially creative program is constructed and run, and list some of the relationships (for example, between input and output) which might contribute to a decision about creativity. Specifically, we list a number of criteria which might indicate interesting properties of a programâs behaviour, from the perspective of possible creativity. We go on to review some ways in which these criteria have been applied to actual implementations, and some possible improvements to this way of assessing creativity</div>
<div id='_490_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RITSEC",this.href,0);return true;' href="http://www.springerlink.com/content/873382581451wk27/fulltext.pdf">http://www.springerlink.com/content/873382581451wk27/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RITSEC",this.href,0);return true;' href="http://www.springerlink.com/index/873382581451WK27.pdf">http://www.springerlink.com/index/873382581451WK27.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RITSEC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2007/00000017/00000001/00009066">http://www.ingentaconnect.com/content/klu/mind/2007/00000017/00000001/00009066</a><br></div></div>
</div><!--entry-->

<div id='_491_entry' class='entry'><span ><span class='name'>Ronald, E.</span> &amp; <span class='name'>Sipper, Moshe</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("RONIIN",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596943'>Intelligence is not enough: On the socialization of talking machines.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (4):567-576. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=875182470831172257'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intelligence%20is%20not%20enough+author%3ARonald&amp;btnG=Search'>Google</a> | <a href='javascript:show("_491_links")'>More links</a>)</span><div id='_491_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Since the introduction of the imitation game by Turing in 1950 there has been much debate as to its validity in ascertaining machine intelligence. We wish herein to consider a different issue altogether: granted that a computing machine passes the Turing Test, thereby earning the label of ``Turing Chatterbox'', would it then be of any use (to us humans)? From the examination of scenarios, we conclude that when machines begin to participate in social transactions, unresolved issues of trust and responsibility may well overshadow any raw reasoning ability they possess</div>
<div id='_491_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RONIIN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=5BJaXSedqfIC&amp;oi=fnd&amp;pg=RA2-PA151&amp;ots=rzjaYNDgnt&amp;sig=3A-d8vteZ5VxcLftqerbTWdpGLI">http://books.google.com/books?hl=en&lr=&id=5BJaXSedqfIC&oi=fnd&pg=RA2-PA151&ots=rzjaYNDgnt&sig=3A-d8vteZ5VxcLftqerbTWdpGLI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RONIIN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ECj6fuEMdp0C&amp;oi=fnd&amp;pg=RA2-PA151&amp;ots=blQIHqmec_&amp;sig=7-0Vb2LD-6m2dlj8qK05keaxOEU">http://books.google.com/books?hl=en&lr=&id=ECj6fuEMdp0C&oi=fnd&pg=RA2-PA151&ots=blQIHqmec_&sig=7-0Vb2LD-6m2dlj8qK05keaxOEU</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RONIIN",this.href,0);return true;' href="http://www.springerlink.com/content/l363406154q21317/fulltext.pdf">http://www.springerlink.com/content/l363406154q21317/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RONIIN",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=338896&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=338896&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RONIIN",this.href,0);return true;' href="http://www.springerlink.com/index/L363406154Q21317.pdf">http://www.springerlink.com/index/L363406154Q21317.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RONIIN",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000004/00338896">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000004/00338896</a><br></div></div>
</div><!--entry-->

<div id='_492_entry' class='entry'><span ><span class='name'>Baker, Lynne Rudder</span> (1981). Why computers can't act.</span> <span class='pub_name'>American Philosophical Quarterly</span> 18 (April):157-163. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2118115849462995199'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20computers%20can%27t%20act+author%3ABaker&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_493_entry' class='entry'><span ><span class='name'>Schmidt, C. T. A.</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("SCHORA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1077959'>Of robots and believing.</a></span> <span class='pub_name'>Minds and Machines</span> 15 (2):195-205. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16729500222840098052'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Of%20robots%20and%20believing+author%3ASchmidt&amp;btnG=Search'>Google</a> | <a href='javascript:show("_493_links")'>More links</a>)</span><div id='_493_abstract' class='extra' style='font-size:12px;'>Abstract:  Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are âpeopleâ. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions about the significance of an artificial version of it. Without intending to defend or refute the discourse in favour of ârecreatingâ Man, a lesser familiar question is brought forth: âand what if we were capable of creating a very convincible replica of man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?â Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours implementing weaker techniques</div>
<div id='_493_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHORA",this.href,0);return true;' href="http://www.springerlink.com/content/h605152238852292/fulltext.pdf">http://www.springerlink.com/content/h605152238852292/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHORA",this.href,0);return true;' href="http://www.springerlink.com/index/H605152238852292.pdf">http://www.springerlink.com/index/H605152238852292.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHORA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000002/00004734">http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000002/00004734</a><br></div></div>
</div><!--entry-->

<div id='_494_entry' class='entry'><span ><span class='name'>Scriven, Michael</span> (1960). The compleat robot: A prolegomena to androidology.</span> In Sidney Hook (ed.), <em>Dimensions of Mind</em>. New York University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8486421167341944600'>Cited by 6</a> | <span class='ll' onclick='$("_494_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20compleat%20robot+author%3AScriven&amp;btnG=Search'>Google</a>)</span><div id='_494_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A machine could possess every characteristic of human thought: e.g. freedom, creativity, learning, understanding, perceiving, feeling.</div></div>
</div><!--entry-->

<div id='_495_entry' class='entry'><span ><span class='name'>Scriven, Michael</span> (1963). <a rel="nofollow" class='article_title' onclick='trackclick("SCRTSA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(196302)13:52&lt;313:TSAL&gt;2.0.CO;2-N'>The supercomputer as liar.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 13 (February):313-314. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20supercomputer%20as%20liar+author%3AScriven&amp;btnG=Search'>Google</a> | <a href='javascript:show("_495_links")'>More links</a>)</span>
<div id='_495_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCRTSA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(196302)13:52&lt;313:TSAL&gt;2.0.CO;2-N">http://www.jstor.org/sici?sici=0007-0882(196302)13:52<313:TSAL>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCRTSA",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/XIII/52/313">http://bjps.oxfordjournals.org/cgi/content/citation/XIII/52/313</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCRTSA",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/XIII/52/313">http://bjps.oxfordjournals.org/cgi/reprint/XIII/52/313</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCRTSA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/685329.pdf">http://www.jstor.org/stable/pdfplus/685329.pdf</a><br></div></div>
</div><!--entry-->

<div id='_496_entry' class='entry'><span ><span class='name'>Selinger, Evan</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("SELCID",this.href,0);return true;' href='http://www.springerlink.com/content/nlh8p1g677254227/fulltext.pdf'>Collins's incorrect depiction of Dreyfus's critique of artificial intelligence.</a></span> <span class='pub_name'>Phenomenology and the Cognitive Sciences</span> 7 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Collins%27s%20incorrect%20depiction%20of%20Dreyfus%27s%20critique%20of%20artificial%20intelligence+author%3ASelinger&amp;btnG=Search'>Google</a>)</span><div id='_496_abstract' class='extra' style='font-size:12px;'>Abstract: Harry Collins interprets Hubert Dreyfusâs philosophy of embodiment as a criticism of all possible forms of artificial intelligence. I argue that this characterization is inaccurate and predicated upon a misunderstanding of the relevance of phenomenology for empirical scientific research</div>
</div><!--entry-->

<div id='_497_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> (1986). What sorts of machines can understand the symbols they use?</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 61:61-80. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=182012265650544774'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20sorts%20of%20machines%20can%20understand%20the%20symbols%20they%20use%3F+author%3ASloman&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_498_entry' class='entry'><span ><span class='name'>Spilsbury, R. J.</span> (1952). Mentality in machines.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 26:27-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14804576130866939878'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentality%20in%20machines+author%3ASpilsbury&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_499_entry' class='entry'><span ><span class='name'>Spilsbury, R. J.</span> (1952). Mentality in machines, part II.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 27:27-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentality%20in%20machines%2C%20part%20II+author%3ASpilsbury&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_500_entry' class='entry'><span ><span class='name'>Srzednicki, Jan</span> (1962). <a rel="nofollow" class='article_title' onclick='trackclick("SRZCMT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(196204)22:5&lt;113:CMT&gt;2.0.CO;2-H'>Could machines talk?</a></span> <span class='pub_name'>Analysis</span> 22 (April):113-117. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Could%20machines%20talk%3F+author%3ASrzednicki&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_501_entry' class='entry'><span ><span class='name'>Stahl, Bernd Carsten</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("STARCA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1188147'>Responsible computers? A case for ascribing quasi-responsibility to computers independent of personhood or agency.</a></span> <span class='pub_name'>Ethics and Information Technology</span> 8 (4):205-213. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Responsible%20computers%3F%20A%20case%20for%20ascribing%20quasi-responsibility%20to%20computers%20independent%20of%20personhood%20or%20agency+author%3AStahl&amp;btnG=Search'>Google</a> | <a href='javascript:show("_501_links")'>More links</a>)</span><div id='_501_abstract' class='extra' style='font-size:12px;'>Abstract:  There has been much debate whether computers can be responsible. This question is usually discussed in terms of personhood and personal characteristics, which a computer may or may not possess. If a computer fulfils the conditions required for agency or personhood, then it can be responsible; otherwise not. This paper suggests a different approach. An analysis of the concept of responsibility shows that it is a social construct of ascription which is only viable in certain social contexts and which serves particular social aims. If this is the main aspect of responsibility then the question whether computers can be responsible no longer hinges on the difficult problem of agency but on the possibly simpler question whether responsibility ascriptions to computers can fulfil social goals. The suggested solution to the question whether computers can be subjects of responsibility is the introduction of a new concept, called âquasi-responsibilityâ which will emphasise the social aim of responsibility ascription and which can be applied to computers</div>
<div id='_501_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STARCA",this.href,0);return true;' href="http://www.cse.dmu.ac.uk/~bstahl/publications/2006_responsible_computers_EIT.pdf">http://www.cse.dmu.ac.uk/~bstahl/publications/2006_responsible_computers_EIT.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STARCA",this.href,0);return true;' href="http://www.springerlink.com/content/27607300gt85x46k/fulltext.pdf">http://www.springerlink.com/content/27607300gt85x46k/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STARCA",this.href,0);return true;' href="http://www.springerlink.com/index/27607300GT85X46K.pdf">http://www.springerlink.com/index/27607300GT85X46K.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STARCA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/etin/2006/00000008/00000004/00009112">http://www.ingentaconnect.com/content/klu/etin/2006/00000008/00000004/00009112</a><br></div></div>
</div><!--entry-->

<div id='_502_entry' class='entry'><span ><span class='name'>Tallis, Raymond C.</span> (2004). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("TALWTM",this.href,0);return true;' href='http://books.google.com/books?id=xxCQ72zMBKsC&amp;printsec=front_cover'>Why the Mind Is Not a Computer: A Pocket Lexicon of Neuromythology.</a></span></em></span> Thorverton UK: Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5768118994817337272'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20the%20Mind%20Is%20Not%20a%20Computer+author%3ATallis&amp;btnG=Search'>Google</a> | <a href='javascript:show("_502_links")'>More links</a>)</span><div id='_502_abstract' class='extra' style='font-size:12px;'>Abstract: Taking a series of key words such as calculation, language, information and memory, Professor Tallis shows how their misuse has lured a whole generation into...</div>
<div id='_502_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TALWTM",this.href,0);return true;' href="http://imprint.co.uk/books/tallis.html">http://imprint.co.uk/books/tallis.html</a><br></div></div>
</div><!--entry-->

<div id='_503_entry' class='entry'><span ><span class='name'>Taube, M.</span> (1961). <em><span class='pub_name'>Computers And Common Sense: The Myth Of Thinking Machines.</span></em></span> Ny: Columbia University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9180385385222695349'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computers%20And%20Common%20Sense+author%3ATaube&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_504_entry' class='entry'><span ><span class='name'>Velleman, J. David</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("VELAA",this.href,0);return true;' href='http://ssrn.com/abstract=1006884'>Artificial agency.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20agency+author%3AVelleman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_504_links")'>More links</a>)</span><div id='_504_abstract' class='extra' style='font-size:12px;'>Abstract: I argue that participants in a virtual world such as "Second Life" exercise genuine agency via their avatars. Indeed, their avatars are fictional bodies with which they act in the virtual world, just as they act in the real world with their physical bodies. Hence their physical bodies can be regarded as their default avatars. I also discuss recent research into "believable" software agents, which are designed on principles borrowed from the character-based arts, especially cinematic animation as practiced by the artists at Disney and Warner Brothers Studios. I claim that these agents exemplify a kind of autonomy that should be of greater interest to philosophers than that exemplified by the generic agent modeled in current philosophical theory. The latter agent is autonomous by virtue of being governed by itself; but a believable agent appears to be governed by a self, which is the anima by which it appears to be animated. Putting these two discussions together, I suggest that philosophers of action should focus their attention on how we animate our bodies</div>
<div id='_504_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VELAA",this.href,0);return true;' href="http://phonline.org/paper.php?keynum=807">http://phonline.org/paper.php?keynum=807</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VELAA",this.href,0);return true;' href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1006884">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1006884</a><br></div></div>
</div><!--entry-->

<div id='_505_entry' class='entry'><span ><span class='name'>Wait, Eldon C.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("WAIWCC",this.href,0);return true;' href='http://www.springerlink.com/index/pl875up324358502.pdf'>What computers could never do.</a></span> In <em>Analecta Husserliana: The Yearbook of Phenomenological Research, Volume XD:Artificial Intelligence;Experience;Premise;Searle, John R</em>. Dordrecht: Springer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20computers%20could%20never%20do+author%3AWait&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_506_entry' class='entry'><span ><span class='name'>Waldrop, Mitchell</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("WALCCT",this.href,0);return true;' href='http://www.kurzweilai.net/articles/art0103.html?printable=1'>Can computers think?</a></span> In R. Kurzweil (ed.), <em>The Age of Intelligent Machines</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8020923008314494410'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20computers%20think%3F+author%3AWaldrop&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_507_entry' class='entry'><span ><span class='name'>Wallace, Rodrick</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("WALNMF",this.href,0);return true;' href='http://cogprints.org/4892/01/brooks4.pdf'>New mathematical foundations for AI and alife: Are the necessary conditions for animal consciousness sufficient for the design of intelligent machines?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=New%20mathematical%20foundations%20for%20AI%20and%20alife+author%3AWallace&amp;btnG=Search'>Google</a> | <a href='javascript:show("_507_links")'>More links</a>)</span><div id='_507_abstract' class='extra' style='font-size:12px;'>Abstract: Rodney Brooks' call for 'new mathematics' to revitalize the disciplines of artificial intelligence and artificial life can be answered by adaptation of what Adams has called 'the informational turn in philosophy', aided by the novel perspectives that program gives regarding empirical studies of animal cognition and consciousness. Going backward from the necessary conditions communication theory imposes on animal cognition and consciousness to sufficient conditions for machine design is, however, an extraordinarily difficult engineering task. The most likely use of the first generations of conscious machines will be to model the various forms of psychopathology, since we have little or no understanding of how consciousness is stabilized in humans or other animals</div>
<div id='_507_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WALNMF",this.href,0);return true;' href="http://philsci-archive.pitt.edu/archive/00002646/01/alife.pdf">http://philsci-archive.pitt.edu/archive/00002646/01/alife.pdf</a><br></div></div>
</div><!--entry-->

<div id='_508_entry' class='entry'><span ><span class='name'>Weiss, Paul A.</span> (1990). On the impossibility of artificial intelligence.</span> <span class='pub_name'>Review of Metaphysics (December)</span> 335 (December):335-341. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20impossibility%20of%20artificial%20intelligence+author%3AWeiss&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_509_entry' class='entry'><span ><span class='name'>Whiteley, C. H.</span> (1956). <a rel="nofollow" class='article_title' onclick='trackclick("WHINOT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(195601)16:3&lt;68:NOTCOM&gt;2.0.CO;2-9'>Note on the concept of mind.</a></span> <span class='pub_name'>Analysis</span> 16 (January):68-70. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Note%20on%20the%20concept%20of%20mind+author%3AWhiteley&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_510_entry' class='entry'><span ><span class='name'>Whobrey, Darren</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("WHOMMA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596935'>Machine mentality and the nature of the ground relation.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (3):307-346. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9272015080474589269'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20mentality%20and%20the%20nature%20of%20the%20ground%20relation+author%3AWhobrey&amp;btnG=Search'>Google</a> | <a href='javascript:show("_510_links")'>More links</a>)</span><div id='_510_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â John Searle distinguished between weak and strong artificial intelligence (AI). This essay discusses a third alternative, mild AI, according to which a machine may be capable of possessing a species of mentality. Using James Fetzer's conception of minds as semiotic systems, the possibility of what might be called ``mild AI'' receives consideration. Fetzer argues against strong AI by contending that digital machines lack the ground relationship required of semiotic systems. In this essay, the implementational nature of semiotic processes posited by Charles S. Peirce's triadic sign relation is re-examined in terms of the underlying dispositional processes and the ontological levels they would span in an inanimate machine. This suggests that, if non-human mentality can be replicated rather than merely simulated in a digital machine, the direction to pursue appears to be that of mild AI</div>
<div id='_510_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WHOMMA",this.href,0);return true;' href="http://www.mildai.org/papers/MAM2000-0-DJRW.pdf">http://www.mildai.org/papers/MAM2000-0-DJRW.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WHOMMA",this.href,0);return true;' href="http://www.springerlink.com/content/tm143v51k2638028/fulltext.pdf">http://www.springerlink.com/content/tm143v51k2638028/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WHOMMA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=323262&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=323262&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WHOMMA",this.href,0);return true;' href="http://www.springerlink.com/index/TM143V51K2638028.pdf">http://www.springerlink.com/index/TM143V51K2638028.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WHOMMA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000003/00323262">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000003/00323262</a><br></div></div>
</div><!--entry-->

<div id='_511_entry' class='entry'><span ><span class='name'>Wilks, Yorick</span> (1976). <a rel="nofollow" class='article_title' onclick='trackclick("WILDD",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(197606)27:2&lt;177:DD&gt;2.0.CO;2-T'>Dreyfus's disproofs.</a></span> <span class='pub_name'>Britis Journal for the Philosophy of Science</span> 27 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 1 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dreyfus%27s%20disproofs+author%3AWilks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_511_links")'>More links</a>)</span>
<div id='_511_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILDD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/27/2/177">http://bjps.oxfordjournals.org/cgi/reprint/27/2/177</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILDD",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686169.pdf">http://www.jstor.org/stable/pdfplus/686169.pdf</a><br></div></div>
</div><!--entry-->

<div id='_512_entry' class='entry'><span ><span class='name'>Wisdom, John O.</span> (1952). Mentality in machines, part I.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 1:1-26. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentality%20in%20machines%2C%20part%20I+author%3AWisdom&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.2'></a><a name=''></a><span class='myh2'>6.2 Computation and Representation</span></p>

<div id='cat_6.2' class='cat_content'>
<div id='__new_entries_6.2__'></div><div id='__new_entry_6.2__' class='entry'></div></div>
<p><a name='.6.2a'></a><a name=''></a><span class='myh3'>6.2a Symbols and Symbol Systems</span></p>

<div id='cat_6.2a' class='cat_content'>
<div id='__new_entries_6.2a__'></div><div id='__new_entry_6.2a__' class='entry'></div>
<div id='_513_entry' class='entry'><span ><span class='name'>Boyle, C. Franklin</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("BOYTAD",this.href,0);return true;' href='http://psycprints.ecs.soton.ac.uk/archive/00000165/'>Transduction and degree of grounding.</a></span> <span class='pub_name'>Psycoloquy</span> 12 (36). <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Transduction%20and%20degree%20of%20grounding+author%3ABoyle&amp;btnG=Search'>Google</a> | <a href='javascript:show("_513_links")'>More links</a>)</span><div id='_513_abstract' class='extra' style='font-size:12px;'>Abstract: While I agree in general with Stevan Harnad's symbol grounding proposal, I do not believe "transduction" (or "analog process") PER SE is useful in distinguishing between what might best be described as different "degrees" of grounding and, hence, for determining whether a particular system might be capable of cognition. By 'degrees of grounding' I mean whether the effects of grounding go "all the way through" or not. Why is transduction limited in this regard? Because transduction is a physical process which does not speak to the issue of representation, and, therefore, does not explain HOW the informational aspects of signals impinging on sensory surfaces become embodied as symbols or HOW those symbols subsequently cause behavior, both of which, I believe, are important to grounding and to a system's cognitive capacity. Immunity to Searle's Chinese Room (CR) argument does not ensure that a particular system is cognitive, and whether or not a particular degree of groundedness enables a system to pass the Total Turing Test (TTT) may never be determined</div>
<div id='_513_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOYTAD",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Temp/Think/boyle.htm">http://cogsci.soton.ac.uk/~harnad/Temp/Think/boyle.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOYTAD",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.boyle.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.boyle.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOYTAD",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.boyle.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.boyle.html</a><br></div></div>
</div><!--entry-->

<div id='_514_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("BRIPAI",this.href,0);return true;' href='http://psycprints.ecs.soton.ac.uk/archive/00000167'>People are infinitary symbol systems: No sensorimotor capacity necessary.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14780101283427354154'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=People%20are%20infinitary%20symbol%20systems+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_514_links")'>More links</a>)</span><div id='_514_abstract' class='extra' style='font-size:12px;'>Abstract: Stevan Harnad and I seem to be thinking about many of the same issues. Sometimes we agree, sometimes we don't; but I always find his reasoning refreshing, his positions sensible, and the problems with which he's concerned to be of central importance to cognitive science. His "Grounding Symbols in the Analog World with Neural Nets" (= GS) is no exception. And GS not only exemplifies Harnad's virtues, it also provides a springboard for diving into Harnad- Bringsjord terrain</div>
<div id='_514_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIPAI",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000167/">http://psycprints.ecs.soton.ac.uk/archive/00000167/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIPAI",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Temp/Think/bringsj.htm">http://cogsci.soton.ac.uk/~harnad/Temp/Think/bringsj.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIPAI",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.bringsjord.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.bringsjord.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIPAI",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.bringsjord.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.bringsjord.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIPAI",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000167/02/psyc.01.12.038.symbolism-connectionism.5.bringsjord">http://psycprints.ecs.soton.ac.uk/archive/00000167/02/psyc.01.12.038.symbolism-connectionism.5.bringsjord</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIPAI",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000167/01/psyc.01.12.038.symbolism-connectionism.5.bringsjord.xml">http://psycprints.ecs.soton.ac.uk/archive/00000167/01/psyc.01.12.038.symbolism-connectionism.5.bringsjord.xml</a><br></div></div>
</div><!--entry-->

<div id='_515_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("CLAMS",this.href,0);return true;' href='https://www.era.lib.ed.ac.uk/handle/1842/1439?mode=simple'>Material symbols.</a></span> <span class='pub_name'>Philosophical Psychology</span> 19 (3):291-307. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5898047959874952257'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Material%20symbols+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_515_links")'>More links</a>)</span><div id='_515_abstract' class='extra' style='font-size:12px;'>Abstract: What is the relation between the material, conventional symbol structures that we encounter in the spoken and written word, and human thought? A common assumption, that structures a wide variety of otherwise competing views, is that the way in which these material, conventional symbol-structures do their work is by being translated into some kind of content-matching inner code. One alternative to this view is the tempting but thoroughly elusive idea that we somehow think in some natural language (such as English). In the present treatment I explore a third option, which I shall call the "complementarity" view of language. According to this third view the actual symbol structures of a given language add cognitive value by complementing (without being replicated by) the more basic modes of operation and representation endemic to the biological brain. The "cognitive bonus" that language brings is, on this model, not to be cashed out either via the ultimately mysterious notion of "thinking in a given natural language" or via some process of exhaustive translation into another inner code. Instead, we should try to think in terms of a kind of coordination dynamics in which the forms and structures of a language qua material symbol system play a key and irreducible role. Understanding language as a complementary cognitive resource is, I argue, an important part of the much larger project (sometimes glossed in terms of the "extended mind") of understanding human cognition as essentially and multiply hybrid: as involving a complex interplay between internal biological resources and external non-biological resources</div>
<div id='_515_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMS",this.href,0);return true;' href="http://www.psych.unito.it/csc/cogsci05/frame/talk/plen1-clark.pdf">http://www.psych.unito.it/csc/cogsci05/frame/talk/plen1-clark.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMS",this.href,0);return true;' href="http://data.cstr.ed.ac.uk/internal/library/proceedings/2005/cogsci2005/docs/p1.pdf">http://data.cstr.ed.ac.uk/internal/library/proceedings/2005/cogsci2005/docs/p1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMS",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a747697830~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a747697830~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMS",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/XNRG5M77H65766ML.pdf">http://taylorandfrancis.metapress.com/index/XNRG5M77H65766ML.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMS",this.href,0);return true;' href="http://www.informaworld.com/index/747697830.pdf">http://www.informaworld.com/index/747697830.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2006/00000019/00000003/art00002">http://www.ingentaconnect.com/content/routledg/cphp/2006/00000019/00000003/art00002</a><br></div></div>
</div><!--entry-->

<div id='_516_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> (1996). Why there is no symbol grounding problem?</span> In <em>Representations, Targets, and Attitudes</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20there%20is%20no%20symbol%20grounding%20problem%3F+author%3ACummins&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_517_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("HARCOT",this.href,0);return true;' href='http://cogprints.org/1583/'>Connecting object to symbol in modeling cognition.</a></span> In A. Clark &amp; Ronald Lutz (eds.), <em>Connectionism in Context</em>. Springer-Verlag. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5398022614342552534'>Cited by 61</a> | <span class='ll' onclick='$("_517_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connecting%20object%20to%20symbol%20in%20modeling%20cognition+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_517_links")'>More links</a>)</span><div id='_517_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the limitations of symbol systems, and the potential for grounding symbols in sensory icons and categorical perception, e.g. with neural networks.</div></div><div id='_517_abstract' class='extra' style='font-size:12px;'>Abstract: Connectionism and computationalism are currently vying for hegemony in cognitive modeling. At first glance the opposition seems incoherent, because connectionism is itself computational, but the form of computationalism that has been the prime candidate for encoding the "language of thought" has been symbolic computationalism (Dietrich 1990, Fodor 1975, Harnad 1990c; Newell 1980; Pylyshyn 1984), whereas connectionism is nonsymbolic (Fodor & Pylyshyn 1988, or, as some have hopefully dubbed it, "subsymbolic" Smolensky 1988). This paper will examine what is and is not a symbol system. A hybrid nonsymbolic/symbolic system will be sketched in which the meanings of the symbols are grounded bottom-up in the system's capacity to discriminate and identify the objects they refer to. Neural nets are one possible mechanism for learning the invariants in the analog sensory projection on which successful categorization is based. "Categorical perception" (Harnad 1987a), in which similarity space is "warped" in the service of categorization, turns out to be exhibited by both people and nets, and may mediate the constraints exerted by the analog world of objects on the formal world of symbols</div>
<div id='_517_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/3374/">http://eprints.ecs.soton.ac.uk/3374/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/3374/">http://eprints.resist.ecs.soton.ac.uk/3374/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001583/">http://cogprints.ecs.soton.ac.uk/archive/00001583/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/83/">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/83/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad92.symbol.object.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad92.symbol.object.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.symbol.object.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad92.symbol.object.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003374/02/harnad92.symbol.object.html">http://eprints.ecs.soton.ac.uk/archive/00003374/02/harnad92.symbol.object.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3374">http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3374</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1583">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1583</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://cogprints.org/1583/1/harnad92.symbol.object.html">http://cogprints.org/1583/1/harnad92.symbol.object.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARCOT",this.href,0);return true;' href="http://cogprints.org/1583/0/harnad92.symbol.object.html">http://cogprints.org/1583/0/harnad92.symbol.object.html</a><br></div></div>
</div><!--entry-->

<div id='_518_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("HARSGA",this.href,0);return true;' href='http://cogprints.org/2133/'>Symbol grounding and the origin of language.</a></span> In Matthias Scheutz (ed.), <em>Computationalism: New Directions</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9054214814907387101'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Symbol%20grounding%20and%20the%20origin%20of%20language+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_518_links")'>More links</a>)</span><div id='_518_abstract' class='extra' style='font-size:12px;'>Abstract: What language allows us to do is to "steal" categories quickly and effortlessly through hearsay instead of having to earn them the hard way, through risky and time-consuming sensorimotor "toil" (trial-and-error learning, guided by corrective feedback from the consequences of miscategorisation). To make such linguistic "theft" possible, however, some, at least, of the denoting symbols of language must first be grounded in categories that have been earned through sensorimotor toil (or else in categories that have already been "prepared" for us through Darwinian theft by the genes of our ancestors); it cannot be linguistic theft all the way down. The symbols that denote categories must be grounded in the capacity to sort, label and interact with the proximal sensorimotor projections of their distal category-members in a way that coheres systematically with their semantic interpretations, both for individual symbols, and for symbols strung together to express truth-value-bearing propositions</div>
<div id='_518_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/7714/">http://eprints.resist.ecs.soton.ac.uk/7714/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/6471/">http://eprints.resist.ecs.soton.ac.uk/6471/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://bi.snu.ac.kr/Courses/4ai05s/Essay/2-06.pdf">http://bi.snu.ac.kr/Courses/4ai05s/Essay/2-06.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00002133/">http://cogprints.ecs.soton.ac.uk/archive/00002133/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/21/33/">http://cogprints.soton.ac.uk/documents/disk0/00/00/21/33/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad02.symlang.htm">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad02.symlang.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad02.symlang.htm">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad02.symlang.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00007714/01/harnad02.symlang.htm">http://eprints.ecs.soton.ac.uk/archive/00007714/01/harnad02.symlang.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00006471/01/harnad02.symlang.html">http://eprints.ecs.soton.ac.uk/archive/00006471/01/harnad02.symlang.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGA",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:eprints.ecs.soton.ac.uk:7714">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:eprints.ecs.soton.ac.uk:7714</a><br></div></div>
</div><!--entry-->

<div id='_519_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("HARSGI",this.href,0);return true;' href='http://cogprints.org/1588/'>Symbol grounding is an empirical problem: Neural nets are just a candidate component.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17103589167273724734'>Cited by 27</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Symbol%20grounding%20is%20an%20empirical%20problem+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_519_links")'>More links</a>)</span><div id='_519_abstract' class='extra' style='font-size:12px;'>Abstract: "Symbol Grounding" is beginning to mean too many things to too many people. My own construal has always been simple: Cognition cannot be just computation, because computation is just the systematically interpretable manipulation of meaningless symbols, whereas the meanings of my thoughts don't depend on their interpretability or interpretation by someone else. On pain of infinite regress, then, symbol meanings must be grounded in something other than just their interpretability if they are to be candidates for what is going on in our heads. Neural nets may be one way to ground the names of concrete objects and events in the capacity to categorize them (by learning the invariants in their sensorimotor projections). These grounded elementary symbols could then be combined into symbol strings expressing propositions about more abstract categories. Grounding does not equal meaning, however, and does not solve any philosophical problems</div>
<div id='_519_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/3367/">http://eprints.resist.ecs.soton.ac.uk/3367/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00003367/">http://eprints.ecs.soton.ac.uk/archive/00003367/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://cogprints.org/1588/0/harnad93.cogsci.html">http://cogprints.org/1588/0/harnad93.cogsci.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001588/">http://cogprints.ecs.soton.ac.uk/archive/00001588/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/15/88/">http://cogprints.soton.ac.uk/documents/disk0/00/00/15/88/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/3367/01/harnad93.cogsci.html">http://eprints.ecs.soton.ac.uk/3367/01/harnad93.cogsci.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/documents/disk0/00/00/15/88/">http://cogprints.ecs.soton.ac.uk/documents/disk0/00/00/15/88/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.cogsci.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad93.cogsci.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.cogsci.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.cogsci.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00001588/00/harnad93.cogsci.html">http://cogprints.ecs.soton.ac.uk/archive/00001588/00/harnad93.cogsci.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3367">http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:3367</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1588">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1588</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARSGI",this.href,0);return true;' href="http://cogprints.org/1588/1/harnad93.cogsci.html">http://cogprints.org/1588/1/harnad93.cogsci.html</a><br></div></div>
</div><!--entry-->

<div id='_520_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("HARTSG",this.href,0);return true;' href='http://arxiv.org/abs/cs/9906002v1'>The symbol grounding problem.</a></span> <span class='pub_name'>[Journal (Paginated)]</span> 42:335-346. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13645814153540272031'>Cited by 1265</a> | <span class='ll' onclick='$("_520_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20symbol%20grounding%20problem+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_520_links")'>More links</a>)</span><div id='_520_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>AI symbols are empty and meaningless. They need to be "grounded" in something, e.g. sensory projection. Maybe connectionism can do the trick?</div></div><div id='_520_abstract' class='extra' style='font-size:12px;'>Abstract: There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the symbol grounding problem: How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) iconic representations, which are analogs of the proximal sensory projections of distal objects and events, and (2) categorical representations, which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) symbolic representations, grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., An X is a Y that is Z). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic module, however; the symbolic functions would emerge as an intrinsically dedicated symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded</div>
<div id='_520_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://arxiv.org/abs/cs.AI/9906002">http://arxiv.org/abs/cs.AI/9906002</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/8175/">http://eprints.resist.ecs.soton.ac.uk/8175/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=96679">http://portal.acm.org/citation.cfm?id=96679</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.org/3106/1/sgproblem1.html">http://cogprints.org/3106/1/sgproblem1.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://citeseer.ist.psu.edu/harnad90symbol.html">http://citeseer.ist.psu.edu/harnad90symbol.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/archive/00008175/">http://eprints.ecs.soton.ac.uk/archive/00008175/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1999cs........6002H">http://adsabs.harvard.edu/abs/1999cs........6002H</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/symgro.htm">http://www.ecs.soton.ac.uk/~harnad/Temp/symgro.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003106/">http://cogprints.ecs.soton.ac.uk/archive/00003106/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/06/15/">http://cogprints.soton.ac.uk/documents/disk0/00/00/06/15/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.org/615/00/The_Symbol_Grounding_Problem.html">http://cogprints.org/615/00/The_Symbol_Grounding_Problem.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://www.isrl.uiuc.edu/~amag/langev/paper/harnad90theSymbol.html">http://www.isrl.uiuc.edu/~amag/langev/paper/harnad90theSymbol.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003106/01/sgproblem1.html">http://cogprints.ecs.soton.ac.uk/archive/00003106/01/sgproblem1.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad90.sgproblem.html">http://cogsci.soton.ac.uk/~harnad/Papers/Harnad/harnad90.sgproblem.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad90.sgproblem.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad90.sgproblem.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://wexler.free.fr/library/files/harnad (1990) the symbol grounding problem.pdf">http://wexler.free.fr/library/files/harnad (1990) the symbol grounding problem.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000615/00/The_Symbol_Grounding_Problem.html">http://cogprints.ecs.soton.ac.uk/archive/00000615/00/The_Symbol_Grounding_Problem.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/%7Eharnad/Papers/Harnad/harnad90.sgproblem.html">http://www.ecs.soton.ac.uk/%7Eharnad/Papers/Harnad/harnad90.sgproblem.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.org/615/1/The_Symbol_Grounding_Problem.html">http://cogprints.org/615/1/The_Symbol_Grounding_Problem.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARTSG",this.href,0);return true;' href="http://cogprints.org/615/0/The_Symbol_Grounding_Problem.html">http://cogprints.org/615/0/The_Symbol_Grounding_Problem.html</a><br></div></div>
</div><!--entry-->

<div id='_521_entry' class='entry'><span ><span class='name'>Kosslyn, Stephen M.</span> &amp; <span class='name'>Hatfield, Gary</span> (1984). Representation without symbol systems.</span> <span class='pub_name'>Social Research</span> 51:1019-1045. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8858128331976555111'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representation%20without%20symbol%20systems+author%3AKosslyn&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_522_entry' class='entry'><span ><span class='name'>Lumsden, David</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("LUMHCA",this.href,0);return true;' href='http://beta.philosophyonline.org/xtf/data/dlg/44-1/dlg_0044_0001_0087_0096.pdf'>How can a symbol system come into being?</a></span> <span class='pub_name'>Dialogue</span> 44 (1):87-96. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20can%20a%20symbol%20system%20come%20into%20being%3F+author%3ALumsden&amp;btnG=Search'>Google</a>)</span><div id='_522_abstract' class='extra' style='font-size:12px;'>Abstract: One holistic thesis about symbols is that a symbol cannot exist singly, but only as apart of a symbol system. There is also the plausible view that symbol systems emerge gradually in an individual, in a group, and in a species. The problem is that symbol holism makes it hard to see how a symbol system can emerge gradually, at least if we are considering the emergence of a first symbol system. The only way it seems possible is if being a symbol can be a matter of degree, which is initially problematic. This article explains how being a cognitive symbol can be a matter of degree after all. The contrary intuition arises from the way a process of interpretation forces an all-or-nothing character on symbols, leaving room for underlying material to realize symbols to different degrees in a way that Daniel Dennettâs work can help illuminate. Holism applies to symbols as interpreted, while gradualism applies to how the underlying material realizes symbols.Selon une thÃ¨se holistique sur les symboles, un symbole ne peut exister isolÃ©ment mais doit faire partie dâun systÃ©me symbolique. Une opinion, elle aussi plausible, veut que les systÃ¨mes symboliques Ã©mergent graduellement chez un individu, un groupe ou une espÃ¨ce. Le problÃ¨me câest quâon voit mal, si le holisme des systÃ¨mes symboliques tient, comment un systÃ¨me symbolique peut Ã©merger graduellement, du moins pour la premiÃ¨re fois. Ce nâest possible, semble-t-il, que si Ãªtre un symbole est affaire de degrÃ©, thÃ¨se au dÃ©part problÃ©matique. Cet article explique comment Ãªtre un symbole cognitif peut aprÃ¨s tout Ãªtre affaire de degrÃ©. Lâintuition contraire vient de ce que le processus dâinterprÃ©tation nous force au tout ou rien, ce qui laisse un jeu dans la faÃ§on dont le matÃ©riel sous-jacent rÃ©alise les symboles Ã  des degrÃ©s divers. Les travaux de Daniel Dennett sont Ã  cet Ã©gard Ã©clairants. Le holisme vaut pour les symboles tels quâils sont interprÃ©tÃ©s, tandis que le gradualisme vaut pour la faÃ§on dont le matÃ©riel sous-jacent rÃ©alise les symboles</div>
</div><!--entry-->

<div id='_523_entry' class='entry'><span ><span class='name'>MacDorman, Karl F.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("MACHTG",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=Z2OTEkN9U1wC&amp;oi=fnd&amp;pg=PA135&amp;dq=How+to+ground+symbols+adaptively+MacDorman&amp;ots=JRHE91a7uu&amp;sig=hrqprNzzKui5v1baEN2Gln5rS2k'>How to ground symbols adaptively.</a></span> In S. O'Nuillain, Paul McKevitt &amp; E. MacAogain (eds.), <em>Two Sciences of Mind</em>. John Benjamins. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13116082918081810187'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20to%20ground%20symbols%20adaptively+author%3AMacDorman&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_524_entry' class='entry'><span ><span class='name'>Newell, Allen</span> &amp; <span class='name'>Simon, Herbert A.</span> (1981). <a rel="nofollow" class='article_title' onclick='trackclick("NEWCSA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=360022'>Computer science as empirical inquiry: Symbols and search.</a></span> <span class='pub_name'>Communications of the Association for Computing Machinery</span> 19:113-26. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2918170868892501302'>Cited by 758</a> | <span class='ll' onclick='$("_524_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computer%20science%20as%20empirical%20inquiry+author%3ANewell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_524_links")'>More links</a>)</span><div id='_524_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On computer science, AI, & the Physical Symbol System Hypothesis.</div></div>
<div id='_524_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=1283930">http://portal.acm.org/citation.cfm?id=1283930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://www.jdl.ac.cn/turing/pdf/p113-newell.pdf">http://www.jdl.ac.cn/turing/pdf/p113-newell.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=216000.216007">http://portal.acm.org/citation.cfm?id=216000.216007</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://home.dei.polimi.it/colombet/IA_2004/NewellandSimon.pdf">http://home.dei.polimi.it/colombet/IA_2004/NewellandSimon.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://www.elet.polimi.it/upload/colombet/IA_2004/NewellandSimon.pdf">http://www.elet.polimi.it/upload/colombet/IA_2004/NewellandSimon.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://act-r.psy.cmu.edu/~douglass/Douglass/Agents/TopicPapers/PSSH/PSSH1.pdf">http://act-r.psy.cmu.edu/~douglass/Douglass/Agents/TopicPapers/PSSH/PSSH1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://act-r.psy.cmu.edu/people/douglass/Douglass/Agents/TopicPapers/PSSH/PSSH1.pdf">http://act-r.psy.cmu.edu/people/douglass/Douglass/Agents/TopicPapers/PSSH/PSSH1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E4xI7EhGQs&amp;sig=JepEkCn93darsdPpvcGEn7VG61E">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E4xI7EhGQs&sig=JepEkCn93darsdPpvcGEn7VG61E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oJfHgzVu&amp;sig=5jb8G10Jz9vcHSA8SMjvAyDa79E">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oJfHgzVu&sig=5jb8G10Jz9vcHSA8SMjvAyDa79E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E4xIcIdzXt&amp;sig=x8TqXd03sMF7Ku2tjTjKPLStp7M">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E4xIcIdzXt&sig=x8TqXd03sMF7Ku2tjTjKPLStp7M</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oKbHjCZv&amp;sig=G4uV6cXYV2x1beYCw6nX6T4sbdI">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oKbHjCZv&sig=G4uV6cXYV2x1beYCw6nX6T4sbdI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oIdGczZr&amp;sig=-ndDGHatiVA3bw4jwnF9OuPsYOE">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oIdGczZr&sig=-ndDGHatiVA3bw4jwnF9OuPsYOE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oJ9HbFUs&amp;sig=bj8ATdZXgK2geid62HIRWyOdnuo">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oJ9HbFUs&sig=bj8ATdZXgK2geid62HIRWyOdnuo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oFdDiBTr&amp;sig=aHVuO1cvjfMeqsc-mx75yheObrA">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oFdDiBTr&sig=aHVuO1cvjfMeqsc-mx75yheObrA</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oF7DeyQy&amp;sig=cEaNBtdTsZioMpkk6W2Yd7_Ecf8">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oF7DeyQy&sig=cEaNBtdTsZioMpkk6W2Yd7_Ecf8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oI7FhAWv&amp;sig=TORphnvN5dYkzgzVFVGRZUaWdJc">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oI7FhAWv&sig=TORphnvN5dYkzgzVFVGRZUaWdJc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oEbCjyVy&amp;sig=NrAngS_FECgzGE2Iwqo6KD9OnDU">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oEbCjyVy&sig=NrAngS_FECgzGE2Iwqo6KD9OnDU</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E4xIaIczSt&amp;sig=YUwqrPXzwnaBIYgYiu0RVv1K52I">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E4xIaIczSt&sig=YUwqrPXzwnaBIYgYiu0RVv1K52I</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oHbFcCWw&amp;sig=0Avl1AKiXUbrSFEGnL7r0e8A8bM">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oHbFcCWw&sig=0Avl1AKiXUbrSFEGnL7r0e8A8bM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oG9EdDXt&amp;sig=43O3YB2BeYIwnOoSeJ-LE-V8lao">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oG9EdDXt&sig=43O3YB2BeYIwnOoSeJ-LE-V8lao</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWCSA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UqhjMVwYKJsC&amp;oi=fnd&amp;pg=PA109&amp;ots=E5oGfEiFSy&amp;sig=uTVh7cE69OpNBo9FxMib124gZ00">http://books.google.com/books?hl=en&lr=&id=UqhjMVwYKJsC&oi=fnd&pg=PA109&ots=E5oGfEiFSy&sig=uTVh7cE69OpNBo9FxMib124gZ00</a><br></div></div>
</div><!--entry-->

<div id='_525_entry' class='entry'><span ><span class='name'>Newell, Allen</span> (1980). <a rel="nofollow" class='article_title' onclick='trackclick("NEWPSS",this.href,0);return true;' href='http://www.leaonline.com/doi/abs/10.1207/s15516709cog0402_2'>Physical symbol systems.</a></span> <span class='pub_name'>Cognitive Science</span> 4:135-83. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4375905435357650352'>Cited by 469</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Physical%20symbol%20systems+author%3ANewell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_525_links")'>More links</a>)</span>
<div id='_525_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWPSS",this.href,0);return true;' href="http://www.leaonline.com/doi/pdf/10.1207/s15516709cog0402_2">http://www.leaonline.com/doi/pdf/10.1207/s15516709cog0402_2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWPSS",this.href,0);return true;' href="http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog0402_2">http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog0402_2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWPSS",this.href,0);return true;' href="http://www.cogsci.rpi.edu/CSJarchive/1980v04/i02/p0135p0183/MAIN.PDF">http://www.cogsci.rpi.edu/CSJarchive/1980v04/i02/p0135p0183/MAIN.PDF</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NEWPSS",this.href,0);return true;' href="http://stinet.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA224247">http://stinet.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA224247</a><br></div></div>
</div><!--entry-->

<div id='_526_entry' class='entry'><span ><span class='name'>Pinker, Steven</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("PINWN",this.href,0);return true;' href='http://amacad.org/publications/fall2004/pinker.pdf'>Why nature & nurture won't go away.</a></span> <span class='pub_name'>Daedalus</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2494057554727671281'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20nature%20%26%20nurture%20won%27t%20go%20away+author%3APinker&amp;btnG=Search'>Google</a> | <a href='javascript:show("_526_links")'>More links</a>)</span>
<div id='_526_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINWN",this.href,0);return true;' href="http://www.mitpressjournals.org/doi/abs/10.1162/0011526042365591">http://www.mitpressjournals.org/doi/abs/10.1162/0011526042365591</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINWN",this.href,0);return true;' href="http://pinker.wjh.harvard.edu/articles/papers/nature_nurture.pdf">http://pinker.wjh.harvard.edu/articles/papers/nature_nurture.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINWN",this.href,0);return true;' href="http://pinker.wjh.harvard.edu/articles/papers/nature_nurture.pdf ">http://pinker.wjh.harvard.edu/articles/papers/nature_nurture.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINWN",this.href,0);return true;' href="http://mitpress.mit.edu/catalog/item/default.asp?tid=17270&amp;ttype=6">http://mitpress.mit.edu/catalog/item/default.asp?tid=17270&ttype=6</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINWN",this.href,0);return true;' href="http://mitpress.mit.edu/catalog/item/default.asp?ttype=6&amp;tid=17270">http://mitpress.mit.edu/catalog/item/default.asp?ttype=6&tid=17270</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINWN",this.href,0);return true;' href="http://www.mitpressjournals.org/doi/pdfplus/10.1162/0011526042365591">http://www.mitpressjournals.org/doi/pdfplus/10.1162/0011526042365591</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINWN",this.href,0);return true;' href="http://www.ingentaconnect.com/content/mitpress/dae/2004/00000133/00000004/art00001">http://www.ingentaconnect.com/content/mitpress/dae/2004/00000133/00000004/art00001</a><br></div></div>
</div><!--entry-->

<div id='_527_entry' class='entry'><span ><span class='name'>Robinson, William S.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("ROBBSA",this.href,0);return true;' href='http://www.springerlink.com/content/l075451262856x7g/fulltext.pdf'>Brain symbols and computationalist explanation.</a></span> <span class='pub_name'>Minds and Machines</span> 5 (1):25-44. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9286180813998858138'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Brain%20symbols%20and%20computationalist%20explanation+author%3ARobinson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_527_links")'>More links</a>)</span><div id='_527_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Computationalist theories of mind require brain symbols, that is, neural events that represent kinds or instances of kinds. Standard models of computation require multiple inscriptions of symbols with the same representational content. The satisfaction of two conditions makes it easy to see how this requirement is met in computers, but we have no reason to think that these conditions are satisfied in the brain. Thus, if we wish to give computationalist explanations of human cognition, without committing ourselvesa priori to a strong and unsupported claim in neuroscience, we must first either explain how we can provide multiple brain symbols with the same content, or explain how we can abandon standard models of computation. It is argued that both of these alternatives require us to explain the execution of complex tasks that have a cognition-like structure. Circularity or regress are thus threatened, unless noncomputationalist principles can provide the required explanations. But in the latter case, we do not know that noncomputationalist principles might not bear most of the weight of explaining cognition. Four possible types of computationalist theory are discussed; none appears to provide a promising solution to the problem. Thus, despite known difficulties in noncomputationalist investigations, we have every reason to pursue the search for noncomputationalist principles in cognitive theory</div>
<div id='_527_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROBBSA",this.href,0);return true;' href="http://www.springerlink.com/index/L075451262856X7G.pdf">http://www.springerlink.com/index/L075451262856X7G.pdf</a><br></div></div>
</div><!--entry-->

<div id='_528_entry' class='entry'><span ><span class='name'>Roitblat, Herbert L.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("ROICG",this.href,0);return true;' href='http://psycprints.ecs.soton.ac.uk/archive/00000187/'>Computational grounding.</a></span> <span class='pub_name'>Psycoloquy</span> 12 (58). <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 1 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computational%20grounding+author%3ARoitblat&amp;btnG=Search'>Google</a> | <a href='javascript:show("_528_links")'>More links</a>)</span><div id='_528_abstract' class='extra' style='font-size:12px;'>Abstract: Harnad defines computation to mean the manipulation of physical symbol tokens on the basis of syntactic rules defined over the shapes of the symbols, independent of what, if anything, those symbols represent. He is, of course, free to define terms in any way that he chooses, and he is very clear about what he means by computation, but I am uncomfortable with this definition. It excludes, at least at a functional level of description, much of what a computer is actually used for, and much of what the brain/mind does. When I toss a Frisbee to the neighbor's dog, the dog does not, I think, engage in a symbolic soliloquy about the trajectory of the disc, the wind's effects on it, and formulas for including lift and the acceleration due to gravity. There are symbolic formulas for each of these relations, but the dog insofar as I can tell, does not use any of these formulas. Nevertheless, it computes these factors in order to intercept the disc in the air. I argue that determining the solution to a differential equation is at least as much computation as is processing symbols. The disagreement is over what counts as computation, I think that Harnad and I both agree that the dog solves the trajectory problem implicitly. This definition is important, because, although Harnad offers a technical definition for what he means by computation, the folk- definition of the term is probably interpreted differently, and I believe this leads to trouble</div>
<div id='_528_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROICG",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.roitblat.html">http://www.ecs.soton.ac.uk/~harnad/Papers/Harnad/harnad93.symb.anal.net.roitblat.html</a><br></div></div>
</div><!--entry-->

<div id='_529_entry' class='entry'><span ><span class='name'>Schneider, Susan</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("SCHLCA",this.href,0);return true;' href='http://www.sas.upenn.edu/~sls/SchneiderLOTSynthese.rtf'>Lot, ctm, and the elephant in the room.</a></span> <span class='pub_name'>Synthese</span> 170 (2):235-250. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Lot%2C%20ctm%2C%20and%20the%20elephant%20in%20the%20room+author%3ASchneider&amp;btnG=Search'>Google</a> | <a href='javascript:show("_529_links")'>More links</a>)</span><div id='_529_abstract' class='extra' style='font-size:12px;'>Abstract: According to the language of thought (LOT) approach and the related computational theory of mind (CTM), thinking is the processing of symbols in an inner mental language that is distinct from any public language. Herein, I explore a deep problem at the heart of the LOT/CTM programâit has yet to provide a plausible conception of a mental symbol</div>
<div id='_529_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHLCA",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/SchneiderLOTSynthesesent.rtf">http://www.sas.upenn.edu/~sls/SchneiderLOTSynthesesent.rtf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHLCA",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/documents/SchneiderSyntheseLOT.pdf">http://www.sas.upenn.edu/~sls/documents/SchneiderSyntheseLOT.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHLCA",this.href,0);return true;' href="http://www.springerlink.com/content/f9312g2m003630r0/fulltext.pdf">http://www.springerlink.com/content/f9312g2m003630r0/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_530_entry' class='entry'><span ><span class='name'>Schneider, Susan</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href='http://www.sas.upenn.edu/~sls/documents/1NatureofSymbols.doc'>The nature of primitive symbols in the language of thought.</a></span> <span class='pub_name'>Mind and Language</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20nature%20of%20primitive%20symbols%20in%20the%20language%20of%20thought+author%3ASchneider&amp;btnG=Search'>Google</a> | <a href='javascript:show("_530_links")'>More links</a>)</span><div id='_530_abstract' class='extra' style='font-size:12px;'>Abstract: This paper provides a theory of the nature of symbols in the language of thought (LOT). My discussion consists in three parts. In part one, I provide three arguments for the individuation of primitive symbols in terms of total computational role. The first of these arguments claims that Classicism requires that primitive symbols be typed in this manner; no other theory of typing will suffice. The second argument contends that without this manner of symbol individuation, there will be computational processes that fail to supervene on syntax, together with the rules of composition and the computational algorithms. The third argument says that cognitive science needs a natural kind that is typed by total computational role. Otherwise, either cognitive science will be incomplete, or its laws will have counterexamples. Then, part two defends this view from a criticism, offered by both Jerry Fodor and Jesse Prinz, who respond to my view with the charge that because the types themselves are individuated</div>
<div id='_530_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang.doc">http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang.doc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang-1-2.pdf">http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang-1-2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/documents/Schneider-MindLangSymbols.pdf">http://www.sas.upenn.edu/~sls/documents/Schneider-MindLangSymbols.pdf</a><br></div></div>
</div><!--entry-->

<div id='_531_entry' class='entry'><span ><span class='name'>Sun, Ron</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("SUNSGA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/285913.html'>Symbol grounding: A new look at an old idea.</a></span> <span class='pub_name'>Philosophical Psychology</span> 13 (2):149-172. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8490479044347003851'>Cited by 39</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Symbol%20grounding+author%3ASun&amp;btnG=Search'>Google</a> | <a href='javascript:show("_531_links")'>More links</a>)</span><div id='_531_abstract' class='extra' style='font-size:12px;'>Abstract: Symbols should be grounded, as has been argued before. But we insist that they should be grounded not only in subsymbolic activities, but also in the interaction between the agent and the world. The point is that concepts are not formed in isolation (from the world), in abstraction, or "objectively." They are formed in relation to the experience of agents, through their perceptual/motor apparatuses, in their world and linked to their goals and actions. This paper takes a detailed look at this relatively old issue, with a new perspective, aided by our work of computational cognitive model development. To further our understanding, we also go back in time to link up with earlier philosophical theories related to this issue. The result is an account that extends from computational mechanisms to philosophical abstractions</div>
<div id='_531_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUNSGA",this.href,0);return true;' href="http://www.cogsci.rpi.edu/~rsun/sun.PP00.ps">http://www.cogsci.rpi.edu/~rsun/sun.PP00.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUNSGA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/sun99symbol.html">http://citeseer.ist.psu.edu/sun99symbol.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUNSGA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a713690432~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a713690432~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUNSGA",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/KKLQAQTYVG4RUY7G.pdf">http://taylorandfrancis.metapress.com/index/KKLQAQTYVG4RUY7G.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUNSGA",this.href,0);return true;' href="http://www.informaworld.com/index/KKLQAQTYVG4RUY7G.pdf">http://www.informaworld.com/index/KKLQAQTYVG4RUY7G.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUNSGA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000002/art00001">http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000002/art00001</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUNSGA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713690432~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713690432~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_532_entry' class='entry'><span ><span class='name'>Taddeo, Mariarosaria</span> &amp; <span class='name'>Floridi, Luciano</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("TADAPS",this.href,0);return true;' href='http://philsci-archive.pitt.edu/archive/00004077/01/apsotsgp.pdf'>A praxical solution of the symbol grounding problem.</a></span> <span class='pub_name'>Minds and Machines</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20praxical%20solution%20of%20the%20symbol%20grounding%20problem+author%3ATaddeo&amp;btnG=Search'>Google</a> | <a href='javascript:show("_532_links")'>More links</a>)</span><div id='_532_abstract' class='extra' style='font-size:12px;'>Abstract:  This article is the second step in our research into the Symbol Grounding Problem (SGP). In a previous work, we defined the main condition that must be satisfied by any strategy in order to provide a valid solution to the SGP, namely the zero semantic commitment condition (Z condition). We then showed that all the main strategies proposed so far fail to satisfy the Z condition, although they provide several important lessons to be followed by any new proposal. Here, we develop a new solution of the SGP. It is called praxical in order to stress the key role played by the interactions between the agents and their environment. It is based on a new theory of meaningâAction-based Semantics (AbS)âand on a new kind of artificial agents, called two-machine artificial agents (AMÂ²). Thanks to their architecture, AM2s implement AbS, and this allows them to ground their symbols semantically and to develop some fairly advanced semantic abilities, including the development of semantically grounded communication and the elaboration of representations, while still respecting the Z condition</div>
<div id='_532_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TADAPS",this.href,0);return true;' href="http://www.springerlink.com/content/f748ru5636784058/fulltext.pdf">http://www.springerlink.com/content/f748ru5636784058/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_533_entry' class='entry'><span ><span class='name'>Thompson, Evan</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("THOSGA",this.href,0);return true;' href='http://individual.utoronto.ca/evant/SymbolGrounding.pdf'>Symbol grounding: A bridge from artiï¬cial life to artiï¬cial intelligence.</a></span> <span class='pub_name'>Brain and Cognition</span> 34 (1):48-71. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 8 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Symbol%20grounding+author%3AThompson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_533_links")'>More links</a>)</span><div id='_533_abstract' class='extra' style='font-size:12px;'>Abstract: This paper develops a bridge from AL issues about the symbolâmatter relation to AI issues about symbol-grounding by focusing on the concepts of formality and syntactic interpretability. Using the DNA triplet-amino acid speciï¬cation relation as a paradigm, it is argued that syntactic properties can be grounded as high-level features of the non-syntactic interactions in a physical dynamical system. This argu- ment provides the basis for a rebuttal of John Searleâs recent assertion that syntax is observer-relative (1990, 1992). But the argument as developed also challenges the classic symbol-processing theory of mind against which Searle is arguing, as well as the strong AL thesis that life is realizable in a purely computational medium. Finally, it provides a new line of support for the autonomous systems approach in AL and AI (Varela & Bourgine 1992a, 1992b). Â© 1997 Academic Press</div>
<div id='_533_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOSGA",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=9209755&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=9209755&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOSGA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/ap/br/1997/00000034/00000001/art00906">http://www.ingentaconnect.com/content/ap/br/1997/00000034/00000001/art00906</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.2b'></a><a name=''></a><span class='myh3'>6.2b Computational Semantics</span></p>

<div id='cat_6.2b' class='cat_content'>
<div id='__new_entries_6.2b__'></div><div id='__new_entry_6.2b__' class='entry'></div>
<div id='_534_entry' class='entry'><span ><span class='name'>Akman, Varol</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("AKMSAA",this.href,0);return true;' href='http://www.cs.bilkent.edu.tr/~akman/jour-papers/mam/mam1998.pdf'>Situations and artificial intelligence.</a></span> <span class='pub_name'>Minds and Machines</span> 8 (4):475-477. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Situations%20and%20artificial%20intelligence+author%3AAkman&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_535_entry' class='entry'><span ><span class='name'>Blackburn, Patrick</span> &amp; <span class='name'>Bos, Johan</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("BLACS-3",this.href,0);return true;' href='http://beta.philosophyonline.org/xtf/data/tss/18-1/tss_0018_0001_0027_0045.pdf'>Computational semantics.</a></span> <span class='pub_name'>Theoria: Revista de TeorÃ­a, Historia y Fundamentos de la Ciencia</span> 18 (1):27-45. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computational%20semantics+author%3ABlackburn&amp;btnG=Search'>Google</a>)</span><div id='_535_abstract' class='extra' style='font-size:12px;'>Abstract: In this article we discuss what constitutes a good choice of semantic representation, compare different approaches of constructing semantic representations for fragments of natural language, and give an overview of recent methods for employing inference engines for natural language understanding tasks</div>
</div><!--entry-->

<div id='_536_entry' class='entry'><span ><span class='name'>Blackburn, Patrick</span> &amp; <span class='name'>Kohlhase, Michael</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("BLAIAC",this.href,0);return true;' href='http://www.springerlink.com/content/j1552255x22990u7/fulltext.pdf'>Inference and computational semantics.</a></span> <span class='pub_name'>Journal of Logic, Language and Information</span> 13 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Inference%20and%20computational%20semantics+author%3ABlackburn&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_537_entry' class='entry'><span ><span class='name'>Blackburn, Patrick</span> (2005). <em><span class='pub_name'>Representation and Inference for Natural Language: A First Course in Computational Semantics.</span></em></span> Center for the Study of Language and Information. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representation%20and%20Inference%20for%20Natural%20Language+author%3ABlackburn&amp;btnG=Search'>Google</a>)</span><div id='_537_abstract' class='extra' style='font-size:12px;'>Abstract: How can computers distinguish the coherent from the unintelligible, recognize new information in a sentence, or draw inferences from a natural language passage? Computational semantics is an exciting new field that seeks answers to these questions, and this volume is the first textbook wholly devoted to this growing subdiscipline. The book explains the underlying theoretical issues and fundamental techniques for computing semantic representations for fragments of natural language. This volume will be an essential text for computer scientists, linguists, and anyone interested in the development of computational semantics</div>
</div><!--entry-->

<div id='_538_entry' class='entry'><span ><span class='name'>Bogdan, Radu J.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("BOGBWO",this.href,0);return true;' href='http://www.tulane.edu/~bogdan/teleology.pdf'>By way of means and ends.</a></span> In Radu J. Bogdan (ed.), <em>Grounds for Cognition</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=By%20way%20of%20means%20and%20ends+author%3ABogdan&amp;btnG=Search'>Google</a>)</span><div id='_538_abstract' class='extra' style='font-size:12px;'>Abstract: This chapter provides the teleological foundations for our analysis of guidance to goal. Its objective is to ground goal-directedness genetically. The basic suggestion is this. Organisms are small things, with few energy resources and puny physical means, battling a ruthless physical and biological nature. How do they manage to survive and multiply? CLEVERLY, BY ORGANIZING</div>
</div><!--entry-->

<div id='_539_entry' class='entry'><span ><span class='name'>Bos, Johan</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("BOSCSI",this.href,0);return true;' href='http://www.springerlink.com/content/wv32vl67q0657320/fulltext.pdf'>Computational semantics in discourse: Underspecification, resolution, and inference.</a></span> <span class='pub_name'>Journal of Logic, Language and Information</span> 13 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computational%20semantics%20in%20discourse+author%3ABos&amp;btnG=Search'>Google</a>)</span><div id='_539_abstract' class='extra' style='font-size:12px;'>Abstract:  In this paper I introduce a formalism for natural language understandingbased on a computational implementation of Discourse RepresentationTheory. The formalism covers a wide variety of semantic phenomena(including scope and lexical ambiguities, anaphora and presupposition),is computationally attractive, and has a genuine inference component. Itcombines a well-established linguistic formalism (DRT) with advancedtechniques to deal with ambiguity (underspecification), and isinnovative in the use of first-order theorem proving techniques.The architecture of the formalism for natural language understandingthat I advocate consists of three levels of processing:underspecification, resolution, andinference. Each of these levels has a distinct function andtherefore employs a different kind of semantic representation. Themappings between these different representations define the interfacesbetween the levels</div>
</div><!--entry-->

<div id='_540_entry' class='entry'><span ><span class='name'>Charniak, Eugene</span> &amp; <span class='name'>Wilks, Yorick</span> (eds.) (1976). <em><span class='pub_name'>Computational Semantics: An Introduction to Artificial Intelligence and Natural Language Comprehension.</span></em></span> Distributors for the U.S.A. And Canada, Elsevier/North Holland. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computational%20Semantics+author%3ACharniak&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_541_entry' class='entry'><span ><span class='name'>Szymanik, Jakub</span> &amp; <span class='name'>Zajenkowski, Marcin</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("COS",this.href,0);return true;' href='http://staff.science.uva.nl/~szymanik/papers/kwantyfikatory.pdf'>Comprehension of Simple Quantifiers. Empirical Evaluation of a Computational Model.</a></span> <span class='pub_name'>Cognitive Science: A Multidisciplinary Journal</span> 34 (3):521-532. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Comprehension%20of%20Simple%20Quantifiers.%20Empirical%20Evaluation%20of%20a%20Computational%20Model+author%3ASzymanik&amp;btnG=Search'>Google</a>)</span><div id='_541_abstract' class='extra' style='font-size:12px;'>Abstract: We examine the verification of simple quantifiers in natural language from a computational model perspective. We refer to previous neuropsychological investigations of the same problem and suggest extending their experimental setting. Moreover, we give some direct empirical evidence linking computational complexity predictions with cognitive reality.<br>In the empirical study we compare time needed for understanding different types of quantifiers. We show that the computational distinction between quantifiers recognized by finite-automata and push-down automata is psychologically relevant. Our research improves upon hypothesis and explanatory power of recent neuroimaging studies as well as provides<br>evidence</div>
</div><!--entry-->

<div id='_542_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("DENTBE",this.href,0);return true;' href='http://ase.tufts.edu/cogstud/papers/baldwincranefin.htm'>The Baldwin Effect: A Crane, Not a Skyhook.</a></span> In Bruce H. Weber &amp; D.J. Depew (eds.), <em>And Learning: The Baldwin Effect Reconsidered</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1240263229571627667'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Baldwin%20Effect+author%3ADennett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_542_links")'>More links</a>)</span><div id='_542_abstract' class='extra' style='font-size:12px;'>Abstract: In 1991, I included a brief discussion of the Baldwin effect in my account of the evolution of human consciousness, thinking I was introducing to non-specialist readers a little-appreciated, but no longer controversial, wrinkle in orthodox neo-Darwinism. I had thought that Hinton and Nowlan (1987) and Maynard Smith (1987) had shown clearly and succinctly how and why it worked, and restored the neglected concept to grace. Here is how I put it then</div>
<div id='_542_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENTBE",this.href,0);return true;' href="http://ase.tufts.edu/cogstud/papers/baldwincranefin.htm ">http://ase.tufts.edu/cogstud/papers/baldwincranefin.htm </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENTBE",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=yBtRzBilw1MC&amp;oi=fnd&amp;pg=PA69&amp;dq=The+Baldwin+effect+Dennett&amp;ots=2I8w0wd3n_&amp;sig=urmY-aQvjQsgpb_W81dI6SjJvGc">http://books.google.com/books?hl=en&lr=&id=yBtRzBilw1MC&oi=fnd&pg=PA69&dq=The+Baldwin+effect+Dennett&ots=2I8w0wd3n_&sig=urmY-aQvjQsgpb_W81dI6SjJvGc</a><br></div></div>
</div><!--entry-->

<div id='_543_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> (1979). In reply to Philip Johnson-Laird's <em>What's Wrong with Grandma's Guide to Procedural Semantics: A Reply to Jerry Fodor</em>.</span> <span class='pub_name'>Cognition</span> 7 (March):93-95. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=In%20reply%20to%20Philip%20Johnson-Laird%27s%20What%27s%20Wrong%20with%20Grandma%27s%20Guide%20to%20Procedural%20Semantics+author%3AFodor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_544_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> (1978). <a rel="nofollow" class='article_title' onclick='trackclick("FODTSA",this.href,0);return true;' href='http://www.nyu.edu/gsas/dept/philo/courses/mindsandmachines/Papers/tomswift.pdf'>Tom swift and his procedural grandmother.</a></span> <span class='pub_name'>Cognition</span> 6 (September):229-47. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=260080448441290192'>Cited by 24</a> | <span class='ll' onclick='$("_544_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Tom%20swift%20and%20his%20procedural%20grandmother+author%3AFodor&amp;btnG=Search'>Google</a>)</span><div id='_544_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Against procedural semantics; it's a rerun of verificationism.</div></div>
</div><!--entry-->

<div id='_545_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1990). Truth conditions and procedural semantics.</span> In Philip P. Hanson (ed.), <em>Information, Language and Cognition</em>. University of British Columbia Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11885572562717933664'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Truth%20conditions%20and%20procedural%20semantics+author%3AHadley&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_546_entry' class='entry'><span ><span class='name'>Harnad, Stevan</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("HARDST",this.href,0);return true;' href='http://eprints.ecs.soton.ac.uk/7715/'>Darwin, Skinner, Turing and the mind.</a></span> <span class='pub_name'>Magyar Pszichologiai Szemle</span> 57 (4):521-528. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Darwin%2C%20Skinner%2C%20Turing%20and%20the%20mind+author%3AHarnad&amp;btnG=Search'>Google</a> | <a href='javascript:show("_546_links")'>More links</a>)</span><div id='_546_abstract' class='extra' style='font-size:12px;'>Abstract: Darwin differs from Newton and Einstein in that his ideas do not require a complicated or deep mind to understand them, and perhaps did not even require such a mind in order to generate them in the first place. It can be explained to any school-child (as Newtonian mechanics and Einsteinian relativity cannot) that living creatures are just Darwinian survival/reproduction machines. They have whatever structure they have through a combination of chance and its consequences: Chance causes changes in the genetic blueprint from which organisms' bodies are built, and if those changes are more successful in helping their owners survive and reproduce than their predecessors or their rivals, then, by definition, those changes are reproduced, and thereby become more prevalent in succeeding generations: Whatever survives/reproduces better survives/reproduces better. That is the tautological force that shaped us</div>
<div id='_546_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://cogprints.org/3016/01/darwin.htm ">http://cogprints.org/3016/01/darwin.htm </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://eprints.resist.ecs.soton.ac.uk/7715/">http://eprints.resist.ecs.soton.ac.uk/7715/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/7715/01/darwin.htm">http://eprints.ecs.soton.ac.uk/7715/01/darwin.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003016/">http://cogprints.ecs.soton.ac.uk/archive/00003016/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/darwin.htm">http://www.ecs.soton.ac.uk/~harnad/Temp/darwin.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://eprints.ecs.soton.ac.uk/7715/01/darwin.htm ">http://eprints.ecs.soton.ac.uk/7715/01/darwin.htm </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://www.ecs.soton.ac.uk/~harnad/Temp/darwin.htm ">http://www.ecs.soton.ac.uk/~harnad/Temp/darwin.htm </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00003016/ ">http://cogprints.ecs.soton.ac.uk/archive/00003016/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:3016">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:3016</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:3016 ">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:3016 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HARDST",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:7715">http://citebase.eprints.org/cgi-bin/citations?id=oai:eprints.ecs.soton.ac.uk:7715</a><br></div></div>
</div><!--entry-->

<div id='_547_entry' class='entry'><span ><span class='name'>Johnson-Laird, Philip N.</span> (1977). <a rel="nofollow" class='article_title' onclick='trackclick("JOHPS",this.href,0);return true;' href='http://www.nyu.edu/gsas/dept/philo/courses/mindsandmachines/Papers/procedural.pdf'>Procedural semantics.</a></span> <span class='pub_name'>Cognition</span> 5:189-214. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18139012698253839193'>Cited by 37</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Procedural%20semantics+author%3AJohnson-Laird&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_548_entry' class='entry'><span ><span class='name'>Johnson-Laird, Philip N.</span> (1978). What's wrong with grandma's guide to procedural semantics: A reply to Jerry Fodor.</span> <span class='pub_name'>Cognition</span> 9 (September):249-61. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14387210116435115178'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%27s%20wrong%20with%20grandma%27s%20guide%20to%20procedural%20semantics+author%3AJohnson-Laird&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_549_entry' class='entry'><span ><span class='name'>McDermott, Drew</span> (1978). <a rel="nofollow" class='article_title' onclick='trackclick("MCDTSO",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=24333'>Tarskian semantics, or no notation without denotation.</a></span> <span class='pub_name'>Cognitive Science</span> 2:277-82. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12111241236628880989'>Cited by 33</a> | <span class='ll' onclick='$("_549_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Tarskian%20semantics%2C%20or%20no%20notation%20without%20denotation+author%3AMcDermott&amp;btnG=Search'>Google</a> | <a href='javascript:show("_549_links")'>More links</a>)</span><div id='_549_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the virtues of denotational semantics for AI. Notation without denotation, as found in many AI systems, leads to castles in the air.</div></div>
<div id='_549_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCDTSO",this.href,0);return true;' href="http://www.leaonline.com/doi/abs/10.1207/s15516709cog0203_5">http://www.leaonline.com/doi/abs/10.1207/s15516709cog0203_5</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCDTSO",this.href,0);return true;' href="http://www.leaonline.com/doi/pdf/10.1207/s15516709cog0203_5">http://www.leaonline.com/doi/pdf/10.1207/s15516709cog0203_5</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCDTSO",this.href,0);return true;' href="http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog0203_5">http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog0203_5</a><br></div></div>
</div><!--entry-->

<div id='_550_entry' class='entry'><span ><span class='name'>Papineau, David</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("PAPTCO-2",this.href,0);return true;' href='http://www.kcl.ac.uk/ip/davidpapineau/Staff/Papineau/OnlinePapers/CultOrCogAdptns.htm '>The cultural origins of cognitive adaptations.</a></span> <span class='pub_name'>Royal Institute of Philosophy Supplement</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20cultural%20origins%20of%20cognitive%20adaptations+author%3APapineau&amp;btnG=Search'>Google</a> | <a href='javascript:show("_550_links")'>More links</a>)</span><div id='_550_abstract' class='extra' style='font-size:12px;'>Abstract: According to an influential view in contemporary cognitive science, many human cognitive capacities are innate. The primary support for this view comes from âpoverty of stimulusâ arguments. In general outline, such arguments contrast the meagre informational input to cognitive development with its rich informational output. Consider the ease with which humans acquire languages, become facile at attributing psychological states (âfolk psychologyâ), gain knowledge of biological kinds (âfolk biologyâ), or come to understand basic physical processes (âfolk physicsâ). In all these cases, the evidence available to a growing child is far too thin and noisy for it to be plausible that the underlying principles involved are derived from general learning mechanisms. This only alternative hypothesis seems to be that the childâs grasp of these principles is innate. (Cf. Laurence and Margolis, 2001.)</div>
<div id='_550_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PAPTCO-2",this.href,0);return true;' href="http://journals.cambridge.org/abstract_S1358246105056134">http://journals.cambridge.org/abstract_S1358246105056134</a><br></div></div>
</div><!--entry-->

<div id='_551_entry' class='entry'><span ><span class='name'>Perlis, Donald R.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("PERPOF",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0029-4624(199109)25:4&lt;435:POFIOH&gt;2.0.CO;2-1'>Putting one's foot in one's head -- part 1: Why.</a></span> <span class='pub_name'>NoÃ»s</span> 25 (September):435-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4078106182870868464'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Putting%20one%27s%20foot%20in%20one%27s%20head%20--%20part%201+author%3APerlis&amp;btnG=Search'>Google</a> | <a href='javascript:show("_551_links")'>More links</a>)</span>
<div id='_551_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PERPOF",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0029-4624(199109)25:4&lt;435:POFIOH&gt;2.0.CO;2-1">http://www.jstor.org/sici?sici=0029-4624(199109)25:4<435:POFIOH>2.0.CO;2-1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PERPOF",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2216073.pdf">http://www.jstor.org/stable/pdfplus/2216073.pdf</a><br></div></div>
</div><!--entry-->

<div id='_552_entry' class='entry'><span ><span class='name'>Perlis, Donald R.</span> (1994). Putting one's foot in one's head -- part 2: How.</span> In Eric Dietrich (ed.), <em>Thinking Computers and Virtual Persons</em>. Academic Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Putting%20one%27s%20foot%20in%20one%27s%20head%20--%20part%202+author%3APerlis&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_553_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (1988). Syntactic semantics: Foundations of computational natural language understanding.</span> In James H. Fetzer (ed.), <em>Aspects of AI</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2445002725136557054'>Cited by 44</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Syntactic%20semantics+author%3ARapaport&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_554_entry' class='entry'><span ><span class='name'>Rapaport, William J.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("RAPUUS",this.href,0);return true;' href='http://www.cse.buffalo.edu/tech-reports/94-28.ps'>Understanding understanding: Syntactic semantics and computational cognition.</a></span> <span class='pub_name'>Philosophical Perspectives</span> 9:49-88. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9511544090872807945'>Cited by 22</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Understanding%20understanding+author%3ARapaport&amp;btnG=Search'>Google</a> | <a href='javascript:show("_554_links")'>More links</a>)</span>
<div id='_554_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPUUS",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/understanding.ps">http://www.cse.buffalo.edu/~rapaport/Papers/understanding.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPUUS",this.href,0);return true;' href="http://historical.ncstrl.org/litesite-data/suny_buffalo_cs/94-28.ps.Z">http://historical.ncstrl.org/litesite-data/suny_buffalo_cs/94-28.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPUUS",this.href,0);return true;' href="http://links.jstor.org/sici?sici=1520-8583(1995)9&lt;49:UUSSAC&gt;2.0.CO;2-G">http://links.jstor.org/sici?sici=1520-8583(1995)9<49:UUSSAC>2.0.CO;2-G</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPUUS",this.href,0);return true;' href="http://www.jstor.org/sici?sici=1520-8583(1995)9&lt;49:UUSSAC&gt;2.0.CO;2-G">http://www.jstor.org/sici?sici=1520-8583(1995)9<49:UUSSAC>2.0.CO;2-G</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAPUUS",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2214212.pdf">http://www.jstor.org/stable/pdfplus/2214212.pdf</a><br></div></div>
</div><!--entry-->

<div id='_555_entry' class='entry'><span ><span class='name'>Smith, B.</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("SMIOTS",this.href,0);return true;' href='http://www.dfki.uni-sb.de/imedia/lidos/bibtex/Fetzer_a10623-35.html'>On the semantics of clocks.</a></span> In James H. Fetzer (ed.), <em>Aspects of AI</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4055078825392252216'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20semantics%20of%20clocks+author%3ASmith&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_556_entry' class='entry'><span ><span class='name'>Smith, B.</span> (1987). The correspondence continuum.</span> <span class='pub_name'>Csli</span> 87. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16228045560331453871'>Cited by 34</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20correspondence%20continuum+author%3ASmith&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_557_entry' class='entry'><span ><span class='name'>Szymanik, Jakub</span> &amp; <span class='name'>Zajenkowski, Marcin</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("SZYUQI",this.href,0);return true;' href='http://www-abc.mpib-berlin.mpg.de/CogSci09/'>Understanding Quantifiers in Language.</a></span> In N. A. Taatgen &amp; H. van Rijn (eds.), <em>Proceedings of the 31st Annual Conference of the Cognitive Science Society</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Understanding%20Quantifiers%20in%20Language+author%3ASzymanik&amp;btnG=Search'>Google</a>)</span><div id='_557_abstract' class='extra' style='font-size:12px;'>Abstract: We compare time needed for understanding different types
of quantifiers. We show that the computational distinction
between quantifiers recognized by finite-automata and pushdown
automata is psychologically relevant. Our research improves
upon hypothesis and explanatory power of recent neuroimaging
studies as well as provides evidence for the claim
that human linguistic abilities are constrained by computational
complexity.</div>
</div><!--entry-->

<div id='_558_entry' class='entry'><span ><span class='name'>Tin, Erkan</span> &amp; <span class='name'>Akman, Varol</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("TINCST",this.href,0);return true;' href='http://cogprints.org/200/'>Computational situation theory.</a></span> <span class='pub_name'>ACM SIGART Bulletin</span> 5 (4):4-17. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 15 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computational%20situation%20theory+author%3ATin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_558_links")'>More links</a>)</span><div id='_558_abstract' class='extra' style='font-size:12px;'>Abstract: Situation theory has been developed over the last decade and various versions of the theory have been applied to a number of linguistic issues. However, not much work has been done in regard to its computational aspects. In this paper, we review the existing approaches towards `computational situation theory' with considerable emphasis on our own research</div>
<div id='_558_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://citeseer.ist.psu.edu/599996.html">http://citeseer.ist.psu.edu/599996.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000200/">http://cogprints.ecs.soton.ac.uk/archive/00000200/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=191604.191608">http://portal.acm.org/citation.cfm?id=191604.191608</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://citeseer.ist.psu.edu/tin94computational.html">http://citeseer.ist.psu.edu/tin94computational.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://www.cs.bilkent.edu.tr/~akman/jour-papers/sigart/sigart1994.pdf">http://www.cs.bilkent.edu.tr/~akman/jour-papers/sigart/sigart1994.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:200">http://citebase.eprints.org/cgi-bin/citations?id=oai:cogprints.soton.ac.uk:200</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:200">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:200</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://cogprints.org/200/2/sig.ps">http://cogprints.org/200/2/sig.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TINCST",this.href,0);return true;' href="http://cogprints.org/200/0/sig.ps">http://cogprints.org/200/0/sig.ps</a><br></div></div>
</div><!--entry-->

<div id='_559_entry' class='entry'><span ><span class='name'>Wilks, Y.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("WILFAC-2",this.href,0);return true;' href='http://www.springerlink.com/content/n51t8ht6v72g63m4/fulltext.pdf'>Form and content in semantics.</a></span> <span class='pub_name'>Synthese</span> 82 (3):329-51. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7815912874846153249'>Cited by 10</a> | <span class='ll' onclick='$("_559_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Form%20and%20content%20in%20semantics+author%3AWilks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_559_links")'>More links</a>)</span><div id='_559_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Criticism of McDermott's views on semantics, logic and natural language.</div></div><div id='_559_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper continues a strain of intellectual complaint against the presumptions of certain kinds of formal semantics (the qualification is important) and their bad effects on those areas of artificial intelligence concerned with machine understanding of human language. After some discussion of the use of the term epistemology in artificial intelligence, the paper takes as a case study the various positions held by McDermott on these issues and concludes, reluctantly, that, although he has reversed himself on the issue, there was no time at which he was right</div>
<div id='_559_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILFAC-2",this.href,0);return true;' href="http://www.springerlink.com/index/N51T8HT6V72G63M4.pdf">http://www.springerlink.com/index/N51T8HT6V72G63M4.pdf</a><br></div></div>
</div><!--entry-->

<div id='_560_entry' class='entry'><span ><span class='name'>Wilks, Y.</span> (1982). Some thoughts on procedural semantics.</span> In W. Lehnert (ed.), <em>Strategies for Natural Language Processing</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12571617434355537939'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Some%20thoughts%20on%20procedural%20semantics+author%3AWilks&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_561_entry' class='entry'><span ><span class='name'>Winograd, Terry</span> (1985). <a rel="nofollow" class='article_title' onclick='trackclick("WINMTS",this.href,0);return true;' href='http://www.springerlink.com/content/n7w873341553w800/fulltext.pdf'>Moving the semantic fulcrum.</a></span> <span class='pub_name'>Linguistics and Philosophy</span> 8 (February):91-104. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15770255206587762210'>Cited by 16</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Moving%20the%20semantic%20fulcrum+author%3AWinograd&amp;btnG=Search'>Google</a> | <a href='javascript:show("_561_links")'>More links</a>)</span>
<div id='_561_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINMTS",this.href,0);return true;' href="http://www.springerlink.com/index/N7W873341553W800.pdf">http://www.springerlink.com/index/N7W873341553W800.pdf</a><br></div></div>
</div><!--entry-->

<div id='_562_entry' class='entry'><span ><span class='name'>Woods, W.</span> (1986). Problems in procedural semantics.</span> In Zenon W. Pylyshyn &amp; W. Demopolous (eds.), <em>Meaning and Cognitive Structure</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1510338010677002446'>Cited by 2</a> | <span class='ll' onclick='$("_562_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Problems%20in%20procedural%20semantics+author%3AWoods&amp;btnG=Search'>Google</a>)</span><div id='_562_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>With commentaries by Haugeland, J. D. Fodor.</div></div>
</div><!--entry-->

<div id='_563_entry' class='entry'><span ><span class='name'>Woods, W.</span> (1981). <a rel="nofollow" class='article_title' onclick='trackclick("WOOPSA",this.href,0);return true;' href='http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=N8123815AH'>Procedural semantics as a theory of meaning.</a></span> In A. Joshi, Bruce H. Weber &amp; Ivan A. Sag (eds.), <em>Elements of Discourse Understanding</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12551062442209408296'>Cited by 33</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Procedural%20semantics%20as%20a%20theory%20of%20meaning+author%3AWoods&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.2c'></a><a name=''></a><span class='myh3'>6.2c Implicit/Explicit Rules and Representations</span></p>

<div id='cat_6.2c' class='cat_content'>
<div id='__new_entries_6.2c__'></div><div id='__new_entry_6.2c__' class='entry'></div>
<div id='_564_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("BECEMM",this.href,0);return true;' href='http://mechanism.ucsd.edu/~bill/research/situatedcognitionpaper.webversion.pdf'>Explanation: Mechanism, modularity, and situated cognition.</a></span> In  P. Robbins &amp;  M. Aydede (eds.), <em>Cambridge Handbook of Situated Cognition</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Explanation+author%3ABechtel&amp;btnG=Search'>Google</a>)</span><div id='_564_abstract' class='extra' style='font-size:12px;'>Abstract: The situated cognition movement has emerged in recent decades (although it has roots in psychologists working earlier in the 20<sup>th</sup> century including Vygotsky, Bartlett, and Dewey) largely in reaction to an approach to explaining cognition that tended to ignore the context in which cognitive activities typically occur. Fodorâs (1980) account of the research strategy of methodological solipsism, according to which only representational states within the mind are viewed as playing causal roles in producing cognitive activity, is an extreme characterization of this approach. (As Keith Gunderson memorably commented when Fodor first presented this characterization, it amounts to reversing behaviorism by construing the mind as a white box in a black world). Critics as far back as the 1970s and 1980s objected to many experimental paradigms in cognitive psychology as not being ecologically valid; that is, they maintained that the findings only applied to the artificial circumstances created in the laboratory and did not generalize to real world settings (Neisser, 1976; 1987). The situated cognition movement, however, goes much further than demanding ecologically valid experimentsâit insists that an agentâs cognitive activities are inherently embedded and supported by dynamic interactions with the agentâs body and features of its environment</div>
</div><!--entry-->

<div id='_565_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("CLAIDO",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=UckGbfzYkkgC&amp;oi=fnd&amp;pg=PA115&amp;dq=In+defense+of+explicit+rules+Clark&amp;ots=8HpVqVx_xg&amp;sig=G5Jt9ggXHYv3anbFUMKub2cPFRw'>In defense of explicit rules.</a></span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10637903911500738248'>Cited by 11</a> | <span class='ll' onclick='$("_565_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=In%20defense%20of%20explicit%20rules+author%3AClark&amp;btnG=Search'>Google</a>)</span><div id='_565_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that we need explicit rules for flexibility, adaptibility, and representational redescription. With remarks on eliminativism.</div></div>
</div><!--entry-->

<div id='_566_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> (1986). Inexplicit information.</span> In Myles Brand &amp; Robert M. Harnish (eds.), <em>The Representation of Knowledge and Belief</em>. University of Arizona Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4192946919724023880'>Cited by 13</a> | <span class='ll' onclick='$("_566_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Inexplicit%20information+author%3ACummins&amp;btnG=Search'>Google</a>)</span><div id='_566_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On various kinds of representation of knowledge or belief without explicit tokens: control-implicit, domain-implicit, and procedural information. The key distinction is representation vs. execution of a rule.</div></div>
</div><!--entry-->

<div id='_567_entry' class='entry'><span ><span class='name'>Davies, Martin</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("DAVTNO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=1520-8583(1995)9&lt;153:TNOIR&gt;2.0.CO;2-F'>Two notions of implicit rules.</a></span> <span class='pub_name'>Philosophical Perspectives</span> 9:153-83. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13637922850333185915'>Cited by 14</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Two%20notions%20of%20implicit%20rules+author%3ADavies&amp;btnG=Search'>Google</a> | <a href='javascript:show("_567_links")'>More links</a>)</span>
<div id='_567_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAVTNO",this.href,0);return true;' href="http://www.jstor.org/sici?sici=1520-8583(1995)9&lt;153:TNOIR&gt;2.0.CO;2-F">http://www.jstor.org/sici?sici=1520-8583(1995)9<153:TNOIR>2.0.CO;2-F</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAVTNO",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2214216.pdf">http://www.jstor.org/stable/pdfplus/2214216.pdf</a><br></div></div>
</div><!--entry-->

<div id='_568_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("DENROF-2",this.href,0);return true;' href='http://cogprints.org/273/ '>Review of F. Varela, E. Thompson and E. Rosch, <em>The Embodied Mind</em>.</a></span> <span class='pub_name'>American Journal of Psychology</span> 106:121-126. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Review%20of%20F.%20Varela%2C%20E.%20Thompson%20and%20E.%20Rosch%2C%20The%20Embodied%20Mind+author%3ADennett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_568_links")'>More links</a>)</span><div id='_568_abstract' class='extra' style='font-size:12px;'>Abstract: Cognitive science, as an interdisciplinary school of thought, may have recently moved beyond the bandwagon stage onto the throne of orthodoxy, but it does not make a favorable first impression on many people. Familiar reactions on first encounters range from revulsion to condescending dismissal--very few faces in the crowd light up with the sense of "Aha! So that's how the mind works! Of course!" Cognitive science leaves something out, it seems; moreover, what it apparently leaves out is important, even precious. Boiled down to its essence, cognitive science proclaims that in one way or another our minds are computers, and this seems so mechanistic, reductionistic, intellectualistic, dry, philistine, unbiological. It leaves out emotion, or what philosophers call qualia, or value, or mattering, or . . . the soul. It doesn't explain what minds are so much as attempt to explain minds away</div>
<div id='_568_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENROF-2",this.href,0);return true;' href="http://ase.tufts.edu/cogstud/papers/varela.htm ">http://ase.tufts.edu/cogstud/papers/varela.htm </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENROF-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000273/">http://cogprints.ecs.soton.ac.uk/archive/00000273/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENROF-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:273">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:273</a><br></div></div>
</div><!--entry-->

<div id='_569_entry' class='entry'><span ><span class='name'>Fulda, Joseph S.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("FULTLO",this.href,0);return true;' href='http://www.springerlink.com/content/m6x1661073276867/fulltext.pdf'>The logic of âimproper crossâ.</a></span> <span class='pub_name'>Artificial Intelligence and Law</span> 8 (4):337-341. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20logic%20of%20%E2%80%9Cimproper%20cross%E2%80%9D+author%3AFulda&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_570_entry' class='entry'><span ><span class='name'>G.  , Nagarjuna</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("GCCO",this.href,0);return true;' href='http://philpapers.org/archive/GCCO'>Collaborative creation of teaching-learning sequences and an Atlas of knowledge.</a></span> <span class='pub_name'>Mathematics Teaching-Research Journal Online</span> 3 (N3):23-40. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Collaborative%20creation%20of%20teaching-learning%20sequences%20and%20an%20Atlas%20of%20knowledge+author%3AG.%20%20&amp;btnG=Search'>Google</a> | <a href='javascript:show("_570_links")'>More links</a>)</span><div id='_570_abstract' class='extra' style='font-size:12px;'>Abstract: Our focus in the article is to introduce a simple methodology of generating teaching-learning sequences using the semantic network techinque, followed by the emergent properties of such a network and their implications for the teaching-learning process (didactics) with marginal notes on epistemological implications.   A collaborative portal for teachers, which publishes a network of prerequisites for teaching/learning any concept or an activity is introduced.  The article ends with an appeal to the global community to contribute prerequisites of any subject to complete the global roadmap for an altas being built on similar lines as Wikipedia. The portal is launched and waiting for community participation at http://www.gnowledge.org.</div>
<div id='_570_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GCCO",this.href,0);return true;' href="http://cogprints.org/6588/1/collaborative-LTS-wpversion-preprint.pdf">http://cogprints.org/6588/1/collaborative-LTS-wpversion-preprint.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GCCO",this.href,0);return true;' href="http://cogprints.org/6588/1/collaborative%2DLTS%2Dwpversion%2Dpreprint.pdf">http://cogprints.org/6588/1/collaborative%2DLTS%2Dwpversion%2Dpreprint.pdf</a><br></div></div>
</div><!--entry-->

<div id='_571_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("HADCER",this.href,0);return true;' href='http://www.springerlink.com/content/p6445n4854j7t407/fulltext.pdf'>Connectionism, explicit rules, and symbolic manipulation.</a></span> <span class='pub_name'>Minds and Machines</span> 3 (2):183-200. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7147968263745184325'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20explicit%20rules%2C%20and%20symbolic%20manipulation+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_571_links")'>More links</a>)</span><div id='_571_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â At present, the prevailing Connectionist methodology forrepresenting rules is toimplicitly embody rules in neurally-wired networks. That is, the methodology adopts the stance that rules must either be hard-wired or trained into neural structures, rather than represented via explicit symbolic structures. Even recent attempts to implementproduction systems within connectionist networks have assumed that condition-action rules (or rule schema) are to be embodied in thestructure of individual networks. Such networks must be grown or trained over a significant span of time. However, arguments are presented herein that humanssometimes follow rules which arevery rapidly assignedexplicit internal representations, and that humans possessgeneral mechanisms capable of interpreting and following such rules. In particular, arguments are presented that thespeed with which humans are able to follow rules ofnovel structure demonstrates the existence of general-purpose rule following mechanisms. It is further argued that the existence of general-purpose rule following mechanisms strongly indicates that explicit rule following is not anisolated phenomenon, but may well be a common and important aspect of cognition. The relationship of the foregoing conclusions to Smolensky''s view of explicit rule following is also explored. The arguments presented here are pragmatic in nature, and are contrasted with thekind of arguments developed by Fodor and Pylyshyn in their recent, influential paper</div>
<div id='_571_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCER",this.href,0);return true;' href="http://www.springerlink.com/index/P6445N4854J7T407.pdf">http://www.springerlink.com/index/P6445N4854J7T407.pdf</a><br></div></div>
</div><!--entry-->

<div id='_572_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1990). Connectionism, rule-following, and symbolic manipulation.</span> <span class='pub_name'>Proc AAAI</span> 3 (2):183-200. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5263252835071729100'>Cited by 10</a> | <span class='ll' onclick='$("_572_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20rule-following%2C%20and%20symbolic%20manipulation+author%3AHadley&amp;btnG=Search'>Google</a>)</span><div id='_572_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Some rules are learnt so quickly that representation must be explicit.</div></div>
</div><!--entry-->

<div id='_573_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("HADTED",this.href,0);return true;' href='http://fas.sfu.ca/pub/cs/hadley/implicit-explicit.ps'>The 'explicit-implicit' distinction.</a></span> <span class='pub_name'>Minds and Machines</span> 5 (2):219-42. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14674452098715080723'>Cited by 25</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20%27explicit-implicit%27%20distinction+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_573_links")'>More links</a>)</span><div id='_573_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Much of traditional AI exemplifies the explicit representation paradigm, and during the late 1980''s a heated debate arose between the classical and connectionist camps as to whether beliefs and rules receive an explicit or implicit representation in human cognition. In a recent paper, Kirsh (1990) questions the coherence of the fundamental distinction underlying this debate. He argues that our basic intuitions concerning explicit and implicit representations are not only confused but inconsistent. Ultimately, Kirsh proposes a new formulation of the distinction, based upon the criterion ofconstant time processing.The present paper examines Kirsh''s claims. It is argued that Kirsh fails to demonstrate that our usage of explicit and implicit is seriously confused or inconsistent. Furthermore, it is argued that Kirsh''s new formulation of the explicit-implicit distinction is excessively stringent, in that it banishes virtually all sentences of natural language from the realm of explicit representation. By contrast, the present paper proposes definitions for explicit and implicit which preserve most of our strong intuitions concerning straightforward uses of these terms. It is also argued that the distinction delineated here sustains the meaningfulness of the abovementioned debate between classicists and connectionists</div>
<div id='_573_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADTED",this.href,0);return true;' href="http://www.springerlink.com/content/content/kl736k107182317h/fulltext.pdf">http://www.springerlink.com/content/content/kl736k107182317h/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADTED",this.href,0);return true;' href="http://www.springerlink.com/content/kl736k107182317h/fulltext.pdf">http://www.springerlink.com/content/kl736k107182317h/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADTED",this.href,0);return true;' href="http://www.springerlink.com/index/KL736K107182317H.pdf">http://www.springerlink.com/index/KL736K107182317H.pdf</a><br></div></div>
</div><!--entry-->

<div id='_574_entry' class='entry'><span ><span class='name'>Kirsh, David</span> (1990). When is information explicitly represented?</span> In Philip P. Hanson (ed.), <em>Information, Language and Cognition</em>. University of British Columbia Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1910635143392604291'>Cited by 62</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=When%20is%20information%20explicitly%20represented%3F+author%3AKirsh&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_575_entry' class='entry'><span ><span class='name'>MartÃ­nez, Fernando</span> &amp; <span class='name'>Ezquerro MartÃ­nez, JesÃºs</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("MAREWP",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596785'>Explicitness with psychological ground.</a></span> <span class='pub_name'>Minds and Machines</span> 8 (3):353-374. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3392197354495533847'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Explicitness%20with%20psychological%20ground+author%3AMart%C3%ADnez&amp;btnG=Search'>Google</a> | <a href='javascript:show("_575_links")'>More links</a>)</span><div id='_575_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Explicitness has usually been approached from two points of view, labelled by Kirsh the structural and the process view, that hold opposite assumptions to determine when information is explicit. In this paper, we offer an intermediate view that retains intuitions from both of them. We establish three conditions for explicit information that preserve a structural requirement, and a notion of explicitness as a continuous dimension. A problem with the former accounts was their disconnection with psychological work on the issue. We review studies by Karmiloff-Smith, and Shanks and St. John to show that the proposed conditions have psychological grounds. Finally, we examine the problem of explicit rules in connectionist systems in the light of our framework</div>
<div id='_575_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAREWP",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=381463CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=381463CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAREWP",this.href,0);return true;' href="http://www.springerlink.com/content/j4u0011h11660267/fulltext.pdf">http://www.springerlink.com/content/j4u0011h11660267/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAREWP",this.href,0);return true;' href="http://www.springerlink.com/index/J4U0011H11660267.pdf">http://www.springerlink.com/index/J4U0011H11660267.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAREWP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000003/00160303">http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000003/00160303</a><br></div></div>
</div><!--entry-->

<div id='_576_entry' class='entry'><span ><span class='name'>Shapiro, Lawrence A.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("SHATEC",this.href,0);return true;' href='http://philosophy.wisc.edu/shapiro/PhilComp.pdf'>The embodied cognition research program.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4420017747194513550'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20embodied%20cognition%20research%20program+author%3AShapiro&amp;btnG=Search'>Google</a> | <a href='javascript:show("_576_links")'>More links</a>)</span><div id='_576_abstract' class='extra' style='font-size:12px;'>Abstract: Unifying traditional cognitive science is the idea that thinking is a process of symbol manipulation, where symbols lead both a syntactic and a semantic life. The syntax of a symbol comprises those properties in virtue of which the symbol undergoes rule-dictated transformations. The semantics of a symbol constitute the symbolsÃ meaning or representational content. Thought consists in the syntactically determined manipulation of symbols, but in a way that respects their semantics. Thus, for instance, a calculating computer sensitive only to the shape of symbols might produce the symbol Ã5Ã in response to the inputs Ã2Ã, Ã+Ã, and Ã3Ã. As far as the computer is concerned, these symbols have no meaning, but because of its program it will produce outputs that, to the user, Ãmake senseÃ given the meanings the user attributes to the symbols</div>
<div id='_576_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHATEC",this.href,0);return true;' href="http://philosophy.wisc.edu/shapiro/HomePage/PhilComp.htm ">http://philosophy.wisc.edu/shapiro/HomePage/PhilComp.htm </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHATEC",this.href,0);return true;' href="http://philosophy.wisc.edu/shapiro/HomePage/embodiedcognition.pdf">http://philosophy.wisc.edu/shapiro/HomePage/embodiedcognition.pdf</a><br></div></div>
</div><!--entry-->

<div id='_577_entry' class='entry'><span ><span class='name'>Skokowski, Paul G.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("SKOCCC",this.href,0);return true;' href='http://www-csli.stanford.edu/~paulsko/papers/InexplicitPenultimate.pdf'>Can computers carry content "inexplicitly"?</a></span> <span class='pub_name'>Minds and Machines</span> 4 (3):333-44. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14017513225037673104'>Cited by 2</a> | <span class='ll' onclick='$("_577_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20computers%20carry%20content%20inexplicitly%3F+author%3ASkokowski&amp;btnG=Search'>Google</a> | <a href='javascript:show("_577_links")'>More links</a>)</span><div id='_577_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Cummins' account of inexplicit information fails, as even "executed" rules must be represented in the system. With remarks on the Chinese room.</div></div><div id='_577_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â I examine whether it is possible for content relevant to a computer''s behavior to be carried without an explicit internal representation. I consider three approaches. First, an example of a chess playing computer carrying emergent content is offered from Dennett. Next I examine Cummins response to this example. Cummins says Dennett''s computer executes a rule which is inexplicitly represented. Cummins describes a process wherein a computer interprets explicit rules in its program, implements them to form a chess-playing device, then this device executes the rules in a way that exhibits them inexplicitly. Though this approach is intriguing, I argue that the chess-playing device cannot exist as imagined. The processes of interpretation and implementation produce explicit representations of the content claimed to be inexplicit. Finally, the Chinese Room argument is examined and shown not to save the notion of inexplicit information. This means the strategy of attributing inexplicit content to a computer which is executing a rule, fails</div>
<div id='_577_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SKOCCC",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=0148099CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=0148099CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SKOCCC",this.href,0);return true;' href="http://www.springerlink.com/content/j821320368ht5863/fulltext.pdf">http://www.springerlink.com/content/j821320368ht5863/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SKOCCC",this.href,0);return true;' href="http://www.springerlink.com/index/J821320368HT5863.pdf">http://www.springerlink.com/index/J821320368HT5863.pdf</a><br></div></div>
</div><!--entry-->

<div id='_578_entry' class='entry'><span ><span class='name'>Slezak, Peter</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("SLESC",this.href,0);return true;' href='http://hps.arts.unsw.edu.au/hps_content/staff_homepages/p_slezak_site/Article Links/1999/Slezak_SitCog_1999.doc'>Situated cognition.</a></span> <span class='pub_name'>Perspectives on Cognitive Science</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2463331783616152149'>Cited by 22</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Situated%20cognition+author%3ASlezak&amp;btnG=Search'>Google</a>)</span><div id='_578_abstract' class='extra' style='font-size:12px;'>Abstract: The self-advertising, at least, suggests that 'situated cognition' involves the most fundamental conceptual re-organization in AI and cognitive science, even appearing to deny that cognition is to be explained by mental representations. In their defence of the orthodox symbolic representational theory, A. Vera and H. Simon (1993) have rebutted many of these claims, but they overlook an important reading of situated arguments which may, after all, involve a revolutionary insight. I show that the whole debate turns on puzzles familiar from the history of philosophy and psychology and these may serve to clarify the current disputes</div>
</div><!--entry-->

<div id='_579_entry' class='entry'><span ><span class='name'>Sutton, John</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("SUTTBA",this.href,0);return true;' href='http://www.phil.mq.edu.au/staff/jsutton/Sutton_ch28_Body_Brain.rtf'>The body and the brain.</a></span> In  S. Gaukroger,  J. Schuster &amp;  J. Sutton (eds.), <em>Descartes' Natural Philosophy</em>. Routledge. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20body%20and%20the%20brain+author%3ASutton&amp;btnG=Search'>Google</a>)</span><div id='_579_abstract' class='extra' style='font-size:12px;'>Abstract: Does self?knowledge help? A rationalist, presumably, thinks that it does: both that self?knowledge is possible and that, if gained through appropriate channels, it is desirable. Descartes notoriously claimed that, with appropriate methods of enquiry, each of his readers could become an expert on herself or himself. As well as the direct, first?person knowledge of self to which we are led in the Meditationes , we can also seek knowledge of our own bodies, and of the union of our minds and our bodies: the latter forms of self?knowledge are inevitably imperfect, but are no less important in guiding our conduct in the search after truth</div>
</div><!--entry-->

<div id='_580_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1998). Review: <em>Being There: Body and World Together Again</em>, by Andy Clark.</span> <span class='pub_name'>Philosophical Review</span> 107 (4):647-650. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Review+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span><div id='_580_abstract' class='extra' style='font-size:12px;'>Abstract: Are any nonhuman animals rational? What issues are we raising when we ask this question? Are there different kinds or levels of rationality, some of which fall short of full human rationality? Should any behaviour by nonhuman animals be regarded as rational? What kinds of tasks can animals successfully perform? What kinds of processes control their performance at these tasks, and do they count as rational processes? Is it useful or theoretically justified to raise questions about the rationality of animals at all? Should we be interested in whether they are rational? Why does it matter?</div>
</div><!--entry-->
</div>
<p><a name='.6.2d'></a><a name=''></a><span class='myh3'>6.2d AI without Representation?</span></p>

<div id='cat_6.2d' class='cat_content'>
<div id='__new_entries_6.2d__'></div><div id='__new_entry_6.2d__' class='entry'></div>
<div id='_581_entry' class='entry'><span ><span class='name'>Andrews, Kristin</span> (web). <a rel="nofollow" class='article_title' onclick='trackclick("ANDCPO",this.href,0);return true;' href='http://www.yorku.ca/andrewsk/documents/CritterFinal.doc'>Critter psychology: On the possibility of nonhuman animal folk psychology.</a></span> In Daniel D. Hutto &amp; Matthew Ratcliffe (eds.), <em>Folk Psychology Re-Assessed</em>. Kluwer/Springer Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Critter%20psychology+author%3AAndrews&amp;btnG=Search'>Google</a> | <a href='javascript:show("_581_links")'>More links</a>)</span><div id='_581_abstract' class='extra' style='font-size:12px;'>Abstract: Humans have a folk psychology, without question. Paul Churchland used the term to describe âour commonsense conception of psychological phenomenaâ (Churchland 1981, p. 67), whatever that may be. When we ask the question whether animals have their own folk psychology, weâre asking whether any other species has a commonsense conception of psychological phenomenon as well. Different versions of this question have been discussed over the past 25 years, but no clear answer has emerged. Perhaps one reason for this lack of progress is that we donât clearly understand the question. In asking whether animals have folk psychology, I hope to help clarify the concept of folk psychology itself, and in the process, to gain a greater understanding of the role of belief and desire attribution in human social interaction</div>
<div id='_581_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ANDCPO",this.href,0);return true;' href="http://www.springerlink.com/index/w2506611815711g1.pdf">http://www.springerlink.com/index/w2506611815711g1.pdf</a><br></div></div>
</div><!--entry-->

<div id='_582_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1996). Yet another revolution? Defusing the dynamical system theorists' attack on mental representations.</span> <span class='pub_name'>Presidential Address to Society of Philosophy and Psychology</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3384478351634542115'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Yet%20another%20revolution%3F%20Defusing%20the%20dynamical%20system%20theorists%27%20attack%20on%20mental%20representations+author%3ABechtel&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_583_entry' class='entry'><span ><span class='name'>Brooks, Rodney</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("BROIWR",this.href,0);return true;' href='http://philosophy.wisc.edu/shapiro/Phil554/PAPERS/Brooks.pdf'>Intelligence without representation.</a></span> <span class='pub_name'>Artificial Intelligence</span> 47:139-159. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13620062451897369298'>Cited by 2501</a> | <span class='ll' onclick='$("_583_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intelligence%20without%20representation+author%3ABrooks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_583_links")'>More links</a>)</span><div id='_583_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>We don't need explicit representation; the world can do the job instead. Use embodied, complete systems, starting simple and working incrementally.</div></div><div id='_583_abstract' class='extra' style='font-size:12px;'>Abstract: Artificial intelligence research has foundered on the issue of representation. When intelligence is approached in an incremental manner, with strict reliance on interfacing to the real world through perception and action, reliance on representation disappears. In this paper we outline our approach to incrementally building complete intelligent Creatures. The fundamental decomposition of the intelligent system is not into independent information processing units which must interface with each other via representations. Instead, the intelligent system is decomposed into independent and parallel activity producers which all interface directly to the world through perception and action, rather than interface to each other particularly much. The notions of central and peripheral systems evaporateeverything is both central and peripheral. Based on these principles we have built a very successful series of mobile robots which operate without supervision as Creatures in standard office environments</div>
<div id='_583_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://people.csail.mit.edu/brooks/papers/representation.pdf">http://people.csail.mit.edu/brooks/papers/representation.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://people.csail.mit.edu/~brooks/papers/representation.pdf">http://people.csail.mit.edu/~brooks/papers/representation.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://www.ai.mit.edu/people/brooks/papers/representation.pdf">http://www.ai.mit.edu/people/brooks/papers/representation.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://www.cs.iastate.edu/~honavar/Courses/cs673/spring00/brooks2.pdf">http://www.cs.iastate.edu/~honavar/Courses/cs673/spring00/brooks2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://www.valentiniweb.com/Piermo/robotica/doc/Brooks/representation.pdf">http://www.valentiniweb.com/Piermo/robotica/doc/Brooks/representation.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://www.scs.ryerson.ca/~aferworn/courses/CPS607/CLASSES/subsumption.pdf">http://www.scs.ryerson.ca/~aferworn/courses/CPS607/CLASSES/subsumption.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://hugo.csie.ntu.edu.tw/~yjhsu/courses/u1760/Online/papers/brooks2.pdf">http://hugo.csie.ntu.edu.tw/~yjhsu/courses/u1760/Online/papers/brooks2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://agents.csie.ntu.edu.tw/~yjhsu/courses/u1760/Online/papers/brooks2.pdf">http://agents.csie.ntu.edu.tw/~yjhsu/courses/u1760/Online/papers/brooks2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://www.ee.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/brooks.representation.pdf">http://www.ee.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/brooks.representation.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://www.inf.ufrgs.br/~alvares/CMP124SMA/IntelligenceWithoutRepresentation.pdf">http://www.inf.ufrgs.br/~alvares/CMP124SMA/IntelligenceWithoutRepresentation.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://courses.media.mit.edu/2004spring/mas966/Brooks Int wo rep (orig version).pdf">http://courses.media.mit.edu/2004spring/mas966/Brooks Int wo rep (orig version).pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2506361CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2506361CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://act-r.psy.cmu.edu/~douglass/Douglass/Agents/TopicPapers/~TopCandidates~/Robotics/brooks87intelligence.pdf">http://act-r.psy.cmu.edu/~douglass/Douglass/Agents/TopicPapers/~TopCandidates~/Robotics/brooks87intelligence.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncnuyuq7xF&amp;sig=605f19sD3y7t4DoispNMxvmyy3Y">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncnuyuq7xF&sig=605f19sD3y7t4DoispNMxvmyy3Y</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncnvuuu4CF&amp;sig=DAI5FtzBm8byWUcnf5U3qBR0ihk">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncnvuuu4CF&sig=DAI5FtzBm8byWUcnf5U3qBR0ihk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncnryrt5CC&amp;sig=HHybOULxfTdFwfwaliV_tWAF-rY">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncnryrt5CC&sig=HHybOULxfTdFwfwaliV_tWAF-rY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncntqss8yH&amp;sig=qiqJVUCetwl0cyAg5v_FQkGQePw">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncntqss8yH&sig=qiqJVUCetwl0cyAg5v_FQkGQePw</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncntwsx7vB&amp;sig=CcPsaAISyDSP5mOKB52AxYOWprI">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncntwsx7vB&sig=CcPsaAISyDSP5mOKB52AxYOWprI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncnqwqt7AE&amp;sig=kaOJuTY3bDJqBoxZyS0StZghsM4">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncnqwqt7AE&sig=kaOJuTY3bDJqBoxZyS0StZghsM4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=NbwtvuyawC&amp;sig=ZOLRXpLrB5DFvnDlSf6wNaw3gYg">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=NbwtvuyawC&sig=ZOLRXpLrB5DFvnDlSf6wNaw3gYg</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Nbwtqrsaty&amp;sig=wE7wq6m3Inq7Z4qwmXLucc7RI00">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Nbwtqrsaty&sig=wE7wq6m3Inq7Z4qwmXLucc7RI00</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Nbwttux6wz&amp;sig=LYLowQNnoYxvhtwzFNt0X9gEQ4Y">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Nbwttux6wz&sig=LYLowQNnoYxvhtwzFNt0X9gEQ4Y</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncnustw1wE&amp;sig=eFSDUHWbsnHEh9S4Zn_paKguMWc">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncnustw1wE&sig=eFSDUHWbsnHEh9S4Zn_paKguMWc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncnpupt8BB&amp;sig=lN7SP76JP7P7VOlJEKQ4NEl3MkU">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncnpupt8BB&sig=lN7SP76JP7P7VOlJEKQ4NEl3MkU</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=NcnqqpyaBB&amp;sig=WBYA3src9nEuAgdYTkk4CjPHrqQ">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=NcnqqpyaBB&sig=WBYA3src9nEuAgdYTkk4CjPHrqQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROIWR",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA139&amp;ots=Ncnsury1zy&amp;sig=gzFoWrIH5zSH1JxwjugtFKvBPxs">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA139&ots=Ncnsury1zy&sig=gzFoWrIH5zSH1JxwjugtFKvBPxs</a><br></div></div>
</div><!--entry-->

<div id='_584_entry' class='entry'><span ><span class='name'>Clark, Andy</span> &amp; <span class='name'>Toribio, Josefa</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("CLADWR",this.href,0);return true;' href='https://www.era.lib.ed.ac.uk/handle/1842/1301?mode=simple'>Doing without representing.</a></span> <span class='pub_name'>Synthese</span> 101 (3):401-31. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4362948522888617259'>Cited by 97</a> | <span class='ll' onclick='$("_584_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Doing%20without%20representing+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_584_links")'>More links</a>)</span><div id='_584_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A discussion of anti-representationalism in situated robotics and the dynamic systems movement (Brooks, Beer, van Gelder). These arguments appeal to overly simple domains, and a modest notion of representation survives.</div></div><div id='_584_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Connectionism and classicism, it generally appears, have at least this much in common: both place some notion of internal representation at the heart of a scientific study of mind. In recent years, however, a much more radical view has gained increasing popularity. This view calls into question the commitment to internal representation itself. More strikingly still, this new wave of anti-representationalism is rooted not in armchair theorizing but in practical attempts to model and understand intelligent, adaptive behavior. In this paper we first present, and then critically assess, a variety of recent anti-representationalist treatments. We suggest that so far, at least, the sceptical rhetoric outpaces both evidence and argument. Some probable causes of this premature scepticism are isolated. Nonetheless, the anti-representationalist challenge is shown to be both important and progressive insofar as it forces us to see beyond the bare representational/non-representational dichotomy and to recognize instead a rich continuum of degrees and types of representationality</div>
<div id='_584_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLADWR",this.href,0);return true;' href="http://wexler.free.fr/library/files/clark (1994) doing without representing.pdf">http://wexler.free.fr/library/files/clark (1994) doing without representing.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLADWR",this.href,0);return true;' href="http://www.springerlink.com/content/w02t5nm8j7164v10/fulltext.pdf">http://www.springerlink.com/content/w02t5nm8j7164v10/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLADWR",this.href,0);return true;' href="http://www.springerlink.com/index/W02T5NM8J7164V10.pdf">http://www.springerlink.com/index/W02T5NM8J7164V10.pdf</a><br></div></div>
</div><!--entry-->

<div id='_585_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("DENCE-3",this.href,0);return true;' href='http://ase.tufts.edu/cogstud/papers/cogetho.htm'>Cognitive ethology.</a></span> In <em>Goals, No-Goals and Own Goals</em>. Unwin Hyman. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17912885265344465683'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognitive%20ethology+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_585_abstract' class='extra' style='font-size:12px;'>Abstract: The field of Artificial Intelligence has produced so many new concepts--or at least vivid and more structured versions of old concepts--that it would be surprising if none of them turned out to be of value to students of animal behavior. Which will be most valuable? I will resist the temptation to engage in either prophecy or salesmanship; instead of attempting to answer the question: "How might Artificial Intelligence inform the study of animal behavior?" I will concentrate on the obverse: "How might the study of animal behavior inform research in Artificial Intelligence?"</div>
</div><!--entry-->

<div id='_586_entry' class='entry'><span ><span class='name'>Millikan, Ruth G.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("GARORS",this.href,0);return true;' href='http://vm.uconn.edu/~wwwphil/lorenz.pdf '>On reading signs.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 1 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20reading%20signs+author%3AMillikan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_586_links")'>More links</a>)</span><div id='_586_abstract' class='extra' style='font-size:12px;'>Abstract: On Reading Signs; Some Differences between Us and The Others If there are certain kinds of signs that an animal cannot learn to interpret, that might be for any of a number of reasons. It might be, first, because the animal cannot discriminate the signs from one another. For example, although human babies learn to discriminate human speech sounds according to the phonological structures of their native languages very easily, it may be that few if any other animals are capable of fully grasping the phonological structures of human languages. If an animal cannot learn to interpret certain signs it might be, second, because the decoding is too difficult for it. It could be, for example, that some animals are incapable of decoding signs that exhibit syntactic embedding, or signs that are spread out over time as opposed to over space. Problems of these various kinds might be solved by using another sign system, say, gestures rather than noises, or visual icons laid out in spatial order, or by separating out embedded propositions and presenting each separately. But a more interesting reason that an animal might be incapable of understanding a sign would be that it lacked mental representations of the necessary kind. It might be incapable of representing mentally what the sign conveys. When discussing what signs animals can understand or</div>
<div id='_586_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARORS",this.href,0);return true;' href="http://www.ucc.uconn.edu/~wwwphil/lorenz.pdf ">http://www.ucc.uconn.edu/~wwwphil/lorenz.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARORS",this.href,0);return true;' href="http://www.philosophy.uconn.edu/department/millikan/lorenz.pdf">http://www.philosophy.uconn.edu/department/millikan/lorenz.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARORS",this.href,0);return true;' href="http://www.philosophy.uconn.edu/department/millikan/lorenz.pdf ">http://www.philosophy.uconn.edu/department/millikan/lorenz.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARORS",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=GsSWKPB6KW8C&amp;oi=fnd&amp;pg=PA15&amp;dq=On+reading+signs+Millikan&amp;ots=l7qcSFGra0&amp;sig=uhILZgZBxuWhg03CdjzvarNZ8wc">http://books.google.com/books?hl=en&lr=&id=GsSWKPB6KW8C&oi=fnd&pg=PA15&dq=On+reading+signs+Millikan&ots=l7qcSFGra0&sig=uhILZgZBxuWhg03CdjzvarNZ8wc</a><br></div></div>
</div><!--entry-->

<div id='_587_entry' class='entry'><span ><span class='name'>Keijzer, Fred A.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("KEIDWR",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a793919850~fulltext=713240930'>Doing without representations which specify what to do.</a></span> <span class='pub_name'>Philosophical Psychology</span> 11 (3):269-302. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9623815802483186002'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Doing%20without%20representations%20which%20specify%20what%20to%20do+author%3AKeijzer&amp;btnG=Search'>Google</a>)</span><div id='_587_abstract' class='extra' style='font-size:12px;'>Abstract: A discussion is going on in cognitive science about the use of representations to explain how intelligent behavior is generated. In the traditional view, an organism is thought to incorporate representations. These provide an internal model that is used by the organism to instruct the motor apparatus so that the adaptive and anticipatory characteristics of behavior come about. So-called interactionists claim that this representational specification of behavior raises more problems than it solves. In their view, the notion of internal representational models is to be dispensed with. Instead, behavior is to be explained as the intricate interaction between an embodied organism and the specific make up of an environment. The problem with a non-representational interactive account is that it has severe difficulties with anticipatory, future oriented behavior. The present paper extends the interactionist conceptual framework by drawing on ideas derived from the study of morphogenesis. This extended interactionist framework is based on an analysis of anticipatory behavior as a process which involves multiple spatio-temporal scales of neural, bodily and environmental dynamics. This extended conceptual framework provides the outlines for an explanation of anticipatory behavior without involving a representational specification of future goal states</div>
</div><!--entry-->

<div id='_588_entry' class='entry'><span ><span class='name'>Kirsh, David</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("KIRTTE",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=110289.110296'>Today the earwig, tomorrow man?</a></span> <span class='pub_name'>Artificial Intelligence</span> 47:161-184. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1047827152695087501'>Cited by 111</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Today%20the%20earwig%2C%20tomorrow%20man%3F+author%3AKirsh&amp;btnG=Search'>Google</a> | <a href='javascript:show("_588_links")'>More links</a>)</span><div id='_588_abstract' class='extra' style='font-size:12px;'>Abstract: A startling amount of intelligent activity can be controlled without reasoning or thought. By tuning the perceptual system to task relevant properties a creature can cope with relatively sophisticated environments without concepts. There is a limit, however, to how far a creature without concepts can go. Rod Brooks, like many ecologically oriented scientists, argues that the vast majority of intelligent behaviour is concept-free. To evaluate this position I consider what special benefits accrue to concept-using creatures. Concepts are either necessary for certain types of perception, learning, and control, or they make those processes computationally simpler. Once a creature has concepts its capacities are vastly multiplied.</div>
<div id='_588_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIRTTE",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2506371CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2506371CI</a><br></div></div>
</div><!--entry-->

<div id='_589_entry' class='entry'><span ><span class='name'>MÃ¼ller, Vincent C.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("MLLITA",this.href,0);return true;' href='http://www.ingentaconnect.com/content/klu/mind/2007/00000017/00000001/00009067'>Is there a future for AI without representation?</a></span> <span class='pub_name'>Minds and Machines</span> 17 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20there%20a%20future%20for%20AI%20without%20representation%3F+author%3AM%C3%BCller&amp;btnG=Search'>Google</a> | <a href='javascript:show("_589_links")'>More links</a>)</span><div id='_589_abstract' class='extra' style='font-size:12px;'>Abstract: This paper investigates the prospects of Rodney Brooksâ proposal for AI without representation. It turns out that the supposedly characteristic features of ânew AIâ (embodiment, situatedness, absence of reasoning, and absence of representation) are all present in conventional systems: âNew AIâ is just like old AI. Brooks proposal boils down to the architectural rejection of central control in intelligent agentsâWhich, however, turns out to be crucial. Some of more recent cognitive science suggests that we might do well to dispose of the image of intelligent agents as central representation processors. If this paradigm shift is achieved, Brooksâ proposal for cognition without representation appears promising for full-blown intelligent agentsâThough not for conscious agents</div>
<div id='_589_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MLLITA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=1285561.1285568">http://portal.acm.org/citation.cfm?id=1285561.1285568</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MLLITA",this.href,0);return true;' href="http://www.springerlink.com/index/T65JK1H2705383L8.pdf">http://www.springerlink.com/index/T65JK1H2705383L8.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MLLITA",this.href,0);return true;' href="http://www.typos.de/pdf/2007_AI_without_representation_M&amp;M.pdf">http://www.typos.de/pdf/2007_AI_without_representation_M&M.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MLLITA",this.href,0);return true;' href="http://www.springerlink.com/content/t65jk1h2705383l8/fulltext.pdf">http://www.springerlink.com/content/t65jk1h2705383l8/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_590_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("VANWMC",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iLWO_4Hfgv&amp;sig=GkWQRsEOnDSYzvt2nd7eaEmjCNw'>What might cognition be if not computation?</a></span> <span class='pub_name'>Journal of Philosophy</span> 92 (7):345-81. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5459288819123324454'>Cited by 266</a> | <span class='ll' onclick='$("_590_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20might%20cognition%20be%20if%20not%20computation%3F+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_590_links")'>More links</a>)</span><div id='_590_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues for a dynamic-systems conception of the mind that is non-computational and non-representational. Uses an analogy with the Watt steam governor to argue for a new kind of dynamic explanation.</div></div>
<div id='_590_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iLWO_4GjfB&amp;sig=_-hLgEKPrvzRGqiHU3WB-ByPxG4">http://books.google.com/books?hl=en&lr=&id=FEnPpGB6HE0C&oi=fnd&pg=PT158&ots=iLWO_4GjfB&sig=_-hLgEKPrvzRGqiHU3WB-ByPxG4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iK3S02IheD&amp;sig=9bvnduaEm9LGyoZvLb9vrkbzLwc">http://books.google.com/books?hl=en&lr=&id=FEnPpGB6HE0C&oi=fnd&pg=PT158&ots=iK3S02IheD&sig=9bvnduaEm9LGyoZvLb9vrkbzLwc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iLWOW7Jo9y&amp;sig=nbynhfg_nmoW_oos5qyFfZKaq_w">http://books.google.com/books?hl=en&lr=&id=FEnPpGB6HE0C&oi=fnd&pg=PT158&ots=iLWOW7Jo9y&sig=nbynhfg_nmoW_oos5qyFfZKaq_w</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(199507)92:7&lt;345:WMCBIN&gt;2.0.CO;2-F">http://www.jstor.org/sici?sici=0022-362X(199507)92:7<345:WMCBIN>2.0.CO;2-F</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2941061.pdf">http://www.jstor.org/stable/pdfplus/2941061.pdf</a><br></div></div>
</div><!--entry-->

<div id='_591_entry' class='entry'><span ><span class='name'>Wallis, Peter</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("WALIWR",this.href,0);return true;' href='http://www.agents.org.au/20040528Wallis-abstract.html'>Intention without representation.</a></span> <span class='pub_name'>Philosophical Psychology</span> 17 (2):209-223. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2988268770948572554'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intention%20without%20representation+author%3AWallis&amp;btnG=Search'>Google</a> | <a href='javascript:show("_591_links")'>More links</a>)</span><div id='_591_abstract' class='extra' style='font-size:12px;'>Abstract: A mechanism for planning ahead would appear to be essential to any creature with more than insect level intelligence. In this paper it is shown how planning, using full means-ends analysis, can be had while avoiding the so called symbol grounding problem. The key role of knowledge representation in intelligence has been acknowledged since at least the enlightenment, but the advent of the computer has made it possible to explore the limits of alternate schemes, and to explore the nature of our everyday understanding of the world around us. In particular, artificial intelligence (AI) and robotics has forced a close examination, by people other than philosophers, of what it means to say for instance that "snow is white." One interpretation of the "new AI" is that it is questioning the need for representation altogether. Brooks and others have shown how a range of intelligent behaviors can be had without representation, and this paper goes one step further showing how intending to do things can be achieved without symbolic representation. The paper gives a concrete example of a mechanism in terms of robots that play soccer. It describes a belief, desire and intention (BDI) architecture that plans in terms of activities. The result is a situated agent that plans to do things with no more ontological commitment than the reactive systems Brooks described in his seminal paper, "Intelligence without Representation."</div>
<div id='_591_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WALIWR",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a713630032~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a713630032~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WALIWR",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/T86XG5YMR7KE123J.pdf">http://taylorandfrancis.metapress.com/index/T86XG5YMR7KE123J.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WALIWR",this.href,0);return true;' href="http://www.informaworld.com/index/713630032.pdf">http://www.informaworld.com/index/713630032.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WALIWR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2004/00000017/00000002/art00004">http://www.ingentaconnect.com/content/routledg/cphp/2004/00000017/00000002/art00004</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WALIWR",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713630032~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713630032~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_592_entry' class='entry'><span ><span class='name'>Webber, Jonathan</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("WEBDWR",this.href,0);return true;' href='http://eprints.whiterose.ac.uk/archive/00001215/'>Doing without representation: Coping with Dreyfus.</a></span> <span class='pub_name'>Philosophical Explorations</span> 5 (1):82-88. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Doing%20without%20representation+author%3AWebber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_592_links")'>More links</a>)</span><div id='_592_abstract' class='extra' style='font-size:12px;'>Abstract: Hubert Dreyfus argues that the traditional and currently dominant conception of an action, as an event initiated or governed by a mental representation of a possible state of affairs that the agent is trying to realise, is inadequate. If Dreyfus is right, then we need a new conception of action. I argue, however, that the considerations that Dreyfus adduces show only that an action need not be initiated or governed by a conceptual representation, but since a representation need not be conceptually structured, do not show that we need a conception of action that does not involve representation</div>
<div id='_592_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEBDWR",this.href,0);return true;' href="http://www.bristol.ac.uk/philosophy/department/staff/JW/DoingWithoutRepresentation.pdf">http://www.bristol.ac.uk/philosophy/department/staff/JW/DoingWithoutRepresentation.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEBDWR",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a782351921~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a782351921~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEBDWR",this.href,0);return true;' href="http://www.informaworld.com/index/782351921.pdf">http://www.informaworld.com/index/782351921.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEBDWR",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a782351921~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a782351921~fulltext=713240930</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.2e'></a><a name=''></a><span class='myh3'>6.2e Computation and Representation, Misc</span></p>

<div id='cat_6.2e' class='cat_content'>
<div id='__new_entries_6.2e__'></div><div id='__new_entry_6.2e__' class='entry'></div>
<div id='_593_entry' class='entry'><span ><span class='name'>Akman, Varol</span> &amp; <span class='name'>ten Hagen, Paul J. W.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("AKMTPO",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=68662.68664'>The power of physical representations.</a></span> <span class='pub_name'>AI Magazine</span> 10 (3):49-65. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 10 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20power%20of%20physical%20representations+author%3AAkman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_593_links")'>More links</a>)</span>
<div id='_593_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMTPO",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=65965.69627">http://portal.acm.org/citation.cfm?id=65965.69627</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMTPO",this.href,0);return true;' href="http://www.cs.bilkent.edu.tr/~akman/jour-papers/aimag/aimag1989-2.pdf">http://www.cs.bilkent.edu.tr/~akman/jour-papers/aimag/aimag1989-2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMTPO",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2227604CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2227604CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMTPO",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=N8920612AH">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=N8920612AH</a><br></div></div>
</div><!--entry-->

<div id='_594_entry' class='entry'><span ><span class='name'>Bailey, Andrew R.</span> (1994). Representations versus regularities: Does computation require representation?</span> <span class='pub_name'>Eidos</span> 12 (1):47-58. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representations%20versus%20regularities+author%3ABailey&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_595_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span>; <span class='name'>French, Robert M.</span> &amp; <span class='name'>Hofstadter, Douglas R.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href='http://consc.net/papers/highlevel.pdf'>High-level perception, representation, and analogy:A critique of artificial intelligence methodology.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intellige</span> 4 (3):185 - 211. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9882312320981562757'>Cited by 123</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=High-level%20perception%2C%20representation%2C%20and%20analogy+author%3AChalmers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_595_links")'>More links</a>)</span><div id='_595_abstract' class='extra' style='font-size:12px;'>Abstract: High-level perception--âthe process of making sense of complex data at an abstract, conceptual level--âis fundamental to human cognition. Through high-level perception, chaotic environmen- tal stimuli are organized into the mental representations that are used throughout cognitive pro- cessing. Much work in traditional artificial intelligence has ignored the process of high-level perception, by starting with hand-coded representations. In this paper, we argue that this dis- missal of perceptual processes leads to distorted models of human cognition. We examine some existing artificial-intelligence models--ânotably BACON, a model of scientific discovery, and the Structure-Mapping Engine, a model of analogical thought--âand argue that these are flawed pre- cisely because they downplay the role of high-level perception. Further, we argue that perceptu- al processes cannot be separated from other cognitive processes even in principle, and therefore that traditional artificial-intelligence models cannot be defended by supposing the existence of a --Årepresentation module--ï¿½ that supplies representations ready-made. Finally, we describe a model of high-level perception and analogical thought in which perceptual processing is integrated with analogical mapping, leading to the flexible build-up of representations appropriate to a given context</div>
<div id='_595_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://citeseer.ist.psu.edu/49715.html">http://citeseer.ist.psu.edu/49715.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=175346.175347">http://portal.acm.org/citation.cfm?id=175346.175347</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.u.arizona.edu/~chalmers/papers/highlevel.pdf">http://www.u.arizona.edu/~chalmers/papers/highlevel.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.nbu.bg/cogs/personal/kokinov/COG501/hightlevel.pdf">http://www.nbu.bg/cogs/personal/kokinov/COG501/hightlevel.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2767459CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2767459CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.informaworld.com/index/778787585.pdf">http://www.informaworld.com/index/778787585.pdf</a><br></div></div>
</div><!--entry-->

<div id='_596_entry' class='entry'><span ><span class='name'>Dartnall, Terry</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("DARRPC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596715.596852'>Reverse psychologism, cognition and content.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (1):31-52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=533438808656410201'>Cited by 32</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reverse%20psychologism%2C%20cognition%20and%20content+author%3ADartnall&amp;btnG=Search'>Google</a> | <a href='javascript:show("_596_links")'>More links</a>)</span><div id='_596_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The confusion between cognitive states and the content of cognitive states that gives rise to psychologism also gives rise to reverse psychologism. Weak reverse psychologism says that we can study cognitive states by studying content â for instance, that we can study the mind by studying linguistics or logic. This attitude is endemic in cognitive science and linguistic theory. Strong reverse psychologism says that we can generate cognitive states by giving computers representations that express the content of cognitive states and that play a role in causing appropriate behaviour. This gives us strong representational, classical AI (REPSCAI), and I argue that it cannot succeed. This is not, as Searle claims in his Chinese Room Argument, because syntactic manipulation cannot generate content. Syntactic manipulation can generate content, and this is abundantly clear in the Chinese Room scenano. REPSCAI cannot succeed because inner content is not sufficient for cognition, even when the representations that carry the content play a role in generating appropriate behaviour</div>
<div id='_596_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DARRPC",this.href,0);return true;' href="http://www98.griffith.edu.au/dspace/handle/10072/3245">http://www98.griffith.edu.au/dspace/handle/10072/3245</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DARRPC",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=475243CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=475243CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DARRPC",this.href,0);return true;' href="http://www.springerlink.com/content/content/r64783586474k030/fulltext.pdf">http://www.springerlink.com/content/content/r64783586474k030/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DARRPC",this.href,0);return true;' href="http://www.springerlink.com/content/r64783586474k030/fulltext.pdf">http://www.springerlink.com/content/r64783586474k030/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DARRPC",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=231754&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=231754&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DARRPC",this.href,0);return true;' href="http://www.springerlink.com/index/R64783586474K030.pdf">http://www.springerlink.com/index/R64783586474K030.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DARRPC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000001/00231754">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000001/00231754</a><br></div></div>
</div><!--entry-->

<div id='_597_entry' class='entry'><span ><span class='name'>Dietrich, Eric</span> (1988). Computers, intentionality, and the new dualism.</span> <span class='pub_name'>Computers and Philosophy Newsletter</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computers%2C%20intentionality%2C%20and%20the%20new%20dualism+author%3ADietrich&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_598_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> (1979). A framework for misrepresenting knowledge.</span> In Martin Ringle (ed.), <em>Philosophical Perspectives in Artificial Intelligence</em>. Humanities Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17492953733837191682'>Cited by 7</a> | <span class='ll' onclick='$("_598_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20framework%20for%20misrepresenting%20knowledge+author%3ADreyfus&amp;btnG=Search'>Google</a>)</span><div id='_598_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the problems with context-free symbolic representation.</div></div>
</div><!--entry-->

<div id='_599_entry' class='entry'><span ><span class='name'>Echavarria, Ricardo Restrepo</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("ECHRSA",this.href,0);return true;' href='http://www.springerlink.com/content/031891v48t787x22/fulltext.pdf'>Russell's structuralism and the supposed death of computational cognitive science.</a></span> <span class='pub_name'>Minds and Machines</span> 19 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Russell%27s%20structuralism%20and%20the%20supposed%20death%20of%20computational%20cognitive%20science+author%3AEchavarria&amp;btnG=Search'>Google</a>)</span><div id='_599_abstract' class='extra' style='font-size:12px;'>Abstract: John Searle believes that computational properties are purely formal and that consequently, computational properties are not intrinsic, empirically discoverable, nor causal; and therefore, that an entityâs having certain computational properties could not be sufficient for its having certain mental properties. To make his case, Searleâs employs an argument that had been used before him by Max Newman, against Russellâs structuralism; one that Russell himself considered fatal to his own position. This paper formulates a not-so-explored version of Searleâs problem with computational cognitive science, and refutes it by suggesting how our understanding of computation is far from implying the structuralism Searle vitally attributes to it. On the way, I formulate and argue for a thesis that strengthens Newmanâs case against Russellâs structuralism, and thus raises the apparent risk for computational cognitive science too</div>
</div><!--entry-->

<div id='_600_entry' class='entry'><span ><span class='name'>Fields, Christopher A.</span> (1994). Real machines and virtual intentionality: An experimentalist takes on the problem of representational content.</span> In Eric Dietrich (ed.), <em>Thinking Computers and Virtual Persons</em>. Academic Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Real%20machines%20and%20virtual%20intentionality+author%3AFields&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_601_entry' class='entry'><span ><span class='name'>Franklin, James</span>, <a rel="nofollow" class='article_title' onclick='trackclick("FRATRO-6",this.href,0);return true;' href='http://www.maths.unsw.edu.au/~jim/context.pdf'>The representation of context: Ideas from artiï¬cial intelligence.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20representation%20of%20context+author%3AFranklin&amp;btnG=Search'>Google</a>)</span><div id='_601_abstract' class='extra' style='font-size:12px;'>Abstract: To move beyond vague platitudes about the importance of context in legal reasoning or natural language understanding, one must take account of ideas from artiï¬cial intelligence on how to represent context formally. Work on topics like prior probabilities, the theory-ladenness of observation, encyclopedic knowledge for disambiguation in language translation and pathology test diagnosis has produced a body of knowledge on how to represent context in artiï¬cial intelligence applications</div>
</div><!--entry-->

<div id='_602_entry' class='entry'><span ><span class='name'>Fulda, Joseph S.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("FULTLO",this.href,0);return true;' href='http://www.springerlink.com/content/m6x1661073276867/fulltext.pdf'>The logic of âimproper crossâ.</a></span> <span class='pub_name'>Artificial Intelligence and Law</span> 8 (4):337-341. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20logic%20of%20%E2%80%9Cimproper%20cross%E2%80%9D+author%3AFulda&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_603_entry' class='entry'><span ><span class='name'>Garzon, Francisco Calvo</span> &amp; <span class='name'>Rodriguez, Angel Garcia</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("GARWIC",this.href,0);return true;' href='http://dx.doi.org/10.1007/s11023-009-9157-3'>Where is cognitive science heading?</a></span> <span class='pub_name'>Minds and Machines</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Where%20is%20cognitive%20science%20heading%3F+author%3AGarzon&amp;btnG=Search'>Google</a>)</span><div id='_603_abstract' class='extra' style='font-size:12px;'>Abstract: According to Ramsey (Representation reconsidered, Cambridge University Press, New York, 2007), only classical cognitive science, with the related notions of inputâoutput and structural representations, meets the job description challenge (the challenge to show that a certain structure or process serves a representational role at the subpersonal level). By contrast, connectionism and other nonclassical models, insofar as they exploit receptor and tacit notions of representation, are not genuinely representational. As a result, Ramsey submits, cognitive science is taking a U-turn from representationalism back to behaviourism, thus presupposing that (1) the emergence of cognitivism capitalized on the concept of representation, and that (2) the materialization of nonclassical cognitive science involves a return to some form of pre-cognitivist behaviourism. We argue against both (1) and (2), by questioning Ramseyâs divide between classical and representational, versus nonclassical and nonrepresentational, cognitive models. For, firstly, connectionist and other nonclassical accounts have the resources to exploit the notion of a structural isomorphism, like classical accounts (the beefing-up strategy); and, secondly, insofar as inputâoutput and structural representations refer to a cognitive agent, classical explanations fail to meet the job description challenge (the deflationary strategy). Both strategies work independently of each other: if the deflationary strategy succeeds, contra (1), cognitivism has failed to capitalize on the relevant concept of representation; if the beefing-up strategy is sound, contra (2), the return to a pre-cognitivist era cancels out.</div>
</div><!--entry-->

<div id='_604_entry' class='entry'><span ><span class='name'>Guvenir, Halil A.</span> &amp; <span class='name'>Akman, Varol</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("GUVPRF",this.href,0);return true;' href='http://www.springerlink.com/content/9522322854447002/fulltext.pdf'>Problem representation for refinement.</a></span> <span class='pub_name'>Minds and Machines</span> 2 (3):267-282. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Problem%20representation%20for%20refinement+author%3AGuvenir&amp;btnG=Search'>Google</a> | <a href='javascript:show("_604_links")'>More links</a>)</span><div id='_604_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In this paper we attempt to develop a problem representation technique which enables the decomposition of a problem into subproblems such that their solution in sequence constitutes a strategy for solving the problem. An important issue here is that the subproblems generated should be easier than the main problem. We propose to represent a set of problem states by a statement which is true for all the members of the set. A statement itself is just a set of atomic statements which are binary predicates on state variables. Then, the statement representing the set of goal states can be partitioned into its subsets each of which becomes a subgoal of the resulting strategy. The techniques involved in partitioning a goal into its subgoals are presented with examples</div>
<div id='_604_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUVPRF",this.href,0);return true;' href="http://www.springerlink.com/index/9522322854447002.pdf">http://www.springerlink.com/index/9522322854447002.pdf</a><br></div></div>
</div><!--entry-->

<div id='_605_entry' class='entry'><span ><span class='name'>Haugeland, John</span> (1981). <a rel="nofollow" class='article_title' onclick='trackclick("HAUSEA-3",this.href,0);return true;' href='http://www.dfki.uni-sb.de/imedia/lidos/bibtex/Haugeland_a10582-90.html'>Semantic engines: An introduction to mind design.</a></span> In J. Haugel (ed.), <em>Mind Design</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10004605737735858981'>Cited by 92</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Semantic%20engines+author%3AHaugeland&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_606_entry' class='entry'><span ><span class='name'>Marsh, Leslie</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("MARROA",this.href,0);return true;' href='http://cogprints.org/5897/1/Clark.pdf'>Review Essay: Andy Clark's Natural-Born Cyborgs: Minds, Technologies, and the Future of Human Intelligence_.</a></span> <span class='pub_name'>Cognitive Systems Research</span> 6:405-409. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Review%20Essay+author%3AMarsh&amp;btnG=Search'>Google</a>)</span><div id='_606_abstract' class='extra' style='font-size:12px;'>Abstract: The notion of the cyborg has exercised the popular imagination for almost two hundred years. In
very general terms the idea that a living entity can be a hybrid of both organic matter and mechanical parts, and for all intents and purposes be seamlessly functional and self-regulating, was prefigured in literary works such as Shellys Frankenstein (1816/18) and Samuel Butlers Erewhon (1872). This notion of hybridism has been a staple theme of 20th century science fiction writing, television programmes and the cinema. For the most part, these works trade on a deep sense of unease we have about our personal identity â how could some non-organic matter to which I have so little conscious access count as a bona fide part of me? Cognitive scientist and philosopher, Andy Clark, picks up this general theme and presents an empirical and philosophical case for the following inextricably linked theses.</div>
</div><!--entry-->

<div id='_607_entry' class='entry'><span ><span class='name'>Prem, Erich</span> (2000). Changes of representational AI concepts induced by embodied autonomy.</span> <span class='pub_name'>Communication and Cognition-Artificial Intelligence</span> 17 (3-4):189-208. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17589899513788690799'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Changes%20of%20representational%20AI%20concepts%20induced%20by%20embodied%20autonomy+author%3APrem&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_608_entry' class='entry'><span ><span class='name'>Robinson, William S.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("ROBDR",this.href,0);return true;' href='http://www.springerlink.com/content/n84x1826k3573762/fulltext.pdf'>Direct representation.</a></span> <span class='pub_name'>Philosophical Studies</span> 80 (3):305-22. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14384700445391009791'>Cited by 3</a> | <span class='ll' onclick='$("_608_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Direct%20representation+author%3ARobinson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_608_links")'>More links</a>)</span><div id='_608_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On Searle's critique of computational explanation, contrasted with Gallistel's use thereof. The real issue is computation on indirect vs. direct representations; direct computationalism is an attractive view.</div></div>
<div id='_608_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROBDR",this.href,0);return true;' href="http://www.springerlink.com/index/N84X1826K3573762.pdf">http://www.springerlink.com/index/N84X1826K3573762.pdf</a><br></div></div>
</div><!--entry-->

<div id='_609_entry' class='entry'><span ><span class='name'>Shani, Itay</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("SHACAI",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1077955'>Computation and intentionality: A recipe for epistemic impasse.</a></span> <span class='pub_name'>Minds and Machines</span> 15 (2):207-228. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15537131672249950332'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computation%20and%20intentionality+author%3AShani&amp;btnG=Search'>Google</a> | <a href='javascript:show("_609_links")'>More links</a>)</span><div id='_609_abstract' class='extra' style='font-size:12px;'>Abstract:  Searleâs celebrated Chinese room thought experiment was devised as an attempted refutation of the view that appropriately programmed digital computers literally are the possessors of genuine mental states. A standard reply to Searle, known as the ârobot replyâ (which, I argue, reflects the dominant approach to the problem of content in contemporary philosophy of mind), consists of the claim that the problem he raises can be solved by supplementing the computational device with some âappropriateâ environmental hookups. I argue that not only does Searle himself casts doubt on the adequacy of this idea by applying to it a slightly revised version of his original argument, but that the weakness of this encoding-based approach to the problem of intentionality can also be exposed from a somewhat different angle. Capitalizing on the work of several authors and, in particular, on that of psychologist Mark Bickhard, I argue that the existence of symbol-world correspondence is not a property that the cognitive system itself can appreciate, from its own perspective, by interacting with the symbol and therefore, not a property that can constitute intrinsic content. The foundational crisis to which Searle alluded is, I conclude, very much alive</div>
<div id='_609_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHACAI",this.href,0);return true;' href="http://www.springerlink.com/content/k26t830883g84041/fulltext.pdf">http://www.springerlink.com/content/k26t830883g84041/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHACAI",this.href,0);return true;' href="http://www.springerlink.com/index/K26T830883G84041.pdf">http://www.springerlink.com/index/K26T830883G84041.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHACAI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000002/00002004">http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000002/00002004</a><br></div></div>
</div><!--entry-->

<div id='_610_entry' class='entry'><span ><span class='name'>Stanley, Jason</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("STAROR",this.href,0);return true;' href='http://www.rci.rutgers.edu/~jasoncs/Carston.doc'>Review of Robyn Carston, <em>Thoughts and Utterances</em>.</a></span> <span class='pub_name'>Mind and Language</span> 20 (3). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Review%20of%20Robyn%20Carston%2C%20Thoughts%20and%20Utterances+author%3AStanley&amp;btnG=Search'>Google</a>)</span><div id='_610_abstract' class='extra' style='font-size:12px;'>Abstract: Relevance Theory is the influential theory of linguistic interpretation first championed by Dan Sperber and Deirdre Wilson. Relevance theorists have made important contributions to our understanding of a wide range of constructions, especially constructions that tend to receive less attention in semantics and philosophy of language. But advocates of Relevance Theory also have had a tendency to form a rather closed community, with an unwillingness to translate their own special vocabulary and distinctions into more neutral vernacular. Since Robyn Carston has long been the advocate of Relevance Theory most able to communicate with a broader philosophical and linguistic audience, it is with particular interest that the emergence of her long-awaited volume, Thoughts and Utterances has been greeted. The volume exhibits many of the strengths, but also some of the weaknesses, of this well-known program</div>
</div><!--entry-->

<div id='_611_entry' class='entry'><span ><span class='name'>Thornton, Chris</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("THOBMU",this.href,0);return true;' href='http://citeseer.ist.psu.edu/149184.html'>Brave mobots use representation: Emergence of representation in fight-or-flight learning.</a></span> <span class='pub_name'>Minds and Machines</span> 7 (4):475-494. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13709185989561217305'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Brave%20mobots%20use%20representation+author%3AThornton&amp;btnG=Search'>Google</a> | <a href='javascript:show("_611_links")'>More links</a>)</span><div id='_611_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The paper uses ideas from Machine Learning, Artificial Intelligence and Genetic Algorithms to provide a model of the development of a fight-or-flight response in a simulated agent. The modelled development process involves (simulated) processes of evolution, learning and representation development. The main value of the model is that it provides an illustration of how simple learning processes may lead to the formation of structures which can be given a representational interpretation. It also shows how these may form the infrastructure for closely-coupled agent/environment interaction</div>
<div id='_611_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596763">http://portal.acm.org/citation.cfm?id=596763</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.cogs.susx.ac.uk/users/christ/fight-or-flight.html">http://www.cogs.susx.ac.uk/users/christ/fight-or-flight.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.cogs.susx.ac.uk/users/christ/papers/brave-mobots.ps">http://www.cogs.susx.ac.uk/users/christ/papers/brave-mobots.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.cogs.sussex.ac.uk/users/christ/papers/brave-mobots.ps">http://www.cogs.sussex.ac.uk/users/christ/papers/brave-mobots.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.informatics.sussex.ac.uk/users/christ/papers/brave-mobots.ps">http://www.informatics.sussex.ac.uk/users/christ/papers/brave-mobots.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=316236CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=316236CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.springerlink.com/content/q228732u4h164l35/fulltext.pdf">http://www.springerlink.com/content/q228732u4h164l35/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=136246&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=136246&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.springerlink.com/index/Q228732U4H164L35.pdf">http://www.springerlink.com/index/Q228732U4H164L35.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THOBMU",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00136246">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00136246</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.3'></a><a name=''></a><span class='myh2'>6.3 Philosophy of Connectionism</span></p>

<div id='cat_6.3' class='cat_content'>
<div id='__new_entries_6.3__'></div><div id='__new_entry_6.3__' class='entry'></div></div>
<p><a name='.6.3a'></a><a name=''></a><span class='myh3'>6.3a Connectionism and Compositionality</span> <p style='font-size:smaller;display:inline;'>54 / 55 entries displayed</p></p>

<div id='cat_6.3a' class='cat_content'>
<div id='__new_entries_6.3a__'></div><div id='__new_entry_6.3a__' class='entry'></div>
<div id='_612_entry' class='entry'><span ><span class='name'>Aizawa, Kenneth</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("AIZES",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1997.tb00065.x'>Explaining systematicity.</a></span> <span class='pub_name'>Mind and Language</span> 12 (2):115-36. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2630203528900586029'>Cited by 48</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Explaining%20systematicity+author%3AAizawa&amp;btnG=Search'>Google</a> | <a href='javascript:show("_612_links")'>More links</a>)</span>
<div id='_612_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AIZES",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119154896/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119154896/PDFSTART</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AIZES",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00039">http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00039</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AIZES",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00039">http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00039</a><br></div></div>
</div><!--entry-->

<div id='_613_entry' class='entry'><span ><span class='name'>Aizawa, Kenneth</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("AIZEVE",this.href,0);return true;' href='http://www.springerlink.com/content/content/tuq4w37067306080/fulltext.pdf'>Exhibiting verses explaining systematicity: A reply to Hadley and Hayward.</a></span> <span class='pub_name'>Minds and Machines</span> 7 (1):39-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Exhibiting%20verses%20explaining%20systematicity+author%3AAizawa&amp;btnG=Search'>Google</a> | <a href='javascript:show("_613_links")'>More links</a>)</span>
<div id='_613_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AIZEVE",this.href,0);return true;' href="http://www.springerlink.com/content/tuq4w37067306080/fulltext.pdf">http://www.springerlink.com/content/tuq4w37067306080/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_614_entry' class='entry'><span ><span class='name'>Aizawa, Kenneth</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("AIZTRO",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=Z2OTEkN9U1wC&amp;oi=fnd&amp;pg=PA197&amp;dq=The+role+of+the+systematicity+argument+in+classicism+and+connectionism+Aizawa&amp;ots=JRHE9265sD&amp;sig=PYkUvaYbLWPsAKhRg5A9dgURm5I'>The role of the systematicity argument in classicism and connectionism.</a></span> In S. O'Nuallain (ed.), <em>Two Sciences of Mind</em>. John Benjamins. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4251487016264335357'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20role%20of%20the%20systematicity%20argument%20in%20classicism%20and%20connectionism+author%3AAizawa&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_615_entry' class='entry'><span ><span class='name'>Aizawa, Kenneth</span> (2003). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("AIZTSA",this.href,0);return true;' href='http://books.google.com/books?id=CC6pG-6O96QC&amp;printsec=front_cover'>The Systematicity Arguments.</a></span></em></span> Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 4 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Systematicity%20Arguments+author%3AAizawa&amp;btnG=Search'>Google</a>)</span><div id='_615_abstract' class='extra' style='font-size:12px;'>Abstract: The Systematicity Arguments is the only book-length treatment of the systematicity and productivity arguments.</div>
</div><!--entry-->

<div id='_616_entry' class='entry'><span ><span class='name'>Antony, Michael V.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("ANTFAP",this.href,0);return true;' href='http://www.springerlink.com/content/content/u316462310k73495/fulltext.pdf'>Fodor and Pylyshyn on connectionism.</a></span> <span class='pub_name'>Minds and Machines</span> 1 (3):321-41. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4663232971208804916'>Cited by 3</a> | <span class='ll' onclick='$("_616_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Fodor%20and%20Pylyshyn%20on%20connectionism+author%3AAntony&amp;btnG=Search'>Google</a> | <a href='javascript:show("_616_links")'>More links</a>)</span><div id='_616_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Fodor and Pylyshyn's argument is an invalid instance of inference to the best explanation, as there is much to explain than systematicity. Connectionism and classicism may be compatible even without implementation, in any case.</div></div><div id='_616_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Fodor and Pylyshyn (1988) have argued that the cognitive architecture is not Connectionist. Their argument takes the following form: (1) the cognitive architecture is Classical; (2) Classicalism and Connectionism are incompatible; (3) therefore the cognitive architecture is not Connectionist. In this essay I argue that Fodor and Pylyshyn's defenses of (1) and (2) are inadequate. Their argument for (1), based on their claim that Classicalism best explains the systematicity of cognitive capacities, is an invalid instance of inference to the best explanation. And their argument for (2) turns out to be question-begging. The upshot is that, while Fodor and Pylyshyn have presented Connectionists with the important empirical challenge of explaining systematicity, they have failed to provide sufficient reason for inferring that the cognitive architecture is Classical and not Connectionist</div>
<div id='_616_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ANTFAP",this.href,0);return true;' href="http://www.springerlink.com/content/u316462310k73495/fulltext.pdf">http://www.springerlink.com/content/u316462310k73495/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ANTFAP",this.href,0);return true;' href="http://www.springerlink.com/index/U316462310K73495.pdf">http://www.springerlink.com/index/U316462310K73495.pdf</a><br></div></div>
</div><!--entry-->

<div id='_617_entry' class='entry'><span ><span class='name'>Aydede, Murat</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("AYDLOT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596704.596729'>Language of thought: The connectionist contribution.</a></span> <span class='pub_name'>Minds and Machines</span> 7 (1):57-101. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4281339986054084169'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Language%20of%20thought+author%3AAydede&amp;btnG=Search'>Google</a> | <a href='javascript:show("_617_links")'>More links</a>)</span><div id='_617_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Fodor and Pylyshyn's critique of connectionism has posed a challenge to connectionists: Adequately explain such nomological regularities as systematicity and productivity without postulating a "language of thought" (LOT). Some connectionists like Smolensky took the challenge very seriously, and attempted to meet it by developing models that were supposed to be non-classical. At the core of these attempts lies the claim that connectionist models can provide a representational system with a combinatorial syntax and processes sensitive to syntactic structure. They are not implementation models because, it is claimed, the way they obtain syntax and structure sensitivity is not "concatenative," hence "radically different" from the way classicists handle them. In this paper, I offer an analysis of what it is to physically satisfy/realize a formal system. In this context, I examine the minimal truth-conditions of LOT Hypothesis. From my analysis it will follow that concatenative realization of formal systems is irrelevant to LOTH since the very notion of LOT is indifferent to such an implementation level issue as concatenation. I will conclude that to the extent to which they can explain the law-like cognitive regularities, a certain class of connectionist models proposed as radical alternatives to the classical LOT paradigm will in fact turn out to be LOT models, even though new and potentially very exciting ones</div>
<div id='_617_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AYDLOT",this.href,0);return true;' href="http://www.springerlink.com/content/content/v8365g5vp26x7x75/fulltext.pdf">http://www.springerlink.com/content/content/v8365g5vp26x7x75/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AYDLOT",this.href,0);return true;' href="http://www.springerlink.com/content/v8365g5vp26x7x75/fulltext.pdf">http://www.springerlink.com/content/v8365g5vp26x7x75/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AYDLOT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=115552&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=115552&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AYDLOT",this.href,0);return true;' href="http://www.springerlink.com/index/V8365G5VP26X7X75.pdf">http://www.springerlink.com/index/V8365G5VP26X7X75.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AYDLOT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000001/00115552">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000001/00115552</a><br></div></div>
</div><!--entry-->

<div id='_618_entry' class='entry'><span ><span class='name'>Butler, Keith</span> (1993). Connectionism, classical cognitivism, and the relation between cognitive and implementational levels of analysis.</span> <span class='pub_name'>Philosophical Psychology</span> 6 (3):321-33. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1234778331204154716'>Cited by 6</a> | <span class='ll' onclick='$("_618_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20classical%20cognitivism%2C%20and%20the%20relation%20between%20cognitive%20and%20implementational%20levels%20of%20analysis+author%3AButler&amp;btnG=Search'>Google</a>)</span><div id='_618_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Contra Chalmers 1993, F&P's argument doesn't apply at the implementational level. Contra Chater and Oaksford 1990, connectionism can't be purely implementational, but some implementational details can be relevant.</div></div><div id='_618_abstract' class='extra' style='font-size:12px;'>Abstract: This paper discusses the relation between cognitive and implementational levels of analysis. Chalmers (1990, 1993) argues that a connectionist implementation of a classical cognitive architecture possesses a compositional semantics, and therefore undercuts Fodor and Pylyshyn's (1988) argument that connectionist networks cannot possess a compositional semantics. I argue that Chalmers argument misconstrues the relation between cognitive and implementational levels of analysis. This paper clarifies the distinction, and shows that while Fodor and Pylyshyn's argument survives Chalmers' critique, it cannot be used to establish the irrelevance of neurophysiological implementation to cognitive modeling; some aspects of Chater and Oaksford's (1990) response to Fodor and Pylyshyn, though not all, are therefore cogent</div>
</div><!--entry-->

<div id='_619_entry' class='entry'><span ><span class='name'>Butler, Keith</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("BUTCIC",this.href,0);return true;' href='http://www.springerlink.com/content/t05q0506v1349189/fulltext.pdf'>Compositionality in cognitive models: The real issue.</a></span> <span class='pub_name'>Philosophical Studies</span> 78 (2):153-62. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9652760118167458021'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Compositionality%20in%20cognitive%20models+author%3AButler&amp;btnG=Search'>Google</a> | <a href='javascript:show("_619_links")'>More links</a>)</span>
<div id='_619_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTCIC",this.href,0);return true;' href="http://www.springerlink.com/index/T05Q0506V1349189.pdf">http://www.springerlink.com/index/T05Q0506V1349189.pdf</a><br></div></div>
</div><!--entry-->

<div id='_620_entry' class='entry'><span ><span class='name'>Butler, Keith</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("BUTOCO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(199303)44:1&lt;37:OCOSAC&gt;2.0.CO;2-L'>On Clark on systematicity and connectionism.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 44 (1):37-44. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=81854263552331831'>Cited by 1</a> | <span class='ll' onclick='$("_620_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20Clark%20on%20systematicity%20and%20connectionism+author%3AButler&amp;btnG=Search'>Google</a> | <a href='javascript:show("_620_links")'>More links</a>)</span><div id='_620_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues against Clark on holism and the conceptual truth of systematicity.</div></div>
<div id='_620_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTOCO",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(199303)44:1&lt;37:OCOSAC&gt;2.0.CO;2-L">http://www.jstor.org/sici?sici=0007-0882(199303)44:1<37:OCOSAC>2.0.CO;2-L</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTOCO",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/44/1/37">http://bjps.oxfordjournals.org/cgi/content/citation/44/1/37</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTOCO",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/44/1/37">http://bjps.oxfordjournals.org/cgi/reprint/44/1/37</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTOCO",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/687848.pdf">http://www.jstor.org/stable/pdfplus/687848.pdf</a><br></div></div>
</div><!--entry-->

<div id='_621_entry' class='entry'><span ><span class='name'>Butler, Keith</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("BUTTAC",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1991.tb00191.x'>Towards a connectionist cognitive architecture.</a></span> <span class='pub_name'>Mind and Language</span> 6 (3):252-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11104030479266110494'>Cited by 12</a> | <span class='ll' onclick='$("_621_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Towards%20a%20connectionist%20cognitive%20architecture+author%3AButler&amp;btnG=Search'>Google</a> | <a href='javascript:show("_621_links")'>More links</a>)</span><div id='_621_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism can make do with unstructured representations, as long have they have the right causal relations between them.</div></div>
<div id='_621_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTTAC",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119352985/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119352985/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_622_entry' class='entry'><span ><span class='name'>Chater, Nick</span> &amp; <span class='name'>Oaksford, Mike</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("CHAAIA-2",this.href,0);return true;' href='http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=2302942&amp;dopt=Citation'>Autonomy, implementation and cognitive architecture: A reply to Fodor and Pylyshyn.</a></span> <span class='pub_name'>Cognition</span> 34:93-107. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9560282638565456056'>Cited by 63</a> | <span class='ll' onclick='$("_622_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Autonomy%2C%20implementation%20and%20cognitive%20architecture+author%3AChater&amp;btnG=Search'>Google</a>)</span><div id='_622_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Implementation can make a difference at the algorithmic level.</div></div>
</div><!--entry-->

<div id='_623_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("CHACAC-2",this.href,0);return true;' href='http://consc.net/papers/f-and-p.pdf'>Connectionism and compositionality: Why Fodor and Pylyshyn were wrong.</a></span> <span class='pub_name'>Philosophical Psychology</span> 6 (3):305-319. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_623_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20compositionality+author%3AChalmers&amp;btnG=Search'>Google</a>)</span><div id='_623_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Points out a structural flaw in F&P's argument, and traces the problem to a lack of appreciation of distributed representation. With some empirical results on structure sensitive processing, and some remarks on explanation.</div></div><div id='_623_abstract' class='extra' style='font-size:12px;'>Abstract: This paper offers both a theoretical and an experimental perspective on the relationship between connectionist and Classical (symbol-processing) models. Firstly, a serious flaw in Fodor and Pylyshynâs argument against connectionism is pointed out: if, in fact, a part of their argument is valid, then it establishes a conclusion quite different from that which they intend, a conclusion which is demonstrably false. The source of this flaw is traced to an underestimation of the differences between localist and distributed representation. It has been claimed that distributed representations cannot support systematic operations, or that if they can, then they will be mere implementations of traditional ideas. This paper presents experimental evidence against this conclusion: distributed representations can be used to support direct structure-sensitive operations, in a man- ner quite unlike the Classical approach. Finally, it is argued that even if Fodor and Pylyshynâs argument that connectionist models of compositionality must be mere implementations were correct, then this would still not be a serious argument against connectionism as a theory of mind</div>
</div><!--entry-->

<div id='_624_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("CHADSA",this.href,0);return true;' href='http://consc.net/misc-papers.html'>Deep systematicity and connectionist representation.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Deep%20systematicity%20and%20connectionist%20representation+author%3AChalmers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_624_links")'>More links</a>)</span><div id='_624_abstract' class='extra' style='font-size:12px;'>Abstract: 1. I think that by emphasizing theoretical spaces of representations, Andy has put his finger on an issue that is key to connectionism's success, and whose investigation will be a key determinant of the field's further progress. I also think that if we look at representational spaces in the right way, we can see that they are deeply related to classical phenomenon of systematicity in representation. I want to argue that the key to understanding representational spaces, and in particular their ability to capture the deep organization underlying various problems, lies in the idea of what I will call</div>
<div id='_624_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHADSA",this.href,0);return true;' href="http://consc.net/notes/clark-comments.html">http://consc.net/notes/clark-comments.html</a><br></div></div>
</div><!--entry-->

<div id='_625_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("CHASTO",this.href,0);return true;' href='http://consc.net/papers/transformations.pdf'>Syntactic transformations on distributed representations.</a></span> <span class='pub_name'>Connection Science</span> 2:53-62. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4375639414803514259'>Cited by 180</a> | <span class='ll' onclick='$("_625_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Syntactic%20transformations%20on%20distributed%20representations+author%3AChalmers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_625_links")'>More links</a>)</span><div id='_625_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>An experimental demonstration that connectionist models can handle structure-sensitive operations in a non-classical way, transforming structured representations of active sentences to passive sentences.</div></div><div id='_625_abstract' class='extra' style='font-size:12px;'>Abstract: There has been much interest in the possibility of connectionist models whose representations can be endowed with compositional structure, and a variety of such models have been proposed. These models typically use distributed representations that arise from the functional composition of constituent parts. Functional composition and decomposition alone, however, yield only an implementation of classical symbolic theories. This paper explores the possibility of moving beyond implementation by exploiting holistic structure-sensitive operations on distributed representations. An experiment is performed using Pollackâs Recursive Auto-Associative Memory. RAAM is used to construct distributed representations of syntactically structured sentences. A feed-forward network is then trained to operate directly on these representations, modeling syn- tactic transformations of the represented sentences. Successful training and generalization is obtained, demonstrating that the implicit structure present in these representations can be used for a kind of structure-sensitive processing unique to the connectionist domain</div>
<div id='_625_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASTO",this.href,0);return true;' href="http://citeseer.ist.psu.edu/517265.html">http://citeseer.ist.psu.edu/517265.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASTO",this.href,0);return true;' href="http://citeseer.ist.psu.edu/chalmers90syntactic.html">http://citeseer.ist.psu.edu/chalmers90syntactic.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASTO",this.href,0);return true;' href="http://www.u.arizona.edu/~chalmers/papers/transformations.pdf">http://www.u.arizona.edu/~chalmers/papers/transformations.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASTO",this.href,0);return true;' href="http://www.informaworld.com/index/776705615.pdf">http://www.informaworld.com/index/776705615.pdf</a><br></div></div>
</div><!--entry-->

<div id='_626_entry' class='entry'><span ><span class='name'>Christiansen, M. H.</span> &amp; <span class='name'>Chater, Nick</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("CHRGAC",this.href,0);return true;' href='http://www.isrl.uiuc.edu/~amag/langev/paper/christiansen94generalizationAnd.html'>Generalization and connectionist language learning.</a></span> <span class='pub_name'>Mind and Language</span> 9:273-87. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7755413956806493238'>Cited by 45</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Generalization%20and%20connectionist%20language%20learning+author%3AChristiansen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_626_links")'>More links</a>)</span>
<div id='_626_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHRGAC",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00226.x">http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00226.x</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHRGAC",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119275792/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119275792/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_627_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("CUMS",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(199612)93:12&lt;591:S&gt;2.0.CO;2-C'>Systematicity.</a></span> <span class='pub_name'>Journal of Philosophy</span> 93 (12):591-614. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16384863980710874739'>Cited by 14</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Systematicity+author%3ACummins&amp;btnG=Search'>Google</a> | <a href='javascript:show("_627_links")'>More links</a>)</span>
<div id='_627_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CUMS",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(199612)93:12&lt;591:S&gt;2.0.CO;2-C">http://www.jstor.org/sici?sici=0022-362X(199612)93:12<591:S>2.0.CO;2-C</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CUMS",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2941118.pdf">http://www.jstor.org/stable/pdfplus/2941118.pdf</a><br></div></div>
</div><!--entry-->

<div id='_628_entry' class='entry'><span ><span class='name'>Davis, Wayne A.</span> (2005). On begging the systematicity question.</span> <span class='pub_name'>Journal of Philosophical Research</span> 30:399-404. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20begging%20the%20systematicity%20question+author%3ADavis&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_629_entry' class='entry'><span ><span class='name'>Fetzer, James H.</span> (1992). Connectionism and cognition: Why Fodor and Pylyshyn are wrong.</span> In A. Clark &amp; Ronald Lutz (eds.), <em>Connectionism in Context</em>. Springer-Verlag. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6498757229626760345'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20cognition+author%3AFetzer&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_630_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> &amp; <span class='name'>Pylyshyn, Zenon W.</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("FODCAC",this.href,0);return true;' href='http://ruccs.rutgers.edu/pub/papers/jaf.pdf'>Connectionism and cognitive architecture.</a></span> <span class='pub_name'>Cognition</span> 28:3-71. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5846360074642923893'>Cited by 1496</a> | <span class='ll' onclick='$("_630_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20cognitive%20architecture+author%3AFodor&amp;btnG=Search'>Google</a> | <a href='javascript:show("_630_links")'>More links</a>)</span><div id='_630_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionist models can't explain cognitive systematicity and productivity, as their representations lack compositional structure. The allures of connectionism are illusory; it's best used as an implementation strategy.</div></div><div id='_630_abstract' class='extra' style='font-size:12px;'>Abstract: This paper explores the difference between Connectionist proposals for cognitive a r c h i t e c t u r e a n d t h e s o r t s o f m o d e l s t hat have traditionally been assum e d i n c o g n i t i v e s c i e n c e . W e c l a i m t h a t t h e m a j o r d i s t i n c t i o n i s t h a t , w h i l e b o t h Connectionist and Classical architectures postulate representational mental states, the latter but not the former are committed to a symbol-level of representation, or to a âlanguage of thoughtâ: i.e., to representational states that have combinatorial syntactic and semantic structure. Several arguments for combinatorial structure in mental representations are then reviewed. These include arguments based on the âsystematicityâ of mental representation: i.e., on the fact that cognitive capacities always exhibit certain symmetries, so that the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents. We claim that such arguments make a powerful case that mind/brain architecture is not Connectionist at the cognitive level. We then consider the possibility that Connectionism may provide an account of the neural (or âabstract neurologicalâ) structures in which Classical cognitive architecture is implemented. We survey a n u m b e r o f t h e s t a n d a r d a r g u m e n t s t h a t h a v e b e e n o f f e r e d i n f a v o r o f Connectionism, and conclude that they are coherent only on this interpretation</div>
<div id='_630_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=58067">http://portal.acm.org/citation.cfm?id=58067</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://www.blutner.de/philom/connect/jaf.pdf">http://www.blutner.de/philom/connect/jaf.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://ruccs.rutgers.edu/ftp/pub/papers/jaf.pdf">http://ruccs.rutgers.edu/ftp/pub/papers/jaf.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=190704.190740">http://portal.acm.org/citation.cfm?id=190704.190740</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://www.ii.metu.edu.tr/~tekman/fodor&amp;pylyshyn.pdf">http://www.ii.metu.edu.tr/~tekman/fodor&pylyshyn.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://citeseer.ist.psu.edu/fodor88connectionism.html">http://citeseer.ist.psu.edu/fodor88connectionism.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLzaEHRW&amp;sig=1PDJYThCtCF24M7R6UJK4T">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLzaEHRW&sig=1PDJYThCtCF24M7R6UJK4T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://watarts.uwaterloo.ca/~celiasmi/courses/Phil256/papers/fodor.pylyshyn.1988.Connectionism cog architec.bbs.pdf">http://watarts.uwaterloo.ca/~celiasmi/courses/Phil256/papers/fodor.pylyshyn.1988.Connectionism cog architec.bbs.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bKr8GASZ&amp;sig=lvbjst___yAcJlOgVzyRdzEV09k">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bKr8GASZ&sig=lvbjst___yAcJlOgVzyRdzEV09k</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bGv5IAW0&amp;sig=bfPrm5H3Z-QZFIh2WX-XvqgjqHE">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bGv5IAW0&sig=bfPrm5H3Z-QZFIh2WX-XvqgjqHE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bIt7BHPT&amp;sig=W9wLTgrsP59cPqZhSN0ysQbSVoM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bIt7BHPT&sig=W9wLTgrsP59cPqZhSN0ysQbSVoM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bHr6CFR-&amp;sig=ic0bVVM1PfuvCnadV8OCRGBbNA4">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bHr6CFR-&sig=ic0bVVM1PfuvCnadV8OCRGBbNA4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bGv5HHV-&amp;sig=UkXTSX19hHzvmMUKvLT-lq0r50I">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bGv5HHV-&sig=UkXTSX19hHzvmMUKvLT-lq0r50I</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKr7GJXU&amp;sig=LBgHuNyf_KzzIi7ocvlxiFsIWIE">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKr7GJXU&sig=LBgHuNyf_KzzIi7ocvlxiFsIWIE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLtaAJQ0&amp;sig=-rBwtgEcuMHfIKQJzOHWYIrBX9E">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLtaAJQ0&sig=-rBwtgEcuMHfIKQJzOHWYIrBX9E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKwbCDTZ&amp;sig=00wE8Svuh3W8kqsUo0UKOYCfcAI">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKwbCDTZ&sig=00wE8Svuh3W8kqsUo0UKOYCfcAI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bHx6HGX-&amp;sig=5IusXYTvApV1_rtpQEkaBet0xn4">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bHx6HGX-&sig=5IusXYTvApV1_rtpQEkaBet0xn4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKubBBQY&amp;sig=HFGXyuxr_1mxH5ACFOe-zyaTw4o">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKubBBQY&sig=HFGXyuxr_1mxH5ACFOe-zyaTw4o</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bIz7HEWT&amp;sig=CAuCWiDdEmwTntCDA3H1Zyfn5a0">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bIz7HEWT&sig=CAuCWiDdEmwTntCDA3H1Zyfn5a0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLzaEEXV&amp;sig=e9QEFe5nD4bGAK5W4dDIRZBKNuM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLzaEEXV&sig=e9QEFe5nD4bGAK5W4dDIRZBKNuM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bIz7HCQU&amp;sig=4TMgHlnpnDyehNFJT-NG470Bbz8">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bIz7HCQU&sig=4TMgHlnpnDyehNFJT-NG470Bbz8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bMvaHGVW&amp;sig=9UEpXL5XYxZdQa3NvX7yU9iikyw">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bMvaHGVW&sig=9UEpXL5XYxZdQa3NvX7yU9iikyw</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bKx9AJPT&amp;sig=7sjHbKdagqCd6sUT-Kk-fcITZlc">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bKx9AJPT&sig=7sjHbKdagqCd6sUT-Kk-fcITZlc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bHx6HEPT&amp;sig=9ypKOA18BrlaitMu_it-TVCBfUw">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bHx6HEPT&sig=9ypKOA18BrlaitMu_it-TVCBfUw</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKr7GFP0&amp;sig=tdUqyz4ARusp_kokrKNOJedNknk">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKr7GFP0&sig=tdUqyz4ARusp_kokrKNOJedNknk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLtaAHPT&amp;sig=cUrJjY2sKfVLW5Zp1ZtlEsdhcaM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLtaAHPT&sig=cUrJjY2sKfVLW5Zp1ZtlEsdhcaM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bJv8BJW0&amp;sig=Qe8qR4Go6tnV95LlvTT6ELC_0Ds">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bJv8BJW0&sig=Qe8qR4Go6tnV95LlvTT6ELC_0Ds</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKwbCBVX&amp;sig=iCTIyYq8EOvBdYu-srEXgyt-HoM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKwbCBVX&sig=iCTIyYq8EOvBdYu-srEXgyt-HoM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O2dHfvmUIJ&amp;sig=7hnYM8j4zdtpN4THjVSpzpGFEDs">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O2dHfvmUIJ&sig=7hnYM8j4zdtpN4THjVSpzpGFEDs</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34InykTQC&amp;sig=F0CONzdT49KnmoIp41iOngjBa_A">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34InykTQC&sig=F0CONzdT49KnmoIp41iOngjBa_A</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34IhygWIA&amp;sig=Zks6FRmma9XZGHW2EO1kvwIxesQ">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34IhygWIA&sig=Zks6FRmma9XZGHW2EO1kvwIxesQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34DjtnWOI&amp;sig=ohgYrPGd2Ut0_gQqvfJPXg0_xJo">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34DjtnWOI&sig=ohgYrPGd2Ut0_gQqvfJPXg0_xJo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34FnvnRJB&amp;sig=snID_Ptc5j-K-DxZvSjAScHkD6s">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34FnvnRJB&sig=snID_Ptc5j-K-DxZvSjAScHkD6s</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34GjwhYPJ&amp;sig=YnoEHTZY6rwzlL8DcfCj45uUQo0">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34GjwhYPJ&sig=YnoEHTZY6rwzlL8DcfCj45uUQo0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34JjynVOD&amp;sig=XBIWzRchQULcgPTlX6HyBgOg_pQ">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34JjynVOD&sig=XBIWzRchQULcgPTlX6HyBgOg_pQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34HfwmPLG&amp;sig=35GDmDcPG526574Ar-pZaGlfYXA">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34HfwmPLG&sig=35GDmDcPG526574Ar-pZaGlfYXA</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34ElunTIA&amp;sig=OzlrEEZ2Td9CGt5mgUD99UXGCWE">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34ElunTIA&sig=OzlrEEZ2Td9CGt5mgUD99UXGCWE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34HlxgYIA&amp;sig=ZsqjFV8LrCGXI-3jf8Pliu_sVsc">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34HlxgYIA&sig=ZsqjFV8LrCGXI-3jf8Pliu_sVsc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34FhvhWIA&amp;sig=1yq1WHwwotr3qVSaqN0K4StIWc8">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34FhvhWIA&sig=1yq1WHwwotr3qVSaqN0K4StIWc8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34EfuiUKI&amp;sig=lDwkN-dMTxlLX_1XELpsD4ONtM4">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34EfuiUKI&sig=lDwkN-dMTxlLX_1XELpsD4ONtM4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O2dHizhQJF&amp;sig=s7d-fmzg598bYH-IpAMNrcyO8eo">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O2dHizhQJF&sig=s7d-fmzg598bYH-IpAMNrcyO8eo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O2dHkziQOE&amp;sig=6AJnryXo_R8vj8qseWkK5DD31zQ">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O2dHkziQOE&sig=6AJnryXo_R8vj8qseWkK5DD31zQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=2450716&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=2450716&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_631_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> &amp; <span class='name'>McLaughlin, Brian P.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("FODCAT",this.href,0);return true;' href='http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=2354612&amp;dopt=Citation'>Connectionism and the problem of systematicity: Why Smolensky's solution doesn't work.</a></span> <span class='pub_name'>Cognition</span> 35:183-205. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2127168635050024077'>Cited by 193</a> | <span class='ll' onclick='$("_631_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20problem%20of%20systematicity+author%3AFodor&amp;btnG=Search'>Google</a>)</span><div id='_631_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Smolensky's weak compositionality is useless; and tensor product architecture can't support systematicity, as nonexistent tokens can't play a causal role.</div></div>
</div><!--entry-->

<div id='_632_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("FODCAT-2",this.href,0);return true;' href='http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=8997173&amp;dopt=Citation'>Connectionism and the problem of systematicity (continued): Why Smolensky's solution still doesn't work.</a></span> <span class='pub_name'>Cognition</span> 62:109-19. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4555049566412038217'>Cited by 25</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20problem%20of%20systematicity%20%28continued%29+author%3AFodor&amp;btnG=Search'>Google</a> | <a href='javascript:show("_632_links")'>More links</a>)</span>
<div id='_632_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAT-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/00100277/1997/00000062/00000001/art00780">http://www.ingentaconnect.com/content/els/00100277/1997/00000062/00000001/art00780</a><br></div></div>
</div><!--entry-->

<div id='_633_entry' class='entry'><span ><span class='name'>Garfield, Jay L.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("GARMNS",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793918582~fulltext=713240930'>Mentalese not spoken here: Computation, cognition, and causation.</a></span> <span class='pub_name'>Philosophical Psychology</span> 10 (4):413-35. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11823617147383940327'>Cited by 38</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mentalese%20not%20spoken%20here+author%3AGarfield&amp;btnG=Search'>Google</a>)</span><div id='_633_abstract' class='extra' style='font-size:12px;'>Abstract: Classical computational modellers of mind urge that the mind is something like a von Neumann computer operating over a system of symbols constituting a language of thought. Such an architecture, they argue, presents us with the best explanation of the compositionality, systematicity and productivity of thought. The language of thought hypothesis is supported by additional independent arguments made popular by Jerry Fodor. Paul Smolensky has developed a connectionist architecture he claims adequately explains compositionality, systematicity and productivity without positing any language of thought, and without positing any operations over a set of symbols. This architecture encodes the information represented in linguistic trees without explicitly representing those trees or their constituents, and indeed without employing any representational vehicles with constituent structure. In a recent article, Fodor (1997; Connectionism and systematicity, Cognition , 62, 109-119) argues that Smolensky's proposal does not work. I defend Smolensky against Fodor's attack, and use this interchange as a vehicle for exploring and criticising the âLanguage of Thoughtâ hypothesis more generally and the arguments Fodor adduces on its behalf</div>
</div><!--entry-->

<div id='_634_entry' class='entry'><span ><span class='name'>Garcia-Carpintero, Manuel</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("GARTSV",this.href,0);return true;' href='http://www.springerlink.com/content/content/j74132418g368g21/fulltext.pdf'>Two spurious varieties of compositionality.</a></span> <span class='pub_name'>Minds and Machines</span> 6 (2):159-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Two%20spurious%20varieties%20of%20compositionality+author%3AGarcia-Carpintero&amp;btnG=Search'>Google</a> | <a href='javascript:show("_634_links")'>More links</a>)</span><div id='_634_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The paper examines an alleged distinction claimed to exist by Van Gelder between two different, but equally acceptable ways of accounting for the systematicity of cognitive output (two varieties of compositionality): concatenative compositionality vs. functional compositionality. The second is supposed to provide an explanation alternative to the Language of Thought Hypothesis. I contend that, if the definition of concatenative compositionality is taken in a different way from the official one given by Van Gelder (but one suggested by some of his formulations) then there is indeed a different sort of compositionality; however, the second variety is not an alternative to the language of thought in that case. On the other hand, if the concept of concatenative compositionality is taken in a different way, along the lines of Van Gelder's explicit definition, then there is no reason to think that there is an alternative way of explaining systematicity</div>
<div id='_634_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARTSV",this.href,0);return true;' href="http://www.springerlink.com/content/j74132418g368g21/fulltext.pdf">http://www.springerlink.com/content/j74132418g368g21/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARTSV",this.href,0);return true;' href="http://www.springerlink.com/index/J74132418G368G21.pdf">http://www.springerlink.com/index/J74132418G368G21.pdf</a><br></div></div>
</div><!--entry-->

<div id='_635_entry' class='entry'><span ><span class='name'>Guarini, Marcello</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("GUATPA",this.href,0);return true;' href='http://www.jstor.org/sici?sici=0031-8248(199609)63:3&lt;S239:TPASAF&gt;2.0.CO;2-L'>Tensor products and split-level architecture: Foundational issues in the classicism-connectionism debate.</a></span> <span class='pub_name'>Philosophy of Science</span> 63 (3):S239-S247. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Tensor%20products%20and%20split-level%20architecture+author%3AGuarini&amp;btnG=Search'>Google</a> | <a href='javascript:show("_635_links")'>More links</a>)</span>
<div id='_635_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUATPA",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0031-8248(199609)63&lt;S239:TPASAF&gt;2.0.CO;2-T">http://links.jstor.org/sici?sici=0031-8248(199609)63<S239:TPASAF>2.0.CO;2-T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUATPA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/188532.pdf">http://www.jstor.org/stable/pdfplus/188532.pdf</a><br></div></div>
</div><!--entry-->

<div id='_636_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("HADCSA",this.href,0);return true;' href='http://fas.sfu.ca/pub/cs/hadley/nomic.ps'>Cognition, systematicity, and nomic necessity.</a></span> <span class='pub_name'>Mind and Language</span> 12 (2):137-53. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7096063179048930452'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognition%2C%20systematicity%2C%20and%20nomic%20necessity+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_636_links")'>More links</a>)</span>
<div id='_636_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCSA",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1997.tb00066.x">http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1997.tb00066.x</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCSA",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119154897/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119154897/PDFSTART</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCSA",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00040">http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00040</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCSA",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00040">http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00040</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCSA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00002">http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00002</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCSA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00040">http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00040</a><br></div></div>
</div><!--entry-->

<div id='_637_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("HADESA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596707.596755'>Explaining systematicity: A reply to Kenneth Aizawa.</a></span> <span class='pub_name'>Minds and Machines</span> 12 (4):571-79. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11409591259303728164'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Explaining%20systematicity+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_637_links")'>More links</a>)</span><div id='_637_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In his discussion of results which I (with Michael Hayward) recently reported in this journal, Kenneth Aizawa takes issue with two of our conclusions, which are: (a) that our connectionist model provides a basis for explaining systematicity within the realm of sentence comprehension, and subject to a limited range of syntax (b) that the model does not employ structure-sensitive processing, and that this is clearly true in the early stages of the network''s training. Ultimately, Aizawa rejects both (a) and (b) for reasons which I think are ill-founded. In what follows, I offer a defense of our position. In particular, I argue (1) that Aizawa adopts a standard of explanation that many accepted scientific explanations could not meet, and (2) that Aizawa misconstrues the relevant meaning of structure-sensitive process</div>
<div id='_637_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADESA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=316242CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=316242CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADESA",this.href,0);return true;' href="http://www.springerlink.com/content/m395128140134l86/fulltext.pdf">http://www.springerlink.com/content/m395128140134l86/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADESA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=122810&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=122810&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADESA",this.href,0);return true;' href="http://www.springerlink.com/index/M395128140134L86.pdf">http://www.springerlink.com/index/M395128140134L86.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADESA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00122810">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00122810</a><br></div></div>
</div><!--entry-->

<div id='_638_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("HADSIC",this.href,0);return true;' href='http://fas.sfu.ca/pub/cs/hadley/systematicity.ps'>Systematicity in connectionist language learning.</a></span> <span class='pub_name'>Mind and Language</span> 9:247-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5743048181152774128'>Cited by 74</a> | <span class='ll' onclick='$("_638_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Systematicity%20in%20connectionist%20language%20learning+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_638_links")'>More links</a>)</span><div id='_638_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that existing connectionist models do not achieve an adequate systematicity in learning; they fail to generalize to handle structures with novel constituents.</div></div>
<div id='_638_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADSIC",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00225.x">http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00225.x</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADSIC",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119275791/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119275791/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_639_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("HADSR",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00317.x'>Systematicity revisited.</a></span> <span class='pub_name'>Mind and Language</span> 9:431-44. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2880279171942652531'>Cited by 34</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Systematicity%20revisited+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_639_links")'>More links</a>)</span>
<div id='_639_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADSR",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119970226/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119970226/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_640_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> &amp; <span class='name'>Hayward, M. B.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("HADSSS",this.href,0);return true;' href='http://fas.sfu.ca/pub/cs/hadley/sem.sys.ps'>Strong semantic systematicity from Hebbian connectionist learning.</a></span> <span class='pub_name'>Minds and Machines</span> 7 (1):1-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5867711012463047431'>Cited by 46</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Strong%20semantic%20systematicity%20from%20Hebbian%20connectionist%20learning+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_640_links")'>More links</a>)</span><div id='_640_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Fodor's and Pylyshyn's stand on systematicity in thought and language has been debated and criticized. Van Gelder and Niklasson, among others, have argued that Fodor and Pylyshyn offer no precise definition of systematicity. However, our concern here is with a learning based formulation of that concept. In particular, Hadley has proposed that a network exhibits strong semantic systematicity when, as a result of training, it can assign appropriate meaning representations to novel sentences (both simple and embedded) which contain words in syntactic positions they did not occupy during training. The experience of researchers indicates that strong systematicity in any form is difficult to achieve in connectionist systems.Herein we describe a network which displays strong semantic systematicity in response to Hebbian, connectionist training. During training, two-thirds of all nouns are presented only in a single syntactic position (either as grammatical subject or object). Yet, during testing, the network correctly interprets thousands of sentences containing those nouns in novel positions. In addition, the network generalizes to novel levels of embedding. Successful training requires a, corpus of about 1000 sentences, and network training is quite rapid. The architecture and learning algorithms are purely connectionist, but classical insights are discernible in one respect, viz, that complex semantic representations spatially contain their semantic constituents. However, in other important respects, the architecture is distinctly non-classical</div>
<div id='_640_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADSSS",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596704.596727">http://portal.acm.org/citation.cfm?id=596704.596727</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADSSS",this.href,0);return true;' href="http://www.springerlink.com/content/k4l352163l5777l2/fulltext.pdf">http://www.springerlink.com/content/k4l352163l5777l2/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADSSS",this.href,0);return true;' href="http://www.springerlink.com/index/K4L352163L5777L2.pdf">http://www.springerlink.com/index/K4L352163L5777L2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADSSS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000001/00112501">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000001/00112501</a><br></div></div>
</div><!--entry-->

<div id='_641_entry' class='entry'><span ><span class='name'>Haselager, W. F. G.</span> &amp; <span class='name'>Van Rappard, J. F. H.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("HASCSA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596775'>Connectionism, systematicity, and the frame problem.</a></span> <span class='pub_name'>Minds and Machines</span> 8 (2):161-179. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16434015131078879242'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20systematicity%2C%20and%20the%20frame%20problem+author%3AHaselager&amp;btnG=Search'>Google</a> | <a href='javascript:show("_641_links")'>More links</a>)</span><div id='_641_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper investigates connectionism's potential to solve the frame problem. The frame problem arises in the context of modelling the human ability to see the relevant consequences of events in a situation. It has been claimed to be unsolvable for classical cognitive science, but easily manageable for connectionism. We will focus on a representational approach to the frame problem which advocates the use of intrinsic representations. We argue that although connectionism's distributed representations may look promising from this perspective, doubts can be raised about the potential of distributed representations to allow large amounts of complexly structured information to be adequately encoded and processed. It is questionable whether connectionist models that are claimed to effectively represent structured information can be scaled up to a realistic extent. We conclude that the frame problem provides a difficulty to connectionism that is no less serious than the obstacle it constitutes for classical cognitive science</div>
<div id='_641_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=371129CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=371129CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.springerlink.com/content/um0x474450532866/fulltext.pdf">http://www.springerlink.com/content/um0x474450532866/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=150466&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=150466&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.springerlink.com/index/UM0X474450532866.pdf">http://www.springerlink.com/index/UM0X474450532866.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000002/00150466">http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000002/00150466</a><br></div></div>
</div><!--entry-->

<div id='_642_entry' class='entry'><span ><span class='name'>Hawthorne, John</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("HAWOTC",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793917218~fulltext=713240930'>On the compatibility of connectionist and classical models.</a></span> <span class='pub_name'>Philosophical Psychology</span> 2 (1):5-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2129264410490757083'>Cited by 9</a> | <span class='ll' onclick='$("_642_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20compatibility%20of%20connectionist%20and%20classical%20models+author%3AHawthorne&amp;btnG=Search'>Google</a>)</span><div id='_642_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Localist connectionist models may not be able to handle structured presentation, but appropriate distributed models can.</div></div><div id='_642_abstract' class='extra' style='font-size:12px;'>Abstract: This paper presents considerations in favour of the view that traditional (classical) architectures can be seen as emergent features of connectionist networks with distributed representation. A recent paper by William Bechtel (1988) which argues for a similar conclusion is unsatisfactory in that it fails to consider whether the compositional syntax and semantics attributed to mental representations by classical models can emerge within a connectionist network. The compatibility of the two paradigms hinges largely, I suggest, on how this question is answered. Focusing on the issue of syntax, I argue that while such structure is lacking in connectionist models with local representation, it can be accommodated within networks where representation is distributed. I discuss an important paper by Smolenski (1988) which attempts to show how connectionists can incorporate the relevant syntactic structure, suggesting that some criticisms levelled against that paper by Fodor & Pylyshyn (1988) are wanting. I then go on to indicate a strategy by which a compositional syntax and semantics can be defined for the sort of network that Smolenski describes. I conclude that since the connectionist can respect the central tenets of classicism, the two approaches are compatible with one another</div>
</div><!--entry-->

<div id='_643_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1991). Structured representations in connectionist systems?</span> In S. Davis (ed.), <em>Connectionism: Theorye and Practice</em>. Oup. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6027896860369556870'>Cited by 9</a> | <span class='ll' onclick='$("_643_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Structured%20representations%20in%20connectionist%20systems%3F+author%3AHorgan&amp;btnG=Search'>Google</a>)</span><div id='_643_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A discussion of how connectionism might achieve "effective syntax" without implementing a classical system.</div></div>
</div><!--entry-->

<div id='_644_entry' class='entry'><span ><span class='name'>Macdonald, Cynthia</span> (1995). Classicism V connectionism.</span> In C. Macdonald &amp; Graham F. Macdonald (eds.), <em>Connectionism: Debates on Psychological Explanation</em>. Cambridge: Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Classicism%20V%20connectionism+author%3AMacdonald&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_645_entry' class='entry'><span ><span class='name'>Matthews, Robert J.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("MATCCE",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1997.tb00067.x'>Can connectionists explain systematicity?</a></span> <span class='pub_name'>Mind and Language</span> 12 (2):154-77. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7418867388239800615'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20connectionists%20explain%20systematicity%3F+author%3AMatthews&amp;btnG=Search'>Google</a> | <a href='javascript:show("_645_links")'>More links</a>)</span>
<div id='_645_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MATCCE",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119154898/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119154898/PDFSTART</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MATCCE",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00041">http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00041</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MATCCE",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00041">http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00041</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MATCCE",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00003">http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00003</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MATCCE",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00041">http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000002/art00041</a><br></div></div>
</div><!--entry-->

<div id='_646_entry' class='entry'><span ><span class='name'>Matthews, Robert J.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("MATTME",this.href,0);return true;' href='http://www.springerlink.com/content/l3656473h0382735/fulltext.pdf'>Three-concept Monte: Explanation, implementation, and systematicity.</a></span> <span class='pub_name'>Synthese</span> 101 (3):347-63. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5411716470164650793'>Cited by 12</a> | <span class='ll' onclick='$("_646_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Three-concept%20Monte+author%3AMatthews&amp;btnG=Search'>Google</a> | <a href='javascript:show("_646_links")'>More links</a>)</span><div id='_646_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>F&P deal a sucker bet: on their terms, connectionism could never give a a non-implementational explanation of systematicity, as the notions are construed in a manner specific to classical architectures.</div></div><div id='_646_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Fodor and Pylyshyn (1988), Fodor and McLaughlin (1990) and McLaughlin (1993) challenge connectionists to explain systematicity without simply implementing a classical architecture. In this paper I argue that what makes the challenge difficult for connectionists to meet has less to do with what is to be explained than with what is to count as an explanation. Fodor et al. are prepared to admit as explanatory, accounts of a sort that only classical models can provide. If connectionists are to meet the challenge, they are going to have to insist on the propriety of changing what counts as an explanation of systematicity. Once that is done, there would seem to be as yet no reason to suppose that connectionists are unable to explain systematicity</div>
<div id='_646_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MATTME",this.href,0);return true;' href="http://www.springerlink.com/index/L3656473H0382735.pdf">http://www.springerlink.com/index/L3656473H0382735.pdf</a><br></div></div>
</div><!--entry-->

<div id='_647_entry' class='entry'><span ><span class='name'>McLaughlin, Brian P.</span> (1992). Systematicity, conceptual truth, and evolution.</span> <span class='pub_name'>Philosophy and the Cognitive Sciences</span> 34:217-234. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3268223172051779016'>Cited by 13</a> | <span class='ll' onclick='$("_647_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Systematicity%2C%20conceptual%20truth%2C%20and%20evolution+author%3AMcLaughlin&amp;btnG=Search'>Google</a>)</span><div id='_647_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Against responses to Fodor and Pylyshyn claiming that cognitive theories needn't explain systematicity. Contra Clark, the conceptual truth of systematicity won't help. Contra others, nor will evolution.</div></div>
</div><!--entry-->

<div id='_648_entry' class='entry'><span ><span class='name'>McLaughlin, Brian P.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("MCLTCB",this.href,0);return true;' href='http://www.springerlink.com/content/n20x21753v2565j1/fulltext.pdf'>The connectionism/classicism battle to win souls.</a></span> <span class='pub_name'>Philosophical Studies</span> 71 (2):163-190. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15017982738066042701'>Cited by 19</a> | <span class='ll' onclick='$("_648_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20connectionism%2Fclassicism%20battle%20to%20win%20souls+author%3AMcLaughlin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_648_links")'>More links</a>)</span><div id='_648_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that no connectionist model so far has come close to explaining systematicity. Considers the models of Elman, Chalmers, and Smolensky.</div></div>
<div id='_648_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCLTCB",this.href,0);return true;' href="http://www.springerlink.com/index/N20X21753V2565J1.pdf">http://www.springerlink.com/index/N20X21753V2565J1.pdf</a><br></div></div>
</div><!--entry-->

<div id='_649_entry' class='entry'><span ><span class='name'>Niklasson, L. F.</span> &amp; <span class='name'>van Gelder, Tim</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("NIKOBS",this.href,0);return true;' href='http://citeseer.ist.psu.edu/362575.html'>On being systematically connectionist.</a></span> <span class='pub_name'>Mind and Language</span> 9:288-302. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13523912491904892622'>Cited by 42</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20being%20systematically%20connectionist+author%3ANiklasson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_649_links")'>More links</a>)</span><div id='_649_abstract' class='extra' style='font-size:12px;'>Abstract: In 1988 Fodor and Pylyshyn issued a challenge to the newly-popular connectionism: explain the systematicity of cognition without merely implementing a so-called classical architecture. Since that time quite a number of connectionist models have been put forward, either by their designers or by others, as in some measure demonstrating that the challenge can be met (e.g., Pollack, 1988, 1990; Smolensky, 1990; Chalmers, 1990; Niklasson and Sharkey, 1992; Brousse, 1993). Unfortu- nately, it has generally been unclear whether these models actually do have this implication (see, for instance, the extensive philosophical debate in Smolensky, 1988; Fodor and McLaughlin, 1990; van Gelder, 1990, 1991; McLaughlin, 1993a, 1993b; Clark, 1993). Indeed, we know of no major supporter of classical orthodoxy who has felt compelled, by connectionist models and argu- ments, to concede in print that connectionists have in fact delivered a non-classical explanation of systematicity</div>
<div id='_649_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NIKOBS",this.href,0);return true;' href="http://citeseer.ist.psu.edu/niklasson94being.html">http://citeseer.ist.psu.edu/niklasson94being.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NIKOBS",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00227.x">http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00227.x</a><br></div></div>
</div><!--entry-->

<div id='_650_entry' class='entry'><span ><span class='name'>Petersen, Steven E.</span> &amp; <span class='name'>Roskies, Adina L.</span> (2001). Visualizing human brain function.</span> In  E. Bizzi,  P. Calissano &amp;  V. Volterra (eds.), <em>Frontiers of Life, Vol III: The Intelligent Systems, Part One: The Brain of Homo Sapiens</em>. Academic Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Visualizing%20human%20brain%20function+author%3APetersen&amp;btnG=Search'>Google</a>)</span><div id='_650_abstract' class='extra' style='font-size:12px;'>Abstract: Running head: Functional neuroimaging Abstract Several recently developed techniques enable the investigation of the neural basis of cognitive function in the human brain. Two of these, PET and fMRI, yield whole-brain images reflecting regional neural activity associated with the performance of specific tasks. This article explores the spatial and temporal capabilities and limitations of these techniques, and discusses technical, biological, and cognitive issues relevant to understanding the goals and methods of neuroimaging studies. The types of advances in understanding cognitive and brain function made possible with these methods are illustrated with examples from the neuroimaging literature</div>
</div><!--entry-->

<div id='_651_entry' class='entry'><span ><span class='name'>Phillips, Stephen H.</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("PHIDCE",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596968'>Does classicism explain universality?</a></span> <span class='pub_name'>Minds and Machines</span> 12 (3):423-434. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2359717711801453103'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Does%20classicism%20explain%20universality%3F+author%3APhillips&amp;btnG=Search'>Google</a> | <a href='javascript:show("_651_links")'>More links</a>)</span><div id='_651_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â One of the hallmarks of human cognition is the capacity to generalize over arbitrary constituents. Recently, Marcus (1998, 1998a, b; Cognition 66, p. 153; Cognitive Psychology 37, p. 243) argued that this capacity, called universal generalization (universality), is not supported by Connectionist models. Instead, universality is best explained by Classical symbol systems, with Connectionism as its implementation. Here it is argued that universality is also a problem for Classicism in that the syntax-sensitive rules that are supposed to provide causal explanations of mental processes are either too strict, precluding possible generalizations; or too lax, providing no information as to the appropriate alternative. Consequently, universality is not explained by a Classical theory</div>
<div id='_651_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PHIDCE",this.href,0);return true;' href="http://www.springerlink.com/content/9lycmrkn91j71qqe/fulltext.pdf">http://www.springerlink.com/content/9lycmrkn91j71qqe/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PHIDCE",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=408595&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=408595&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PHIDCE",this.href,0);return true;' href="http://www.springerlink.com/index/9LYCMRKN91J71QQE.pdf">http://www.springerlink.com/index/9LYCMRKN91J71QQE.pdf</a><br></div></div>
</div><!--entry-->

<div id='_652_entry' class='entry'><span ><span class='name'>Plate, Tony A.</span> (2003). <em><span class='pub_name'>Holographic Reduced Representation: Distributed Representation for Cognitive Structures.</span></em></span> Center for the Study of Language and Information. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 18 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Holographic%20Reduced%20Representation+author%3APlate&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_653_entry' class='entry'><span ><span class='name'>Pollack, Jordan B.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("POLRDR",this.href,0);return true;' href='http://citeseer.ist.psu.edu/53494.html'>Recursive distributed representations.</a></span> <span class='pub_name'>Artificial Intelligence</span> 46:77-105. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8219791350695890989'>Cited by 539</a> | <span class='ll' onclick='$("_653_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Recursive%20distributed%20representations+author%3APollack&amp;btnG=Search'>Google</a> | <a href='javascript:show("_653_links")'>More links</a>)</span><div id='_653_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Develops a connectionist architecture -- recursive auto-associative memory -- that can recursively represent compositional structures in distributed form.</div></div>
<div id='_653_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://demo.cs.brandeis.edu/papers/raam.pdf">http://demo.cs.brandeis.edu/papers/raam.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=102423">http://portal.acm.org/citation.cfm?id=102423</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.ing.unisi.it/~monica/Paper/p19.ps.gz">http://www.ing.unisi.it/~monica/Paper/p19.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.uow.edu.au/~markus/apods/doc/papers/raam.ps">http://www.uow.edu.au/~markus/apods/doc/papers/raam.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.blutner.de/philom/connect/pollack90recursive.pdf">http://www.blutner.de/philom/connect/pollack90recursive.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.blutner.de/NeuralNets/Texts/pollack90recursive.pdf">http://www.blutner.de/NeuralNets/Texts/pollack90recursive.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.idi.ntnu.no/emner/it3708/archive/2004/files/raam.pdf">http://www.idi.ntnu.no/emner/it3708/archive/2004/files/raam.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://ftp.uni-koeln.de/neural-nets/papers/pollack.newraam.ps.gz">http://ftp.uni-koeln.de/neural-nets/papers/pollack.newraam.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.cse.ohio-state.edu/~jj/pub/papers/89-JP-RECURSIVE.ps.Z">http://www.cse.ohio-state.edu/~jj/pub/papers/89-JP-RECURSIVE.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.umiacs.umd.edu/~ymarton/ling849/pollack90recursive.pdf">http://www.umiacs.umd.edu/~ymarton/ling849/pollack90recursive.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://ftp.funet.fi/pub/sci/neural/neuroprose/pollack.newraam.ps.Z">http://ftp.funet.fi/pub/sci/neural/neuroprose/pollack.newraam.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.funet.fi/pub/sci/neural/neuroprose/pollack.newraam.ps.Z">http://www.funet.fi/pub/sci/neural/neuroprose/pollack.newraam.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.ftp.funet.fi/ftp/pub/sci/ai/neural/neuroprose/pollack.newraam.ps.Z">http://www.ftp.funet.fi/ftp/pub/sci/ai/neural/neuroprose/pollack.newraam.ps.Z</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRDR",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2470980CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2470980CI</a><br></div></div>
</div><!--entry-->

<div id='_654_entry' class='entry'><span ><span class='name'>Rowlands, Mark</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("ROWCAT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(199406)45:2&lt;485:CATLOT&gt;2.0.CO;2-H'>Connectionism and the language of thought.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 45 (2):485-503. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_654_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20language%20of%20thought+author%3ARowlands&amp;btnG=Search'>Google</a> | <a href='javascript:show("_654_links")'>More links</a>)</span><div id='_654_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>F&P's argument confuses constituent structure with logical/sentential structure. Connectionism is a psychotechtonic project, whereas propositional description is a psychosemantic project.</div></div><div id='_654_abstract' class='extra' style='font-size:12px;'>Abstract: In an influential critique, Jerry Fodor and Zenon Pylyshyn point to the existence of a potentially devastating dilemma for connectionism (Fodor and Pylyshyn [1988]). Either connectionist models consist in mere associations of unstructured representations, or they consist in processes involving complex representations. If the former, connectionism is mere associationism, and will not be capable of accounting for very much of cognition. If the latter, then connectionist models concern only the implementation of cognitive processes, and are, therefore, not informative at the level of cognition. I shall argue that Fodor and Pylyshyn's argument is based on a crucial misunderstanding, the same misunderstanding which motivates the entire language of thought hypothesis</div>
<div id='_654_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROWCAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(199406)45:2&lt;485:CATLOT&gt;2.0.CO;2-H">http://www.jstor.org/sici?sici=0007-0882(199406)45:2<485:CATLOT>2.0.CO;2-H</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROWCAT",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/45/2/485">http://bjps.oxfordjournals.org/cgi/content/abstract/45/2/485</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROWCAT",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/45/2/485">http://bjps.oxfordjournals.org/cgi/reprint/45/2/485</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROWCAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/687678.pdf">http://www.jstor.org/stable/pdfplus/687678.pdf</a><br></div></div>
</div><!--entry-->

<div id='_655_entry' class='entry'><span ><span class='name'>Schroder, Jurgen</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("SCHKOR",this.href,0);return true;' href='http://www.springerlink.com/content/w8735t5747313v32/fulltext.pdf'>Knowledge of rules, causal systematicity, and the language of thought.</a></span> <span class='pub_name'>Synthese</span> 117 (3):313-330. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Knowledge%20of%20rules%2C%20causal%20systematicity%2C%20and%20the%20language%20of%20thought+author%3ASchroder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_655_links")'>More links</a>)</span><div id='_655_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Martin Davies' criterion for the knowledge of implicit rules, viz. the causal systematicity of cognitive processes, is first exposed. Then the inference from causal systematicity of a process to syntactic properties of the input states is examined. It is argued that Davies' notion of a syntactic property is too weak to bear the conclusion that causal systematicity implies a language of thought as far as the input states are concerned. Next, it is shown that Davies' criterion leads to a counterintuitive consequence: it groups together distributed connectionist systems with look-up tables. To avoid this consequence, a modified construal of causal systematicity is proposed and Davies' argument for the causal systematicity of thought is shown to be question-begging. It is briefly sketched how the modified construal links up with multiple dispositions of the same categorical base. Finally, the question of the causal efficacy of single rules is distinguished from the question of their psychological reality: implicit rules might be psychologically real without being causally efficacious</div>
<div id='_655_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHKOR",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=188458&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=188458&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHKOR",this.href,0);return true;' href="http://www.springerlink.com/index/W8735T5747313V32.pdf">http://www.springerlink.com/index/W8735T5747313V32.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHKOR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/synt/1998/00000117/00000003/00188458">http://www.ingentaconnect.com/content/klu/synt/1998/00000117/00000003/00188458</a><br></div></div>
</div><!--entry-->

<div id='_656_entry' class='entry'><span ><span class='name'>Smolensky, Paul</span> (1991). Connectionism, constituency and the language of thought.</span> In Barry M. Loewer &amp; Georges Rey (eds.), <em>Meaning in Mind: Fodor and His Critics</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8595831336166542798'>Cited by 68</a> | <span class='ll' onclick='$("_656_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20constituency%20and%20the%20language%20of%20thought+author%3ASmolensky&amp;btnG=Search'>Google</a>)</span><div id='_656_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism can do compositionality its own way, including both weak compositionality (with context effects) or strong compositionality (via tensor products).</div></div>
</div><!--entry-->

<div id='_657_entry' class='entry'><span ><span class='name'>Smolensky, Paul</span> (1995). Constituent structure and explanation in an integrated connectionist/symbolic cognitive architecture.</span> In C. Macdonald (ed.), <em>Connectionism: Debates on Psychological Explanation</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3683446024781777217'>Cited by 51</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Constituent%20structure%20and%20explanation%20in%20an%20integrated%20connectionist%2Fsymbolic%20cognitive%20architecture+author%3ASmolensky&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_658_entry' class='entry'><span ><span class='name'>Smolensky, Paul</span> (1987). The constituent structure of connectionist mental states.</span> <span class='pub_name'>Southern Journal of Philosophy Supplement</span> 26:137-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2223297261894978641'>Cited by 2</a> | <span class='ll' onclick='$("_658_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20constituent%20structure%20of%20connectionist%20mental%20states+author%3ASmolensky&amp;btnG=Search'>Google</a>)</span><div id='_658_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>F&P ignore distributed representation and interaction effects.</div></div>
</div><!--entry-->

<div id='_659_entry' class='entry'><span ><span class='name'>Smolensky, Paul</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("SMOTPV",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=102425'>Tensor product variable binding and the representation of symbolic structures in connectionist systems.</a></span> <span class='pub_name'>Artificial Intelligence</span> 46:159-216. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15569472403192975236'>Cited by 335</a> | <span class='ll' onclick='$("_659_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Tensor%20product%20variable%20binding%20and%20the%20representation%20of%20symbolic%20structures%20in%20connectionist%20systems+author%3ASmolensky&amp;btnG=Search'>Google</a> | <a href='javascript:show("_659_links")'>More links</a>)</span><div id='_659_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Develops a connectionist architecture that represents compositional structures as tensor products of distributed representations.</div></div>
<div id='_659_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SMOTPV",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2470919CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2470919CI</a><br></div></div>
</div><!--entry-->

<div id='_660_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("VANCAC-2",this.href,0);return true;' href='http://www.leaonline.com/doi/abs/10.1207/s15516709cog1403_2'>Compositionality: A connectionist variation on a classical theme.</a></span> <span class='pub_name'>Cognitive Science</span> 14:355-84. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7388824618995137153'>Cited by 187</a> | <span class='ll' onclick='$("_660_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Compositionality+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_660_links")'>More links</a>)</span><div id='_660_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism can do compositionality functionally. All one needs is the right functional relation between representations; physical concatenation is not necessary.</div></div>
<div id='_660_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANCAC-2",this.href,0);return true;' href="http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog1403_2">http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog1403_2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANCAC-2",this.href,0);return true;' href="http://www.cogsci.rpi.edu/CSJarchive/1990v14/i03/p0355p0384/MAIN.PDF">http://www.cogsci.rpi.edu/CSJarchive/1990v14/i03/p0355p0384/MAIN.PDF</a><br></div></div>
</div><!--entry-->

<div id='_661_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("VANCCM",this.href,0);return true;' href='http://citeseer.ist.psu.edu/326140.html'>Can connectionist models exhibit non-classical structure sensitivity?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20connectionist%20models%20exhibit%20non-classical%20structure%20sensitivity%3F+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_661_links")'>More links</a>)</span><div id='_661_abstract' class='extra' style='font-size:12px;'>Abstract: Department of Computer Science Philosophy Program, Research School of Social Sciences University of SkÃ¶vde, S-54128, SWEDEN Australian National University, Canberra ACT 0200</div>
<div id='_661_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANCCM",this.href,0);return true;' href="http://citeseer.ist.psu.edu/niklasson94can.html">http://citeseer.ist.psu.edu/niklasson94can.html</a><br></div></div>
</div><!--entry-->

<div id='_662_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1991). Classical questions, radical answers.</span> In Terence E. Horgan &amp; John L. Tienson (eds.), <em>Connectionism and the Philosophy of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12105308261402098305'>Cited by 20</a> | <span class='ll' onclick='$("_662_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Classical%20questions%2C%20radical%20answers+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span><div id='_662_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On connectionism as a Kuhnian paradigm shift in cognitive science, with emphasis on the implications of functional compositionality and distributed representations.</div></div>
</div><!--entry-->

<div id='_663_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("VANOBS",this.href,0);return true;' href='http://citeseer.ist.psu.edu/362575.html'>On being systematically connectionist.</a></span> <span class='pub_name'>Mind and Language</span> 9:288-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2651083367509882229'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20being%20systematically%20connectionist+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_663_links")'>More links</a>)</span><div id='_663_abstract' class='extra' style='font-size:12px;'>Abstract: In 1988 Fodor and Pylyshyn issued a challenge to the newly-popular connectionism: explain the systematicity of cognition without merely implementing a so-called classical architecture. Since that time quite a number of connectionist models have been put forward, either by their designers or by others, as in some measure demonstrating that the challenge can be met (e.g., Pollack, 1988, 1990; Smolensky, 1990; Chalmers, 1990; Niklasson and Sharkey, 1992; Brousse, 1993). Unfortu- nately, it has generally been unclear whether these models actually do have this implication (see, for instance, the extensive philosophical debate in Smolensky, 1988; Fodor and McLaughlin, 1990; van Gelder, 1990, 1991; McLaughlin, 1993a, 1993b; Clark, 1993). Indeed, we know of no major supporter of classical orthodoxy who has felt compelled, by connectionist models and argu- ments, to concede in print that connectionists have in fact delivered a non-classical explanation of systematicity</div>
<div id='_663_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANOBS",this.href,0);return true;' href="http://citeseer.ist.psu.edu/niklasson94being.html">http://citeseer.ist.psu.edu/niklasson94being.html</a><br></div></div>
</div><!--entry-->

<div id='_664_entry' class='entry'><span ><span class='name'>Waskan, Jonathan A.</span> &amp; <span class='name'>Bechtel, William P.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("WASDIC",this.href,0);return true;' href='http://mechanism.ucsd.edu/~bill/research/HORGAN.pdf'>Directions in connectionist research: Tractable computations without syntactically structured representations.</a></span> <span class='pub_name'>Metaphilosophy</span> 28 (1-2):31-62. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3332691633404787235'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Directions%20in%20connectionist%20research+author%3AWaskan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_664_links")'>More links</a>)</span><div id='_664_abstract' class='extra' style='font-size:12px;'>Abstract: <b>Figure 1</b>: A pr ototyp ical exa mple of a three-layer feed forward network, used by Plunkett and M archm an (1 991 ) to simulate learning the past-tense of En glish verbs. The inpu t units encode representations of the three phonemes of the present tense of the artificial words used in this simulation. Th e netwo rk is trained to produce a representation of the phonemes employed in the past tense form and the suffix (/d/, /ed/, or /t/) used on regular verbs. To run the network, each input unit is assigned an activation value o f 0 or 1 , dep ending on whethe r the featu re is present or not. Eac h input unit is conne cted to each of the 30 hidden units by a we ighted conn ection and p rovid es an inp ut to each hidden unit equal to the product of the input unit's activation and the weight. Each hidd en unit's activation is then determined by summing ov er the va lues co ming fro m each inp ut unit to deter mine a netinput, and then applying a non-linear function (e.g., the logistic function 1/(1+e<sup>netinput</sup>). Th is whole proced ure is</div>
<div id='_664_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WASDIC",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1467-9973.00040">http://www.blackwell-synergy.com/links/doi/10.1111/1467-9973.00040</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WASDIC",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1467-9973.00040">http://www.blackwell-synergy.com/doi/abs/10.1111/1467-9973.00040</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WASDIC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/F0020001/art00002">http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/F0020001/art00002</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WASDIC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/f0020001">http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/f0020001</a><br></div></div>
</div><!--entry-->

<div id='_665_entry' class='entry'><span ><span class='name'>Young, Robert M.</span> (1970). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("YOUMBA",this.href,0);return true;' href='http://human-nature.com/mba/chap2.html'>Mind, Brain and Adaptation.</a></span></em></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16543717498424214651'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%2C%20Brain%20and%20Adaptation+author%3AYoung&amp;btnG=Search'>Google</a> | <a href='javascript:show("_665_links")'>More links</a>)</span>
<div id='_665_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("YOUMBA",this.href,0);return true;' href="http://human-nature.com/mba/mba1.html ">http://human-nature.com/mba/mba1.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("YOUMBA",this.href,0);return true;' href="http://human-nature.com/mba/chap1.html">http://human-nature.com/mba/chap1.html</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.3b'></a><a name=''></a><span class='myh3'>6.3b Representation in Connectionism</span></p>

<div id='cat_6.3b' class='cat_content'>
<div id='__new_entries_6.3b__'></div><div id='__new_entry_6.3b__' class='entry'></div>
<div id='_666_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("BECNDI",this.href,0);return true;' href='http://citeseer.ist.psu.edu/107226.html'>Natural deduction in connectionist systems.</a></span> <span class='pub_name'>Synthese</span> 101 (3):433-463. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18425094242001200422'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Natural%20deduction%20in%20connectionist%20systems+author%3ABechtel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_666_links")'>More links</a>)</span><div id='_666_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The relation between logic and thought has long been controversial, but has recently influenced theorizing about the nature of mental processes in cognitive science. One prominent tradition argues that to explain the systematicity of thought we must posit syntactically structured representations inside the cognitive system which can be operated upon by structure sensitive rules similar to those employed in systems of natural deduction. I have argued elsewhere that the systematicity of human thought might better be explained as resulting from the fact that we have learned natural languages which are themselves syntactically structured. According to this view, symbols of natural language are external to the cognitive processing system and what the cognitive system must learn to do is produce and comprehend such symbols. In this paper I pursue that idea by arguing that ability in natural deduction itself may rely on pattern recognition abilities that enable us to operate on external symbols rather than encodings of rules that might be applied to internal representations. To support this suggestion, I present a series of experiments with connectionist networks that have been trained to construct simple natural deductions in sentential logic. These networks not only succeed in reconstructing the derivations on which they have been trained, but in constructing new derivations that are only similar to the ones on which they have been trained</div>
<div id='_666_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECNDI",this.href,0);return true;' href="http://citeseer.ist.psu.edu/bechtel94natural.html">http://citeseer.ist.psu.edu/bechtel94natural.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECNDI",this.href,0);return true;' href="http://www.blutner.de/NeuralNets/Texts/DERIVATI.pdf">http://www.blutner.de/NeuralNets/Texts/DERIVATI.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECNDI",this.href,0);return true;' href="http://mechanism.ucsd.edu/~bill/research/DERIVATI.pdf">http://mechanism.ucsd.edu/~bill/research/DERIVATI.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECNDI",this.href,0);return true;' href="http://www.springerlink.com/content/q71158t2342jl517/fulltext.pdf">http://www.springerlink.com/content/q71158t2342jl517/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECNDI",this.href,0);return true;' href="http://www.springerlink.com/index/Q71158T2342JL517.pdf">http://www.springerlink.com/index/Q71158T2342JL517.pdf</a><br></div></div>
</div><!--entry-->

<div id='_667_entry' class='entry'><span ><span class='name'>Butler, Keith</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("BUTRAC",this.href,0);return true;' href='http://www.springerlink.com/content/r347125074346147/fulltext.pdf'>Representation and computation in a deflationary assessment of connectionist cognitive science.</a></span> <span class='pub_name'>Synthese</span> 104 (1):71-97. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representation%20and%20computation%20in%20a%20deflationary%20assessment%20of%20connectionist%20cognitive%20science+author%3AButler&amp;btnG=Search'>Google</a> | <a href='javascript:show("_667_links")'>More links</a>)</span><div id='_667_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Connectionism provides hope for unifying work in neuroscience, computer science, and cognitive psychology. This promise has met with some resistance from Classical Computionalists, which may have inspired Connectionists to retaliate with bold, inflationary claims on behalf of Connectionist models. This paper demonstrates, by examining three intimately connected issues, that these inflationary claims made on behalf of Connectionism are wrong. This should not be construed as an attack on Connectionism, however, since the inflated claims made on its behalf have the look of cures for which there are no ailments. There is nothing wrong with Connectionism for its failure to solve illusory problems</div>
<div id='_667_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BUTRAC",this.href,0);return true;' href="http://www.springerlink.com/index/R347125074346147.pdf">http://www.springerlink.com/index/R347125074346147.pdf</a><br></div></div>
</div><!--entry-->

<div id='_668_entry' class='entry'><span ><span class='name'>Calvo GarzÃ³n, Francisco</span> (2000). A connectionist defence of the inscrutability thesis.</span> <span class='pub_name'>Mind and Language</span> 15 (5):465-480. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20connectionist%20defence%20of%20the%20inscrutability%20thesis+author%3ACalvo%20Garz%C3%B3n&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_669_entry' class='entry'><span ><span class='name'>Calvo GarzÃ³n, Francisco</span> (2003). Connectionist semantics and the collateral information challenge.</span> <span class='pub_name'>Mind and Language</span> 18 (1):77-94. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20semantics%20and%20the%20collateral%20information%20challenge+author%3ACalvo%20Garz%C3%B3n&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_670_entry' class='entry'><span ><span class='name'>Calvo GarzÃ³n, Francisco</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("CALSSS",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a713690428~fulltext=713240930'>State space semantics and conceptual similarity: Reply to Churchland.</a></span> <span class='pub_name'>Philosophical Psychology</span> 13 (1):77-95. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=State%20space%20semantics%20and%20conceptual%20similarity+author%3ACalvo%20Garz%C3%B3n&amp;btnG=Search'>Google</a>)</span><div id='_670_abstract' class='extra' style='font-size:12px;'>Abstract: Jerry Fodor and Ernest Lepore [(1992) Holism: a shopper's guide, Oxford: Blackwell; (1996) in R. McCauley (Ed.) The Churchlands and their critics , Cambridge: Blackwell] have launched a powerful attack against Paul Churchland's connectionist theory of semantics--also known as state space semantics. In one part of their attack, Fodor and Lepore argue that the architectural and functional idiosyncrasies of connectionist networks preclude us from articulating a notion of conceptual similarity applicable to state space semantics. Aarre Laakso and Gary Cottrell [(1998) in M. A. Gernsbacher & S. Derry (Eds) Proceedings of the 20th Annual Conference of the Cognitive Science Society, Mahway, NJ: Erlbaum; Philosophical Psychology ] 13, 47-76 have recently run a number of simulations on simple feedforward networks and applied a mathematical technique for measuring conceptual similarity in the representational spaces of those networks. Laakso and Cottrell contend that their results decisively refute Fodor and Lepore's criticisms. Paul Churchland [(1998) Journal of Philosophy, 95, 5-32 ] goes further. He uses Laakso and Cottrell's neurosimulations to argue that connectionism does furnish us with all we need to construct a robust theory of semantics and a robust theory of translation. In this paper I shall argue that whereas Laakso and Cottrell's neurocomputational results may provide us with a rebuttal of Fodor and Lepore's argument, Churchland's conclusion is far too optimistic. In particular, I shall try to show that connectionist modelling does not provide any objective criterion for achieving a one-to-one accurate translational mapping across networks</div>
</div><!--entry-->

<div id='_671_entry' class='entry'><span ><span class='name'>Cilliers, F. P.</span> (1991). Rules and relations: Some connectionist implications for cognitive science and language.</span> <span class='pub_name'>South African Journal of Philosophy</span> 49 (May):49-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17584635711704127287'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rules%20and%20relations+author%3ACilliers&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_672_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1993). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("CLAAEC",this.href,0);return true;' href='http://books.google.com/books?id=G4fBLKAh-IUC&amp;printsec=front_cover'>Associative Engines: Connectionism, Concepts, and Representational Change.</a></span></em></span> MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12816891728303846819'>Cited by 222</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Associative%20Engines+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_672_links")'>More links</a>)</span><div id='_672_abstract' class='extra' style='font-size:12px;'>Abstract: As Ruben notes, the macrostrategy can allow that the distinction may also be 
drawn at some micro level, but it insists that descent to the micro level is ...</div>
<div id='_672_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAAEC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=164767">http://portal.acm.org/citation.cfm?id=164767</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAAEC",this.href,0);return true;' href="http://www.reiters.com/index.cgi?ISBN=0262032104&amp;f=p">http://www.reiters.com/index.cgi?ISBN=0262032104&f=p</a><br></div></div>
</div><!--entry-->

<div id='_673_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("CLACNC",this.href,0);return true;' href='http://cogslib.informatics.scitech.susx.ac.uk/csr_abs.php?type=csrp&amp;num=143&amp;id=7504'>Connectionism, nonconceptual content, and representational redescription.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_673_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20nonconceptual%20content%2C%20and%20representational%20redescription+author%3AClark&amp;btnG=Search'>Google</a>)</span><div id='_673_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On some troubles connectionism has with higher-order knowledge. Contrasts Cussins, Karmiloff-Smith on development. Subsymbols without symbols are blind.</div></div>
</div><!--entry-->

<div id='_674_entry' class='entry'><span ><span class='name'>Clark, Andy</span> &amp; <span class='name'>Karmiloff-Smith, Annette</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("CLATCI",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1993.tb00299.x'>The cognizer's innards: A psychological and philosophical perspective on the development of thought.</a></span> <span class='pub_name'>Mind and Language</span> 8 (4):487-519. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1454360912073231158'>Cited by 196</a> | <span class='ll' onclick='$("_674_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20cognizer%27s%20innards+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_674_links")'>More links</a>)</span><div id='_674_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the importance of representational redescription, and on the limits of connectionist networks in cross-domain knowledge transfer. What does a true believer need, above behavior: conceptual combination, real-world fluency?</div></div>
<div id='_674_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATCI",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119302072/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119302072/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_675_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("CUMTRO",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=UckGbfzYkkgC&amp;oi=fnd&amp;pg=PA91&amp;dq=The+role+of+representation+in+connectionist+explanation+of+cognitive+capacities+Cummins&amp;ots=8HpVqVEZBg&amp;sig=G12kejRYm5VsEF0y30Rd0o_2JcU'>The role of representation in connectionist explanation of cognitive capacities.</a></span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13885913499557466628'>Cited by 8</a> | <span class='ll' onclick='$("_675_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20role%20of%20representation%20in%20connectionist%20explanation%20of%20cognitive%20capacities+author%3ACummins&amp;btnG=Search'>Google</a>)</span><div id='_675_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism isn't really radical. There's no new concept of representation or of learning, and cognition can still be the manipulation of semantically structured representations.</div></div>
</div><!--entry-->

<div id='_676_entry' class='entry'><span ><span class='name'>Cussins, Adrian</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("CUSTCC",this.href,0);return true;' href='http://www.haecceia.com/FILES/c3_kings_london.htm'>The connectionist construction of concepts.</a></span> In Margaret A. Boden (ed.), <em>The Philosophy of AI</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8841178135411931769'>Cited by 107</a> | <span class='ll' onclick='$("_676_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20connectionist%20construction%20of%20concepts+author%3ACussins&amp;btnG=Search'>Google</a>)</span><div id='_676_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism builds up concepts from the nonconceptual level. From nonconceptual content (e.g. perceptual experiences) to the emergence of objectivity.</div></div><div id='_676_abstract' class='extra' style='font-size:12px;'>Abstract: The character of computational modelling of cognition depends on an underlying theory of representation. Classical cognitive science has exploited the syntax/semantics theory of representation that derives from logic. But this has had the consequence that the kind of psychological explanation supported by classical cognitive science is <blockquote> _conceptualist_: </blockquote> psychological phenomena are modelled in terms of relations that hold between concepts, and between the sensors/effectors and concepts. This kind of explanation is inappropriate for the Proper Treatment of Connectionism (Smolensky 1988)</div>
</div><!--entry-->

<div id='_677_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("ELISWS",this.href,0);return true;' href='http://www.arts.uwaterloo.ca/~celiasmi/Papers/SSPP.html'>Structure without symbols: Providing a distributed account of high-level cognition.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Structure%20without%20symbols+author%3AEliasmith&amp;btnG=Search'>Google</a>)</span><div id='_677_abstract' class='extra' style='font-size:12px;'>Abstract: There has been a long-standing debate between symbolicists and connectionists concerning the nature of representation used by human cognizers. In general, symbolicist commitments have allowed them to provide superior models of high-level cognitive function. In contrast, connectionist distributed representations are preferred for providing a description of low-level cognition. The development of Holographic Reduced Representations (HRRs) has opened the possibility of one representational medium unifying both low-level and high-level descriptions of cognition. This paper describes the relative strengths and weaknesses of symbolic and distributed representations. HRRs are shown to capture the important strengths of both types of representation. These properties of HRRs allow a rebuttal of Fodor and McLaughlin's (1990) criticism that distributed representations are not adequately structure sensitive to provide a full account of human cognition</div>
</div><!--entry-->

<div id='_678_entry' class='entry'><span ><span class='name'>Garzon, Francisco Calvo</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("GARACD",this.href,0);return true;' href='http://www.blackwell-synergy.com/links/doi/10.1111/1468-0017.00145/abs/'>A connectionist defence of the inscrutability thesis.</a></span> <span class='pub_name'>Mind and Language</span> 15 (5):465-480. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8685876861342545974'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20connectionist%20defence%20of%20the%20inscrutability%20thesis+author%3AGarzon&amp;btnG=Search'>Google</a> | <a href='javascript:show("_678_links")'>More links</a>)</span>
<div id='_678_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARACD",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119041838/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119041838/PDFSTART</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARACD",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00145">http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00145</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARACD",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/2000/00000015/00000005/art00145">http://www.ingentaconnect.com/content/bpl/mila/2000/00000015/00000005/art00145</a><br></div></div>
</div><!--entry-->

<div id='_679_entry' class='entry'><span ><span class='name'>Garzon, Francisco Calvo</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("GARSSS",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a713690428~fulltext=713240930'>State space semantics and conceptual similarity: Reply to Churchland.</a></span> <span class='pub_name'>Philosophical Psychology</span> 13 (1):77-96. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6763359036685755029'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=State%20space%20semantics%20and%20conceptual%20similarity+author%3AGarzon&amp;btnG=Search'>Google</a> | <a href='javascript:show("_679_links")'>More links</a>)</span><div id='_679_abstract' class='extra' style='font-size:12px;'>Abstract: Jerry Fodor and Ernest Lepore [(1992) Holism: a shopper's guide, Oxford: Blackwell; (1996) in R. McCauley (Ed.) The Churchlands and their critics , Cambridge: Blackwell] have launched a powerful attack against Paul Churchland's connectionist theory of semantics--also known as state space semantics. In one part of their attack, Fodor and Lepore argue that the architectural and functional idiosyncrasies of connectionist networks preclude us from articulating a notion of conceptual similarity applicable to state space semantics. Aarre Laakso and Gary Cottrell [(1998) in M. A. Gernsbacher & S. Derry (Eds) Proceedings of the 20th Annual Conference of the Cognitive Science Society, Mahway, NJ: Erlbaum; Philosophical Psychology ] 13, 47-76 have recently run a number of simulations on simple feedforward networks and applied a mathematical technique for measuring conceptual similarity in the representational spaces of those networks. Laakso and Cottrell contend that their results decisively refute Fodor and Lepore's criticisms. Paul Churchland [(1998) Journal of Philosophy, 95, 5-32 ] goes further. He uses Laakso and Cottrell's neurosimulations to argue that connectionism does furnish us with all we need to construct a robust theory of semantics and a robust theory of translation. In this paper I shall argue that whereas Laakso and Cottrell's neurocomputational results may provide us with a rebuttal of Fodor and Lepore's argument, Churchland's conclusion is far too optimistic. In particular, I shall try to show that connectionist modelling does not provide any objective criterion for achieving a one-to-one accurate translational mapping across networks</div>
<div id='_679_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARSSS",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/U2D6G36BN8KQEMXH.pdf">http://taylorandfrancis.metapress.com/index/U2D6G36BN8KQEMXH.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARSSS",this.href,0);return true;' href="http://www.informaworld.com/index/U2D6G36BN8KQEMXH.pdf">http://www.informaworld.com/index/U2D6G36BN8KQEMXH.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARSSS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000001/art00003">http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000001/art00003</a><br></div></div>
</div><!--entry-->

<div id='_680_entry' class='entry'><span ><span class='name'>Gauker, Christopher</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("GAUACO",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.2007.00311.x'>A critique of the similarity space theory of concepts.</a></span> <span class='pub_name'>Mind and Language</span> 22 (4):317&#8211;345. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20critique%20of%20the%20similarity%20space%20theory%20of%20concepts+author%3AGauker&amp;btnG=Search'>Google</a> | <a href='javascript:show("_680_links")'>More links</a>)</span><div id='_680_abstract' class='extra' style='font-size:12px;'>Abstract:  A similarity space is a hyperspace in which the dimensions represent various dimensions on which objects may differ. The similarity space theory of concepts is the thesis that concepts are regions of similarity spaces that are somehow realized in the brain. Proponents of such a theory of concepts include Paul Churchland and Peter GÃ¤rdenfors. This paper argues that the similarity space theory of concepts is mistaken because regions of similarity spaces cannot serve as the components of judgments. It emerges that although similarity spaces cannot model concepts, they may model a kind of nonconceptual representation</div>
<div id='_680_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GAUACO",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/117998149/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/117998149/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_681_entry' class='entry'><span ><span class='name'>Goschke, T.</span> &amp; <span class='name'>Koppelberg, Dirk</span> (1990). Connectionism and the semantic content of internal representation.</span> <span class='pub_name'>Review of International Philosophy</span> 44 (172):87-103. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20semantic%20content%20of%20internal%20representation+author%3AGoschke&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_682_entry' class='entry'><span ><span class='name'>Goschke, T.</span> &amp; <span class='name'>Koppelberg, Dirk</span> (1991). The concept of representation and the representation of concepts in connectionist models.</span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17734830999845545692'>Cited by 17</a> | <span class='ll' onclick='$("_682_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20concept%20of%20representation%20and%20the%20representation%20of%20concepts%20in%20connectionist%20models+author%3AGoschke&amp;btnG=Search'>Google</a>)</span><div id='_682_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On correlational semantics and context-dependent representations.</div></div>
</div><!--entry-->

<div id='_683_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("HADOTP",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=976702.976735'>On the proper treatment of semantic systematicity.</a></span> <span class='pub_name'>Minds and Machines</span> 14 (2):145-172. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13211904477637387444'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20proper%20treatment%20of%20semantic%20systematicity+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_683_links")'>More links</a>)</span><div id='_683_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The past decade has witnessed the emergence of a novel stance on semantic representation, and its relationship to context sensitivity. Connectionist-minded philosophers, including Clark and van Gelder, have espoused the merits of viewing hidden-layer, context-sensitive representations as possessing semantic content, where this content is partially revealed via the representations'' position in vector space. In recent work, BodÃ©n and Niklasson have incorporated a variant of this view of semantics within their conception of semantic systematicity. Moreover, BodÃ©n and Niklasson contend that they have produced experimental results which not only satisfy a kind of context-based, semantic systematicity, but which, to the degree that reality permits, effectively deals with challenges posed by Fodor and Pylyshyn (1988), and Hadley (1994a). The latter challenge involved well-defined criteria for strong semantic systematicity. This paper examines the relevant claims and experiments of BodÃ©n and Niklasson. It is argued that their case fatally involves two fallacies of equivocation; one concerning ''semantic content'' and the other concerning ''novel test sentences''. In addition, it is argued that their ultimate construal of context sensitive semantics contains serious confusions. These confusions are also found in certain publications dealing with "latent semantic analysis". Thus, criticisms presented here have relevance beyond the work of BodÃ©n and Niklasson</div>
<div id='_683_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADOTP",this.href,0);return true;' href="http://www.springerlink.com/content/p4312417q27100p0/fulltext.pdf">http://www.springerlink.com/content/p4312417q27100p0/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADOTP",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5142070&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5142070&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADOTP",this.href,0);return true;' href="http://www.springerlink.com/index/P4312417Q27100P0.pdf">http://www.springerlink.com/index/P4312417Q27100P0.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADOTP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000002/05142070">http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000002/05142070</a><br></div></div>
</div><!--entry-->

<div id='_684_entry' class='entry'><span ><span class='name'>Haselager, W. F. G.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("HASOTP",this.href,0);return true;' href='http://www.nici.ru.nl/~haselag/publications/1999c.pdf'>On the potential of non-classical constituency.</a></span> <span class='pub_name'>Acta Analytica</span> 22 (22):23-42. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9446474541572865228'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20potential%20of%20non-classical%20constituency+author%3AHaselager&amp;btnG=Search'>Google</a> | <a href='javascript:show("_684_links")'>More links</a>)</span>
<div id='_684_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASOTP",this.href,0);return true;' href="http://www.nici.kun.nl/~haselag/publications/1999c.pdf">http://www.nici.kun.nl/~haselag/publications/1999c.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASOTP",this.href,0);return true;' href="http://www.socsci.kun.nl/~haselag/publications/1999c.pdf">http://www.socsci.kun.nl/~haselag/publications/1999c.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASOTP",this.href,0);return true;' href="http://www.nici.ru.nl/~haselag/publications/NonClassConst99.pdf">http://www.nici.ru.nl/~haselag/publications/NonClassConst99.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASOTP",this.href,0);return true;' href="http://www.nici.kun.nl/~haselag/publications/NonClassConst99.pdf">http://www.nici.kun.nl/~haselag/publications/NonClassConst99.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASOTP",this.href,0);return true;' href="http://www.socsci.kun.nl/~haselag/publications/NonClassConst99.pdf">http://www.socsci.kun.nl/~haselag/publications/NonClassConst99.pdf</a><br></div></div>
</div><!--entry-->

<div id='_685_entry' class='entry'><span ><span class='name'>Hatfield, Gary</span> (1991). Representation and rule-instantiation in connectionist systems.</span> In Terence E. Horgan &amp; John L. Tienson (eds.), <em>Connectionism and the Philosophy of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4858899978704404682'>Cited by 11</a> | <span class='ll' onclick='$("_685_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representation%20and%20rule-instantiation%20in%20connectionist%20systems+author%3AHatfield&amp;btnG=Search'>Google</a>)</span><div id='_685_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Some remarks on psychology & physiology. Even connectionism uses psychological concepts.</div></div>
</div><!--entry-->

<div id='_686_entry' class='entry'><span ><span class='name'>Hatfield, Gary</span> (1991). Representation in perception and cognition: Connectionist affordances.</span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17246258575746697728'>Cited by 49</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representation%20in%20perception%20and%20cognition+author%3AHatfield&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_687_entry' class='entry'><span ><span class='name'>Haybron, Daniel M.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596886'>The causal and explanatory role of information stored in connectionist networks.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (3):361-380. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13443447853591335461'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20causal%20and%20explanatory%20role%20of%20information%20stored%20in%20connectionist%20networks+author%3AHaybron&amp;btnG=Search'>Google</a> | <a href='javascript:show("_687_links")'>More links</a>)</span><div id='_687_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In this paper I defend the propriety of explaining the behavior of distributed connectionist networks by appeal to selected data stored therein. In particular, I argue that if there is a problem with such explanations, it is a consequence of the fact that information storage in networks is superpositional, and not because it is distributed. I then develop a ``proto-account'''' of causation for networks, based on an account of Andy Clark''s, that shows even superpositionality does not undermine information-based explanation. Finally, I argue that the resulting explanations are genuinely informative and not vacuous</div>
<div id='_687_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href="http://www.slu.edu/users/users/haybrond/Connectionist information storage.pdf ">http://www.slu.edu/users/users/haybrond/Connectionist information storage.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=536479CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=536479CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href="http://www.springerlink.com/content/content/t061056966k44051/fulltext.pdf">http://www.springerlink.com/content/content/t061056966k44051/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href="http://www.springerlink.com/content/t061056966k44051/fulltext.pdf">http://www.springerlink.com/content/t061056966k44051/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=258827&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=258827&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href="http://www.springerlink.com/index/T061056966K44051.pdf">http://www.springerlink.com/index/T061056966K44051.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYTCA-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000003/00258827">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000003/00258827</a><br></div></div>
</div><!--entry-->

<div id='_688_entry' class='entry'><span ><span class='name'>Laakso, Aarre</span> &amp; <span class='name'>Cottrell, Garrison W.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("LAACAC",this.href,0);return true;' href='http://www245.pair.com/aarre/cv/phipsy.pdf'>Content and cluster analysis: Assessing representational similarity in neural systems.</a></span> <span class='pub_name'>Philosophical Psychology</span> 13 (1):47-76. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2071244828389062225'>Cited by 18</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Content%20and%20cluster%20analysis+author%3ALaakso&amp;btnG=Search'>Google</a> | <a href='javascript:show("_688_links")'>More links</a>)</span><div id='_688_abstract' class='extra' style='font-size:12px;'>Abstract: If connectionism is to be an adequate theory of mind, we must have a theory of representation for neural networks that allows for individual differences in weighting and architecture while preserving sameness, or at least similarity, of content. In this paper we propose a procedure for measuring sameness of content of neural representations. We argue that the correct way to compare neural representations is through analysis of the distances between neural activations, and we present a method for doing so. We then use the technique to demonstrate empirically that different artificial neural networks trained by backpropagation on the same categorization task, even with different representational encodings of the input patterns and different numbers of hidden units, reach states in which representations at the hidden units are similar. We discuss how this work provides a rebuttal to Fodor and Lepore's critique of Paul Churchland's state space semantics</div>
<div id='_688_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://www.laakshmi.com/aarre/cv/phipsy.pdf">http://www.laakshmi.com/aarre/cv/phipsy.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://www.cs.ucsd.edu/groups/guru/docs/laakso2000.pdf">http://www.cs.ucsd.edu/groups/guru/docs/laakso2000.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://www-cse.ucsd.edu/groups/guru/docs/laakso2000.pdf">http://www-cse.ucsd.edu/groups/guru/docs/laakso2000.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://www.cse.ucsd.edu/groups/guru/docs/laakso2000.pdf">http://www.cse.ucsd.edu/groups/guru/docs/laakso2000.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a713690421~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a713690421~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/RY0JBTH3PY9B6GF2.pdf">http://taylorandfrancis.metapress.com/index/RY0JBTH3PY9B6GF2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://www.informaworld.com/index/RY0JBTH3PY9B6GF2.pdf">http://www.informaworld.com/index/RY0JBTH3PY9B6GF2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LAACAC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000001/art00002">http://www.ingentaconnect.com/content/routledg/cphp/2000/00000013/00000001/art00002</a><br></div></div>
</div><!--entry-->

<div id='_689_entry' class='entry'><span ><span class='name'>Lormand, Eric</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("LORCC",this.href,0);return true;' href='http://www-personal.umich.edu/~lormand/phil/cogsci/diss_ch2.htm'>Connectionist content.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20content+author%3ALormand&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_690_entry' class='entry'><span ><span class='name'>Mandik, Pete</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("MANVOR",this.href,0);return true;' href='http://citeseer.ist.psu.edu/528697.html'>Varieties of representation in evolved and embodied neural networks.</a></span> <span class='pub_name'>Biology and Philosophy</span> 18 (1):95-130. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15040654643425519370'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Varieties%20of%20representation%20in%20evolved%20and%20embodied%20neural%20networks+author%3AMandik&amp;btnG=Search'>Google</a> | <a href='javascript:show("_690_links")'>More links</a>)</span><div id='_690_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In this paper I discuss one of the key issuesin the philosophy of neuroscience:neurosemantics. The project of neurosemanticsinvolves explaining what it means for states ofneurons and neural systems to haverepresentational contents. Neurosemantics thusinvolves issues of common concern between thephilosophy of neuroscience and philosophy ofmind. I discuss a problem that arises foraccounts of representational content that Icall ``the economy problem'': the problem ofshowing that a candidate theory of mentalrepresentation can bear the work requiredwithin in the causal economy of a mind and anorganism. My approach in the current paper isto explore this and other key themes inneurosemantics through the use of computermodels of neural networks embodied and evolvedin virtual organisms. The models allow for thelaying bare of the causal economies of entireyet simple artificial organisms so that therelations between the neural bases of, forinstance, representation in perception andmemory can be regarded in the context of anentire organism. On the basis of thesesimulations, I argue for an account ofneurosemantics adequate for the solution of theeconomy problem</div>
<div id='_690_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://citeseer.ist.psu.edu/mandik02varieties.html">http://citeseer.ist.psu.edu/mandik02varieties.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://www.cogs.indiana.edu/cogx/Mandik_var_rep_03.pdf">http://www.cogs.indiana.edu/cogx/Mandik_var_rep_03.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://www.petemandik.com/philosophy/papers/varrep.pdf">http://www.petemandik.com/philosophy/papers/varrep.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://testweb.wpunj.edu/cohss/philosophy/FACULTY/mandik/papers/vreenn.pdf">http://testweb.wpunj.edu/cohss/philosophy/FACULTY/mandik/papers/vreenn.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://www.springerlink.com/content/m8023w0720l50p81/fulltext.pdf">http://www.springerlink.com/content/m8023w0720l50p81/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5109389&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5109389&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://www.springerlink.com/index/M8023W0720L50P81.pdf">http://www.springerlink.com/index/M8023W0720L50P81.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MANVOR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/biph/2003/00000018/00000001/05109389">http://www.ingentaconnect.com/content/klu/biph/2003/00000018/00000001/05109389</a><br></div></div>
</div><!--entry-->

<div id='_691_entry' class='entry'><span ><span class='name'>Markic, Olga</span> (1995). Finding the right level for connectionist representations (a critical note on Ramsey's paper).</span> <span class='pub_name'>Acta Analytica</span> 14 (14):27-35. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Finding%20the%20right%20level%20for%20connectionist%20representations%20%28a%20critical%20note%20on%20Ramsey%27s%20paper%29+author%3AMarkic&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_692_entry' class='entry'><span ><span class='name'>O'Brien, Gerard</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("OBRCAA",this.href,0);return true;' href='http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Connectionism_Analogicity_and_Mental_Content.pdf'>Connectionism, analogicity and mental content.</a></span> <span class='pub_name'>Acta Analytica</span> 22 (22):111-31. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20analogicity%20and%20mental%20content+author%3AO%27Brien&amp;btnG=Search'>Google</a> | <a href='javascript:show("_692_links")'>More links</a>)</span><div id='_692_abstract' class='extra' style='font-size:12px;'>Abstract: In Connectionism and the Philosophy of Psychology, Horgan and Tienson (1996) argue that cognitive processes, pace classicism, are not governed by exceptionless, Ârepresentation-levelÂ rules; they are instead the work of defeasible cognitive tendencies subserved by the non-linear dynamics of the brainÂs neural networks. Many theorists are sympathetic with the dynamical characterisation of connectionism and the general (re)conception of cognition that it affords. But in all the excitement surrounding the connectionist revolution in cognitive science, it has largely gone unnoticed that connectionism adds to the traditional focus on computational processes, a new focus Â one on the vehicles of mental representation, on the entities that carry content through the mind. Indeed, if Horgan and TiensonÂs dynamical characterisation of connectionism is on the right track, then so intimate is the relationship between computational processes and representational vehicles, that connectionist cognitive science is committed to a resemblance theory of mental content</div>
<div id='_692_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRCAA",this.href,0);return true;' href="http://cogprints.org/1675/3/Connectionism_Analogicity_and_Mental_Content.pdf">http://cogprints.org/1675/3/Connectionism_Analogicity_and_Mental_Content.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRCAA",this.href,0);return true;' href="http://cogprints.org/1675/0/Connectionism_Analogicity_and_Mental_Content.pdf">http://cogprints.org/1675/0/Connectionism_Analogicity_and_Mental_Content.pdf</a><br></div></div>
</div><!--entry-->

<div id='_693_entry' class='entry'><span ><span class='name'>O'Brien, Gerard</span> &amp; <span class='name'>Opie, Jonathan</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("OBRNTA",this.href,0);return true;' href='http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Notes_toward_a_structuralist_theory_of_MR.pdf'>Notes toward a structuralist theory of mental representation.</a></span> In Hugh Clapin (ed.), <em>Representation in Mind</em>. Elsevier. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Notes%20toward%20a%20structuralist%20theory%20of%20mental%20representation+author%3AO%27Brien&amp;btnG=Search'>Google</a>)</span><div id='_693_abstract' class='extra' style='font-size:12px;'>Abstract: Any creature that must move around in its environment to find nutrients and mates, in order to survive and reproduce, faces the problem of sensorimotor control. A solution to this problem requires an on-board control mechanism that can shape the creatureâs behaviour so as to render it âappropriateâ to the conditions that obtain. There are at least three ways in which such a control mechanism can work, and Nature has exploited them all. The first and most basic way is for a creature to bump into the things in its environment, and then, depending on what has been encountered, seek to modify its behaviour accordingly. Such an approach is risky, however, since some things in the environment are distinctly unfriendly. A second and better way, therefore, is for a creature to exploit ambient forms of energy that carry information about the distal structure of the environment. This is an improvement on the first method since it enables the creature to respond to the surroundings without actually bumping into anything. Nonetheless, this second method also has its limitations, one of which is that the information conveyed by such ambient energy is often impoverished, ambiguous and intermittent</div>
</div><!--entry-->

<div id='_694_entry' class='entry'><span ><span class='name'>Place, Ullin T.</span> (1989). Toward a connectionist version of the causal theory of reference.</span> <span class='pub_name'>Acta Analytica</span> 4 (5):71-97. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Toward%20a%20connectionist%20version%20of%20the%20causal%20theory%20of%20reference+author%3APlace&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_695_entry' class='entry'><span ><span class='name'>Potrc, Matjaz</span> (1999). Morphological content.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):133-149. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Morphological%20content+author%3APotrc&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_696_entry' class='entry'><span ><span class='name'>Prinz, Jesse J.</span> (2006). Empiricism and state-space semantics.</span> In Brian L Keeley (ed.), <em>Paul Churchland</em>. Cambridge: Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Empiricism%20and%20state-space%20semantics+author%3APrinz&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_697_entry' class='entry'><span ><span class='name'>Ramsey, William</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("RAMDCR",this.href,0);return true;' href='http://firstsearch.oclc.org/fsip?sici=0268-1064(19970301)12:1&lt;34:DCRETE&gt;2.0.TX;2-S&amp;format=PDF&amp;gsid=03aef2acc24645555b960c6667c5aa36c989677b9c7266beb1f26f54ccea23411494880763d29ddd1c0992469160e7422b69cdfa1e856495a918b58b4a259527e254e1b9ffed308c'>Do connectionist representations earn their explanatory keep?</a></span> <span class='pub_name'>Mind and Language</span> 12 (1):34-66. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13311794159186665547'>Cited by 16</a> | <span class='ll' onclick='$("_697_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Do%20connectionist%20representations%20earn%20their%20explanatory%20keep%3F+author%3ARamsey&amp;btnG=Search'>Google</a> | <a href='javascript:show("_697_links")'>More links</a>)</span><div id='_697_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that talk of representations has no explanatory role in connectionist theory, and can be discarded. It can't be understood along the lines of the teleo-informational or classical frameworks.</div></div>
<div id='_697_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAMDCR",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00035">http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00035</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAMDCR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000001/art00035">http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000001/art00035</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAMDCR",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000001/art00003">http://www.ingentaconnect.com/content/bpl/mila/1997/00000012/00000001/art00003</a><br></div></div>
</div><!--entry-->

<div id='_698_entry' class='entry'><span ><span class='name'>Ramsey, William</span> (1995). Rethinking distributed representation.</span> <span class='pub_name'>Acta Analytica</span> 10 (14):9-25. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4405194978383632082'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rethinking%20distributed%20representation+author%3ARamsey&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_699_entry' class='entry'><span ><span class='name'>Schopman, Joop</span> &amp; <span class='name'>Shawky, A.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("SCHROT",this.href,0);return true;' href='http://books.google.com/books?id=TPbKHAAACAAJ&amp;dq=andy+clark+millican'>Remarks on the impact of connectionism on our thinking about concepts.</a></span> In Peter Millican &amp; A. Clark (eds.), <em>Connectionism, Concepts and Folk Psychology</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Remarks%20on%20the%20impact%20of%20connectionism%20on%20our%20thinking%20about%20concepts+author%3ASchopman&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_700_entry' class='entry'><span ><span class='name'>Shea, Nicholas</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("SHECAI",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.2007.00308.x'>Content and its vehicles in connectionist systems.</a></span> <span class='pub_name'>Mind and Language</span> 22 (3):246â269. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Content%20and%20its%20vehicles%20in%20connectionist%20systems+author%3AShea&amp;btnG=Search'>Google</a> | <a href='javascript:show("_700_links")'>More links</a>)</span><div id='_700_abstract' class='extra' style='font-size:12px;'>Abstract: This paper advocates explicitness about the type of entity to be considered as content- bearing in connectionist systems; it makes a positive proposal about how vehicles of content should be individuated; and it deploys that proposal to argue in favour of representation in connectionist systems. The proposal is that the vehicles of content in some connectionist systems are clusters in the state space of a hidden layer. Attributing content to such vehicles is required to vindicate the standard explanation for some classificatory networksâ ability to generalise to novel samples their correct classification of the samples on which they were trained</div>
<div id='_700_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHECAI",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/117998145/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/117998145/PDFSTART</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHECAI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/2007/00000022/00000003/art00002">http://www.ingentaconnect.com/content/bpl/mila/2007/00000022/00000003/art00002</a><br></div></div>
</div><!--entry-->

<div id='_701_entry' class='entry'><span ><span class='name'>Stone, Tony</span> &amp; <span class='name'>Davies, Martin</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("STOAPA",this.href,0);return true;' href='http://philrsss.anu.edu.au/~mdavies/papers/aut.pdf'>Autonomous psychology and the moderate neuron doctrine.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 22 (5):849-850. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9627959549071240677'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Autonomous%20psychology%20and%20the%20moderate%20neuron%20doctrine+author%3AStone&amp;btnG=Search'>Google</a> | <a href='javascript:show("_701_links")'>More links</a>)</span><div id='_701_abstract' class='extra' style='font-size:12px;'>Abstract: _Two notions of autonomy are distinguished. The respective_ _denials that psychology is autonomous from neurobiology are neuron_ _doctrines, moderate and radical. According to the moderate neuron_ _doctrine, inter-disciplinary interaction need not aim at reduction. It is_ _proposed that it is more plausible that there is slippage from the_ _moderate to the radical neuron doctrine than that there is confusion_ _between the radical neuron doctrine and the trivial version._</div>
<div id='_701_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STOAPA",this.href,0);return true;' href="http://philrsss.anu.edu.au/~mdavies/papers/aut.pdf ">http://philrsss.anu.edu.au/~mdavies/papers/aut.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STOAPA",this.href,0);return true;' href="http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=31694&amp;jid=BBS&amp;volumeId=22&amp;issueId=05&amp;aid=31693">http://journals.cambridge.org/action/displayFulltext?type=1&fid=31694&jid=BBS&volumeId=22&issueId=05&aid=31693</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STOAPA",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X99452197 ">http://www.journals.cambridge.org/abstract_S0140525X99452197 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STOAPA",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X99452197">http://www.journals.cambridge.org/abstract_S0140525X99452197</a><br></div></div>
</div><!--entry-->

<div id='_702_entry' class='entry'><span ><span class='name'>Tiffany, Evan</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("TIFSSD",this.href,0);return true;' href='http://dialnet.unirioja.es/servlet/articulo?codigo=463979'>Semantics San Diego style.</a></span> <span class='pub_name'>Journal of Philosophy</span> 96 (8):416-429. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16724998322360315870'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Semantics%20San%20Diego%20style+author%3ATiffany&amp;btnG=Search'>Google</a> | <a href='javascript:show("_702_links")'>More links</a>)</span>
<div id='_702_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TIFSSD",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0022-362X(199908)96:8&lt;416:SSDS&gt;2.0.CO;2-N">http://links.jstor.org/sici?sici=0022-362X(199908)96:8<416:SSDS>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TIFSSD",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(199908)96:8&lt;416:SSDS&gt;2.0.CO;2-N">http://www.jstor.org/sici?sici=0022-362X(199908)96:8<416:SSDS>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TIFSSD",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2564630.pdf">http://www.jstor.org/stable/pdfplus/2564630.pdf</a><br></div></div>
</div><!--entry-->

<div id='_703_entry' class='entry'><span ><span class='name'>Tye, Michael</span> (1987). Representation in pictorialism and connectionism.</span> <span class='pub_name'>Southern Journal of Philosophy Supplement</span> 26:163-184. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_703_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representation%20in%20pictorialism%20and%20connectionism+author%3ATye&amp;btnG=Search'>Google</a>)</span><div id='_703_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Pictorialism isn't compatible with language of thought, but connectionism might be.</div></div>
</div><!--entry-->

<div id='_704_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("VANDVL",this.href,0);return true;' href='http://citeseer.ist.psu.edu/293265.html'>Distributed vs. local representation.</a></span> In R.A. Wilson &amp; F.C. Keil (eds.), <em>The MIT Encyclopedia of the Cognitive Sciences</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6593779008134595216'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Distributed%20vs.%20local%20representation+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span><div id='_704_abstract' class='extra' style='font-size:12px;'>Abstract: been to define various notions of distribution in terms of represented by one and the same distributed pattern (Mur- structures of correspondence between the represented items dock 1979). For example, it is standard in feedforward and the representational resources (e.g., van Gelder 1992). connectionist networks for one and the same set of synap- This approach may be misguided; the essence of this alter- tic weights to represent many associations between input native category of representation might be some other prop- and output. erty entirely. For example, Haugeland (1991) has suggested â¢ Equipotentiality In some cases, an item is represented by</div>
</div><!--entry-->

<div id='_705_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("VANWDR",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=645762.666630'>Why distributed representation is inherently non-symbolic.</a></span> In G. Dorffner (ed.), <em>Konnektionismus in Artificial Intelligence Und Kognitionsforschung</em>. Berlin: Springer-Verlag. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15714026809154933458'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20distributed%20representation%20is%20inherently%20non-symbolic+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span><div id='_705_abstract' class='extra' style='font-size:12px;'>Abstract: There are many conflicting views concerning the nature of distributed representation, its compatibility or otherwise with symbolic representation, and its importance in characterizing the nature of connectionist models and their relationship to more traditional symbolic approaches to understanding cognition. Many have simply assumed that distribution is merely an implementation issue, and that symbolic mechanisms can be designed to take advantage of the virtues of distribution if so desired. Others, meanwhile, see the use of distributed representation as marking a fundamental difference between the two approaches. One reason for this diversity of opinion is the fact that the relevant notions - especially that of</div>
</div><!--entry-->

<div id='_706_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1991). What is the D in PDP?</span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15316108214171109091'>Cited by 65</a> | <span class='ll' onclick='$("_706_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20the%20D%20in%20PDP%3F+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span><div id='_706_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that distributed representation is best analyzed in terms of superposition of representation, not in terms of extendedness.</div></div>
</div><!--entry-->

<div id='_707_entry' class='entry'><span ><span class='name'>Von Eckardt, Barbara</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("VONTEN",this.href,0);return true;' href='http://www3.interscience.wiley.com/cgi-bin/fulltext/118880018/PDFSTART'>The explanatory need for mental representations in cognitive science.</a></span> <span class='pub_name'>Mind and Language</span> 18 (4):427-439. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17401927219697056454'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20explanatory%20need%20for%20mental%20representations%20in%20cognitive%20science+author%3AVon%20Eckardt&amp;btnG=Search'>Google</a> | <a href='javascript:show("_707_links")'>More links</a>)</span><div id='_707_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Ramsey (1997) argues that connectionist representations 'do not earn their explanatory keep'. The aim of this paper is to examine the argument Ramsey gives to support that conclusion. In doing so, I identify two kinds of explanatory needâneed relative to a possible explanation and need relative to a true explanation and argue that internal representations are not needed for either connectionist or nonconnectionist possible explanations but that it is quite likely that they are needed for true explanations. However, to show that the latter is the case requires more than a consideration of the form of explanation involved</div>
<div id='_707_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTEN",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00235">http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00235</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTEN",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/2003/00000018/00000004/art00006">http://www.ingentaconnect.com/content/bpl/mila/2003/00000018/00000004/art00006</a><br></div></div>
</div><!--entry-->

<div id='_708_entry' class='entry'><span ><span class='name'>Waskan, Jonathan A.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("WASACO",this.href,0);return true;' href='http://taylorandfrancis.metapress.com/index/WGXAHC9FUKFKEVME.pdf'>A critique of connectionist semantics.</a></span> <span class='pub_name'>Connection Science</span> 13 (3):277-292. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20critique%20of%20connectionist%20semantics+author%3AWaskan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_708_links")'>More links</a>)</span>
<div id='_708_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WASACO",this.href,0);return true;' href="http://www.informaworld.com/index/WGXAHC9FUKFKEVME.pdf">http://www.informaworld.com/index/WGXAHC9FUKFKEVME.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WASACO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/ccos/2001/00000013/00000003/art00004">http://www.ingentaconnect.com/content/tandf/ccos/2001/00000013/00000003/art00004</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.3c'></a><a name=''></a><span class='myh3'>6.3c Connectionism and Eliminativism</span></p>

<div id='cat_6.3c' class='cat_content'>
<div id='__new_entries_6.3c__'></div><div id='__new_entry_6.3c__' class='entry'></div>
<div id='_709_entry' class='entry'><span ><span class='name'>Bickle, John</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("BICCEA",this.href,0);return true;' href='http://www.springerlink.com/content/pk525k2222273073/fulltext.pdf'>Connectionism, eliminativism, and the semantic view of theories.</a></span> <span class='pub_name'>Erkenntnis</span> 39 (3):359-382. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6919691481176505792'>Cited by 5</a> | <span class='ll' onclick='$("_709_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20eliminativism%2C%20and%20the%20semantic%20view%20of%20theories+author%3ABickle&amp;btnG=Search'>Google</a> | <a href='javascript:show("_709_links")'>More links</a>)</span><div id='_709_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Outlines the semantic view of scientific theories, and applies it to the connectionism/eliminativism debate. There's no reason why folk psychology shouldn't be reducible, in a homogeneous or heterogeneous way.</div></div><div id='_709_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Recently some philosophers have urged that connectionist artificial intelligence is (potentially) eliminative for the propositional attitudes of folk psychology. At the same time, however, these philosophers have also insisted that since philosophy of science has failed to provide criteria distinguishing ontologically retentive from eliminative theory changes, the resulting eliminativism is not principled. Application of some resources developed within the semantic view of scientific theories, particularly recent formal work on the theory reduction relation, reveals these philosophers to be wrong in this second contention, yet by and large correct in the first</div>
<div id='_709_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BICCEA",this.href,0);return true;' href="http://www.springerlink.com/index/PK525K2222273073.pdf">http://www.springerlink.com/index/PK525K2222273073.pdf</a><br></div></div>
</div><!--entry-->

<div id='_710_entry' class='entry'><span ><span class='name'>Botterill, George</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("BOTBFD",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(199409)45:3&lt;899:BFDSAC&gt;2.0.CO;2-5'>Beliefs, functionally discrete states, and connectionist networks.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 45 (3):899-906. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5461107143770578049'>Cited by 2</a> | <span class='ll' onclick='$("_710_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Beliefs%2C%20functionally%20discrete%20states%2C%20and%20connectionist%20networks+author%3ABotterill&amp;btnG=Search'>Google</a> | <a href='javascript:show("_710_links")'>More links</a>)</span><div id='_710_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Distinguishes active from dispositional beliefs: the former are realized discretely in activation patterns, the latter nondiscretely in weights, which is all that folk psychology needs.</div></div>
<div id='_710_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOTBFD",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(199409)45:3&lt;899:BFDSAC&gt;2.0.CO;2-5">http://www.jstor.org/sici?sici=0007-0882(199409)45:3<899:BFDSAC>2.0.CO;2-5</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOTBFD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/citation/45/3/899">http://bjps.oxfordjournals.org/cgi/content/citation/45/3/899</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOTBFD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/45/3/899">http://bjps.oxfordjournals.org/cgi/reprint/45/3/899</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOTBFD",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/687799.pdf">http://www.jstor.org/stable/pdfplus/687799.pdf</a><br></div></div>
</div><!--entry-->

<div id='_711_entry' class='entry'><span ><span class='name'>Chemero, Anthony</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("CHEAWI",this.href,0);return true;' href='http://edisk.fandm.edu/tony.chemero/papers/bickchurchrev.pdf'>Asking what's inside the head: Neurophilosophy meets the extended mind.</a></span> <span class='pub_name'>Minds and Machines</span> 17 (3). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Asking%20what%27s%20inside%20the%20head+author%3AChemero&amp;btnG=Search'>Google</a> | <a href='javascript:show("_711_links")'>More links</a>)</span><div id='_711_abstract' class='extra' style='font-size:12px;'>Abstract: In their historical overview of cognitive science, Bechtel, Abraham- son and Graham (1999) describe the ï¬eld as expanding in focus be- ginning in the mid-1980s. The ï¬eld had spent the previous 25 years on internalist, high-level GOFAI (âgood old fashioned artiï¬cial intelli- genceâ [Haugeland 1985]), and was ï¬nally moving âoutwards into the environment and downards into the brainâ (Bechtel et al, 1999, p.75). One important force behind the downward movement was Patricia Churchlandâs Neurophilosophy (1986). This book began a movement bearing its name, one that truly came of age in 1999 when Kath- leen Akins won a million-dollar fellowship to begin the McDonnell Project in Philosophy and the Neurosciences. The McDonnell Project put neurophilosophy at the forefront of philosophy of mind and cogni- tive science, yielding proliferating articles, conferences, special journal issues and books. In two major new books, neurophilosophers Patricia Churchland (2002) and John Bickle (2003) clearly feel this newfound prominence: Churchland mocks those who do not apply ï¬ndings in neuroscience to philosophical problems as âno-brainersâ; Bickle mocks anyone with traditional philosophical concerns, including ânaturalistic philosophers of mindâ and other neurophilosophers</div>
<div id='_711_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEAWI",this.href,0);return true;' href="http://edisk.fandm.edu/tony.chemero/papers/bickchurchrev.pdf ">http://edisk.fandm.edu/tony.chemero/papers/bickchurchrev.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEAWI",this.href,0);return true;' href="http://www.springerlink.com/content/m812557162027h08/fulltext.pdf">http://www.springerlink.com/content/m812557162027h08/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_712_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("CLABE",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1989.tb00256.x'>Beyond eliminativism.</a></span> <span class='pub_name'>Mind and Language</span> 4 (4):251-79. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13525570453077911503'>Cited by 5</a> | <span class='ll' onclick='$("_712_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Beyond%20eliminativism+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_712_links")'>More links</a>)</span><div id='_712_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism needn't imply eliminativism, as higher levels may have a causal role, if not causal completeness. Also, it may not tell the whole story.</div></div>
<div id='_712_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLABE",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120006482/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120006482/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_713_entry' class='entry'><span ><span class='name'>Clapin, Hugh</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("CLACIM",this.href,0);return true;' href='http://www.springerlink.com/content/content/j71587tqw5g8141r/fulltext.pdf'>Connectionism isn't magic.</a></span> <span class='pub_name'>Minds and Machines</span> 1 (2):167-84. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12141439343731053313'>Cited by 3</a> | <span class='ll' onclick='$("_713_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20isn%27t%20magic+author%3AClapin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_713_links")'>More links</a>)</span><div id='_713_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Commentary on Ramsey/Stich/Garon. Connectionism has symbols that interact, and has propositional modularity in processing if not in storage.</div></div><div id='_713_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Ramsey, Stich and Garon's recent paper Connectionism, Eliminativism, and the Future of Folk Psychology claims a certain style of connectionism to be the final nail in the coffin of folk psychology. I argue that their paper fails to show this, and that the style of connectionism they illustrate can in fact supplement, rather than compete with, the claims of a theory of cognition based in folk psychology's ontology. Ramsey, Stich and Garon's argument relies on the lack of easily identifiable symbols inside the connectionist network they discuss, and they suggest that the existence of a system which behaves in a cognitively interesting way, but which cannot be explained by appeal to internal symbol processing, falsifies central assumptions of folk psychology. My claim is that this argument is flawed, and that the theorist need not discard folk psychology in order to accept that the network illustrated exhibits cognitively interesting behaviour, even if it is conceded that symbols cannot be readily identified within the network</div>
<div id='_713_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLACIM",this.href,0);return true;' href="http://www.springerlink.com/content/j71587tqw5g8141r/fulltext.pdf">http://www.springerlink.com/content/j71587tqw5g8141r/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLACIM",this.href,0);return true;' href="http://www.springerlink.com/index/J71587TQW5G8141R.pdf">http://www.springerlink.com/index/J71587TQW5G8141R.pdf</a><br></div></div>
</div><!--entry-->

<div id='_714_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1990). Connectionist minds.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 90:83-102. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18374444407575545807'>Cited by 10</a> | <span class='ll' onclick='$("_714_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20minds+author%3AClark&amp;btnG=Search'>Google</a>)</span><div id='_714_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Responding to eliminativist challenge via cluster analysis and recurrence.</div></div>
</div><!--entry-->

<div id='_715_entry' class='entry'><span ><span class='name'>Davies, Martin</span> (1991). Concepts, connectionism, and the language of thought. Philosophy and connectionist theory.</span> <span class='pub_name'>Lawrence Erlbaum</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_715_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Concepts%2C%20connectionism%2C%20and%20the%20language%20of%20thought.%20Philosophy%20and%20connectionist%20theory+author%3ADavies&amp;btnG=Search'>Google</a>)</span><div id='_715_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that our conception of thought requires causal systematicity, which requires a language of thought. Connectionist systems are not causally systematic, so connectionism leads to eliminativism.</div></div>
</div><!--entry-->

<div id='_716_entry' class='entry'><span ><span class='name'>Egan, Frances</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("EGAFPA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8248(199506)62:2&lt;179:FPACA&gt;2.0.CO;2-M'>Folk psychology and cognitive architecture.</a></span> <span class='pub_name'>Philosophy of Science</span> 62 (2):179-96. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2285651507789629275'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20psychology%20and%20cognitive%20architecture+author%3AEgan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_716_links")'>More links</a>)</span>
<div id='_716_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EGAFPA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8248(199506)62:2&lt;179:FPACA&gt;2.0.CO;2-M">http://www.jstor.org/sici?sici=0031-8248(199506)62:2<179:FPACA>2.0.CO;2-M</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EGAFPA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/188429.pdf">http://www.jstor.org/stable/pdfplus/188429.pdf</a><br></div></div>
</div><!--entry-->

<div id='_717_entry' class='entry'><span ><span class='name'>Forster, M.</span> &amp; <span class='name'>Saidel, Eric</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("FORCAT",this.href,0);return true;' href='http://philosophy.wisc.edu/Forster/papers/Connection.pdf'>Connectionism and the fate of folk psychology.</a></span> <span class='pub_name'>Philosophical Psychology</span> 7 (4):437-52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12073497922123373179'>Cited by 6</a> | <span class='ll' onclick='$("_717_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20fate%20of%20folk%20psychology+author%3AForster&amp;btnG=Search'>Google</a> | <a href='javascript:show("_717_links")'>More links</a>)</span><div id='_717_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Contra Ramsey, Stich, and Garon, connectionist representations can be seen to be functionally discrete on an appropriate analysis of causal relevance.</div></div>
<div id='_717_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FORCAT",this.href,0);return true;' href="http://philosophy.wisc.edu/forster/papers/Connection.pdf">http://philosophy.wisc.edu/forster/papers/Connection.pdf</a><br></div></div>
</div><!--entry-->

<div id='_718_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("HORCAT-2",this.href,0);return true;' href='http://links.jstor.org/sici?sici=1520-8583(1995)9&lt;127:CATCOF&gt;2.0.CO;2-R'>Connectionism and the commitments of folk psychology.</a></span> <span class='pub_name'>Philosophical Perspectives</span> 9:127-52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8705292039165634612'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20commitments%20of%20folk%20psychology+author%3AHorgan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_718_links")'>More links</a>)</span>
<div id='_718_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORCAT-2",this.href,0);return true;' href="http://www.jstor.org/sici?sici=1520-8583(1995)9&lt;127:CATCOF&gt;2.0.CO;2-R">http://www.jstor.org/sici?sici=1520-8583(1995)9<127:CATCOF>2.0.CO;2-R</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORCAT-2",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2214215.pdf">http://www.jstor.org/stable/pdfplus/2214215.pdf</a><br></div></div>
</div><!--entry-->

<div id='_719_entry' class='entry'><span ><span class='name'>Macdonald, Cynthia</span> (1995). Connectionism and eliminativism.</span> In C. Macdonald &amp; Graham F. Macdonald (eds.), <em>Connectionism: Debates on Psychological Explanation</em>. Cambridge: Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20eliminativism+author%3AMacdonald&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_720_entry' class='entry'><span ><span class='name'>O'Brien, Gerard</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("OBRICC",this.href,0);return true;' href='http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Is_Connectionism_Common_Sense.pdf'>Is connectionism commonsense?</a></span> <span class='pub_name'>Philosophical Psychology</span> 4 (2):165-78. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20connectionism%20commonsense%3F+author%3AO%27Brien&amp;btnG=Search'>Google</a> | <a href='javascript:show("_720_links")'>More links</a>)</span><div id='_720_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper I critically examine the line of reasoning that has recently appeared in the literature that connects connectionism with eliminativism. This line of reasoning has it that if connectionist models turn out accurately to characterize our cognition, then beliefs, desires and the other intentional entities of commonsense psychology will be eliminated from our theoretical ontology. In complete contrast I argue (1) that not only is this line of reasoning mistaken about the eliminativist tendencies of connectionist models, but (2) that these models have the potential to provide a more robust vindication of commonsense psychology than classical computational models</div>
<div id='_720_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRICC",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793921812~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793921812~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_721_entry' class='entry'><span ><span class='name'>O'Leary-Hawthorne, John</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("OLEOTT",this.href,0);return true;' href='http://www.springerlink.com/content/vq1p720k640p6862/fulltext.pdf'>On the threat of eliminativism.</a></span> <span class='pub_name'>Philosophical Studies</span> 74 (3):325-46. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_721_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20threat%20of%20eliminativism+author%3AO%27Leary-Hawthorne&amp;btnG=Search'>Google</a>)</span><div id='_721_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A dispositional construal of beliefs and desires can distinguish the relevant active states (via counterfactuals) and is compatible with FP, so internals can't threaten FP. With remarks on Davidson, overdetermination, etc.</div></div>
</div><!--entry-->

<div id='_722_entry' class='entry'><span ><span class='name'>Place, Ullin T.</span> (1992). Eliminative connectionism: Its implications for a return to an empiricist/behaviorist linguistics.</span> <span class='pub_name'>Behavior and Philosophy</span> 20 (1):21-35. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Eliminative%20connectionism+author%3APlace&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_723_entry' class='entry'><span ><span class='name'>Ramsey, William</span>; <span class='name'>Stich, Stephen P.</span> &amp; <span class='name'>Garon, J.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("RAMCEA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=1520-8583(1990)4&lt;499:CEATFO&gt;2.0.CO;2-N'>Connectionism, eliminativism, and the future of folk psychology.</a></span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10214399854810695176'>Cited by 85</a> | <span class='ll' onclick='$("_723_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20eliminativism%2C%20and%20the%20future%20of%20folk%20psychology+author%3ARamsey&amp;btnG=Search'>Google</a> | <a href='javascript:show("_723_links")'>More links</a>)</span><div id='_723_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>If connectionism is true, then eliminativism is true, as you can't isolate the causal role of individual beliefs in a connectionist system.</div></div>
<div id='_723_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAMCEA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=1520-8583(1990)4&lt;499:CEATFO&gt;2.0.CO;2-N">http://www.jstor.org/sici?sici=1520-8583(1990)4<499:CEATFO>2.0.CO;2-N</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAMCEA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2214202.pdf">http://www.jstor.org/stable/pdfplus/2214202.pdf</a><br></div></div>
</div><!--entry-->

<div id='_724_entry' class='entry'><span ><span class='name'>Ramsey, William</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("RAMDRA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793923183~fulltext=713240930'>Distributed representation and causal modularity: A rejoinder to Forster and Saidel.</a></span> <span class='pub_name'>Philosophical Psychology</span> 7 (4):453-61. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3503566474818033653'>Cited by 2</a> | <span class='ll' onclick='$("_724_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Distributed%20representation%20and%20causal%20modularity+author%3ARamsey&amp;btnG=Search'>Google</a>)</span><div id='_724_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Upon examination, the model of Forster and Saidel 1994 does not exhibit features that are both distributed and causally discrete.</div></div><div id='_724_abstract' class='extra' style='font-size:12px;'>Abstract: In âConnectionism and the fats of folk psychologyâ, Forster and Saidel argue that the central claim of Ramsey, Stich and Garon (1991)âthat distributed connectionist models are incompatible with the causal discreteness of folk psychologyâis mistaken. To establish their claim, they offer an intriguing model which allegedly shows how distributed representations can function in a causally discrete manner. They also challenge our position regarding projectibility of folk psychology. In this essay, I offer a response to their account and show how their model fails to demonstrate that our original argument was mistaken. While I will discuss several difficulties with their model, my primary criticism will be that the features of their model that are causally discrete are not truly distributed, while the features that are distributed are not really discrete. Concerning the issue of projectibility, I am more inclined to agree with Forster and Saidel and I offer a revised account of what we should have said originally</div>
</div><!--entry-->

<div id='_725_entry' class='entry'><span ><span class='name'>Skokowski, Paul G.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("SKOBIN",this.href,0);return true;' href='http://www-csli.stanford.edu/~paulsko/papers/BIN.pdf'>Belief in networks.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Belief%20in%20networks+author%3ASkokowski&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_726_entry' class='entry'><span ><span class='name'>Smolensky, Paul</span> (1995). On the projectable predicates of connectionist psychology: A case for belief.</span> In C. Macdonald &amp; Graham F. Macdonald (eds.), <em>Connectionism: Debates on Psychological Explanation</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13307198329165279762'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20projectable%20predicates%20of%20connectionist%20psychology+author%3ASmolensky&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_727_entry' class='entry'><span ><span class='name'>Stich, Stephen P.</span> &amp; <span class='name'>Warfield, Ted A.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("STIRTC",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA395&amp;dq=Reply+to+Clark+and+Smolensky+Stich&amp;ots=O2dHlwiUNJ&amp;sig=Q9czgtIkmzgn3kUL77F_ZKBUmHw'>Reply to Clark and Smolensky: Do connectionist minds have beliefs?</a></span> In C. Macdonald &amp; Graham F. Macdonald (eds.), <em>Connectionism: Debates on Psychological Explanation</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6222328920759706821'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reply%20to%20Clark%20and%20Smolensky+author%3AStich&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_728_entry' class='entry'><span ><span class='name'>Von Eckhardt, Barbara</span> (2004). Connectionism and the propositional attitudes.</span> In Christina E. Erneling &amp; David Martel Johnson (eds.), <em>Mind As a Scientific Object</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20propositional%20attitudes+author%3AVon%20Eckhardt&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.3d'></a><a name=''></a><span class='myh3'>6.3d The Connectionist/Classical Debate</span></p>

<div id='cat_6.3d' class='cat_content'>
<div id='__new_entries_6.3d__'></div><div id='__new_entry_6.3d__' class='entry'></div>
<div id='_729_entry' class='entry'><span ><span class='name'>Adams, Frederick R.</span>; <span class='name'>Aizawa, Kenneth</span> &amp; <span class='name'>Fuller, Gary</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("ADARIP",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=2ACrB8JOa8EC&amp;oi=fnd&amp;pg=PA49&amp;ots=5UAiOCdEZN&amp;sig=VTQ6V-YZcxyXVGErIx_xUoZ8QDM'>Rules in programming languages and networks.</a></span> In J. Dinsmore (ed.), <em>The Symbolic and Connectionist Paradigms: Closing the Gap</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17319222026425983818'>Cited by 3</a> | <span class='ll' onclick='$("_729_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rules%20in%20programming%20languages%20and%20networks+author%3AAdams&amp;btnG=Search'>Google</a> | <a href='javascript:show("_729_links")'>More links</a>)</span><div id='_729_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The distinction between programming languages and networks is neutral on rule-following, etc, so there's nothing really new about connectionism.</div></div>
<div id='_729_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ADARIP",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Gyik-KzGOmwC&amp;oi=fnd&amp;pg=PA49&amp;ots=ZoWZXI2Brf&amp;sig=mhv9JiNUtz2joCKf_iL9HXjfIOk">http://books.google.com/books?hl=en&lr=&id=Gyik-KzGOmwC&oi=fnd&pg=PA49&ots=ZoWZXI2Brf&sig=mhv9JiNUtz2joCKf_iL9HXjfIOk</a><br></div></div>
</div><!--entry-->

<div id='_730_entry' class='entry'><span ><span class='name'>Aizawa, Kenneth</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("AIZRWR",this.href,0);return true;' href='http://www.springerlink.com/content/w30780736g40m071/fulltext.pdf'>Representations without rules, connectionism, and the syntactic argument.</a></span> <span class='pub_name'>Synthese</span> 101 (3):465-92. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11542060383946559103'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representations%20without%20rules%2C%20connectionism%2C%20and%20the%20syntactic%20argument+author%3AAizawa&amp;btnG=Search'>Google</a> | <a href='javascript:show("_730_links")'>More links</a>)</span><div id='_730_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Terry Horgan and John Tienson have suggested that connectionism might provide a framework within which to articulate a theory of cognition according to which there are mental representations without rules (RWR) (Horgan and Tienson 1988, 1989, 1991, 1992). In essence, RWR states that cognition involves representations in a language of thought, but that these representations are not manipulated by the sort of rules that have traditionally been posited. In the development of RWR, Horgan and Tienson attempt to forestall a particular line of criticism, theSyntactic Argument, which would show RWR to be inconsistent with connectionism. In essence, the argument claims that the node-level rules of connectionist networks, along with the semantic interpretations assigned to patterns of activation, serve to determine a set of representation-level rules incompatible with the RWR conception of cognition. The present paper argues that the Syntactic Argument can be made to show that RWR is inconsistent with connectionism</div>
<div id='_730_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AIZRWR",this.href,0);return true;' href="http://www.springerlink.com/index/W30780736G40M071.pdf">http://www.springerlink.com/index/W30780736G40M071.pdf</a><br></div></div>
</div><!--entry-->

<div id='_731_entry' class='entry'><span ><span class='name'>Aydede, Murat</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("AYDCAT",this.href,0);return true;' href='http://csli-publications.stanford.edu/papers/CSLI-95-195.html'>Connectionism and the language of thought.</a></span> <span class='pub_name'>CSLI Technical Report</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16679753664016636586'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20language%20of%20thought+author%3AAydede&amp;btnG=Search'>Google</a>)</span><div id='_731_abstract' class='extra' style='font-size:12px;'>Abstract: Fodor and Pylyshyn's (F&P) critique of connectionism has posed a challenge to connectionists: Adequately explain such nomological regularities as systematicity and productivity without postulating a "language of thought'' (LOT). Some connectionists declined to meet the challenge on the basis that the alleged regularities are somehow spurious. Some, like Smolensky, however, took the challenge very seriously, and attempted to meet it by developing models that are supposed to be non-classical</div>
</div><!--entry-->

<div id='_732_entry' class='entry'><span ><span class='name'>beim Graben, Peter</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("BEIIIO",this.href,0);return true;' href='http://www.ingentaconnect.com/content/imp/mm/2004/00000002/00000002/art00003'>Incompatible implementations of physical symbol systems.</a></span> <span class='pub_name'>Mind and Matter</span> 2 (2):29-51. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Incompatible%20implementations%20of%20physical%20symbol%20systems+author%3Abeim%20Graben&amp;btnG=Search'>Google</a>)</span><div id='_732_abstract' class='extra' style='font-size:12px;'>Abstract: Classical cognitive science assumes that intelligently behaving systems must be symbol processors that are implemented in physical systems such as brains or digital computers. By contrast, connectionists suppose that symbol manipulating systems could be approximations of neural networks dynamics. Both classicists and connectionists argue that symbolic computation and subsymbolic dynamics are incompatible, though on different grounds. While classicists say that connectionist architectures and symbol processors are either incompatible or the former are mere implementations of the latter, connectionists reply that neural networks might be incompatible with symbol processors because the latter cannot be implementations of the former. In this contribution, the notions of 'incompatibility' and 'implementation' will be criticized to show that they must be revised in the context of the dynamical system approach to cognitive science. Examples for implementations of symbol processors that are incompatible with respect to contextual topologies will be discussed</div>
</div><!--entry-->

<div id='_733_entry' class='entry'><span ><span class='name'>Bringsjord, Selmer</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("BRIITC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=124206.124211'>Is the connectionist-logicist debate one of ai's wonderful red herrings?</a></span> <span class='pub_name'>Journal of Theoretical and Experimental Artificial Intelligence</span> 3:319-49. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14560401180410480343'>Cited by 16</a> | <span class='ll' onclick='$("_733_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20the%20connectionist-logicist%20debate%20one%20of%20ai%27s%20wonderful%20red%20herrings%3F+author%3ABringsjord&amp;btnG=Search'>Google</a> | <a href='javascript:show("_733_links")'>More links</a>)</span><div id='_733_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A detailed analysis purporting to show that connectionism and "logicism" are compatible, as Turing machines can do everything a neural network can. Entertaining, but misunderstands subsymbolic processing.</div></div>
<div id='_733_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIITC",this.href,0);return true;' href="http://kryten.mm.rpi.edu/connectionist_logicist_clash.pdf">http://kryten.mm.rpi.edu/connectionist_logicist_clash.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRIITC",this.href,0);return true;' href="http://www.informaworld.com/index/776648445.pdf">http://www.informaworld.com/index/776648445.pdf</a><br></div></div>
</div><!--entry-->

<div id='_734_entry' class='entry'><span ><span class='name'>Broadbent, D.</span> (1985). A question of levels: Comment on McClelland and rumelhart.</span> <span class='pub_name'>Journal of Experimental Psychology</span> 114:189-92. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13630745563371665248'>Cited by 29</a> | <span class='ll' onclick='$("_734_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20question%20of%20levels+author%3ABroadbent&amp;btnG=Search'>Google</a>)</span><div id='_734_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Distributed models are at the implementational, not computational, level.</div></div>
</div><!--entry-->

<div id='_735_entry' class='entry'><span ><span class='name'>Chandrasekaran, B.</span>; <span class='name'>Goel, A.</span> &amp; <span class='name'>Allemang, D.</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("CHACAI-3",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=58345.58347'>Connectionism and information-processing abstractions.</a></span> <span class='pub_name'>AI Magazine</span> 24. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1932184303880645819'>Cited by 15</a> | <span class='ll' onclick='$("_735_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20information-processing%20abstractions+author%3AChandrasekaran&amp;btnG=Search'>Google</a> | <a href='javascript:show("_735_links")'>More links</a>)</span><div id='_735_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism won't affect AI too much, as AI is concerned with the information-processing (task) level. With greater modularity, connectionism will look more like traditional AI.</div></div>
<div id='_735_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHACAI-3",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=1914723CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=1914723CI</a><br></div></div>
</div><!--entry-->

<div id='_736_entry' class='entry'><span ><span class='name'>Christensen, Wayne D.</span> &amp; <span class='name'>Tomassi, Luca</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("CHRNIC",this.href,0);return true;' href='http://mitpress.mit.edu/catalog/item/default.asp?ttype=6&amp;tid=19989'>Neuroscience in context: The new flagship of the cognitive sciences.</a></span> <span class='pub_name'>Biological Theory</span> 1 (1):78-83. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Neuroscience%20in%20context+author%3AChristensen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_736_links")'>More links</a>)</span>
<div id='_736_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHRNIC",this.href,0);return true;' href="http://www.arts.adelaide.edu.au/humanities/people/philosophy/christensen_preprints/Christensen_Tommasi_2006_Neuroscience_in_context.pdf">http://www.arts.adelaide.edu.au/humanities/people/philosophy/christensen_preprints/Christensen_Tommasi_2006_Neuroscience_in_context.pdf</a><br></div></div>
</div><!--entry-->

<div id='_737_entry' class='entry'><span ><span class='name'>Corbi, Josep E.</span> (1993). Classical and connectionist models: Levels of description.</span> <span class='pub_name'>Synthese</span> 95 (2):141-68. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Classical%20and%20connectionist%20models+author%3ACorbi&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_738_entry' class='entry'><span ><span class='name'>Davies, Martin</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("DAVCCA-2",this.href,0);return true;' href='http://philrsss.anu.edu.au/~mdavies/papers/lot.pdf'>Concepts, connectionism, and the language of thought.</a></span> In W Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Hillsdale, NJ: Lawrence Erlbaum Associates. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15117531951352436666'>Cited by 40</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Concepts%2C%20connectionism%2C%20and%20the%20language%20of%20thought+author%3ADavies&amp;btnG=Search'>Google</a>)</span><div id='_738_abstract' class='extra' style='font-size:12px;'>Abstract: The aim of this paper is to demonstrate a _prima facie_ tension between our commonsense conception of ourselves as thinkers and the connectionist programme for modelling cognitive processes. The language of thought hypothesis plays a pivotal role. The connectionist paradigm is opposed to the language of thought; and there is an argument for the language of thought that draws on features of the commonsense scheme of thoughts, concepts, and inference. Most of the paper (Sections 3-7) is taken up with the argument for the language of thought hypothesis. The argument for an opposition between connectionism and the language of thought comes towards the end (Section 8), along with some discussion of the potential eliminativist consequences (Sections 9 and</div>
</div><!--entry-->

<div id='_739_entry' class='entry'><span ><span class='name'>Dawson, Michael R. W.</span>; <span class='name'>Medler, D. A.</span> &amp; <span class='name'>Berkeley, Istvan S. N.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("DAWPNC",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a793921353~fulltext=713240930'>PDP networks can provide models that are not mere implementations of classical theories.</a></span> <span class='pub_name'>Philosophical Psychology</span> 10 (1):25-40. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10777556651173201476'>Cited by 17</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=PDP%20networks%20can%20provide%20models%20that%20are%20not%20mere%20implementations%20of%20classical%20theories+author%3ADawson&amp;btnG=Search'>Google</a>)</span><div id='_739_abstract' class='extra' style='font-size:12px;'>Abstract: There is widespread belief that connectionist networks are dramatically different from classical or symbolic models. However, connectionists rarely test this belief by interpreting the internal structure of their nets. A new approach to interpreting networks was recently introduced by Berkeley et al. (1995). The current paper examines two implications of applying this method: (1) that the internal structure of a connectionist network can have a very classical appearance, and (2) that this interpretation can provide a cognitive theory that cannot be dismissed as a mere implementation</div>
</div><!--entry-->

<div id='_740_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("DENMNV",this.href,0);return true;' href='http://cogprints.org/433'>Mother nature versus the walking encyclopedia.</a></span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8869037798570529898'>Cited by 23</a> | <span class='ll' onclick='$("_740_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mother%20nature%20versus%20the%20walking%20encyclopedia+author%3ADennett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_740_links")'>More links</a>)</span><div id='_740_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reiterating the value of connectionism, especially biological plausibility.</div></div><div id='_740_abstract' class='extra' style='font-size:12px;'>Abstract: In 1982, Feldman and Ballard published "Connectionist models and their properties" in Cognitive Science , helping to focus attention on a family of similarly inspired research strategies just then under way, by giving the family a name: "connectionism." Now, seven years later, the connectionist nation has swelled to include such subfamilies as "PDP" and "neural net models." Since the ideological foes of connectionism are keen to wipe it out in one fell swoop aimed at its "essence", it is worth noting the diversity of not only the models but also the aspirations of the modelers. There is no good reason to suppose that they all pledge allegiance to any one principle..</div>
<div id='_740_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENMNV",this.href,0);return true;' href="http://ase.tufts.edu/cogstud/papers/motherna.htm">http://ase.tufts.edu/cogstud/papers/motherna.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENMNV",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000433/">http://cogprints.ecs.soton.ac.uk/archive/00000433/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENMNV",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000433/00/motherna.htm">http://cogprints.ecs.soton.ac.uk/archive/00000433/00/motherna.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENMNV",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:433">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:433</a><br></div></div>
</div><!--entry-->

<div id='_741_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1986). The logical geography of computational approaches: A view from the east pole.</span> In Myles Brand &amp; Robert M. Harnish (eds.), <em>The Representation of Knowledge and Belief</em>. University of Arizona Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4407055365372929181'>Cited by 21</a> | <span class='ll' onclick='$("_741_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20logical%20geography%20of%20computational%20approaches+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_741_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Drawing the battle-lines: High Church Computationalism at the "East Pole", New Connectionism, Zen Holism, etc, at various locations on the "West Coast". With remarks on connectionism, and on AI as thought-experimentation.</div></div>
</div><!--entry-->

<div id='_742_entry' class='entry'><span ><span class='name'>DeVries, Willem A.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("DEVWSW",this.href,0);return true;' href='http://www.springerlink.com/content/l7664w2t0u211253/fulltext.pdf'>Who sees with equal eye,... Atoms or systems into ruin hurl'd?</a></span> <span class='pub_name'>Philosophical Studies</span> 71 (2):191-200. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Who%20sees%20with%20equal%20eye%2C...%20Atoms%20or%20systems%20into%20ruin%20hurl%27d%3F+author%3ADeVries&amp;btnG=Search'>Google</a> | <a href='javascript:show("_742_links")'>More links</a>)</span>
<div id='_742_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DEVWSW",this.href,0);return true;' href="http://www.springerlink.com/index/L7664W2T0U211253.pdf">http://www.springerlink.com/index/L7664W2T0U211253.pdf</a><br></div></div>
</div><!--entry-->

<div id='_743_entry' class='entry'><span ><span class='name'>Dinsmore, J.</span> (ed.) (1992). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("DINTSA",this.href,0);return true;' href='http://books.google.com/books?id=Gyik-KzGOmwC&amp;printsec=front_cover'>The Symbolic and Connectionist Paradigms: Closing the Gap.</a></span></em></span> Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=283314271668829724'>Cited by 18</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Symbolic%20and%20Connectionist%20Paradigms+author%3ADinsmore&amp;btnG=Search'>Google</a>)</span><div id='_743_abstract' class='extra' style='font-size:12px;'>Abstract: This book records the thoughts of researchers -- from both computer science and philosophy -- on resolving the debate between the symbolic and connectionist...</div>
</div><!--entry-->

<div id='_744_entry' class='entry'><span ><span class='name'>Dyer, Michael G.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("DYECVS",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=zUzS0kLd1e4C&amp;oi=fnd&amp;pg=PA382&amp;dq=Connectionism+versus+symbolism+in+high-level+cognition+Dyer&amp;ots=zc89EyUViA&amp;sig=LWOUQxMFQPiqQFwJxO0588daXps'>Connectionism versus symbolism in high-level cognition.</a></span> In Terence E. Horgan &amp; John L. Tienson (eds.), <em>Connectionism and the Philosophy of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6096238181142672298'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20versus%20symbolism%20in%20high-level%20cognition+author%3ADyer&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_745_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("ELIITB",this.href,0);return true;' href='http://watarts.uwaterloo.ca/~celiasmi/Papers/ce.2000.continuity.debate.csq.html'>Is the brain analog or digital?</a></span> <span class='pub_name'>Cognitive Science Quarterly</span> 1 (2):147-170. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20the%20brain%20analog%20or%20digital%3F+author%3AEliasmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_745_links")'>More links</a>)</span><div id='_745_abstract' class='extra' style='font-size:12px;'>Abstract: It will always remain a remarkable phenomenon in the history of philosophy, that there was a time, when even mathematicians, who at the same time were philosophers, began to doubt, not of the accuracy of their geometrical propositions so far as they concerned space, but of their objective validity and the applicability of this concept itself, and of all its corollaries, to nature. They showed much concern whether a line in nature might not consist of physical points, and consequently that true space in the object might consist of simple [discrete] parts, while the space which the geometer has in his mind [being continuous] cannot be such</div>
<div id='_745_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIITB",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~celiasmi/Papers/ce.2000.continuity.debate.csq.html">http://www.arts.uwaterloo.ca/~celiasmi/Papers/ce.2000.continuity.debate.csq.html</a><br></div></div>
</div><!--entry-->

<div id='_746_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> &amp; <span class='name'>Clark, Andy</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("ELIPII",this.href,0);return true;' href='http://www.cogs.indiana.edu/andy/clarkeliasmith2.pdf '>Philosophical issues in brain theory and connectionism.</a></span> In  M. Arbib (ed.), <em>The Handbook of Brain Theory and Neural Networks</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophical%20issues%20in%20brain%20theory%20and%20connectionism+author%3AEliasmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_746_links")'>More links</a>)</span><div id='_746_abstract' class='extra' style='font-size:12px;'>Abstract: In this article, we highlight three questions: (1) Does human cognition rely on structured internal representations? (2) How should theories, models and data relate? (3) In what ways might embodiment, action and dynamics matter for understanding the mind and the brain?</div>
<div id='_746_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIPII",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~celiasmi/Papers/withclark.html">http://www.arts.uwaterloo.ca/~celiasmi/Papers/withclark.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIPII",this.href,0);return true;' href="http://www.philosophy.ed.ac.uk/staff/clark/pubs/clarkeliasmith2.pdf">http://www.philosophy.ed.ac.uk/staff/clark/pubs/clarkeliasmith2.pdf</a><br></div></div>
</div><!--entry-->

<div id='_747_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> &amp; <span class='name'>Pylyshyn, Zenon W.</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("FODCAC",this.href,0);return true;' href='http://ruccs.rutgers.edu/pub/papers/jaf.pdf'>Connectionism and cognitive architecture.</a></span> <span class='pub_name'>Cognition</span> 28:3-71. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5846360074642923893'>Cited by 1496</a> | <span class='ll' onclick='$("_747_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20cognitive%20architecture+author%3AFodor&amp;btnG=Search'>Google</a> | <a href='javascript:show("_747_links")'>More links</a>)</span><div id='_747_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionist models can't explain cognitive systematicity and productivity, as their representations lack compositional structure. The allures of connectionism are illusory; it's best used as an implementation strategy.</div></div><div id='_747_abstract' class='extra' style='font-size:12px;'>Abstract: This paper explores the difference between Connectionist proposals for cognitive a r c h i t e c t u r e a n d t h e s o r t s o f m o d e l s t hat have traditionally been assum e d i n c o g n i t i v e s c i e n c e . W e c l a i m t h a t t h e m a j o r d i s t i n c t i o n i s t h a t , w h i l e b o t h Connectionist and Classical architectures postulate representational mental states, the latter but not the former are committed to a symbol-level of representation, or to a âlanguage of thoughtâ: i.e., to representational states that have combinatorial syntactic and semantic structure. Several arguments for combinatorial structure in mental representations are then reviewed. These include arguments based on the âsystematicityâ of mental representation: i.e., on the fact that cognitive capacities always exhibit certain symmetries, so that the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents. We claim that such arguments make a powerful case that mind/brain architecture is not Connectionist at the cognitive level. We then consider the possibility that Connectionism may provide an account of the neural (or âabstract neurologicalâ) structures in which Classical cognitive architecture is implemented. We survey a n u m b e r o f t h e s t a n d a r d a r g u m e n t s t h a t h a v e b e e n o f f e r e d i n f a v o r o f Connectionism, and conclude that they are coherent only on this interpretation</div>
<div id='_747_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=58067">http://portal.acm.org/citation.cfm?id=58067</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://www.blutner.de/philom/connect/jaf.pdf">http://www.blutner.de/philom/connect/jaf.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://ruccs.rutgers.edu/ftp/pub/papers/jaf.pdf">http://ruccs.rutgers.edu/ftp/pub/papers/jaf.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=190704.190740">http://portal.acm.org/citation.cfm?id=190704.190740</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://www.ii.metu.edu.tr/~tekman/fodor&amp;pylyshyn.pdf">http://www.ii.metu.edu.tr/~tekman/fodor&pylyshyn.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://citeseer.ist.psu.edu/fodor88connectionism.html">http://citeseer.ist.psu.edu/fodor88connectionism.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLzaEHRW&amp;sig=1PDJYThCtCF24M7R6UJK4T">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLzaEHRW&sig=1PDJYThCtCF24M7R6UJK4T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://watarts.uwaterloo.ca/~celiasmi/courses/Phil256/papers/fodor.pylyshyn.1988.Connectionism cog architec.bbs.pdf">http://watarts.uwaterloo.ca/~celiasmi/courses/Phil256/papers/fodor.pylyshyn.1988.Connectionism cog architec.bbs.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bKr8GASZ&amp;sig=lvbjst___yAcJlOgVzyRdzEV09k">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bKr8GASZ&sig=lvbjst___yAcJlOgVzyRdzEV09k</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bGv5IAW0&amp;sig=bfPrm5H3Z-QZFIh2WX-XvqgjqHE">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bGv5IAW0&sig=bfPrm5H3Z-QZFIh2WX-XvqgjqHE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bIt7BHPT&amp;sig=W9wLTgrsP59cPqZhSN0ysQbSVoM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bIt7BHPT&sig=W9wLTgrsP59cPqZhSN0ysQbSVoM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bHr6CFR-&amp;sig=ic0bVVM1PfuvCnadV8OCRGBbNA4">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bHr6CFR-&sig=ic0bVVM1PfuvCnadV8OCRGBbNA4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bGv5HHV-&amp;sig=UkXTSX19hHzvmMUKvLT-lq0r50I">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bGv5HHV-&sig=UkXTSX19hHzvmMUKvLT-lq0r50I</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKr7GJXU&amp;sig=LBgHuNyf_KzzIi7ocvlxiFsIWIE">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKr7GJXU&sig=LBgHuNyf_KzzIi7ocvlxiFsIWIE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLtaAJQ0&amp;sig=-rBwtgEcuMHfIKQJzOHWYIrBX9E">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLtaAJQ0&sig=-rBwtgEcuMHfIKQJzOHWYIrBX9E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKwbCDTZ&amp;sig=00wE8Svuh3W8kqsUo0UKOYCfcAI">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKwbCDTZ&sig=00wE8Svuh3W8kqsUo0UKOYCfcAI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bHx6HGX-&amp;sig=5IusXYTvApV1_rtpQEkaBet0xn4">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bHx6HGX-&sig=5IusXYTvApV1_rtpQEkaBet0xn4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKubBBQY&amp;sig=HFGXyuxr_1mxH5ACFOe-zyaTw4o">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKubBBQY&sig=HFGXyuxr_1mxH5ACFOe-zyaTw4o</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bIz7HEWT&amp;sig=CAuCWiDdEmwTntCDA3H1Zyfn5a0">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bIz7HEWT&sig=CAuCWiDdEmwTntCDA3H1Zyfn5a0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLzaEEXV&amp;sig=e9QEFe5nD4bGAK5W4dDIRZBKNuM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLzaEEXV&sig=e9QEFe5nD4bGAK5W4dDIRZBKNuM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bIz7HCQU&amp;sig=4TMgHlnpnDyehNFJT-NG470Bbz8">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bIz7HCQU&sig=4TMgHlnpnDyehNFJT-NG470Bbz8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bMvaHGVW&amp;sig=9UEpXL5XYxZdQa3NvX7yU9iikyw">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bMvaHGVW&sig=9UEpXL5XYxZdQa3NvX7yU9iikyw</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bKx9AJPT&amp;sig=7sjHbKdagqCd6sUT-Kk-fcITZlc">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bKx9AJPT&sig=7sjHbKdagqCd6sUT-Kk-fcITZlc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bHx6HEPT&amp;sig=9ypKOA18BrlaitMu_it-TVCBfUw">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bHx6HEPT&sig=9ypKOA18BrlaitMu_it-TVCBfUw</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKr7GFP0&amp;sig=tdUqyz4ARusp_kokrKNOJedNknk">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKr7GFP0&sig=tdUqyz4ARusp_kokrKNOJedNknk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bLtaAHPT&amp;sig=cUrJjY2sKfVLW5Zp1ZtlEsdhcaM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bLtaAHPT&sig=cUrJjY2sKfVLW5Zp1ZtlEsdhcaM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z8bJv8BJW0&amp;sig=Qe8qR4Go6tnV95LlvTT6ELC_0Ds">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z8bJv8BJW0&sig=Qe8qR4Go6tnV95LlvTT6ELC_0Ds</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA3&amp;ots=Z7kKwbCBVX&amp;sig=iCTIyYq8EOvBdYu-srEXgyt-HoM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA3&ots=Z7kKwbCBVX&sig=iCTIyYq8EOvBdYu-srEXgyt-HoM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O2dHfvmUIJ&amp;sig=7hnYM8j4zdtpN4THjVSpzpGFEDs">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O2dHfvmUIJ&sig=7hnYM8j4zdtpN4THjVSpzpGFEDs</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34InykTQC&amp;sig=F0CONzdT49KnmoIp41iOngjBa_A">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34InykTQC&sig=F0CONzdT49KnmoIp41iOngjBa_A</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34IhygWIA&amp;sig=Zks6FRmma9XZGHW2EO1kvwIxesQ">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34IhygWIA&sig=Zks6FRmma9XZGHW2EO1kvwIxesQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34DjtnWOI&amp;sig=ohgYrPGd2Ut0_gQqvfJPXg0_xJo">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34DjtnWOI&sig=ohgYrPGd2Ut0_gQqvfJPXg0_xJo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34FnvnRJB&amp;sig=snID_Ptc5j-K-DxZvSjAScHkD6s">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34FnvnRJB&sig=snID_Ptc5j-K-DxZvSjAScHkD6s</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34GjwhYPJ&amp;sig=YnoEHTZY6rwzlL8DcfCj45uUQo0">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34GjwhYPJ&sig=YnoEHTZY6rwzlL8DcfCj45uUQo0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34JjynVOD&amp;sig=XBIWzRchQULcgPTlX6HyBgOg_pQ">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34JjynVOD&sig=XBIWzRchQULcgPTlX6HyBgOg_pQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34HfwmPLG&amp;sig=35GDmDcPG526574Ar-pZaGlfYXA">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34HfwmPLG&sig=35GDmDcPG526574Ar-pZaGlfYXA</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34ElunTIA&amp;sig=OzlrEEZ2Td9CGt5mgUD99UXGCWE">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34ElunTIA&sig=OzlrEEZ2Td9CGt5mgUD99UXGCWE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34HlxgYIA&amp;sig=ZsqjFV8LrCGXI-3jf8Pliu_sVsc">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34HlxgYIA&sig=ZsqjFV8LrCGXI-3jf8Pliu_sVsc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34FhvhWIA&amp;sig=1yq1WHwwotr3qVSaqN0K4StIWc8">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34FhvhWIA&sig=1yq1WHwwotr3qVSaqN0K4StIWc8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O34EfuiUKI&amp;sig=lDwkN-dMTxlLX_1XELpsD4ONtM4">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O34EfuiUKI&sig=lDwkN-dMTxlLX_1XELpsD4ONtM4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O2dHizhQJF&amp;sig=s7d-fmzg598bYH-IpAMNrcyO8eo">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O2dHizhQJF&sig=s7d-fmzg598bYH-IpAMNrcyO8eo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PA90&amp;ots=O2dHkziQOE&amp;sig=6AJnryXo_R8vj8qseWkK5DD31zQ">http://books.google.com/books?hl=en&lr=&id=ZLIAbDZzJ5sC&oi=fnd&pg=PA90&ots=O2dHkziQOE&sig=6AJnryXo_R8vj8qseWkK5DD31zQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FODCAC",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=2450716&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=2450716&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_748_entry' class='entry'><span ><span class='name'>Garson, James W.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("GARCWC",this.href,0);return true;' href='http://www.springerlink.com/content/p4414695610528g3/fulltext.pdf'>Cognition without classical architecture.</a></span> <span class='pub_name'>Synthese</span> 100 (2):291-306. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15301496339247845553'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognition%20without%20classical%20architecture+author%3AGarson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_748_links")'>More links</a>)</span><div id='_748_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Fodor and Pylyshyn (1988) argue that any successful model of cognition must use classical architecture; it must depend upon rule-based processing sensitive to constituent structure. This claim is central to their defense of classical AI against the recent enthusiasm for connectionism. Connectionist nets, they contend, may serve as theories of the implementation of cognition, but never as proper theories of psychology. Connectionist models are doomed to describing the brain at the wrong level, leaving the classical view to account for the mind.This paper considers whether recent results in connectionist research weigh against Fodor and Pylyshyn's thesis. The investigation will force us to develop criteria for determining exactly when a net is capable of systematic processing. Fodor and Pylyshyn clearly intend their thesis to affect the course of research in psychology. I will argue that when systematicity is defined in a way that makes the thesis relevant in this way, the thesis is challenged by recent progress in connectionism</div>
<div id='_748_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARCWC",this.href,0);return true;' href="http://www.springerlink.com/index/P4414695610528G3.pdf">http://www.springerlink.com/index/P4414695610528G3.pdf</a><br></div></div>
</div><!--entry-->

<div id='_749_entry' class='entry'><span ><span class='name'>Garson, James W.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("GARNRW",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1994.tb00214.x'>No representations without rules: The prospects for a compromise between paradigms in cognitive science.</a></span> <span class='pub_name'>Mind and Language</span> 9 (1):25-37. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8683974058645883972'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=No%20representations%20without%20rules+author%3AGarson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_749_links")'>More links</a>)</span>
<div id='_749_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARNRW",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119275779/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119275779/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_750_entry' class='entry'><span ><span class='name'>Garson, James W.</span> (1991). What connectionists cannot do: The threat to classical AI.</span> In Terence E. Horgan &amp; John L. Tienson (eds.), <em>Connectionism and the Philosophy of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15222548384562617980'>Cited by 1</a> | <span class='ll' onclick='$("_750_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20connectionists%20cannot%20do+author%3AGarson&amp;btnG=Search'>Google</a>)</span><div id='_750_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism and classicism aren't necessarily incompatible on symbolic discreteness, causal role, functional discreteness, constituency, representation of rules.</div></div>
</div><!--entry-->

<div id='_751_entry' class='entry'><span ><span class='name'>Guarini, Marcello</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("GUAADO",this.href,0);return true;' href='http://www.springerlink.com/content/x30362p60j65p226/fulltext.pdf'>A defence of connectionism against the "syntactic" argument.</a></span> <span class='pub_name'>Synthese</span> 128 (3):287-317. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11857724139504017614'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20defence%20of%20connectionism%20against%20the%20syntactic%20argument+author%3AGuarini&amp;btnG=Search'>Google</a> | <a href='javascript:show("_751_links")'>More links</a>)</span><div id='_751_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In "Representations without Rules, Connectionism and the Syntactic Argument'', Kenneth Aizawa argues against the view that connectionist nets can be understood as processing representations without the use of representation-level rules, and he provides a positive characterization of how to interpret connectionist nets as following representation-level rules. He takes Terry Horgan and John Tienson to be the targets of his critique. The present paper marshals functional and methodological considerations, gleaned from the practice of cognitive modelling, to argue against Aizawa's characterization of how connectionist nets may be understood as making use of representation-level rules</div>
<div id='_751_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUAADO",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=320358&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=320358&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUAADO",this.href,0);return true;' href="http://www.springerlink.com/index/X30362P60J65P226.pdf">http://www.springerlink.com/index/X30362P60J65P226.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GUAADO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/synt/2001/00000128/00000003/00320358">http://www.ingentaconnect.com/content/klu/synt/2001/00000128/00000003/00320358</a><br></div></div>
</div><!--entry-->

<div id='_752_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (2006). Cognition needs syntax but not rules.</span> In Robert J. Stainton (ed.), <em>Contemporary Debates in Cognitive Science</em>. Malden MA: Blackwell Publishing. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17487781317450941228'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognition%20needs%20syntax%20but%20not%20rules+author%3AHorgan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_753_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1994). Representations don't need rules: Reply to James Garson.</span> <span class='pub_name'>Mind and Language</span> 9 (1):1-24. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6274816172628594902'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representations%20don%27t%20need%20rules+author%3AHorgan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_754_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1989). Representation without rules.</span> <span class='pub_name'>Philosophical Perspectives</span> 17 (1):147-74. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_754_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representation%20without%20rules+author%3AHorgan&amp;btnG=Search'>Google</a>)</span><div id='_754_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Cognition uses structured representations without high-level rules, and connectionism is better at accounting for this. With remarks on exceptions to psychological laws, and the crisis in traditional AI.</div></div>
</div><!--entry-->

<div id='_755_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1987). Settling into a new paradigm.</span> <span class='pub_name'>Southern Journal of Philosophy Supplement</span> 26:97-113. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_755_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Settling%20into%20a%20new%20paradigm+author%3AHorgan&amp;btnG=Search'>Google</a>)</span><div id='_755_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On connectionism, basketball, and representation without rules. Responses to the "syntactic" and "semantic" arguments against connectionism. Nice.</div></div>
</div><!--entry-->

<div id='_756_entry' class='entry'><span ><span class='name'>Lormand, Eric</span> (1991). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("LORCAC",this.href,0);return true;' href='http://www-personal.umich.edu/~lormand/phil/cogsci/diss_ch0.htm'>Classical and Connectionist Models.</a></span></em></span> Dissertation, Mit <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Classical%20and%20Connectionist%20Models+author%3ALormand&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_757_entry' class='entry'><span ><span class='name'>Lormand, Eric</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("LORCLO",this.href,0);return true;' href='http://www-personal.umich.edu/~lormand/phil/cogsci/clot.htm'>Connectionist languages of thought.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12059967420397870685'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20languages%20of%20thought+author%3ALormand&amp;btnG=Search'>Google</a>)</span><div id='_757_abstract' class='extra' style='font-size:12px;'>Abstract: Fodor and Pylyshyn (1988) have presented an influential argument to the effect that any viable connectionist account of human cognition must implement a language of thought. Their basic strategy is to argue that connectionist models that do not implement a language of thought fail to account for the systematic relations among propositional attitudes. Several critics of the LOT hypothesis have tried to pinpoint flaws in Fodor and Pylyshynâs argument (Smolensky 1989; Clark, 1989; Chalmers, 1990; Braddon-Mitchell and Fitzpatrick, 1990). One thing I will try to show is that the argument can be rescued from these criticisms. (Score: LOT 1, Visitors 0.) However, I agree that the argument fails, and I will provide a new account of how it goes wrong. (The score becomes tied.) Of course, the failure of Fodor and Pylyshynâs argument does not mean that their conclusion is false. Consequently, some connectionist criticisms of Fodor and Pylyshynâs article take the form of direct counterexamples to their conclusion (Smolensky 1989; van Gelder, 1990; Chalmers, 1990). I will argue, however, that Fodor and Pylyshynâs conclusion survives confrontation with the alleged counterexamples. Finally, I provide an alternative argument that may succeed where Fodor and Pylyshynâs fails. (Final Score: LOT 3, Visitors 1.)</div>
</div><!--entry-->

<div id='_758_entry' class='entry'><span ><span class='name'>Markic, Olga</span> (1999). Connectionism and the language of thought: The cross-context stability of representations.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):43-57. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14558976158975704624'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20language%20of%20thought+author%3AMarkic&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_759_entry' class='entry'><span ><span class='name'>McClelland, J. L.</span> &amp; <span class='name'>Rumelhart, D. E.</span> (1985). Levels indeed! A response to Broadbent.</span> <span class='pub_name'>Journal of Experimental Psychology</span> 114:193-7. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_759_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Levels%20indeed%21%20A%20response%20to%20Broadbent+author%3AMcClelland&amp;btnG=Search'>Google</a>)</span><div id='_759_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Response to Broadbent 1985: Distributed models are at the algorithmic level. Elucidating the low-level/high-level relation via various analogies.</div></div>
</div><!--entry-->

<div id='_760_entry' class='entry'><span ><span class='name'>McLaughlin, Brian P.</span> &amp; <span class='name'>Warfield, F.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("MCLTAO",this.href,0);return true;' href='http://www.springerlink.com/content/v2103368752nx552/fulltext.pdf'>The allure of connectionism reexamined.</a></span> <span class='pub_name'>Synthese</span> 101 (3):365-400. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15266164186684029922'>Cited by 11</a> | <span class='ll' onclick='$("_760_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20allure%20of%20connectionism%20reexamined+author%3AMcLaughlin&amp;btnG=Search'>Google</a> | <a href='javascript:show("_760_links")'>More links</a>)</span><div id='_760_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that symbolic systems such as decision trees are as good at learning and pattern recognition as connectionist networks, and it is just as plausible that they are implemented in the brain.</div></div><div id='_760_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â There is currently a debate over whether cognitive architecture is classical or connectionist in nature. One finds the following three comparisons between classical architecture and connectionist architecture made in the pro-connectionist literature in this debate: (1) connectionist architecture is neurally plausible and classical architecture is not; (2) connectionist architecture is far better suited to model pattern recognition capacities than is classical architecture; and (3) connectionist architecture is far better suited to model the acquisition of pattern recognition capacities by learning than is classical architecture. If true, (1)â(3) would yield a compelling case against the view that cognitive architecture is classical, and would offer some reason to think that cognitive architecture may be connectionist. We first present the case for (1)â(3) in the very words of connectionist enthusiasts. We then argue that the currently available evidence fails to support any of (1)â(3)</div>
<div id='_760_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCLTAO",this.href,0);return true;' href="http://www.springerlink.com/index/V2103368752NX552.pdf">http://www.springerlink.com/index/V2103368752NX552.pdf</a><br></div></div>
</div><!--entry-->

<div id='_761_entry' class='entry'><span ><span class='name'>Rey, Georges</span> (1991). An explanatory budget for connectionism and eliminativism.</span> In Terence E. Horgan &amp; John L. Tienson (eds.), <em>Connectionism and the Philosophy of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=253360717923076289'>Cited by 11</a> | <span class='ll' onclick='$("_761_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=An%20explanatory%20budget%20for%20connectionism%20and%20eliminativism+author%3ARey&amp;btnG=Search'>Google</a>)</span><div id='_761_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Challenges connectionism to explain things that the classical approach seems to handle better: the structure, systematicity, causal role, and grain of propositional attitudes, their rational relations, and conceptual stability.</div></div>
</div><!--entry-->

<div id='_762_entry' class='entry'><span ><span class='name'>Schneider, Susan</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("SCHTLO-2",this.href,0);return true;' href='http://www.sas.upenn.edu/~sls/documents/LOTcompanion9.9.07_000.doc'>The language of thought.</a></span> In John Symons &amp; Paco Calvo (eds.), <em>Routledge Companion to Philosophy of Psychology</em>. Routledge. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20language%20of%20thought+author%3ASchneider&amp;btnG=Search'>Google</a>)</span><div id='_762_abstract' class='extra' style='font-size:12px;'>Abstract: According to the language of thought (or</div>
</div><!--entry-->

<div id='_763_entry' class='entry'><span ><span class='name'>Schneider, Susan</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href='http://www.sas.upenn.edu/~sls/documents/1NatureofSymbols.doc'>The nature of primitive symbols in the language of thought.</a></span> <span class='pub_name'>Mind and Language</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20nature%20of%20primitive%20symbols%20in%20the%20language%20of%20thought+author%3ASchneider&amp;btnG=Search'>Google</a> | <a href='javascript:show("_763_links")'>More links</a>)</span><div id='_763_abstract' class='extra' style='font-size:12px;'>Abstract: This paper provides a theory of the nature of symbols in the language of thought (LOT). My discussion consists in three parts. In part one, I provide three arguments for the individuation of primitive symbols in terms of total computational role. The first of these arguments claims that Classicism requires that primitive symbols be typed in this manner; no other theory of typing will suffice. The second argument contends that without this manner of symbol individuation, there will be computational processes that fail to supervene on syntax, together with the rules of composition and the computational algorithms. The third argument says that cognitive science needs a natural kind that is typed by total computational role. Otherwise, either cognitive science will be incomplete, or its laws will have counterexamples. Then, part two defends this view from a criticism, offered by both Jerry Fodor and Jesse Prinz, who respond to my view with the charge that because the types themselves are individuated</div>
<div id='_763_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang.doc">http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang.doc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang-1-2.pdf">http://www.sas.upenn.edu/~sls/documents/SchneiderNatureSymbolsMindLang-1-2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHTNO-2",this.href,0);return true;' href="http://www.sas.upenn.edu/~sls/documents/Schneider-MindLangSymbols.pdf">http://www.sas.upenn.edu/~sls/documents/Schneider-MindLangSymbols.pdf</a><br></div></div>
</div><!--entry-->

<div id='_764_entry' class='entry'><span ><span class='name'>ter Hark, Michel</span> (1995). Connectionism, behaviourism, and the language of thought.</span> In <em>Cognitive Patterns in Science and Common Sense</em>. Amsterdam: Rodopi. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20behaviourism%2C%20and%20the%20language%20of%20thought+author%3Ater%20Hark&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.3e'></a><a name=''></a><span class='myh3'>6.3e Subsymbolic Computation</span></p>

<div id='cat_6.3e' class='cat_content'>
<div id='__new_entries_6.3e__'></div><div id='__new_entry_6.3e__' class='entry'></div>
<div id='_765_entry' class='entry'><span ><span class='name'>Berkeley, Istvan S. N.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("BERMTG",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1236566.1236571'>Moving the goal posts: A reply to Dawson and Piercey.</a></span> <span class='pub_name'>Minds and Machines</span> 16 (4):471-478. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Moving%20the%20goal%20posts+author%3ABerkeley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_765_links")'>More links</a>)</span><div id='_765_abstract' class='extra' style='font-size:12px;'>Abstract:  Berkeley [Minds Machines 10 (2000) 1] described a methodology that showed the subsymbolic nature of an artificial neural network system that had been trained on a logic problem, originally described by Bechtel and Abrahamsen [Connectionism and the mind. Blackwells, Cambridge, MA, 1991]. It was also claimed in the conclusion of this paper that the evidence was suggestive that the network might, in fact, count as a symbolic system. Dawson and Piercey [Minds Machines 11 (2001) 197] took issue with this latter claim. They described some lesioning studies that they argued showed that Berkeleyâs (2000) conclusions were premature. In this paper, these lesioning studies are replicated and it is shown that the effects that Dawson and Piercey rely upon for their argument are merely an artifact of a threshold function they chose to employ. When a threshold function much closer to that deployed in the original studies is used, the significant effects disappear</div>
<div id='_765_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERMTG",this.href,0);return true;' href="http://www.springerlink.com/content/g46288063247n5nv/fulltext.pdf">http://www.springerlink.com/content/g46288063247n5nv/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERMTG",this.href,0);return true;' href="http://www.springerlink.com/index/G46288063247N5NV.pdf">http://www.springerlink.com/index/G46288063247N5NV.pdf</a><br></div></div>
</div><!--entry-->

<div id='_766_entry' class='entry'><span ><span class='name'>Berkeley, Istvan S. N.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BERWT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596715.596861'>What the #$*%! Is a subsymbol?</a></span> <span class='pub_name'>Minds and Machines</span> 10 (1):1-13. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1648541469376013643'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20the%20%23%24%2A%25%21%20Is%20a%20subsymbol%3F+author%3ABerkeley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_766_links")'>More links</a>)</span><div id='_766_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In 1988, Smolensky proposed that connectionist processing systems should be understood as operating at what he termed the `subsymbolic'' level. Subsymbolic systems should be understood by comparing them to symbolic systems, in Smolensky''s view. Up until recently, there have been real problems with analyzing and interpreting the operation of connectionist systems which have undergone training. However, recently published work on a network trained on a set of logic problems originally studied by Bechtel and Abrahamsen (1991) seems to offer the potential to provide a detailed, empirically based answer to questions about the nature of subsymbols. In this paper, a network analysis procedure and the results obtained using it are discussed. This provides the basis for an insight into the nature of subsymbols, which is surprising</div>
<div id='_766_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERWT",this.href,0);return true;' href="http://www.ucs.louisiana.edu/~isb9112/dept/phil341/subsymbol/subsymbol.html">http://www.ucs.louisiana.edu/~isb9112/dept/phil341/subsymbol/subsymbol.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERWT",this.href,0);return true;' href="http://www.springerlink.com/content/content/g81p084q505n1210/fulltext.pdf">http://www.springerlink.com/content/content/g81p084q505n1210/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERWT",this.href,0);return true;' href="http://www.springerlink.com/content/g81p084q505n1210/fulltext.pdf">http://www.springerlink.com/content/g81p084q505n1210/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERWT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=258824&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=258824&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERWT",this.href,0);return true;' href="http://www.springerlink.com/index/G81P084Q505N1210.pdf">http://www.springerlink.com/index/G81P084Q505N1210.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERWT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000001/00258824">http://www.ingentaconnect.com/content/klu/mind/2000/00000010/00000001/00258824</a><br></div></div>
</div><!--entry-->

<div id='_767_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("CHASCA-2",this.href,0);return true;' href='http://citeseer.ist.psu.edu/53863.html'>Subsymbolic computation and the chinese room.</a></span> In J. Dinsmore (ed.), <em>The Symbolic and Connectionist Paradigms: Closing the Gap</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2654225510692069431'>Cited by 29</a> | <span class='ll' onclick='$("_767_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Subsymbolic%20computation%20and%20the%20chinese%20room+author%3AChalmers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_767_links")'>More links</a>)</span><div id='_767_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Gives an account of symbolic vs. subsymbolic computation, and argues that the latter is less vulnerable to the Chinese-room intuition, as representations there are not computational tokens.</div></div><div id='_767_abstract' class='extra' style='font-size:12px;'>Abstract: More than a decade ago, philosopher John Searle started a long-running controversy with his paper âMinds, Brains, and Programsâ (Searle, 1980a), an attack on the ambitious claims of artificial intelligence (AI). With his now famous _Chinese Room_ argument, Searle claimed to show that despite the best efforts of AI researchers, a computer could never recreate such vital properties of human mentality as intentionality, subjectivity, and understanding. The AI research program is based on the underlying assumption that all important aspects of human cognition may in principle be captured in a computational model. This assumption stems from the belief that beyond a certain level, implementational details are irrelevant to cognition. According to this belief, neurons, and biological wetware in general, have no preferred status as the substrate for a mind. As it happens, the best examples of minds we have at present have arisen from a carbon-based substrate, but this is due to constraints of evolution and possibly historical accidents, rather than to an absolute metaphysical necessity. As a result of this belief, many cognitive scientists have chosen to focus not on the biological substrate of the mind, but instead on the abstract causal structure_ _that the mind embodies (at an appropriate level of abstraction). The view that it is abstract causal structure that is essential to mentality has been an implicit assumption of the AI research program since Turing (1950), but was first articulated explicitly, in various forms, by Putnam (1960), Armstrong (1970) and Lewis (1970), and has become known as _functionalism_. From here, it is a very short step to _computationalism_, the view that computational structure is what is important in capturing the essence of mentality. This step follows from a belief that any abstract causal structure can be captured computationally: a belief made plausible by the ChurchâTuring Thesis, which articulates the power</div>
<div id='_767_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASCA-2",this.href,0);return true;' href="http://consc.net/papers/subsymbolic.pdf">http://consc.net/papers/subsymbolic.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASCA-2",this.href,0);return true;' href="http://citeseer.ist.psu.edu/chalmers92subsymbolic.html">http://citeseer.ist.psu.edu/chalmers92subsymbolic.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHASCA-2",this.href,0);return true;' href="http://www.u.arizona.edu/~chalmers/papers/subsymbolic.pdf">http://www.u.arizona.edu/~chalmers/papers/subsymbolic.pdf</a><br></div></div>
</div><!--entry-->

<div id='_768_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("CLASCA",this.href,0);return true;' href='http://www.springerlink.com/content/content/l11l1130450x265x/fulltext.pdf'>Superpositional connectionism: A reply to Marinov.</a></span> <span class='pub_name'>Minds and Machines</span> 3 (3):271-81. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17507678307939712166'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Superpositional%20connectionism+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_768_links")'>More links</a>)</span><div id='_768_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Marinov''s critique I argue, is vitiated by its failure to recognize the distinctive role of superposition within the distributed connectionist paradigm. The use of so-called subsymbolic distributed encodings alone is not, I agree, enough to justify treating distributed connectionism as a distinctive approach. It has always been clear that microfeatural decomposition is both possible and actual within the confines of recognizably classical approaches. When such approaches also involve statistically-driven learning algorithms â as in the case of ID3 â the fundamental differences become even harder to spot. To see them, it is necessary to consider not just the nature of an acquired input-output function but the nature of the representational scheme underlying it. Differences between such schemes make themselves best felt outside the domain of immediate problem solving. It is in the more extended contexts of performance DURING learning and cognitive change as a result of SUBSEQUENT training on new tasks (or simultaneous training on several tasks) that the effects of superpositional storage techniques come to the fore. I conclude that subsymbols, distribution and statistically driven learning alone are indeed not of the essence. But connectionism is not just about subsymbols and distribution. It is about the generation of whole subsymbol SYSTEMS in which multiple distributed representations are created and superposed</div>
<div id='_768_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLASCA",this.href,0);return true;' href="http://www.springerlink.com/content/l11l1130450x265x/fulltext.pdf">http://www.springerlink.com/content/l11l1130450x265x/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLASCA",this.href,0);return true;' href="http://www.springerlink.com/index/L11L1130450X265X.pdf">http://www.springerlink.com/index/L11L1130450X265X.pdf</a><br></div></div>
</div><!--entry-->

<div id='_769_entry' class='entry'><span ><span class='name'>Cleeremans, Axel</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("CLETOH",this.href,0);return true;' href='http://citeseer.ist.psu.edu/326240.html'>The other hard problem: How to bridge the gap between subsymbolic and symbolic cognition.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21 (1):22-23. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20other%20hard%20problem+author%3ACleeremans&amp;btnG=Search'>Google</a> | <a href='javascript:show("_769_links")'>More links</a>)</span><div id='_769_abstract' class='extra' style='font-size:12px;'>Abstract: The constructivist notion that features are purely functional is incompatible with the classical computational metaphor of mind. I suggest that the discontent expressed by Schyns, Goldstone and Thibaut about fixed-features theories of categorization reflects the growing impact of connectionism, and show how their perspective is similar to recent research on implicit learning, consciousness, and development. A hard problem remains, however: How to bridge the gap between subsymbolic and symbolic cognition</div>
<div id='_769_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLETOH",this.href,0);return true;' href="http://srsc.ulb.ac.be/axcWWW/papers/BBS-schyns98.html">http://srsc.ulb.ac.be/axcWWW/papers/BBS-schyns98.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLETOH",this.href,0);return true;' href="http://srsc.ulb.ac.be/axcwww/papers/pdf/98-C-on-SGT.pdf">http://srsc.ulb.ac.be/axcwww/papers/pdf/98-C-on-SGT.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLETOH",this.href,0);return true;' href="http://srsc.ulb.ac.be/axcWWW/papers/pdf/98-C-on-SGT.pdf">http://srsc.ulb.ac.be/axcWWW/papers/pdf/98-C-on-SGT.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLETOH",this.href,0);return true;' href="http://srsc.ulb.ac.be/axcWWW/papers/pdf/98-C-on-SGT.pdf ">http://srsc.ulb.ac.be/axcWWW/papers/pdf/98-C-on-SGT.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLETOH",this.href,0);return true;' href="http://srsc-mac1.ulb.ac.be/axcWWW/papers/pdf/98-C-on-SGT.pdf">http://srsc-mac1.ulb.ac.be/axcWWW/papers/pdf/98-C-on-SGT.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLETOH",this.href,0);return true;' href="http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=30266&amp;jid=BBS&amp;volumeId=21&amp;issueId=01&amp;aid=30265">http://journals.cambridge.org/action/displayFulltext?type=1&fid=30266&jid=BBS&volumeId=21&issueId=01&aid=30265</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLETOH",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X98290108">http://www.journals.cambridge.org/abstract_S0140525X98290108</a><br></div></div>
</div><!--entry-->

<div id='_770_entry' class='entry'><span ><span class='name'>Hofstadter, Douglas R.</span> (1983). Artificial intelligence: Subcognition as computation.</span> In Fritz Machlup (ed.), <em>The Study of Information: Interdisciplinary Messages</em>. Wiley. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13456963788089430461'>Cited by 12</a> | <span class='ll' onclick='$("_770_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence+author%3AHofstadter&amp;btnG=Search'>Google</a>)</span><div id='_770_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>AI needs statistical emergence. For real semantics, symbols must be decomposable, complex, autonomous -- i.e. active.</div></div>
</div><!--entry-->

<div id='_771_entry' class='entry'><span ><span class='name'>Marinov, Marin</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("MAROTS",this.href,0);return true;' href='http://www.springerlink.com/content/nh755160272vv7jh/fulltext.pdf'>On the spuriousness of the symbolic/subsymbolic distinction.</a></span> <span class='pub_name'>Minds and Machines</span> 3 (3):253-70. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6671646933455395744'>Cited by 2</a> | <span class='ll' onclick='$("_771_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20spuriousness%20of%20the%20symbolic%2Fsubsymbolic%20distinction+author%3AMarinov&amp;btnG=Search'>Google</a> | <a href='javascript:show("_771_links")'>More links</a>)</span><div id='_771_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues with Smolensky: symbolic systems such as decision trees have all the positive features of neural networks (flexibility, lack of brittleness), and can represent concepts as sets of subconcepts. With a reply by Clark.</div></div><div id='_771_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The article criticises the attempt to establish connectionism as an alternative theory of human cognitive architecture through the introduction of thesymbolic/subsymbolic distinction (Smolensky, 1988). The reasons for the introduction of this distinction are discussed and found to be unconvincing. It is shown that thebrittleness problem has been solved for a large class ofsymbolic learning systems, e.g. the class oftop-down induction of decision-trees (TDIDT) learning systems. Also, the process of articulating expert knowledge in rules seems quite practical for many important domains, including common sense knowledge.The article discusses several experimental comparisons betweenTDIDT systems and artificial neural networks using the error backpropagation algorithm (ANNs usingBP). The properties of one of theTDIDT systemsID3 (Quinlan, 1986a) are examined in detail. It is argued that the differences in performance betweenANNs usingBP andTDIDT systems reflect slightly different inductive biases but are not systematic; these differences do not support the view that symbolic and subsymbolic systems are fundamentally incompatible. It is concluded, that thesymbolic/subsymbolic distinction is spurious. It cannot establish connectionism as an alternative cognitive architecture</div>
<div id='_771_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MAROTS",this.href,0);return true;' href="http://www.springerlink.com/index/NH755160272VV7JH.pdf">http://www.springerlink.com/index/NH755160272VV7JH.pdf</a><br></div></div>
</div><!--entry-->

<div id='_772_entry' class='entry'><span ><span class='name'>Rosenberg, Jay F.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("ROSTCP",this.href,0);return true;' href='http://www.springerlink.com/index/L3W0Q071T86441P1.pdf'>Treating connectionism properly: Reflections on Smolensky.</a></span> <span class='pub_name'>Psychological Research</span> 52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15820863030370978555'>Cited by 5</a> | <span class='ll' onclick='$("_772_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Treating%20connectionism%20properly+author%3ARosenberg&amp;btnG=Search'>Google</a>)</span><div id='_772_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Rejects Smolensky's PTC, as the proper interaction of the microscopic and macroscopic levels would take a "miracle".</div></div>
</div><!--entry-->

<div id='_773_entry' class='entry'><span ><span class='name'>Smolensky, Paul</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("SMOCS",this.href,0);return true;' href='http://www.springerlink.com/index/U4G043XG44Q38M84.pdf'>Connectionist, symbolic, and the brain.</a></span> <span class='pub_name'>AI Review</span> 1:95-109. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3518835011875481544'>Cited by 18</a> | <span class='ll' onclick='$("_773_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%2C%20symbolic%2C%20and%20the%20brain+author%3ASmolensky&amp;btnG=Search'>Google</a>)</span><div id='_773_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On connectionist networks as subsymbolic dynamic systems.</div></div>
</div><!--entry-->

<div id='_774_entry' class='entry'><span ><span class='name'>Smolensky, Paul</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("SMOOTP-2",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=190704.190739'>On the proper treatment of connectionism.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 11:1-23. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11897684759676747603'>Cited by 902</a> | <span class='ll' onclick='$("_774_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20proper%20treatment%20of%20connectionism+author%3ASmolensky&amp;btnG=Search'>Google</a>)</span><div id='_774_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism offers a complete account at the subsymbolic level, rather than an approximate account at the symbolic level.</div></div>
</div><!--entry-->
</div>
<p><a name='.6.3f'></a><a name=''></a><span class='myh3'>6.3f Philosophy of Connectionism, Misc</span></p>

<div id='cat_6.3f' class='cat_content'>
<div id='__new_entries_6.3f__'></div><div id='__new_entry_6.3f__' class='entry'></div>
<div id='_775_entry' class='entry'><span ><span class='name'>Abrahamsen, Adele A.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("ABRCIA",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1993.tb00300.x'>Cognizers' innards and connectionist nets: A holy alliance?</a></span> <span class='pub_name'>Mind and Language</span> 8 (4):520-530. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6967208833663353958'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognizers%27%20innards%20and%20connectionist%20nets+author%3AAbrahamsen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_775_links")'>More links</a>)</span>
<div id='_775_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ABRCIA",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119302073/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119302073/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_776_entry' class='entry'><span ><span class='name'>Aizawa, Kenneth</span> (1999). Connectionist rules: A rejoinder to Horgan and Tienson's connectionism and the philosophy of psychology.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):59-85. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17048202477653776906'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20rules+author%3AAizawa&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_777_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1985). Are the new PDP models of cognition cognitivist or associationist?</span> <span class='pub_name'>Behaviorism</span> 13:53-61. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Are%20the%20new%20PDP%20models%20of%20cognition%20cognitivist%20or%20associationist%3F+author%3ABechtel&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_778_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> &amp; <span class='name'>Abrahamson, A.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("BECBTE",this.href,0);return true;' href='http://www.springerlink.com/content/ww512705u27062rv/fulltext.pdf'>Beyond the exclusively propositional era.</a></span> <span class='pub_name'>Synthese</span> 82 (2):223-53. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9529681103140628501'>Cited by 9</a> | <span class='ll' onclick='$("_778_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Beyond%20the%20exclusively%20propositional%20era+author%3ABechtel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_778_links")'>More links</a>)</span><div id='_778_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>An account of the shift from propositions to pattern recognition in the study of cognition: knowing-how, imagery, categorization, connectionism.</div></div><div id='_778_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Contemporary epistemology has assumed that knowledge is represented in sentences or propositions. However, a variety of extensions and alternatives to this view have been proposed in other areas of investigation. We review some of these proposals, focusing on (1) Ryle's notion of knowing how and Hanson's and Kuhn's accounts of theory-laden perception in science; (2) extensions of simple propositional representations in cognitive models and artificial intelligence; (3) the debate concerning imagistic versus propositional representations in cognitive psychology; (4) recent treatments of concepts and categorization which reject the notion of necessary and sufficient conditions; and (5) parallel distributed processing (connectionist) models of cognition. This last development is especially promising in providing a flexible, powerful means of representing information nonpropositionally, and carrying out at least simple forms of inference without rules. Central to several of the proposals is the notion that much of human cognition might consist in pattern recognition rather than manipulation of rules and propositions</div>
<div id='_778_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECBTE",this.href,0);return true;' href="http://www.springerlink.com/index/WW512705U27062RV.pdf">http://www.springerlink.com/index/WW512705U27062RV.pdf</a><br></div></div>
</div><!--entry-->

<div id='_779_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1988). Connectionism and rules and representation systems: Are they compatible?</span> <span class='pub_name'>Philosophical Psychology</span> 1 (1):5-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8285428876924151207'>Cited by 43</a> | <span class='ll' onclick='$("_779_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20rules%20and%20representation%20systems+author%3ABechtel&amp;btnG=Search'>Google</a>)</span><div id='_779_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>There's room for both styles within a single mind. The rule-based level needn't be autonomous; the connectionist level plays a role in pattern recognition, concepts, and so on.</div></div><div id='_779_abstract' class='extra' style='font-size:12px;'>Abstract: The introduction of connectionist or parallel distributed processing (PDP) systems to model cognitive functions has raised the question of the possible relations between these models and traditional information processing models which employ rules to manipulate representations. After presenting a brief account of PDP models and two ways in which they are commonly interpreted by those seeking to use them to explain cognitive functions, I present two ways one might relate these models to traditional information processing models and so not totally repudiate the tradition of modelling cognition through systems of rules and representations. The proposal that seems most promising is that PDP-type structures might provide the underlying framework in which a rule and representation model might be implemented. To show how one might pursue such a strategy, I discuss recent research by Barsalou on the instability of concepts and show how that might be accounted for in a system whose microstructure had a PDP architecture. I also outline how adopting a multi-leveled view of the mind, where on one level the mind employed a PDP-type system and at another level constituted a rule processing system, would allow researchers to relocate some problems which seemed difficult to explain at one level, such as the capacity for concept learning, to another level where it could be handled in a straightforward manner</div>
</div><!--entry-->

<div id='_780_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1987). Connectionism and the philosophy of mind.</span> <span class='pub_name'>Southern Journal of Philosophy Supplement</span> 26:17-41. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7865252693266667593'>Cited by 18</a> | <span class='ll' onclick='$("_780_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20philosophy%20of%20mind+author%3ABechtel&amp;btnG=Search'>Google</a>)</span><div id='_780_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lots of questions about connectionism.</div></div>
</div><!--entry-->

<div id='_781_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> &amp; <span class='name'>Abrahamsen, Adele A.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("BECCAT-2",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=MqgsysfGzG4C&amp;oi=fnd&amp;pg=PA69&amp;ots=HJua1HD0KQ&amp;sig=t2S6EHOseKWsFu8T0fEcmyNN9Dw'>Connectionism and the future of folk psychology.</a></span> In Robert G. Burton (ed.), <em>Minds: Natural and Artificial</em>. SUNY Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13655710841248014936'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20future%20of%20folk%20psychology+author%3ABechtel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_781_links")'>More links</a>)</span>
<div id='_781_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECCAT-2",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=k9SWKieq6-gC&amp;oi=fnd&amp;pg=PA340&amp;ots=p7B1pO-v5y&amp;sig=QFXNQv5o0oQLrXrlzp1rPvcShxo">http://books.google.com/books?hl=en&lr=&id=k9SWKieq6-gC&oi=fnd&pg=PA340&ots=p7B1pO-v5y&sig=QFXNQv5o0oQLrXrlzp1rPvcShxo</a><br></div></div>
</div><!--entry-->

<div id='_782_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1985). Contemporary connectionism: Are the new parallel distributed processing models cognitive or associationist?</span> <span class='pub_name'>Behaviorism</span> 13:53-61. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12932671860917054780'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Contemporary%20connectionism+author%3ABechtel&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_783_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("BECTCF",this.href,0);return true;' href='http://www.springerlink.com/content/uh58178q9414w317/fulltext.pdf'>The case for connectionism.</a></span> <span class='pub_name'>Philosophical Studies</span> 71 (2):119-54. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7618283393775204433'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20case%20for%20connectionism+author%3ABechtel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_783_links")'>More links</a>)</span>
<div id='_783_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECTCF",this.href,0);return true;' href="http://www.springerlink.com/index/UH58178Q9414W317.pdf">http://www.springerlink.com/index/UH58178Q9414W317.pdf</a><br></div></div>
</div><!--entry-->

<div id='_784_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("BECTPB",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1993.tb00301.x'>The path beyond first-order connectionism.</a></span> <span class='pub_name'>Mind and Language</span> 8 (4):531-539. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7307642183661371890'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20path%20beyond%20first-order%20connectionism+author%3ABechtel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_784_links")'>More links</a>)</span>
<div id='_784_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECTPB",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119302074/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119302074/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_785_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1986). What happens to accounts of mind-brain relations if we forgo an architecture of rules and representations?</span> <span class='pub_name'>Philosophy of Science Association</span> 1986. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_785_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20happens%20to%20accounts%20of%20mind-brain%20relations%20if%20we%20forgo%20an%20architecture%20of%20rules%20and%20representations%3F+author%3ABechtel&amp;btnG=Search'>Google</a>)</span><div id='_785_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the relationship between connectionism, symbol processing, psychology and neuroscience.</div></div>
</div><!--entry-->

<div id='_786_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("BECWSA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/67036.html'>What should a connectionist philosophy of science look like?</a></span> In <em>The Churchlands and Their Critics</em>. Oup. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15454518167119337931'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20should%20a%20connectionist%20philosophy%20of%20science%20look%20like%3F+author%3ABechtel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_786_links")'>More links</a>)</span><div id='_786_abstract' class='extra' style='font-size:12px;'>Abstract: The reemergence of connectionism<sup>2</sup> has profoundly altered the philosophy of mind. Paul Churchland has argued that it should equally transform the philosophy of science. He proposes that connectionism offers radical and useful new ways of understanding theories and explanations</div>
<div id='_786_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECWSA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/134759.html">http://citeseer.ist.psu.edu/134759.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECWSA",this.href,0);return true;' href="http://mechanism.ucsd.edu/~bill/research/CHURCHLA.pdf">http://mechanism.ucsd.edu/~bill/research/CHURCHLA.pdf</a><br></div></div>
</div><!--entry-->

<div id='_787_entry' class='entry'><span ><span class='name'>Berkeley, Istvan S. N.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("BERARH",this.href,0);return true;' href='http://www.ucs.louisiana.edu/~isb9112/dept/phil341/histconn.html'>A revisionist history of connectionism.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18097111234504107151'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20revisionist%20history%20of%20connectionism+author%3ABerkeley&amp;btnG=Search'>Google</a>)</span><div id='_787_abstract' class='extra' style='font-size:12px;'>Abstract: According to the standard (recent) history of connectionism (see for example the accounts offered by Hecht-Nielsen (1990: pp. 14-19) and Dreyfus and Dreyfus (1988), or Papert's (1988: pp. 3-4) somewhat whimsical description), in the early days of Classical Computational Theory of Mind (CCTM) based AI research, there was also another allegedly distinct approach, one based upon network models. The work on network models seems to fall broadly within the scope of the term 'connectionist' (see Aizawa 1992), although the term had yet to be coined at the time. These two approaches were "two daughter sciences" according to Papert (1988: p. 3). The fundamental difference between these two 'daughters', lay (according to Dreyfus and Dreyfus (1988: p. 16)) in what they took to be the paradigm of intelligence. Whereas the early connectionists took learning to be fundamental, the traditional school concentrated upon problem solving</div>
</div><!--entry-->

<div id='_788_entry' class='entry'><span ><span class='name'>Berkeley, IstvÃ¡n S. N.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("BERSMO",this.href,0);return true;' href='http://www.ucs.louisiana.edu/~isb9112/dept/phil341/myths/myths.html'>Some myths of connectionism.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 1 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Some%20myths%20of%20connectionism+author%3ABerkeley&amp;btnG=Search'>Google</a>)</span><div id='_788_abstract' class='extra' style='font-size:12px;'>Abstract: Since the emergence of what Fodor and Pylyshyn (1988) call 'new connectionism', there can be little doubt that connectionist research has become a significant topic for discussion in the Philosophy of Cognitive Science and the Philosophy of Mind. In addition to the numerous papers on the topic in philosophical journals, almost every recent book in these areas contain at least a brief reference to, or discussion of, the issues raised by connectionist research (see Sterelny 1990, Searle, 1992, and O NuallÃ¡in, 1995, for example). Other texts have focused almost exclusively upon connectionist issues (see Clark, 1993, Bechtel and Abrahamsen, 1991 and Lloyd, 1989, for example). Regrettably the discussions of connectionism found in the philosophical literature suffer from a number of deficiencies. My purpose in this paper is to highlight one particular problem and attempt to take a few steps to remedy the situation</div>
</div><!--entry-->

<div id='_789_entry' class='entry'><span ><span class='name'>Berkeley, Istvan S. N.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("BERWIC",this.href,0);return true;' href='http://www.ucs.louisiana.edu/~isb9112/dept/phil341/wisconn.html'>What is connectionism?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20connectionism%3F+author%3ABerkeley&amp;btnG=Search'>Google</a>)</span><div id='_789_abstract' class='extra' style='font-size:12px;'>Abstract: Connectionism is a style of modeling based upon networks of interconnected simple processing devices. This style of modeling goes by a number of other names too. Connectionist models are also sometimes referred to as 'Parallel Distributed Processing' (or PDP for short) models or networks.1 Connectionist systems are also sometimes referred to as 'neural networks' (abbreviated to NNs) or 'artificial neural networks' (abbreviated to ANNs). Although there may be some rhetorical appeal to this neural nomenclature, it is in fact misleading as connectionist networks are commonly significantly dissimilar to neurological systems. For this reason, I will avoid using this terminology, other than in direct quotations. Instead, I will follow the practice I have adopted above and use 'connectionist' as my primary term for systems of this kind</div>
</div><!--entry-->

<div id='_790_entry' class='entry'><span ><span class='name'>Bickle, John</span> (1995). Connectionism, reduction, and multiple realizability.</span> <span class='pub_name'>Behavior and Philosophy</span> 23 (2):29-39. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9802844707783889065'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20reduction%2C%20and%20multiple%20realizability+author%3ABickle&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_791_entry' class='entry'><span ><span class='name'>Blackmore, Susan J.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("BLATCO",this.href,0);return true;' href='http://www.susanblackmore.co.uk/journalism/NSradiantcool03.htm'>The case of the mysterious mind: Review of <em>Radiant Cool</em>, by Dan Lloyd.</a></span> <span class='pub_name'>New Scientist</span> 13:36-39. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13646789545174676481'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20case%20of%20the%20mysterious%20mind+author%3ABlackmore&amp;btnG=Search'>Google</a> | <a href='javascript:show("_791_links")'>More links</a>)</span>
<div id='_791_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BLATCO",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=250536AN">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=250536AN</a><br></div></div>
</div><!--entry-->

<div id='_792_entry' class='entry'><span ><span class='name'>Bradshaw, Denny E.</span> (1991). Connectionism and the specter of representationalism.</span> In Terence E. Horgan &amp; John L. Tienson (eds.), <em>Connectionism and the Philosophy of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7515340549060278432'>Cited by 4</a> | <span class='ll' onclick='$("_792_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20specter%20of%20representationalism+author%3ABradshaw&amp;btnG=Search'>Google</a>)</span><div id='_792_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that connectionism allows for a more plausible epistemology of perception, compatible with direct realism rather than representationalism. With remarks on Fodor and Pylshyn's argument against Gibson.</div></div>
</div><!--entry-->

<div id='_793_entry' class='entry'><span ><span class='name'>Christie, Drew</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("CHRCOB",this.href,0);return true;' href='http://www.springerlink.com/content/lq37582576241k87/fulltext.pdf'>Comments on Bechtel's <em>The Case for Connectionism</em>.</a></span> <span class='pub_name'>Philosophical Studies</span> 71 (2):155-162. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13293074030441813309'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Comments%20on%20Bechtel%27s%20The%20Case%20for%20Connectionism+author%3AChristie&amp;btnG=Search'>Google</a> | <a href='javascript:show("_793_links")'>More links</a>)</span>
<div id='_793_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHRCOB",this.href,0);return true;' href="http://www.springerlink.com/index/LQ37582576241K87.pdf">http://www.springerlink.com/index/LQ37582576241K87.pdf</a><br></div></div>
</div><!--entry-->

<div id='_794_entry' class='entry'><span ><span class='name'>Churchland, Patricia S.</span> &amp; <span class='name'>Sejnowski, Terrence J.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("CHUNRA",this.href,0);return true;' href='http://papers.cnl.salk.edu/PDFs/Neural Representation and Neural Computation 1990-3325.pdf'>Neural representation and neural computation.</a></span> In L. Nadel (ed.), <em>Neural Connections, Mental Computations</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8076491912997423053'>Cited by 78</a> | <span class='ll' onclick='$("_794_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Neural%20representation%20and%20neural%20computation+author%3AChurchland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_794_links")'>More links</a>)</span><div id='_794_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Implications of connectionism and neuroscience for our concept of mind.</div></div>
<div id='_794_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHUNRA",this.href,0);return true;' href="http://links.jstor.org/sici?sici=1520-8583(1990)4&lt;343:NRANC&gt;2.0.CO;2-P">http://links.jstor.org/sici?sici=1520-8583(1990)4<343:NRANC>2.0.CO;2-P</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHUNRA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=1520-8583(1990)4&lt;343:NRANC&gt;2.0.CO;2-P">http://www.jstor.org/sici?sici=1520-8583(1990)4<343:NRANC>2.0.CO;2-P</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHUNRA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2214198.pdf">http://www.jstor.org/stable/pdfplus/2214198.pdf</a><br></div></div>
</div><!--entry-->

<div id='_795_entry' class='entry'><span ><span class='name'>Churchland, Paul M.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("CHUOTN",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=114408'>On the nature of explanation: A PDP approach.</a></span> In <em>A Neurocomputational Perspective</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3039466377366433859'>Cited by 9</a> | <span class='ll' onclick='$("_795_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20nature%20of%20explanation+author%3AChurchland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_795_links")'>More links</a>)</span><div id='_795_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>We achieve explanatory understanding not through the manipulation of propositions but through the activation of prototypes.</div></div>
<div id='_795_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHUOTN",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=87498.87581">http://portal.acm.org/citation.cfm?id=87498.87581</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHUOTN",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1990PhyD...42..281C">http://adsabs.harvard.edu/abs/1990PhyD...42..281C</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHUOTN",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=LqszY4kBw98C&amp;oi=fnd&amp;pg=PA75&amp;ots=qXgwkOTy04&amp;sig=yMyj0EhkKs802wSnrOjoUyDdztg">http://books.google.com/books?hl=en&lr=&id=LqszY4kBw98C&oi=fnd&pg=PA75&ots=qXgwkOTy04&sig=yMyj0EhkKs802wSnrOjoUyDdztg</a><br></div></div>
</div><!--entry-->

<div id='_796_entry' class='entry'><span ><span class='name'>Churchland, Paul M.</span> (1989). On the nature of theories: A neurocomputational perspective.</span> <span class='pub_name'>Minnesota Studies in the Philosophy of Science</span> 14. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6526896635404685552'>Cited by 22</a> | <span class='ll' onclick='$("_796_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20nature%20of%20theories+author%3AChurchland&amp;btnG=Search'>Google</a>)</span><div id='_796_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism will revolutionize our review of scientific theories: >From the deductive-nomological view to descent in weight-space. Some cute analogies.</div></div>
</div><!--entry-->

<div id='_797_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("CLACCA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(199006)41:2&lt;195:CCAE&gt;2.0.CO;2-U'>Connectionism, competence and explanation.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 41 (June):195-222. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5702322979793391798'>Cited by 25</a> | <span class='ll' onclick='$("_797_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20competence%20and%20explanation+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_797_links")'>More links</a>)</span><div id='_797_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism separates processing from competence. Instead of hopping down Marr's levels (theory->process), connectionism goes (1) task (2) low-level performance (3) extract theory from process. Cute.</div></div><div id='_797_abstract' class='extra' style='font-size:12px;'>Abstract: A competence model describes the abstract structure of a solution to some problem. or class of problems, facing the would-be intelligent system. Competence models can be quite derailed, specifying far more than merely the function to be computed. But for all that, they are pitched at some level of abstraction from the details of any particular algorithm or processing strategy which may be said to realize the competence. Indeed, it is the point and virtue of such models to specify some equivalence class of algorithms/processing strategies so that the common properties highlighted by the chosen class may feature in psychologically interesting accounts. A question arises concerning the type of relation a theorist might expect to hold between such a competence model and a psychologically real processing strategy. Classical work in cognitive science expects the actual processing to depend on explicit or tacit knowledge of the competence theory. Connectionist work, for reasons to be explained, represents a departure from this norm. But the precise way in which a connectionist approach may disturb the satisfying classical symmetry of competence and processing has yet to be properly specified. A standard ?Newtonian? connectionist account, due to Paul Smolensky, is discussed and contrasted with a somewhat different ?rogue? account. A standard connectionist understanding has it that a classical competence theory describes an idealized subset of a network's behaviour. But the network's behaviour is not to be explained by its embodying explicit or tacit knowledge of the information laid out in the competence theory. A rogue model, by contrast, posits either two systems, or two aspects of a single system, such that one system does indeed embody the knowledge laid out in the competence theory</div>
<div id='_797_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLACCA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(199006)41:2&lt;195:CCAE&gt;2.0.CO;2-U">http://www.jstor.org/sici?sici=0007-0882(199006)41:2<195:CCAE>2.0.CO;2-U</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLACCA",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/41/2/195">http://bjps.oxfordjournals.org/cgi/content/abstract/41/2/195</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLACCA",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/41/2/195">http://bjps.oxfordjournals.org/cgi/reprint/41/2/195</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLACCA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/687772.pdf">http://www.jstor.org/stable/pdfplus/687772.pdf</a><br></div></div>
</div><!--entry-->

<div id='_798_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1995). Connectionist minds.</span> In <em>Connectionism: Debates on Psychological Explanation</em>. Cambridge: Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18374444407575545807'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20minds+author%3AClark&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_799_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1989). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("CLAM",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=70109'>Microcognition.</a></span></em></span> MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12661705902130334156'>Cited by 300</a> | <span class='ll' onclick='$("_799_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Microcognition+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_799_links")'>More links</a>)</span><div id='_799_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>All kinds of stuff on connectionism and philosophy.</div></div>
<div id='_799_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAM",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=SERIES9429.70109">http://portal.acm.org/citation.cfm?id=SERIES9429.70109</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAM",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;sig=-6Hu6F83CquItCX-Lxms0YhuGlU">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&sig=-6Hu6F83CquItCX-Lxms0YhuGlU</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAM",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;ots=_UfWpc94Y7&amp;sig=TrQYGdxKRMudEvqmpbDjxjPwIaI">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&ots=_UfWpc94Y7&sig=TrQYGdxKRMudEvqmpbDjxjPwIaI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAM",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;ots=_UfVoa35-e&amp;sig=WxqyIRmYNeyowDGBx4FLlmfv08k">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&ots=_UfVoa35-e&sig=WxqyIRmYNeyowDGBx4FLlmfv08k</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAM",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;ots=_UeYse32-f&amp;sig=faEp603Cxj7uK7mYqVrZXJWpOco">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&ots=_UeYse32-f&sig=faEp603Cxj7uK7mYqVrZXJWpOco</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAM",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;ots=_V6Vrb45X9&amp;sig=Qq7mNE3j0WBCdbrqfwaSqfW5LJ8">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&ots=_V6Vrb45X9&sig=Qq7mNE3j0WBCdbrqfwaSqfW5LJ8</a><br></div></div>
</div><!--entry-->

<div id='_800_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("CLAMCA",this.href,0);return true;' href='http://www.hss.caltech.edu/~steve/clark.pdf'>Microfunctionalism: Connectionism and the Scientific Explanation of Mental States.</a></span> In A. Clark (ed.), <em>Microcognition: Philosophy, Cognitive Science, and Parallel Distributed Processing</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Microfunctionalism+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_800_links")'>More links</a>)</span><div id='_800_abstract' class='extra' style='font-size:12px;'>Abstract: This is an amended version of material that first appeared in A. Clark, Microcognition: Philosophy, Cognitive Science, and Parallel Distributed Processing (MIT Press, Cambridge, MA, 1989), Ch. 1, 2, and 6. It appears in German translation in Metzinger,T (Ed) DAS LEIB-SEELE-PROBLEM IN DER ZWEITEN HELFTE DES 20 JAHRHUNDERTS (Frankfurt am Main: Suhrkamp. 1999)</div>
<div id='_800_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMCA",this.href,0);return true;' href="http://www.cogs.indiana.edu/andy/microfx.pdf">http://www.cogs.indiana.edu/andy/microfx.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMCA",this.href,0);return true;' href="http://www.philosophy.ed.ac.uk/staff/clark/pubs/microfx.pdf">http://www.philosophy.ed.ac.uk/staff/clark/pubs/microfx.pdf</a><br></div></div>
</div><!--entry-->

<div id='_801_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1991). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("CLAMPC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=70109'>Microcognition: Philosophy, Cognitive Science, and Parallel Distributed Processing.</a></span></em></span> Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15262065068522698984'>Cited by 224</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Microcognition+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_801_links")'>More links</a>)</span>
<div id='_801_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMPC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=SERIES9429.70109">http://portal.acm.org/citation.cfm?id=SERIES9429.70109</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMPC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;sig=-6Hu6F83CquItCX-Lxms0YhuGlU">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&sig=-6Hu6F83CquItCX-Lxms0YhuGlU</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMPC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;ots=_UfVoa50X8&amp;sig=GCwUSyOMg9UCDXJEGf1L3cfzo-g">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&ots=_UfVoa50X8&sig=GCwUSyOMg9UCDXJEGf1L3cfzo-g</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAMPC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Hfv1WuU_HP0C&amp;oi=fnd&amp;pg=PP13&amp;ots=_UeYse350e&amp;sig=-kb67YkQLwQCZ538E07C2vpuH-4">http://books.google.com/books?hl=en&lr=&id=Hfv1WuU_HP0C&oi=fnd&pg=PP13&ots=_UeYse350e&sig=-kb67YkQLwQCZ538E07C2vpuH-4</a><br></div></div>
</div><!--entry-->

<div id='_802_entry' class='entry'><span ><span class='name'>Clark, Andy</span> &amp; <span class='name'>Eliasmith, Chris</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("CLAPII",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=303568.303914'>Philosophical issues in brain theory and connectionism.</a></span> In Michael A. Arbib (ed.), <em>The Handbook of Brain Theory and Neural Networks, Second Edition</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16348556827645204492'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophical%20issues%20in%20brain%20theory%20and%20connectionism+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_802_links")'>More links</a>)</span>
<div id='_802_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAPII",this.href,0);return true;' href="http://watarts.uwaterloo.ca/~celiasmi/Papers/withclark.html">http://watarts.uwaterloo.ca/~celiasmi/Papers/withclark.html</a><br></div></div>
</div><!--entry-->

<div id='_803_entry' class='entry'><span ><span class='name'>Collier, Mark</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("COLFTG",this.href,0);return true;' href='http://www.morris.umn.edu/academic/philosophy/Collier/collierhumestudies.pdf'>Filling the Gaps: Hume and Connectionism on the Continued Existence of Unperceived Objects&quot;.</a></span> <span class='pub_name'>Hume Studies</span> 25 (1 and 2):155-170. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Filling%20the%20Gaps+author%3ACollier&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_804_entry' class='entry'><span ><span class='name'>Copeland, Jack</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("COPOAT",this.href,0);return true;' href='http://citeseer.ist.psu.edu/389627.html'>On Alan Turing's anticipation of connectionism.</a></span> <span class='pub_name'>Synthese</span> 108 (3):361-377. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13210611891004221630'>Cited by 20</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20Alan%20Turing%27s%20anticipation%20of%20connectionism+author%3ACopeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_804_links")'>More links</a>)</span><div id='_804_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â It is not widely realised that Turing was probably the first person to consider building computing machines out of simple, neuron-like elements connected together into networks in a largely random manner. Turing called his networks unorganised machines. By the application of what he described as appropriate interference, mimicking education an unorganised machine can be trained to perform any task that a Turing machine can carry out, provided the number of neurons is sufficient. Turing proposed simulating both the behaviour of the network and the training process by means of a computer program. We outline Turing's connectionist project of 1948</div>
<div id='_804_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPOAT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/copeland96alan.html">http://citeseer.ist.psu.edu/copeland96alan.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPOAT",this.href,0);return true;' href="http://www.springerlink.com/content/v3571g00l3504874/fulltext.pdf">http://www.springerlink.com/content/v3571g00l3504874/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPOAT",this.href,0);return true;' href="http://www.springerlink.com/index/V3571G00L3504874.pdf">http://www.springerlink.com/index/V3571G00L3504874.pdf</a><br></div></div>
</div><!--entry-->

<div id='_805_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("CUMCAT",this.href,0);return true;' href='http://links.jstor.org/sici?sici=1520-8583(1995)9&lt;105:CATRCO&gt;2.0.CO;2-C'>Connectionist and the rationale constraint on cognitive explanations.</a></span> <span class='pub_name'>Philosophical Perspectives</span> 9:105-25. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8274846859875753550'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20and%20the%20rationale%20constraint%20on%20cognitive%20explanations+author%3ACummins&amp;btnG=Search'>Google</a> | <a href='javascript:show("_805_links")'>More links</a>)</span>
<div id='_805_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CUMCAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=1520-8583(1995)9&lt;105:CATRCO&gt;2.0.CO;2-C">http://www.jstor.org/sici?sici=1520-8583(1995)9<105:CATRCO>2.0.CO;2-C</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CUMCAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2214214.pdf">http://www.jstor.org/stable/pdfplus/2214214.pdf</a><br></div></div>
</div><!--entry-->

<div id='_806_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> &amp; <span class='name'>Schwarz, Georg</span> (1991). Connectionism, computation, and cognition.</span> In Terence E. Horgan &amp; John L. Tienson (eds.), <em>Connectionism and the Philosophy of Mind</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12154867876528401445'>Cited by 55</a> | <span class='ll' onclick='$("_806_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20computation%2C%20and%20cognition+author%3ACummins&amp;btnG=Search'>Google</a>)</span><div id='_806_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Explicates computationalism, and discusses ways in which connectionism might end up non-computational: if causal states cross-classify representational states, or if transitions between representations aren't computable.</div></div>
</div><!--entry-->

<div id='_807_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> &amp; <span class='name'>Schwarz, Georg</span> (1987). Radical connectionism.</span> <span class='pub_name'>Southern Journal of Philosophy Supplement</span> 26:43-61. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3346078037749611909'>Cited by 8</a> | <span class='ll' onclick='$("_807_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Radical%20connectionism+author%3ACummins&amp;btnG=Search'>Google</a>)</span><div id='_807_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On computation and representation in AI and connectionism, and on problems for radical connectionism in reconciling these without denying representation or embracing mystery.</div></div>
</div><!--entry-->

<div id='_808_entry' class='entry'><span ><span class='name'>Davies, Martin</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("DAVCMA-2",this.href,0);return true;' href='http://philrsss.anu.edu.au/~mdavies/papers/connmod.pdf'>Connectionism, modularity and tacit knowledge.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 40 (December):541-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15853784533252701234'>Cited by 11</a> | <span class='ll' onclick='$("_808_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20modularity%20and%20tacit%20knowledge+author%3ADavies&amp;btnG=Search'>Google</a> | <a href='javascript:show("_808_links")'>More links</a>)</span><div id='_808_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues that connectionist networks don't have tacit knowledge of modular theories (as representations lack the appropriate structure, etc.).</div></div><div id='_808_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper, I define tacit knowledge as a kind of causal-explanatory structure, mirroring the derivational structure in the theory that is tacitly known. On this definition, tacit knowledge does not have to be explicitly represented. I then take the notion of a modular theory, and project the idea of modularity to several different levels of description: in particular, to the processing level and the neurophysiological level. The fundamental description of a connectionist network lies at a level between the processing level and the physiological level. At this level, connectionism involves a characteristic departure from modularity, and a correlative absence of syntactic structure. This is linked to the fact that tacit knowledge descriptions of networks are only approximately true. A consequence is that strict causal systematicity in cognitive processes poses a problem for the connectionist programme</div>
<div id='_808_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAVCMA-2",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0007-0882(198912)40:4&lt;541:CMATK&gt;2.0.CO;2-B">http://links.jstor.org/sici?sici=0007-0882(198912)40:4<541:CMATK>2.0.CO;2-B</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAVCMA-2",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(198912)40:4&lt;541:CMATK&gt;2.0.CO;2-B">http://www.jstor.org/sici?sici=0007-0882(198912)40:4<541:CMATK>2.0.CO;2-B</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAVCMA-2",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/40/4/541">http://bjps.oxfordjournals.org/cgi/content/abstract/40/4/541</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAVCMA-2",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/40/4/541">http://bjps.oxfordjournals.org/cgi/reprint/40/4/541</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAVCMA-2",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/687740.pdf">http://www.jstor.org/stable/pdfplus/687740.pdf</a><br></div></div>
</div><!--entry-->

<div id='_809_entry' class='entry'><span ><span class='name'>Duran, Jane</span> &amp; <span class='name'>Doell, Ruth</span> (1993). Naturalized epistemology, connectionism and biology.</span> <span class='pub_name'>Dialectica</span> 47 (4):327-336. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Naturalized%20epistemology%2C%20connectionism%20and%20biology+author%3ADuran&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_810_entry' class='entry'><span ><span class='name'>GarcÃ­a-Carpintero, Manuel</span> (1995). The philosophical import of connectionism: A critical notice of Andy Clark's associative engines.</span> <span class='pub_name'>Mind and Language</span> 10 (4):370-401. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8555967585114484415'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20philosophical%20import%20of%20connectionism+author%3AGarc%C3%ADa-Carpintero&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_811_entry' class='entry'><span ><span class='name'>Globus, Gordon G.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("GLODAC",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793921609~fulltext=713240930'>Derrida and connectionism: Differance in neural nets.</a></span> <span class='pub_name'>Philosophical Psychology</span> 5 (2):183-97. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2480598839777625501'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Derrida%20and%20connectionism+author%3AGlobus&amp;btnG=Search'>Google</a>)</span><div id='_811_abstract' class='extra' style='font-size:12px;'>Abstract: A possible relation between Derrida's deconstruction of metaphysics and connectionism is explored by considering diff rance in neural nets terms. First diff rance , as the crossing of Saussurian difference and Freudian deferral, is modeled and then the fuller 'sheaf of diff rance is taken up. The metaphysically conceived brain has two versions: in the traditional computational version the brain processes information like a computer and in the connectionist version the brain computes input vector to output vector transformations non-symbolically. The 'deconstructed brain' neither processes information nor computes functions but is spontaneously economical</div>
</div><!--entry-->

<div id='_812_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("HADCAN",this.href,0);return true;' href='http://fas.sfu.ca/pub/cs/TR/1998/CMPT1998-01.ps.gz'>Connectionism and novel combinations of skills: Implications for cognitive architecture.</a></span> <span class='pub_name'>Minds and Machines</span> 9 (2):197-221. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18243156053210819153'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20novel%20combinations%20of%20skills+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_812_links")'>More links</a>)</span><div id='_812_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In the late 1980s, there were many who heralded the emergence of connectionism as a new paradigm â one which would eventually displace the classically symbolic methods then dominant in AI and Cognitive Science. At present, there remain influential connectionists who continue to defend connectionism as a more realistic paradigm for modeling cognition, at all levels of abstraction, than the classical methods of AI. Not infrequently, one encounters arguments along these lines: given what we know about neurophysiology, it is just not plausible to suppose that our brains are digital computers. Thus, they could not support a classical architecture. I argue here for a middle ground between connectionism and classicism. I assume, for argument's sake, that some form(s) of connectionism can provide reasonably approximate models â at least for lower-level cognitive processes. Given this assumption, I argue on theoretical and empirical grounds that most human mental skills must reside in separate connectionist modules or sub-networks. Ultimately, it is argued that the basic tenets of connectionism, in conjunction with the fact that humans often employ novel combinations of skill modules in rule following and problem solving, lead to the plausible conclusion that, in certain domains, high level cognition requires some form of classical architecture. During the course of argument, it emerges that only an architecture with classical structure could support the novel patterns of information flow and interaction that would exist among the relevant set of modules. Such a classical architecture might very well reside in the abstract levels of a hybrid system whose lower-level modules are purely connectionist</div>
<div id='_812_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCAN",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596712.596817">http://portal.acm.org/citation.cfm?id=596712.596817</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCAN",this.href,0);return true;' href="http://www.springerlink.com/content/l64416n38j41q278/fulltext.pdf">http://www.springerlink.com/content/l64416n38j41q278/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCAN",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=206285&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=206285&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCAN",this.href,0);return true;' href="http://www.springerlink.com/index/L64416N38J41Q278.pdf">http://www.springerlink.com/index/L64416N38J41Q278.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADCAN",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1999/00000009/00000002/00206285">http://www.ingentaconnect.com/content/klu/mind/1999/00000009/00000002/00206285</a><br></div></div>
</div><!--entry-->

<div id='_813_entry' class='entry'><span ><span class='name'>Hatfield, Gary</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("HATGRA",this.href,0);return true;' href='http://www.springerlink.com/index/VL20KJ8317580273.pdf'>Gibsonian representations and connectionist symbol-processing: Prospects for unification.</a></span> <span class='pub_name'>Psychological Research</span> 52:243-52. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2901925011114536919'>Cited by 5</a> | <span class='ll' onclick='$("_813_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Gibsonian%20representations%20and%20connectionist%20symbol-processing+author%3AHatfield&amp;btnG=Search'>Google</a>)</span><div id='_813_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Gibson is compatible with connectionism. In both, we can have rule-instantiation without rule-following.</div></div>
</div><!--entry-->

<div id='_814_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1999). Authors' replies.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):275-287. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Authors%27%20replies+author%3AHorgan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_815_entry' class='entry'><span ><span class='name'>Horgan, Dianne D.</span> &amp; <span class='name'>Hacker, Douglas J.</span> (1999). Beginning a theoretician-practitioner dialogue about connectionism.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):261-273. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Beginning%20a%20theoretician-practitioner%20dialogue%20about%20connectionism+author%3AHorgan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_816_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (eds.) (1991). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HORCAT-3",this.href,0);return true;' href='http://books.google.com/books?id=zUzS0kLd1e4C&amp;printsec=front_cover'>Connectionism and the Philosophy of Mind.</a></span></em></span> Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13885074975966988012'>Cited by 30</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20Philosophy%20of%20Mind+author%3AHorgan&amp;btnG=Search'>Google</a>)</span><div id='_816_abstract' class='extra' style='font-size:12px;'>Abstract: &quot;A third of the papers in this volume originated at the 1987 Spindel Conference ... at Memphis State University&quot;--Pref.</div>
</div><!--entry-->

<div id='_817_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1996). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HORCAT-4",this.href,0);return true;' href='http://books.google.com/books?id=VaL5uioJo0gC&amp;printsec=front_cover'>Connectionism and the Philosophy of Psychology.</a></span></em></span> MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5784537628396909810'>Cited by 123</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20Philosophy%20of%20Psychology+author%3AHorgan&amp;btnG=Search'>Google</a>)</span><div id='_817_abstract' class='extra' style='font-size:12px;'>Abstract: In Connectionism and the Philosophy of Psychology, Horgan and Tienson articulate and defend a new view of cognition.</div>
</div><!--entry-->

<div id='_818_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("HORCAT-5",this.href,0);return true;' href='http://www3.interscience.wiley.com/cgi-bin/fulltext/119168156/PDFSTART'>Connectionism and the philosophical foundations of cognitive science.</a></span> <span class='pub_name'>Metaphilosophy</span> 28 (1-2):1-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2048904750077623697'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20philosophical%20foundations%20of%20cognitive%20science+author%3AHorgan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_818_links")'>More links</a>)</span>
<div id='_818_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORCAT-5",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1467-9973.00039">http://www.blackwell-synergy.com/links/doi/10.1111/1467-9973.00039</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORCAT-5",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1467-9973.00039">http://www.blackwell-synergy.com/doi/abs/10.1111/1467-9973.00039</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORCAT-5",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/F0020001/art00001">http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/F0020001/art00001</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORCAT-5",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/f0020001">http://www.ingentaconnect.com/content/bpl/meta/1997/00000028/f0020001</a><br></div></div>
</div><!--entry-->

<div id='_819_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("HORMTN",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a793922695~fulltext=713240930'>Modelling the noncomputational mind: Reply to Litch.</a></span> <span class='pub_name'>Philosophical Psychology</span> 10 (3):365-371. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modelling%20the%20noncomputational%20mind+author%3AHorgan&amp;btnG=Search'>Google</a>)</span><div id='_819_abstract' class='extra' style='font-size:12px;'>Abstract: I explain why, within the nonclassical framework for cognitive science we describe in the book, cognitive-state transitions can fail to be tractably computable even if they are subserved by a discrete dynamical system whose mathematical-state transitions are tractably computable. I distinguish two ways that cognitive processing might conform to programmable rules in which all operations that apply to representation-level structure are primitive, and two corresponding constraints on models of cognition. Although Litch is correct in maintaining that classical cognitive science is not committed to the first constraint, it is committed to the second. This fact constitutes an illuminating gloss on our claim that one foundational assumption of classicism is that human cognition conforms to programmable, representation-level, rules</div>
</div><!--entry-->

<div id='_820_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> (1999). Short prcis of connectionism and the philosophy of psychology.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):9-21. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13492286853344460715'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Short%20prcis%20of%20connectionism%20and%20the%20philosophy%20of%20psychology+author%3AHorgan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_821_entry' class='entry'><span ><span class='name'>Humphreys, Glyn W.</span> (1986). Information-processing systems which embody computational rules: The connectionist approach.</span> <span class='pub_name'>Mind and Language</span> 1:201-12. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6367007546488892126'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Information-processing%20systems%20which%20embody%20computational%20rules+author%3AHumphreys&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_822_entry' class='entry'><span ><span class='name'>Kirsh, David</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("KIRPLA",this.href,0);return true;' href='http://crl.ucsd.edu/newsletter/6-3/Article1.html'>PDP Learnability and Innate Knowledge of Language.</a></span> In S. Davis (ed.), <em>Connectionism: Theory and practice (Volume III of The Vancouver Studies in Cognitive Science</em>. Oxford University press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=PDP%20Learnability%20and%20Innate%20Knowledge%20of%20Language+author%3AKirsh&amp;btnG=Search'>Google</a>)</span><div id='_822_abstract' class='extra' style='font-size:12px;'>Abstract: It is sometimes argued that if PDP networks can be trained to
make correct judgements of grammaticality we have an existence proof
that there is enough information in the stimulus to permit learning
grammar by inductive means alone.  This seems inconsistent
superficially with Gold's theorem and at a deeper level with the fact
that networks are designed on the basis of assumptions about the
domain of the function to be learned.  To clarify the issue I consider
what we should learn from Gold's theorem, then go on to inquire into
what it means to say that knowledge is domain specific.  I first try
sharpening the intuitive notion of domain specific knowledge by
reviewing the alleged difference between processing limitatons due to
shartage of resources vs shortages of knowledge.  After rejecting
different formulations of this idea, I suggest that a model is
language specific if it transparently refer to entities and facts
about language as opposed to entities and facts of more general
mathematical domains.  This is a useful but not necessary condition.
I then suggest that a theory is domain specific if it belongs to a
model family which is attuned in a law-like way to domain
regularities.  This leads to a comparison of PDP and parameter setting
models of language learning.  I conclude with a novel version of the
poverty of stimulus argument.
</div>
</div><!--entry-->

<div id='_823_entry' class='entry'><span ><span class='name'>Laakso, Aarre</span> &amp; <span class='name'>Cottrell, Garrison W.</span> (2006). Churchland on connectionism.</span> In Brian L. Keeley (ed.), <em>Paul Churchland</em>. Cambridge: Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Churchland%20on%20connectionism+author%3ALaakso&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_824_entry' class='entry'><span ><span class='name'>Legg, C. R.</span> (1988). Connectionism and physiological psychology: A marriage made in heaven?</span> <span class='pub_name'>Philosophical Psychology</span> 1:263-78. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20physiological%20psychology+author%3ALegg&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_825_entry' class='entry'><span ><span class='name'>Litch, Mary</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("LITCCA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a793922694~fulltext=713240930'>Computation, connectionism and modelling the mind.</a></span> <span class='pub_name'>Philosophical Psychology</span> 10 (3):357-364. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computation%2C%20connectionism%20and%20modelling%20the%20mind+author%3ALitch&amp;btnG=Search'>Google</a>)</span><div id='_825_abstract' class='extra' style='font-size:12px;'>Abstract: Any analysis of the concept of computation as it occurs in the context of a discussion of the computational model of the mind must be consonant with the philosophic burden traditionally carried by that concept as providing a bridge between a physical and a psychological description of an agent. With this analysis in hand, one may ask the question: are connectionist-based systems consistent with the computational model of the mind? The answer depends upon which of several versions of connectionism one presupposes: non-learning connectionist-based systems as simulated on digital computers are consistent with the computational model of the mind, whereas connectionist-based systems (/dynamical systems) qua analog systems are not</div>
</div><!--entry-->

<div id='_826_entry' class='entry'><span ><span class='name'>Litch, Mary</span> (1999). Learning connectionist networks and the philosophy of psychology.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):87-110. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Learning%20connectionist%20networks%20and%20the%20philosophy%20of%20psychology+author%3ALitch&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_827_entry' class='entry'><span ><span class='name'>Lloyd, Dan</span> (1994). Connectionist hysteria: Reducing a Freudian case study to a network model.</span> <span class='pub_name'>Philosophy, Psychiatry, and Psychology</span> 1 (2):69-88. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=243720538415290304'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20hysteria+author%3ALloyd&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_828_entry' class='entry'><span ><span class='name'>Lloyd, Dan</span> (1989). Parallel distributed processing and cognition: Only connect?</span> In <em>Simple Minds</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_828_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Parallel%20distributed%20processing%20and%20cognition+author%3ALloyd&amp;btnG=Search'>Google</a>)</span><div id='_828_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>An overview: local/distributed/featural representations; explanation in connectionism (how to avoid big mush); relation to neuroscience; explicit representations of rules vs weight matrices.</div></div>
</div><!--entry-->

<div id='_829_entry' class='entry'><span ><span class='name'>Lycan, William G.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("LYCHFM",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=UckGbfzYkkgC&amp;oi=fnd&amp;pg=PA259&amp;dq=Homuncular+functionalism+meets+PDP+Lycan&amp;ots=8IgRkYF6Fi&amp;sig=Ksqto6c7pOO_WK08OazYHeIw6zM'>Homuncular functionalism meets PDP.</a></span> In William Ramsey, Stephen P. Stich &amp; D. Rumelhart (eds.), <em>Philosophy and Connectionist Theory</em>. Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8229374859332784314'>Cited by 7</a> | <span class='ll' onclick='$("_829_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Homuncular%20functionalism%20meets%20PDP+author%3ALycan&amp;btnG=Search'>Google</a>)</span><div id='_829_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On various ways in which connectionism relates to representational homuncular functionalism, e.g. on implementation, eliminativism, and explanation.</div></div>
</div><!--entry-->

<div id='_830_entry' class='entry'><span ><span class='name'>Macdonald, C.</span> (ed.) (1995). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("MACCDO",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=ZLIAbDZzJ5sC&amp;oi=fnd&amp;pg=PR7&amp;dq=Connectionism+Macdonald&amp;ots=O34DfzfQRF&amp;sig=xZSY8eFmuaZwOlxLR5Cow9UrURM'>Connectionism: Debates on Psychological Explanation.</a></span></em></span> Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5122061717487970195'>Cited by 36</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism+author%3AMacdonald&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_831_entry' class='entry'><span ><span class='name'>McLaughlin, Brian P.</span> (1987). Tye on connectionism.</span> <span class='pub_name'>Southern Journal of Philosophy (Suppl.)</span> 185:185-193. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1375745474225459'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Tye%20on%20connectionism+author%3AMcLaughlin&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_832_entry' class='entry'><span ><span class='name'>Mills, Stephen L.</span> (1993). Wittgenstein and connectionism: A significant complementarity?</span> <span class='pub_name'>Philosophy</span> 34:137-157. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10090776332203500764'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Wittgenstein%20and%20connectionism+author%3AMills&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_833_entry' class='entry'><span ><span class='name'>Miscevic, Nenad</span> (1994). Connectionism and epistemic value.</span> <span class='pub_name'>Acta Analytica</span> 12 (12):19-37. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20epistemic%20value+author%3AMiscevic&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_834_entry' class='entry'><span ><span class='name'>Nenon, Thomas J.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("NENCAP",this.href,0);return true;' href='http://www.springerlink.com/index/r455674547735414.pdf'>Connectionism and phenomenology.</a></span> In <em>Phenomenology of the Cultural Disciplines</em>. Dordrecht: Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20phenomenology+author%3ANenon&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_835_entry' class='entry'><span ><span class='name'>Niklasson, L. F.</span> &amp; <span class='name'>van Gelder, Tim</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("NIKCCM",this.href,0);return true;' href='http://citeseer.ist.psu.edu/326140.html'>Can connectionist models exhibit non-classical structure sensitivity?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6601142053878300193'>Cited by 30</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Can%20connectionist%20models%20exhibit%20non-classical%20structure%20sensitivity%3F+author%3ANiklasson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_835_links")'>More links</a>)</span><div id='_835_abstract' class='extra' style='font-size:12px;'>Abstract: Department of Computer Science Philosophy Program, Research School of Social Sciences University of SkÃ¶vde, S-54128, SWEDEN Australian National University, Canberra ACT 0200</div>
<div id='_835_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NIKCCM",this.href,0);return true;' href="http://citeseer.ist.psu.edu/niklasson94can.html">http://citeseer.ist.psu.edu/niklasson94can.html</a><br></div></div>
</div><!--entry-->

<div id='_836_entry' class='entry'><span ><span class='name'>O'Brien, Gerard</span> &amp; <span class='name'>Opie, Jonathan</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("OBRRCT",this.href,0);return true;' href='http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Radical_Connectionism-Thinking_with_Language.pdf'>Radical connectionism: Thinking with (not in) language.</a></span> <span class='pub_name'>Language and Communication</span> 22 (3):313-329. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3631402770913387949'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Radical%20connectionism+author%3AO%27Brien&amp;btnG=Search'>Google</a> | <a href='javascript:show("_836_links")'>More links</a>)</span><div id='_836_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper we defend a position we call radical connectionism. Radical connectionism claims that cognition _never_ implicates an internal symbolic medium, not even when natural language plays a part in our thought processes. On the face of it, such a position renders the human capacity for abstract thought quite mysterious. However, we argue that connectionism is committed to an analog conception of neural computation, and that representation of the abstract is no more problematic for a system of analog vehicles than for a symbol system. Natural language is therefore not required as a representational medium for abstract thought. Since natural language is arguably not a representational medium _at all_, but a conventionally governed scheme of communicative signals, we suggest that the role of internalised (i.e., self- directed) language is best conceived in terms of the coordination and control of cognitive activities within the brain</div>
<div id='_836_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRRCT",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S0271530902000101">http://linkinghub.elsevier.com/retrieve/pii/S0271530902000101</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRRCT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/02715309/2002/00000022/00000003/art00010">http://www.ingentaconnect.com/content/els/02715309/2002/00000022/00000003/art00010</a><br></div></div>
</div><!--entry-->

<div id='_837_entry' class='entry'><span ><span class='name'>Piccinini, Gualtiero</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("PICCC",this.href,0);return true;' href='http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4370926'>Connectionist computation.</a></span> In Gualtiero Piccinini (ed.), <em>Proceedings of the 2007 International Joint Conference on Neural Networks</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionist%20computation+author%3APiccinini&amp;btnG=Search'>Google</a>)</span><div id='_837_abstract' class='extra' style='font-size:12px;'>Abstract: The following three theses are inconsistent: (1) (Paradigmatic) connectionist systems perform computations. (2) Performing computations requires executing programs. (3) Connectionist systems do not execute programs. Many authors embrace (2). This leads them to a dilemma: either connectionist systems execute programs or they don't compute. Accordingly, some authors attempt to deny (1), while others attempt to deny (3). But as I will argue, there are compelling reasons to accept both (1) and (3). So, we should replace (2) with a more satisfactory account of computation. Once we do, we can see more clearly what is peculiar to connectionist computation.</div>
</div><!--entry-->

<div id='_838_entry' class='entry'><span ><span class='name'>Place, Ullin T.</span> (1999). Connectionism and the problem of consciousness.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):197-226. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20problem%20of%20consciousness+author%3APlace&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_839_entry' class='entry'><span ><span class='name'>Plunkett, Kim</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("PLUCT",this.href,0);return true;' href='http://www.springerlink.com/content/k0x25844k059h4w2/fulltext.pdf'>Connectionism today.</a></span> <span class='pub_name'>Synthese</span> 129 (2):185-194. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12426862198778679318'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20today+author%3APlunkett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_839_links")'>More links</a>)</span><div id='_839_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Connectionist networks have been used to model a wide range of cognitivephenomena, including developmental, neuropsychological and normal adultbehaviours. They have offered radical alternatives to traditional accounts ofwell-established facts about cognition. The primary source of the success ofthese models is their sensitivity to statistical regularities in their trainingenvironment. This paper provides a brief description of the connectionisttoolbox and how this has developed over the past 2 decades, with particularreference to the problem of reading aloud</div>
<div id='_839_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PLUCT",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=322207&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=322207&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PLUCT",this.href,0);return true;' href="http://www.springerlink.com/index/K0X25844K059H4W2.pdf">http://www.springerlink.com/index/K0X25844K059H4W2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PLUCT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/synt/2001/00000129/00000002/00322207">http://www.ingentaconnect.com/content/klu/synt/2001/00000129/00000002/00322207</a><br></div></div>
</div><!--entry-->

<div id='_840_entry' class='entry'><span ><span class='name'>Ramsey, William</span> &amp; <span class='name'>Stich, Stephen P.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("RAMCAT",this.href,0);return true;' href='http://www.dfki.uni-sb.de/imedia/lidos/bibtex/Fetzer_a26177-88.html'>Connectionism and three levels of nativism.</a></span> <span class='pub_name'>Synthese</span> 82 (2):177-205. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12261035722261005131'>Cited by 14</a> | <span class='ll' onclick='$("_840_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20three%20levels%20of%20nativism+author%3ARamsey&amp;btnG=Search'>Google</a> | <a href='javascript:show("_840_links")'>More links</a>)</span><div id='_840_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>How connectionism bears on the nativism debate. Conclusion: not too much.</div></div><div id='_840_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Along with the increasing popularity of connectionist language models has come a number of provocative suggestions about the challenge these models present to Chomsky's arguments for nativism. The aim of this paper is to assess these claims. We begin by reconstructing Chomsky's argument from the poverty of the stimulus and arguing that it is best understood as three related arguments, with increasingly strong conclusions. Next, we provide a brief introduction to connectionism and give a quick survey of recent efforts to develop networks that model various aspects of human linguistic behavior. Finally, we explore the implications of this research for Chomsky's arguments. Our claim is that the relation between connectionism and Chomsky's views on innate knowledge is more complicated than many have assumed, and that even if these models enjoy considerable success the threat they pose for linguistic nativism is small</div>
<div id='_840_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAMCAT",this.href,0);return true;' href="http://www.springerlink.com/content/p66n338hjq44332p/fulltext.pdf">http://www.springerlink.com/content/p66n338hjq44332p/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RAMCAT",this.href,0);return true;' href="http://www.springerlink.com/index/P66N338HJQ44332P.pdf">http://www.springerlink.com/index/P66N338HJQ44332P.pdf</a><br></div></div>
</div><!--entry-->

<div id='_841_entry' class='entry'><span ><span class='name'>Ramsey, William</span>; <span class='name'>Stich, Stephen P.</span> &amp; <span class='name'>Rumelhart, D. M.</span> (eds.) (1991). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("RAMPAC-2",this.href,0);return true;' href='http://books.google.com/books?id=n7kPbSmWc_QC&amp;printsec=front_cover'>Philosophy and Connectionist Theory.</a></span></em></span> Lawrence Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16556486146399431603'>Cited by 46</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophy%20and%20Connectionist%20Theory+author%3ARamsey&amp;btnG=Search'>Google</a>)</span><div id='_841_abstract' class='extra' style='font-size:12px;'>Abstract: The philosophy of cognitive science has recently become one of the most exciting and fastest growing domains of philosophical inquiry and analysis. Until the early 1980s, nearly all of the models developed treated cognitive processes -- like problem solving, language comprehension, memory, and higher visual processing -- as rule-governed symbol manipulation. However, this situation has changed dramatically over the last half dozen years. In that period there has been an enormous shift of attention toward connectionist models of cognition that are inspired by the network-like architecture of the brain. Because of their unique architecture and style of processing, connectionist systems are generally regarded as radically different from the more traditional symbol manipulation models. This collection was designed to provide philosophers who have been working in the area of cognitive science with a forum for expressing their views on these recent developments. Because the symbol-manipulating paradigm has been so important to the work of contemporary philosophers, many have watched the emergence of connectionism with considerable interest. The contributors take very different stands toward connectionism, but all agree that the potential exists for a radical shift in the way many philosophers think of various aspects of cognition. Exploring this potential and other philosophical dimensions of connectionist research is the aim of this volume</div>
</div><!--entry-->

<div id='_842_entry' class='entry'><span ><span class='name'>Rosenberg, Jay F.</span> (1989). Connectionism and cognition.</span> <span class='pub_name'>Bielefeld Report</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14462546362895003029'>Cited by 7</a> | <span class='ll' onclick='$("_842_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20cognition+author%3ARosenberg&amp;btnG=Search'>Google</a>)</span><div id='_842_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Criticism of Churchland's connectionist epistemology.</div></div>
</div><!--entry-->

<div id='_843_entry' class='entry'><span ><span class='name'>Sehon, Scott R.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("SEHCAT",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793920864~fulltext=713240930'>Connectionism and the causal theory of action explanation.</a></span> <span class='pub_name'>Philosophical Psychology</span> 11 (4):511-532. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1908567642512603902'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20causal%20theory%20of%20action%20explanation+author%3ASehon&amp;btnG=Search'>Google</a>)</span><div id='_843_abstract' class='extra' style='font-size:12px;'>Abstract: It is widely assumed that common sense psychological explanations of human action are a species of causal explanation. I argue against this construal, drawing on Ramsey et al.'s paper, âConnectionism, eliminativism, and the future of folk psychologyâ. I argue that if certain connec-tionist models are correct, then mental states cannot be identified with functionally discrete causes of behavior, and I respond to some recent attempts to deny this claim. However, I further contend that our common sense psychological practices are not committed to the falsity of such connectionist models. The paper concludes that common sense psychology is not committed to the identification of mental states with functionally discrete causes of behavior, and hence that common sense psychology is not committed to the causal account of action explanation</div>
</div><!--entry-->

<div id='_844_entry' class='entry'><span ><span class='name'>Shanon, Benny</span> (1992). Are connectionist models cognitive?</span> <span class='pub_name'>Philosophical Psychology</span> 5 (3):235-255. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1561519470314688815'>Cited by 5</a> | <span class='ll' onclick='$("_844_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Are%20connectionist%20models%20cognitive%3F+author%3AShanon&amp;btnG=Search'>Google</a>)</span><div id='_844_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>In some senses of "cognitive", yes; in other senses, no. Phenomenological, theoretical, and sociological perspectives. Toward meaning-laden models.</div></div><div id='_844_abstract' class='extra' style='font-size:12px;'>Abstract: In their critique of connectionist models Fodor and Pylyshyn (1988) dismiss such models as not being cognitive or psychological. Evaluating Fodor and Pylyshyn's critique requires examining what is required in characterizating models as 'cognitive'. The present discussion examines the various senses of this term. It argues the answer to the title question seems to vary with these different senses. Indeed, by one sense of the term, neither representa-tionalism nor connectionism is cognitive. General ramifications of such an appraisal are discussed and alternative avenues for cognitive research are suggested</div>
</div><!--entry-->

<div id='_845_entry' class='entry'><span ><span class='name'>Smith, Barry</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("SMITCM",this.href,0);return true;' href='http://cogprints.ecs.soton.ac.uk/archive/00000306/'>The connectionist mind: A study of Hayekian psychology.</a></span> In Stephen F. Frowen (ed.), <em>Hayek: Economist and Social Philosopher: A Critical Retrospect</em>. St. Martin's Press. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 16 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20connectionist%20mind+author%3ASmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_845_links")'>More links</a>)</span><div id='_845_abstract' class='extra' style='font-size:12px;'>Abstract: Introduction I shall begin my remarks with some discussion of recent work in cognitive science, and the participants in this meeting might find it useful to note that I might equally well have chosen as title of my paper something like 'Artificial Intelligence and the Free Market Order'. They might care to note also that I am, as far as the achievements and goals of research in artificial intelligence are concerned, something of a sceptic. My appeal to cognitive science in what follows is designed to serve clarificatory ends, and to raise new questions, of a sort which will become clear as the paper progresses</div>
<div id='_845_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SMITCM",this.href,0);return true;' href="http://ontology.buffalo.edu/smith/articles/HAYEK.HTM">http://ontology.buffalo.edu/smith/articles/HAYEK.HTM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SMITCM",this.href,0);return true;' href="http://wings.buffalo.edu/philosophy/faculty/smith/articles/HAYEK.HTM">http://wings.buffalo.edu/philosophy/faculty/smith/articles/HAYEK.HTM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SMITCM",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:306">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:306</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SMITCM",this.href,0);return true;' href="http://wings.buffalo.edu/academic/department/philosophy/faculty/smith/articles/HAYEK.HTM">http://wings.buffalo.edu/academic/department/philosophy/faculty/smith/articles/HAYEK.HTM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SMITCM",this.href,0);return true;' href="http://cogprints.org/306/1/connect.html">http://cogprints.org/306/1/connect.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SMITCM",this.href,0);return true;' href="http://cogprints.org/306/0/connect.html">http://cogprints.org/306/0/connect.html</a><br></div></div>
</div><!--entry-->

<div id='_846_entry' class='entry'><span ><span class='name'>Stark, Herman E.</span> (1994). Connectionism and the form of rational norms.</span> <span class='pub_name'>Acta Analytica</span> 12 (12):39-53. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5448563250784334578'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20form%20of%20rational%20norms+author%3AStark&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_847_entry' class='entry'><span ><span class='name'>Sterelny, Kim</span> (1990). Connectionism.</span> In <em>The Representational Theory of Mind</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism+author%3ASterelny&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_848_entry' class='entry'><span ><span class='name'>Thagard, Paul R.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("THACAE",this.href,0);return true;' href='http://www.springerlink.com/content/4416534216015862/fulltext.pdf'>Connectionism and epistemology: Goldman on Winner-take-all networks.</a></span> <span class='pub_name'>Philosophia</span> 19 (2-3):189-196. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14318088746083599919'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20epistemology+author%3AThagard&amp;btnG=Search'>Google</a> | <a href='javascript:show("_848_links")'>More links</a>)</span>
<div id='_848_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THACAE",this.href,0);return true;' href="http://www.springerlink.com/index/4416534216015862.pdf">http://www.springerlink.com/index/4416534216015862.pdf</a><br></div></div>
</div><!--entry-->

<div id='_849_entry' class='entry'><span ><span class='name'>Tienson, John L.</span> (1987). Introduction to connectionism.</span> <span class='pub_name'>Southern Journal of Philosophy (Suppl.)</span> 1:1-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1000252969864566731'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Introduction%20to%20connectionism+author%3ATienson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_850_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1993). Connectionism and the mind-body problem: Exposing the distinction between mind and cognition.</span> <span class='pub_name'>Artificial Intelligence Review</span> 7:355-369. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20the%20mind-body%20problem+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.3g'></a><a name=''></a><span class='myh3'>6.3g Philosophy of Connectionism, Foundational Empirical Issues</span></p>

<div id='cat_6.3g' class='cat_content'>
<div id='__new_entries_6.3g__'></div><div id='__new_entry_6.3g__' class='entry'></div>
<div id='_851_entry' class='entry'><span ><span class='name'>Aizawa, Kenneth</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("AIZCAA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=161077'>Connectionism and artificial intelligence: History and philosophical interpretation.</a></span> <span class='pub_name'>Journal for Experimental and Theoretical Artificial Intelligence</span> 4:1992. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 1 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20and%20artificial%20intelligence+author%3AAizawa&amp;btnG=Search'>Google</a> | <a href='javascript:show("_851_links")'>More links</a>)</span>
<div id='_851_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AIZCAA",this.href,0);return true;' href="http://www.informaworld.com/index/777592363.pdf">http://www.informaworld.com/index/777592363.pdf</a><br></div></div>
</div><!--entry-->

<div id='_852_entry' class='entry'><span ><span class='name'>Beaman, C. Philip</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BEANAT",this.href,0);return true;' href='http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=65470&amp;jid=BBS&amp;volumeId=23&amp;issueId=04&amp;aid=65469'>Neurons amongst the symbols?</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 23 (4):468-470. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Neurons%20amongst%20the%20symbols%3F+author%3ABeaman&amp;btnG=Search'>Google</a>)</span><div id='_852_abstract' class='extra' style='font-size:12px;'>Abstract: Page's target article presents an argument for the use of localist, connectionist models in future psychological theorising. The âmanifestoâ marshalls a set of arguments in favour of localist connectionism and against distributed connectionism, but in doing so misses a larger argument concerning the level of psychological explanation that is appropriate to a given domain</div>
</div><!--entry-->

<div id='_853_entry' class='entry'><span ><span class='name'>Berkeley, Istvan S. N.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("BERCRM",this.href,0);return true;' href='http://cogprints.ecs.soton.ac.uk/archive/00001975/00/CReconF.pdf'>Connectionism reconsidered: Minds, machines and models.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1635608205657814393'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20reconsidered+author%3ABerkeley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_853_links")'>More links</a>)</span><div id='_853_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper the issue of drawing inferences about biological cognitive systems on the basis of connectionist simulations is addressed. In particular, the justification of inferences based on connectionist models trained using the backpropagation learning algorithm is examined. First it is noted that a justification commonly found in the philosophical literature is inapplicable. Then some general issues are raised about the relationships between models and biological systems. A way of conceiving the role of hidden units in connectionist networks is then introduced. This, in combination with an assumption about the way evolution goes about solving problems, is then used to suggest a means of justifying inferences about biological systems based on connectionist research</div>
<div id='_853_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERCRM",this.href,0);return true;' href="http://www.ucs.louisiana.edu/~isb9112/dept/phil341/conrecon/conrecon.html">http://www.ucs.louisiana.edu/~isb9112/dept/phil341/conrecon/conrecon.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERCRM",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1975">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:1975</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERCRM",this.href,0);return true;' href="http://cogprints.org/1975/3/CReconF.pdf">http://cogprints.org/1975/3/CReconF.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERCRM",this.href,0);return true;' href="http://cogprints.org/1975/0/CReconF.pdf">http://cogprints.org/1975/0/CReconF.pdf</a><br></div></div>
</div><!--entry-->

<div id='_854_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("CLARTI",this.href,0);return true;' href='http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=0148100CI'>Representational trajectories in connectionist learning.</a></span> <span class='pub_name'>Minds and Machines</span> 4 (3):317-32. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3013760173101503413'>Cited by 5</a> | <span class='ll' onclick='$("_854_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representational%20trajectories%20in%20connectionist%20learning+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_854_links")'>More links</a>)</span><div id='_854_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On how to get connectionist networks to learn about structured task domains. Concentrates on incremental learning, and other developmental/scaffolding strategies. With remarks on systematicity.</div></div><div id='_854_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The paper considers the problems involved in getting neural networks to learn about highly structured task domains. A central problem concerns the tendency of networks to learn only a set of shallow (non-generalizable) representations for the task, i.e., to miss the deep organizing features of the domain. Various solutions are examined, including task specific network configuration and incremental learning. The latter strategy is the more attractive, since it holds out the promise of a task-independent solution to the problem. Once we see exactly how the solution works, however, it becomes clear that it is limited to a special class of cases in which (1) statistically driven undersampling is (luckily) equivalent to task decomposition, and (2) the dangers of unlearning are somehow being minimized. The technique is suggestive nonetheless, for a variety of developmental factors may yield the functional equivalent of both statistical AND informed undersampling in early learning</div>
<div id='_854_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLARTI",this.href,0);return true;' href="http://www.springerlink.com/content/content/r7812132kh676544/fulltext.pdf">http://www.springerlink.com/content/content/r7812132kh676544/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLARTI",this.href,0);return true;' href="http://www.springerlink.com/content/r7812132kh676544/fulltext.pdf">http://www.springerlink.com/content/r7812132kh676544/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLARTI",this.href,0);return true;' href="http://www.springerlink.com/index/R7812132KH676544.pdf">http://www.springerlink.com/index/R7812132KH676544.pdf</a><br></div></div>
</div><!--entry-->

<div id='_855_entry' class='entry'><span ><span class='name'>Clark, Andy</span> &amp; <span class='name'>Thornton, S.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("CLATSC",this.href,0);return true;' href='http://citeseer.ist.psu.edu/58177.html'>Trading spaces: Computation, representation, and the limits of uninformed learning.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 20 (1):57-66. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16846604413954665928'>Cited by 204</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Trading%20spaces+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_855_links")'>More links</a>)</span>
<div id='_855_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://www.bbsonline.org/documents/a/00/00/04/44/index.html">http://www.bbsonline.org/documents/a/00/00/04/44/index.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://www.bbsonline.org/Preprints/OldArchive/bbs.clark.html">http://www.bbsonline.org/Preprints/OldArchive/bbs.clark.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://www.psych.nyu.edu/gary/marcusArticles/Marcus 1997 BBS.pdf">http://www.psych.nyu.edu/gary/marcusArticles/Marcus 1997 BBS.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://www.denizyuret.com/ref/clark_andy/clark.trading-spaces.ps">http://www.denizyuret.com/ref/clark_andy/clark.trading-spaces.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://bbsonline.cup.cam.ac.uk/Preprints/OldArchive/bbs.clark.html">http://bbsonline.cup.cam.ac.uk/Preprints/OldArchive/bbs.clark.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://neuron-ai.tuke.sk/~hudecm/d/TradeSpacesComputationRepresentationAndTheLimitsOfUninformedLearning_clark95trading.ps">http://neuron-ai.tuke.sk/~hudecm/d/TradeSpacesComputationRepresentationAndTheLimitsOfUninformedLearning_clark95trading.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=29218&amp;jid=BBS&amp;volumeId=20&amp;issueId=01&amp;aid=29217">http://journals.cambridge.org/action/displayFulltext?type=1&fid=29218&jid=BBS&volumeId=20&issueId=01&aid=29217</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=10096995&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=10096995&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=pubmed&amp;list_uids=10096995&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=pubmed&list_uids=10096995&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X97000022">http://www.journals.cambridge.org/abstract_S0140525X97000022</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://journals.cambridge.org/article_S0140525X97240021">http://journals.cambridge.org/article_S0140525X97240021</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATSC",this.href,0);return true;' href="http://journals.cambridge.org/article_S0140525X97300028">http://journals.cambridge.org/article_S0140525X97300028</a><br></div></div>
</div><!--entry-->

<div id='_856_entry' class='entry'><span ><span class='name'>Clark, Andy</span> &amp; <span class='name'>Thornton, Chris</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("CLAU",this.href,0);return true;' href='http://www.philosophy.ed.ac.uk/staff/clark/pubs/relational-learning.pdf'>Relational learning re-examined.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 20 (1):83-90. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Relational%20learning%20re-examined+author%3AClark&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_857_entry' class='entry'><span ><span class='name'>Cliff, D.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("CLICNA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/9437.html'>Computational Neuroethology: A Provisional Manifesto.</a></span> In Jean-Arcady Meyer &amp; Stewart W. Wilson (eds.), <em>From Animals to Animats: Proceedings of The First International Conference on Simulation of Adaptive Behavior (Complex Adaptive Systems)</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14197952762908825796'>Cited by 103</a> | <span class='ll' onclick='$("_857_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computational%20Neuroethology+author%3ACliff&amp;btnG=Search'>Google</a> | <a href='javascript:show("_857_links")'>More links</a>)</span><div id='_857_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Criticizes connectionism for not being sufficiently rooted in neuroscience, and for not being grounded in the world.</div></div>
<div id='_857_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLICNA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=116521">http://portal.acm.org/citation.cfm?id=116521</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLICNA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/cliff91computational.html">http://citeseer.ist.psu.edu/cliff91computational.html</a><br></div></div>
</div><!--entry-->

<div id='_858_entry' class='entry'><span ><span class='name'>Dawson, Michael R. W.</span> &amp; <span class='name'>Schopflocher, D. P.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("DAWAPI",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793921610~fulltext=713240930'>Autonomous processing in parallel distributed processing networks.</a></span> <span class='pub_name'>Philosophical Psychology</span> 5 (2):199-219. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Autonomous%20processing%20in%20parallel%20distributed%20processing%20networks+author%3ADawson&amp;btnG=Search'>Google</a>)</span><div id='_858_abstract' class='extra' style='font-size:12px;'>Abstract: This paper critically examines the claim that parallel distributed processing (PDP) networks are autonomous learning systems. A PDP model of a simple distributed associative memory is considered. It is shown that the 'generic' PDP architecture cannot implement the computations required by this memory system without the aid of external control. In other words, the model is not autonomous. Two specific problems are highlighted: (i) simultaneous learning and recall are not permitted to occur as would be required of an autonomous system; (ii) connections between processing units cannot simultaneously represent current and previous network activation as would be required if learning is to occur. Similar problems exist for more sophisticated networks constructed from the generic PDP architecture. We argue that this is because these models are not adequately constrained by the properties of the functional architecture assumed by PDP modelers. It is also argued that without such constraints, PDP researchers cannot claim to have developed an architecture radically different from that proposed by the Classical approach in cognitive science</div>
</div><!--entry-->

<div id='_859_entry' class='entry'><span ><span class='name'>Franklin, James</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("FRAHAN",this.href,0);return true;' href='http://www.maths.unsw.edu.au/~jim/nnpap.pdf'>How a neural net grows symbols.</a></span> <span class='pub_name'>Proc</span> 7. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12696008189958954495'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20a%20neural%20net%20grows%20symbols+author%3AFranklin&amp;btnG=Search'>Google</a>)</span><div id='_859_abstract' class='extra' style='font-size:12px;'>Abstract: Brains, unlike artiï¬cial neural nets, use sym- bols to summarise and reason about percep- tual input. But unlike symbolic AI, they âgroundâ the symbols in the data: the sym- bols have meaning in terms of data, not just meaning imposed by the outside user. If neu- ral nets could be made to grow their own sym- bols in the way that brains do, there would be a good prospect of combining neural networks and symbolic AI, in such a way as to combine the good features of each</div>
</div><!--entry-->

<div id='_860_entry' class='entry'><span ><span class='name'>Graham, George</span> (1987). Connectionism in Pavlovian harness.</span> <span class='pub_name'>Southern Journal of Philosophy (Suppl.)</span> 73:73-91. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3642384491468408109'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%20in%20Pavlovian%20harness+author%3AGraham&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_861_entry' class='entry'><span ><span class='name'>Hanson, Susan</span> &amp; <span class='name'>Burr, D.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("HANWCM",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=133849.133857'>What connectionist models learn.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8474619817658198542'>Cited by 81</a> | <span class='ll' onclick='$("_861_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20connectionist%20models%20learn+author%3AHanson&amp;btnG=Search'>Google</a>)</span><div id='_861_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>What's new to connectionism is not learning or representation but the way that learning and representation interact.</div></div>
</div><!--entry-->

<div id='_862_entry' class='entry'><span ><span class='name'>Kaplan, S.</span>; <span class='name'>Weaver, M.</span> &amp; <span class='name'>French, Robert M.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("KAPASA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=87407'>Active symbols and internal models: Towards a cognitive connectionism.</a></span> <span class='pub_name'>AI and Society</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=643375453957847476'>Cited by 18</a> | <span class='ll' onclick='$("_862_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Active%20symbols%20and%20internal%20models+author%3AKaplan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_862_links")'>More links</a>)</span><div id='_862_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Addresses behaviorist/associationist charges. Connectionism needs recurrent circuits to support active symbols.</div></div>
<div id='_862_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KAPASA",this.href,0);return true;' href="http://www.springerlink.com/index/G674K4JTV61G1510.pdf">http://www.springerlink.com/index/G674K4JTV61G1510.pdf</a><br></div></div>
</div><!--entry-->

<div id='_863_entry' class='entry'><span ><span class='name'>Kirsh, David</span> (1987). Putting a price on cognition.</span> <span class='pub_name'>Southern Journal of Philosophy Supplement</span> 26:119-35. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16447515156094525644'>Cited by 9</a> | <span class='ll' onclick='$("_863_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Putting%20a%20price%20on%20cognition+author%3AKirsh&amp;btnG=Search'>Google</a>)</span><div id='_863_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the importance of variable binding, and why it's hard with connectionism.</div></div>
</div><!--entry-->

<div id='_864_entry' class='entry'><span ><span class='name'>Lachter, J.</span> &amp; <span class='name'>Bever, Thomas G.</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("LACTRB",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=58066.58069'>The relation between linguistic structure and associative theories of language learning.</a></span> <span class='pub_name'>Cognition</span> 28:195-247. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4882396110223374373'>Cited by 66</a> | <span class='ll' onclick='$("_864_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20relation%20between%20linguistic%20structure%20and%20associative%20theories%20of%20language%20learning+author%3ALachter&amp;btnG=Search'>Google</a> | <a href='javascript:show("_864_links")'>More links</a>)</span><div id='_864_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Criticism of connectionist language models. They build in too much.</div></div>
<div id='_864_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LACTRB",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=3349761&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=3349761&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_865_entry' class='entry'><span ><span class='name'>Mills, Stephen L.</span> (1989). Connectionism, the classical theory of cognition, and the hundred step constraint.</span> <span class='pub_name'>Acta Analytica</span> 4 (4):5-38. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20the%20classical%20theory%20of%20cognition%2C%20and%20the%20hundred%20step%20constraint+author%3AMills&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_866_entry' class='entry'><span ><span class='name'>Nelson, Raymond J.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("NELPII",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=104919'>Philosophical issues in Edelman's neural darwinism.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 1:195-208. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17990310369164383640'>Cited by 2</a> | <span class='ll' onclick='$("_866_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophical%20issues%20in%20Edelman%27s%20neural%20darwinism+author%3ANelson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_866_links")'>More links</a>)</span><div id='_866_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the relationship between ND, PDP and AI. All are computational.</div></div>
<div id='_866_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NELPII",this.href,0);return true;' href="http://www.informaworld.com/index/778705900.pdf">http://www.informaworld.com/index/778705900.pdf</a><br></div></div>
</div><!--entry-->

<div id='_867_entry' class='entry'><span ><span class='name'>Oaksford, Mike</span>; <span class='name'>Chater, Nick</span> &amp; <span class='name'>Stenning, Keith</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("OAKCCC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=87385.87412'>Connectionism, classical cognitive science and experimental psychology.</a></span> <span class='pub_name'>AI and Society</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11296385644214079692'>Cited by 11</a> | <span class='ll' onclick='$("_867_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20classical%20cognitive%20science%20and%20experimental%20psychology+author%3AOaksford&amp;btnG=Search'>Google</a> | <a href='javascript:show("_867_links")'>More links</a>)</span><div id='_867_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Connectionism is better at explaining empirical findings about mind.</div></div>
<div id='_867_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OAKCCC",this.href,0);return true;' href="http://www.springerlink.com/index/L20P853057770738.pdf">http://www.springerlink.com/index/L20P853057770738.pdf</a><br></div></div>
</div><!--entry-->

<div id='_868_entry' class='entry'><span ><span class='name'>O'Brien, Gerard</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("OBRTRO",this.href,0);return true;' href='http://psycprints.ecs.soton.ac.uk/archive/00000555'>The role of implementation in connectionist explanation.</a></span> <span class='pub_name'>Psycoloquy</span> 9 (6). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17126411321964915638'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20role%20of%20implementation%20in%20connectionist%20explanation+author%3AO%27Brien&amp;btnG=Search'>Google</a> | <a href='javascript:show("_868_links")'>More links</a>)</span>
<div id='_868_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRTRO",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000555/">http://psycprints.ecs.soton.ac.uk/archive/00000555/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRTRO",this.href,0);return true;' href="http://psycprints.ecs.soton.ac.uk/archive/00000555/#html">http://psycprints.ecs.soton.ac.uk/archive/00000555/#html</a><br></div></div>
</div><!--entry-->

<div id='_869_entry' class='entry'><span ><span class='name'>Pinker, Steven</span> &amp; <span class='name'>Prince, Alan</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("PINOLA",this.href,0);return true;' href='http://doi.apa.org/?uid=1989-04635-001'>On language and connectionism.</a></span> <span class='pub_name'>Cognition</span> 28:73-193. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5626771575609814785'>Cited by 612</a> | <span class='ll' onclick='$("_869_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20language%20and%20connectionism+author%3APinker&amp;btnG=Search'>Google</a> | <a href='javascript:show("_869_links")'>More links</a>)</span><div id='_869_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Extremely thorough criticism of the R&M past-tense-learning model, with arguments on why connectionism can't handle linguistic rules.</div></div>
<div id='_869_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=58068">http://portal.acm.org/citation.cfm?id=58068</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://cogsci.soton.ac.uk/harnad/Papers/Py104/pinker.conn.html">http://cogsci.soton.ac.uk/harnad/Papers/Py104/pinker.conn.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://cogsci.soton.ac.uk/~harnad/Papers/Py104/pinker.conn.html">http://cogsci.soton.ac.uk/~harnad/Papers/Py104/pinker.conn.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z7kKwcEIWV&amp;sig=Eg_CAnM1Mg4n2ZmvA2OlpN9m9sw">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z7kKwcEIWV&sig=Eg_CAnM1Mg4n2ZmvA2OlpN9m9sw</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bLtbEAR0&amp;sig=v5UAf_38SNcEICx0yEG3cIhTzJo">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bLtbEAR0&sig=v5UAf_38SNcEICx0yEG3cIhTzJo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z7kKr8IIX_&amp;sig=88u9kHQCTGaVdnM7m8iNb2PPKTY">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z7kKr8IIX_&sig=88u9kHQCTGaVdnM7m8iNb2PPKTY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bLzbIGYY&amp;sig=4kAym1qCPEcgjt8JlqshIRKhIDU">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bLzbIGYY&sig=4kAym1qCPEcgjt8JlqshIRKhIDU</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bKrazHW0&amp;sig=xDNu_Z09OZAy27O-n3WfUmMLQUs">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bKrazHW0&sig=xDNu_Z09OZAy27O-n3WfUmMLQUs</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bMvcCAYZ&amp;sig=5sN8KnPgqLSBs0KApMSatX82EJg">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bMvcCAYZ&sig=5sN8KnPgqLSBs0KApMSatX82EJg</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bKxaDHUT&amp;sig=KeLD5m7m1-u6IfRCZkbe94UL1Es">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bKxaDHUT&sig=KeLD5m7m1-u6IfRCZkbe94UL1Es</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bHx8AFUW&amp;sig=cRtyKLds-QhYetV0FyVJPWnziVI">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bHx8AFUW&sig=cRtyKLds-QhYetV0FyVJPWnziVI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z7kKucDIYZ&amp;sig=E7BrmcOGPhpsKDfBsYC2IVCxHn0">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z7kKucDIYZ&sig=E7BrmcOGPhpsKDfBsYC2IVCxHn0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bHr7GBXY&amp;sig=HMW-DysLVZiCJI1ORuFT8UdXKHM">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bHr7GBXY&sig=HMW-DysLVZiCJI1ORuFT8UdXKHM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bIt8FJUY&amp;sig=ydGhKMgRwpBcRx4at94y5lYz9mE">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bIt8FJUY&sig=ydGhKMgRwpBcRx4at94y5lYz9mE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bGv7AITY&amp;sig=rWgaifux53r8Vm_6Rj2-68EJMjE">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bGv7AITY&sig=rWgaifux53r8Vm_6Rj2-68EJMjE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bJv9EARU&amp;sig=SVeTbYG1MwT2L1atC0yVUgMx0ys">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bJv9EARU&sig=SVeTbYG1MwT2L1atC0yVUgMx0ys</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vZ1t2AnZy3UC&amp;oi=fnd&amp;pg=PA73&amp;ots=Z8bIz9AJU0&amp;sig=-djAWMRY1P5GSdsHAJzC8nqpsAY">http://books.google.com/books?hl=en&lr=&id=vZ1t2AnZy3UC&oi=fnd&pg=PA73&ots=Z8bIz9AJU0&sig=-djAWMRY1P5GSdsHAJzC8nqpsAY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PINOLA",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=2450717&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=2450717&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_870_entry' class='entry'><span ><span class='name'>Potrc, Matjaz</span> (1995). Consciousness and connectionism--the problem of compatability of type identity theory and of connectionism.</span> <span class='pub_name'>Acta Analytica</span> 13 (13):175-190. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Consciousness%20and%20connectionism--the%20problem%20of%20compatability%20of%20type%20identity%20theory%20and%20of%20connectionism+author%3APotrc&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_871_entry' class='entry'><span ><span class='name'>Ross, Don</span> (1998). Internal recurrence.</span> <span class='pub_name'>Dialogue</span> 37 (1):155-161. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Internal%20recurrence+author%3ARoss&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_872_entry' class='entry'><span ><span class='name'>Roth, Martin</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("ROTPEI",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.0268-1064.2005.00295.x'>Program execution in connectionist networks.</a></span> <span class='pub_name'>Mind and Language</span> 20 (4):448-467. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3877559699869863592'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Program%20execution%20in%20connectionist%20networks+author%3ARoth&amp;btnG=Search'>Google</a> | <a href='javascript:show("_872_links")'>More links</a>)</span><div id='_872_abstract' class='extra' style='font-size:12px;'>Abstract:  Recently, connectionist models have been developed that seem to exhibit structuresensitive cognitive capacities without executing a program. This paper examines one such model and argues that it does execute a program. The argument proceeds by showing that what is essential to running a program is preserving the functional structure of the program. It has generally been assumed that this can only be done by systems possessing a certain temporalcausal organization. However, counterfactualpreserving functional architecture can be instantiated in other ways, for example geometrically, which are realizable by connectionist networks</div>
<div id='_872_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROTPEI",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/118696238/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/118696238/PDFSTART</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.4'></a><a name=''></a><span class='myh2'>6.4 Special Topics in AI</span></p>

<div id='cat_6.4' class='cat_content'>
<div id='__new_entries_6.4__'></div><div id='__new_entry_6.4__' class='entry'></div>
<div id='_873_entry' class='entry'><span ><span class='name'>Rhodes, Kris</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("RHOVOT",this.href,0);return true;' href='http://philpapers.org/archive/RHOVOT'>Vindication of the Rights of Machine.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Vindication%20of%20the%20Rights%20of%20Machine+author%3ARhodes&amp;btnG=Search'>Google</a> | <a href='javascript:show("_873_links")'>More links</a>)</span><div id='_873_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper, I argue that certain Machines can have rights independently of whether they are sentient, or conscious, or whatever you might call it.</div>
<div id='_873_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RHOVOT",this.href,0);return true;' href="http://www.igradeyourpaper.com/VRMv3.doc">http://www.igradeyourpaper.com/VRMv3.doc</a><br></div></div>
</div><!--entry-->
</div>
<div id='cat_' class='cat_content'>
<div id='__new_entries___'></div><div id='__new_entry___' class='entry'></div>
<div id='_874_entry' class='entry'><span ><span class='name'>Bostrom, Nick</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("BOSEII",this.href,0);return true;' href='http://www.nickbostrom.com/ethics/ai.pdf'>Ethical issues in advanced artificial intelligence.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Ethical%20issues%20in%20advanced%20artificial%20intelligence+author%3ABostrom&amp;btnG=Search'>Google</a> | <a href='javascript:show("_874_links")'>More links</a>)</span><div id='_874_abstract' class='extra' style='font-size:12px;'>Abstract: The ethical issues related to the possible future creation of machines with general intellectual capabilities far outstripping those of humans are quite distinct from any ethical problems arising in current automation and information systems. Such superintelligence would not be just another technological development; it would be the most important invention ever made, and would lead to explosive progress in all scientific and technological fields, as the superintelligence would conduct research with superhuman efficiency. To the extent that ethics is a cognitive pursuit, a superintelligence could also easily surpass humans in the quality of its moral thinking. However, it would be up to the designers of the superintelligence to specify its original motivations. Since the superintelligence may become unstoppably powerful because of its intellectual superiority and the technologies it could develop, it is crucial that it be provided with human-friendly motivations. This paper surveys some of the unique ethical issues in creating superintelligence, and discusses what motivations we ought to give a superintelligence, and introduces some cost-benefit considerations relating to whether the development of superintelligent machines ought to be accelerated or retarded</div>
<div id='_874_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSEII",this.href,0);return true;' href="http://www.nickbostrom.com/ethics/ai.html">http://www.nickbostrom.com/ethics/ai.html</a><br></div></div>
</div><!--entry-->

<div id='_875_entry' class='entry'><span ><span class='name'>Bostrom, Nick</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("BOSHLB",this.href,0);return true;' href='http://www.nickbostrom.com/superintelligence.html'>How long before superintelligence?</a></span> <span class='pub_name'>International Journal of Futures Studies</span> 2. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8938306286483768875'>Cited by 22</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20long%20before%20superintelligence%3F+author%3ABostrom&amp;btnG=Search'>Google</a>)</span><div id='_875_abstract' class='extra' style='font-size:12px;'>Abstract: _This paper outlines the case for believing that we will have superhuman artificial intelligence_ _within the first third of the next century. It looks at different estimates of the processing power of_ _the human brain; how long it will take until computer hardware achieve a similar performance;_ _ways of creating the software through bottom-up approaches like the one used by biological_ _brains; how difficult it will be for neuroscience figure out enough about how brains work to_ _make this approach work; and how fast we can expect superintelligence to be developed once_ _there is human-level artificial intelligence._</div>
</div><!--entry-->

<div id='_876_entry' class='entry'><span ><span class='name'>Bostrom, Nick</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("BOSTIM",this.href,0);return true;' href='http://www.nickbostrom.com/2050/reply.html'>Taking intelligent machines seriously: Reply to critics.</a></span> <span class='pub_name'>Futures</span> 35 (8):901-906. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Taking%20intelligent%20machines%20seriously+author%3ABostrom&amp;btnG=Search'>Google</a> | <a href='javascript:show("_876_links")'>More links</a>)</span><div id='_876_abstract' class='extra' style='font-size:12px;'>Abstract: In an earlier paper in this journal[1], I sought to defend the claims that (1) substantial probability should be assigned to the hypothesis that machines will outsmart humans within 50 years, (2) such an event would have immense ramifications for many important areas of human concern, and that consequently (3) serious attention should be given to this scenario. Here, I will address a number of points made by several commentators</div>
<div id='_876_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSTIM",this.href,0);return true;' href="http://www.questia.com/PM.qst?a=o&amp;se=gglsc&amp;d=5002030442">http://www.questia.com/PM.qst?a=o&se=gglsc&d=5002030442</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSTIM",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S0016328703000466">http://linkinghub.elsevier.com/retrieve/pii/S0016328703000466</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSTIM",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/00163287/2003/00000035/00000008/art00046">http://www.ingentaconnect.com/content/els/00163287/2003/00000035/00000008/art00046</a><br></div></div>
</div><!--entry-->

<div id='_877_entry' class='entry'><span ><span class='name'>Bostrom, Nick</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("BOSWMO",this.href,0);return true;' href='http://www.nickbostrom.com/2050/outsmart.html'>When machines outsmart humans.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=When%20machines%20outsmart%20humans+author%3ABostrom&amp;btnG=Search'>Google</a>)</span><div id='_877_abstract' class='extra' style='font-size:12px;'>Abstract: Artificial intelligence is a possibility that should not be ignored in any serious thinking about the future, and it raises many profound issues for ethics and public policy that philosophers ought to start thinking about. This article outlines the case for thinking that human-level machine intelligence might well appear within the next half century. It then explains four immediate consequences of such a development, and argues that machine intelligence would have a revolutionary impact on a wide range of the social, political, economic, commercial, technological, scientific and environmental issues that humanity will face over the coming decades</div>
</div><!--entry-->

<div id='_878_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span>, <a rel="nofollow" class='article_title' onclick='trackclick("CHATSA",this.href,0);return true;' href='http://consc.net/papers/singularity.pdf'>The singularity: A philosophical analysis.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20singularity+author%3AChalmers&amp;btnG=Search'>Google</a>)</span><div id='_878_abstract' class='extra' style='font-size:12px;'>Abstract: What happens when machines become more intelligent than humans? One view is that this event will be followed by an explosion to ever-greater levels of intelligence, as each generation of machines creates more intelligent machines in turn. This intelligence explosion is now often known as the âsingularityâ. The basic argument here was set out by the statistician I.J. Good in his 1965 article âSpeculations Concerning the First Ultraintelligent Machineâ: Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an âintelligence explosionâ, and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make. The key idea is that a machine that is more intelligent than humans will be better than humans at designing machines. So it will be capable of designing a machine more intelligent than the most intelligent machine that humans can design. So if it is itself designed by humans, it will be capable of designing a machine more intelligent than itself. By similar reasoning, this next machine will also be capable of designing a machine more intelligent than itself. If every machine in turn does what it is capable of, we should expect a sequence of ever more intelligent machines. This intelligence explosion is sometimes combined with another idea, which we might call the âspeed explosionâ. The argument for a speed explosion starts from the familiar observation that computer processing speed doubles at regular intervals. Suppose that speed doubles every two years and will do so indefinitely. Now suppose that we have human-level artificial intelligence 1 designing new processors. Then faster processing will lead to faster designers and an ever-faster design cycle, leading to a limit point soon afterwards. The argument for a speed explosion was set out by the artificial intelligence researcher Ray Solomonoff in his 1985 article âThe Time Scale of Artificial Intelligenceâ.1 Eliezer Yudkowsky gives a succinct version of the argument in his 1996 article âStaring at the Singularityâ: âComputing speed doubles every two subjective years of work..</div>
</div><!--entry-->

<div id='_879_entry' class='entry'><span ><span class='name'>Hall, John Storrs</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("HALSAA",this.href,0);return true;' href='http://www.springerlink.com/content/0n70u4l8q7235840/fulltext.pdf'>Self-improving AI: An analysis.</a></span> <span class='pub_name'>Minds and Machines</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Self-improving%20AI+author%3AHall&amp;btnG=Search'>Google</a>)</span><div id='_879_abstract' class='extra' style='font-size:12px;'>Abstract:  Self-improvement was one of the aspects of AI proposed for study in the 1956 Dartmouth conference. Turing proposed a âchild machineâ which could be taught in the human manner to attain adult human-level intelligence. In latter days, the contention that an AI system could be built to learn and improve itself indefinitely has acquired the label of the bootstrap fallacy. Attempts in AI to implement such a system have met with consistent failure for half a century. Technological optimists, however, have maintained that a such system is possible, producing, if implemented, a feedback loop that would lead to a rapid exponential increase in intelligence. We examine the arguments for both positions and draw some conclusions</div>
</div><!--entry-->

<div id='_880_entry' class='entry'><span ><span class='name'>Hanson, Robin</span>, <a rel="nofollow" class='article_title' onclick='trackclick("HANIAS-2",this.href,0);return true;' href='http://hanson.gmu.edu/fastgrow.html'>Is a singularity just around the corner?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20a%20singularity%20just%20around%20the%20corner%3F+author%3AHanson&amp;btnG=Search'>Google</a>)</span><div id='_880_abstract' class='extra' style='font-size:12px;'>Abstract: Economic growth is determined by the supply and demand of investment capital; technology determines the demand for capital, while human nature determines the supply. The supply curve has two distinct parts, giving the world economy two distinct modes. In the familiar slow growth mode, rates of return are limited by human discount rates. In the fast growth mode, investment is limited by the world's wealth. Historical trends suggest that we may transition to the fast mode in roughly another century and a half</div>
</div><!--entry-->

<div id='_881_entry' class='entry'><span ><span class='name'>Vinge, Vernor</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("VINTTS",this.href,0);return true;' href='http://wholeearth.com/ArticleBin/111-3.pdf'>The technological singularity.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5611128554145293913'>Cited by 43</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20technological%20singularity+author%3AVinge&amp;btnG=Search'>Google</a> | <a href='javascript:show("_881_links")'>More links</a>)</span>
<div id='_881_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://wholeearthmag.com/ArticleBin/111-3.pdf">http://wholeearthmag.com/ArticleBin/111-3.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1993vise.nasa...11V">http://adsabs.harvard.edu/abs/1993vise.nasa...11V</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.aleph.se/Trans/Global/Singularity/sing.html">http://www.aleph.se/Trans/Global/Singularity/sing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.cs.ucsd.edu/users/goguen/misc/singularity.html">http://www.cs.ucsd.edu/users/goguen/misc/singularity.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.kurzweilai.net/articles/art0092.html?printable=1">http://www.kurzweilai.net/articles/art0092.html?printable=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=N9427359AH">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=N9427359AH</a><br></div></div>
</div><!--entry-->

<div id='_882_entry' class='entry'><span ><span class='name'>Yudkowsky, Eliezer</span> (online). Staring into the singularity.</span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Staring%20into%20the%20singularity+author%3AYudkowsky&amp;btnG=Search'>Google</a>)</span><div id='_882_abstract' class='extra' style='font-size:12px;'>Abstract: 1: The End of History 2: The Beyondness of the Singularity 2.1: The Definition of Smartness 2.2: Perceptual Transcends 2.3: Great Big Numbers 2.4: Smarter Than We Are 3: Sooner Than You Think 4: Uploading 5: The Interim Meaning of Life 6: Getting to the Singularity</div>
</div><!--entry-->
</div>
<div id='cat_' class='cat_content'>
<div id='__new_entries___'></div><div id='__new_entry___' class='entry'></div>
<div id='_883_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span>, <a rel="nofollow" class='article_title' onclick='trackclick("CHATSA",this.href,0);return true;' href='http://consc.net/papers/singularity.pdf'>The singularity: A philosophical analysis.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20singularity+author%3AChalmers&amp;btnG=Search'>Google</a>)</span><div id='_883_abstract' class='extra' style='font-size:12px;'>Abstract: What happens when machines become more intelligent than humans? One view is that this event will be followed by an explosion to ever-greater levels of intelligence, as each generation of machines creates more intelligent machines in turn. This intelligence explosion is now often known as the âsingularityâ. The basic argument here was set out by the statistician I.J. Good in his 1965 article âSpeculations Concerning the First Ultraintelligent Machineâ: Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an âintelligence explosionâ, and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make. The key idea is that a machine that is more intelligent than humans will be better than humans at designing machines. So it will be capable of designing a machine more intelligent than the most intelligent machine that humans can design. So if it is itself designed by humans, it will be capable of designing a machine more intelligent than itself. By similar reasoning, this next machine will also be capable of designing a machine more intelligent than itself. If every machine in turn does what it is capable of, we should expect a sequence of ever more intelligent machines. This intelligence explosion is sometimes combined with another idea, which we might call the âspeed explosionâ. The argument for a speed explosion starts from the familiar observation that computer processing speed doubles at regular intervals. Suppose that speed doubles every two years and will do so indefinitely. Now suppose that we have human-level artificial intelligence 1 designing new processors. Then faster processing will lead to faster designers and an ever-faster design cycle, leading to a limit point soon afterwards. The argument for a speed explosion was set out by the artificial intelligence researcher Ray Solomonoff in his 1985 article âThe Time Scale of Artificial Intelligenceâ.1 Eliezer Yudkowsky gives a succinct version of the argument in his 1996 article âStaring at the Singularityâ: âComputing speed doubles every two subjective years of work..</div>
</div><!--entry-->
</div>
<p><a name='.6.4a'></a><a name=''></a><span class='myh3'>6.4a Cyborgs</span></p>

<div id='cat_6.4a' class='cat_content'>
<div id='__new_entries_6.4a__'></div><div id='__new_entry_6.4a__' class='entry'></div></div>
<p><a name='.6.4b'></a><a name=''></a><span class='myh3'>6.4b Transhumanism</span></p>

<div id='cat_6.4b' class='cat_content'>
<div id='__new_entries_6.4b__'></div><div id='__new_entry_6.4b__' class='entry'></div></div>
<p><a name='.6.4c'></a><a name=''></a><span class='myh3'>6.4c Cybernetics</span></p>

<div id='cat_6.4c' class='cat_content'>
<div id='__new_entries_6.4c__'></div><div id='__new_entry_6.4c__' class='entry'></div>
<div id='_884_entry' class='entry'><span ><span class='name'>Mazis, Glen</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("MAZCLT",this.href,0);return true;' href='http://philpapers.org/archive/MAZCLT'>Cyborg Life: The In-Between of Humans and Machines.</a></span> <span class='pub_name'>PhaenEx</span> 3 (2):14-36. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cyborg%20Life+author%3AMazis&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.4d'></a><a name=''></a><span class='myh3'>6.4d Dynamical Systems</span></p>

<div id='cat_6.4d' class='cat_content'>
<div id='__new_entries_6.4d__'></div><div id='__new_entry_6.4d__' class='entry'></div>
<div id='_885_entry' class='entry'><span ><span class='name'>Abrahamsen, Adele A.</span> &amp; <span class='name'>Bechtel, William P.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("ABRPAM",this.href,0);return true;' href='http://mechanism.ucsd.edu/~bill/research/controversiespaper.pdf'>Phenomena and mechanisms: Putting the symbolic, connectionist, and dynamical systems debate in broader perspective.</a></span> In  R. Stainton (ed.), <em>Contemporary Debates in Cognitive Science</em>. Basil Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Phenomena%20and%20mechanisms+author%3AAbrahamsen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_885_links")'>More links</a>)</span><div id='_885_abstract' class='extra' style='font-size:12px;'>Abstract: Cognitive science is, more than anything else, a pursuit of cognitive mechanisms. To make headway towards a mechanistic account of any particular cognitive phenomenon, a researcher must choose among the many architectures available to guide and constrain the account. It is thus fitting that this volume on contemporary debates in cognitive science includes two issues of architecture, each articulated in the 1980s but still unresolved: <blockquote> â¢ Just how modular is the mind? (section 1) â a debate initially pitting encapsulated <br> mechanisms (Fodorian modules that feed their ultimate outputs to a nonmodular central <br> cognition) against highly interactive ones (e.g., connectionist networks that continuously <br> feed streams of output to one another). <br> â¢ Does the mind process language-like representations according to formal rules? (this <br> section) â a debate initially pitting symbolic architectures (such as Chomskyâs generative <br> grammar or Fodorâs language of thought) against less language-like architectures (such <br> as connectionist or dynamical ones). </blockquote> Our project here is to consider the second issue within the broader context of where cognitive science has been and where it is headed. The notion that cognition in generalânot just language processingâinvolves rules operating on language-like representations actually predates cognitive science. In traditional philosophy of mind, mental life is construed as involving propositional attitudesâthat is, such attitudes towards propositions as believing, fearing, and desiring that they be trueâand logical inferences from them. On this view, if a person desires that a proposition be true and believes that if she performs a certain action it will become true, she will make the inference and (absent any overriding consideration) perform the action</div>
<div id='_885_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ABRPAM",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=OR-ApDfUMUkC&amp;oi=fnd&amp;pg=RA1-PT103&amp;dq=Phenomena+and+mechanisms+Abrahamsen&amp;ots=LNjBNEN5rD&amp;sig=BPLpA8As8Lm_kuVh5kiz4L2Xxuc">http://books.google.com/books?hl=en&lr=&id=OR-ApDfUMUkC&oi=fnd&pg=RA1-PT103&dq=Phenomena+and+mechanisms+Abrahamsen&ots=LNjBNEN5rD&sig=BPLpA8As8Lm_kuVh5kiz4L2Xxuc</a><br></div></div>
</div><!--entry-->

<div id='_886_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("BECDAD",this.href,0);return true;' href='http://mechanism.ucsd.edu/~bill/research/dynamics.htm'>Dynamics and decomposition: Are they compatible?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14959088801283322325'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dynamics%20and%20decomposition+author%3ABechtel&amp;btnG=Search'>Google</a>)</span><div id='_886_abstract' class='extra' style='font-size:12px;'>Abstract: Much of cognitive neuroscience as well as traditional cognitive science is engaged in a quest for mechanisms through a project of decomposition and localization of cognitive functions. Some advocates of the emerging dynamical systems approach to cognition construe it as in opposition to the attempt to decompose and localize functions. I argue that this case is not established and rather explore how dynamical systems tools can be used to analyze and model cognitive functions without abandoning the use of decomposition and localization to understand mechanisms of cognition</div>
</div><!--entry-->

<div id='_887_entry' class='entry'><span ><span class='name'>Bechtel, William P.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("BECRAC",this.href,0);return true;' href='http://mechanism.ucsd.edu/~bill/research/REPRESENT.html'>Representations and cognitive explanations: Assessing the dynamicist challenge in cognitive science.</a></span> <span class='pub_name'>Cognitive Science</span> 22 (3):295-317. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12197414902310144482'>Cited by 64</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Representations%20and%20cognitive%20explanations+author%3ABechtel&amp;btnG=Search'>Google</a> | <a href='javascript:show("_887_links")'>More links</a>)</span><div id='_887_abstract' class='extra' style='font-size:12px;'>Abstract: Advocates of dynamical systems theory (DST) sometimes employ revolutionary rhetoric. In an attempt to clarify how DST models differ from others in cognitive science, I focus on two issues raised by DST: the role for representations in mental models and the conception of explanation invoked. Two features of representations are their role in standing-in for features external to the system and their format. DST advocates sometimes claim to have repudiated the need for stand-ins in DST models, but I argue that they are mistaken. Nonetheless, DST does offer new ideas as to the format of representations employed in cognitive systems. With respect to explanation, I argue that some DST models are better seen as conforming to the covering-law conception of explanation than to the mechanistic conception of explanation implicit in most cognitive science research. But even here, I argue, DST models are a valuable complement to more mechanistic cognitive explanations</div>
<div id='_887_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECRAC",this.href,0);return true;' href="http://www.leaonline.com/doi/abs/10.1207/s15516709cog2203_2">http://www.leaonline.com/doi/abs/10.1207/s15516709cog2203_2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECRAC",this.href,0);return true;' href="http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog2203_2">http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog2203_2</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECRAC",this.href,0);return true;' href="http://www.cogsci.rpi.edu/CSJarchive/1998v22/i03/p0295p0318/MAIN.PDF">http://www.cogsci.rpi.edu/CSJarchive/1998v22/i03/p0295p0318/MAIN.PDF</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BECRAC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/03640213/1998/00000022/00000003/art80042">http://www.ingentaconnect.com/content/els/03640213/1998/00000022/00000003/art80042</a><br></div></div>
</div><!--entry-->

<div id='_888_entry' class='entry'><span ><span class='name'>Bedau, Mark A.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("BEDEMO",this.href,0);return true;' href='http://www.reed.edu/~mab/publications/papers/emergent-models.html'>Emergent models of supple dynamics in life and mind.</a></span> <span class='pub_name'>Brain and Cognition</span> 34:5-27. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 12 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Emergent%20models%20of%20supple%20dynamics%20in%20life%20and%20mind+author%3ABedau&amp;btnG=Search'>Google</a> | <a href='javascript:show("_888_links")'>More links</a>)</span><div id='_888_abstract' class='extra' style='font-size:12px;'>Abstract: The dynamical patterns in mental phenomena have a characteristic suppleness&emdash;a looseness or softness that persistently resists precise formulation&emdash;which apparently underlies the frame problem of artificial intelligence. This suppleness also undermines contemporary philosophical functionalist attempts to define mental capacities. Living systems display an analogous form of supple dynamics. However, the supple dynamics of living systems have been captured in recent artificial life models, due to the emergent architecture of those models. This suggests that analogous emergent models might be able to explain supple dynamics of mental phenomena. These emergent models of the supple mind, if successful, would refashion the nature of contemporary functionalism in the philosophy of mind</div>
<div id='_888_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BEDEMO",this.href,0);return true;' href="http://people.reed.edu/~mab/publications/papers/emergent-models.html">http://people.reed.edu/~mab/publications/papers/emergent-models.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BEDEMO",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=9209753&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=9209753&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BEDEMO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/ap/br/1997/00000034/00000001/art00904">http://www.ingentaconnect.com/content/ap/br/1997/00000034/00000001/art00904</a><br></div></div>
</div><!--entry-->

<div id='_889_entry' class='entry'><span ><span class='name'>Chemero, Anthony</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("CHEAAT",this.href,0);return true;' href='http://edisk.fandm.edu/tony.chemero/papers/ards.pdf'>Anti-representationalism and the dynamical stance.</a></span> <span class='pub_name'>Philosophy of Science</span> 67 (4):625-647. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=593188375690207270'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Anti-representationalism%20and%20the%20dynamical%20stance+author%3AChemero&amp;btnG=Search'>Google</a> | <a href='javascript:show("_889_links")'>More links</a>)</span><div id='_889_abstract' class='extra' style='font-size:12px;'>Abstract: Arguments in favor of anti-representationalism in cognitive science often suffer from a lack of attention to detail. The purpose of this paper is to fill in the gaps in these arguments, and in so doing show that at least one form of anti- representationalism is potentially viable. After giving a teleological definition of representation and applying it to a few models that have inspired anti- representationalist claims, I argue that anti-representationalism must be divided into two distinct theses, one ontological, one epistemological. Given the assumptions that define the debate, I give reason to think that the ontological thesis is false. I then argue that the epistemological thesis might, in the end, turn out to be true, despite a potentially serious difficulty. Along the way, there will be a brief detour to discuss a controversy from early twentieth century physics</div>
<div id='_889_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEAAT",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0031-8248(200012)67:4&lt;625:AATDS&gt;2.0.CO;2-Y">http://links.jstor.org/sici?sici=0031-8248(200012)67:4<625:AATDS>2.0.CO;2-Y</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEAAT",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8248(200012)67:4&lt;625:AATDS&gt;2.0.CO;2-Y">http://www.jstor.org/sici?sici=0031-8248(200012)67:4<625:AATDS>2.0.CO;2-Y</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEAAT",this.href,0);return true;' href="http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/392858">http://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/392858</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEAAT",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/188710.pdf">http://www.jstor.org/stable/pdfplus/188710.pdf</a><br></div></div>
</div><!--entry-->

<div id='_890_entry' class='entry'><span ><span class='name'>Chemero, Tony</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("CHEDEA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/686533.html'>Dynamical explanation and mental representations.</a></span> <span class='pub_name'>Trends in Cognitive Sciences</span> 5 (4):141-142. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11633265261104752986'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dynamical%20explanation%20and%20mental%20representations+author%3AChemero&amp;btnG=Search'>Google</a> | <a href='javascript:show("_890_links")'>More links</a>)</span><div id='_890_abstract' class='extra' style='font-size:12px;'>Abstract: Markman and Dietrich<sup>1</sup> recently recommended extending our understanding of representation to incorporate insights from some âalternativeâ theories of cognition: perceptual symbol systems, situated action, embodied cognition, and dynamical systems. In particular, they suggest that allowances be made for new types of representation which had been previously under-emphasized in cognitive science. The amendments they recommend are based upon the assumption that the alternative positions each agree with the classical view that cognition requires representations, internal mediating states that bear information.<sup>2 </sup>In the case of one of the alternatives, dynamical systems<sup>3</sup>, this is simply false: many dynamically-oriented cognitive scientists are anti-representationalists.<sup>4,5,6</sup></div>
<div id='_890_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEDEA",this.href,0);return true;' href="http://edisk.fandm.edu/tony.chemero/papers/mand.pdf">http://edisk.fandm.edu/tony.chemero/papers/mand.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEDEA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/chemero01dynamical.html">http://citeseer.ist.psu.edu/chemero01dynamical.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEDEA",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S1364661300016272">http://linkinghub.elsevier.com/retrieve/pii/S1364661300016272</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHEDEA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/13646613/2001/00000005/00000004/art01627">http://www.ingentaconnect.com/content/els/13646613/2001/00000005/00000004/art01627</a><br></div></div>
</div><!--entry-->

<div id='_891_entry' class='entry'><span ><span class='name'>Chemero, Anthony</span> &amp; <span class='name'>Cordeiro, William</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("CHEDES",this.href,0);return true;' href='http://host.uniroma3.it/progetti/kant/field/hurleysymp_chemero_cordeiro.htm'>Dynamical, ecological sub-persons.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3831236611237830182'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dynamical%2C%20ecological%20sub-persons+author%3AChemero&amp;btnG=Search'>Google</a>)</span><div id='_891_abstract' class='extra' style='font-size:12px;'>Abstract: Scientific and Philosophical Studies of Mind </text> <text top="177" left="52" width="159" height="17" font="9">Franklin and Marshall College </text> <text top="197" left="52" width="173" height="17" font="9">Lancaster, PA 17604-3003 USA<sub></text> <text top="-5" left="736" width="0" height="20" font="1"></sub></div>
</div><!--entry-->

<div id='_892_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("CLACOT",this.href,0);return true;' href='http://www.california.com/~mcmf/clark.html'>Commentary on "the modularity of dynamic systems".</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Commentary%20on%20the%20modularity%20of%20dynamic%20systems+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_892_links")'>More links</a>)</span><div id='_892_abstract' class='extra' style='font-size:12px;'>Abstract: 1. Throughout the paper, and especially in the section called "LISP vs. DST", I worried that there was not enough focus on EXPLANATION. For the real question, it seems to me, is not whether some dynamical system can implement human cognition, but whether the dynamical description of the system is more explanatorily potent than a computational/representational one. Thus we know, for example, that a purely physical specification can fix a system capable of computing any LISP function. But from this it doesn't follow that the physical description is the one we need to understand the power of the system considered as an information processing device. In the same way, I don't think your demonstration that bifurcating attractor sets can yield the same behavior as a LISP program goes any way towards showing that we should not PREFER the LISP description. To reduce symbolic stories to a subset of DST (as hinted in that section) requires MORE than showing this kind of equivalence: it requires showing that there is explanatory gain, or at the very least, no explanatory loss, at that level. I append an extract from a recent paper of mine that touches on these issues, in case it helps clarify what I am after here</div>
<div id='_892_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLACOT",this.href,0);return true;' href="http://users.california.com/~mcmf/clark.html">http://users.california.com/~mcmf/clark.html</a><br></div></div>
</div><!--entry-->

<div id='_893_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("CLATAM",this.href,0);return true;' href='http://www.cogs.indiana.edu/andy/time.pdf'>Time and mind.</a></span> <span class='pub_name'>Journal of Philosophy</span> 95 (7):354-76. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5926388860807501269'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Time%20and%20mind+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_893_links")'>More links</a>)</span><div id='_893_abstract' class='extra' style='font-size:12px;'>Abstract: Mind, it has recently been argued1, is a thoroughly temporal phenomenon: so temporal, indeed, as to defy description and analysis using the traditional computational tools of cognitive scientific understanding. The proper explanatory tools, so the suggestion goes, are instead the geometric constructs and differential equations of Dynamical Systems Theory. I consider various aspects of the putative temporal challenge to computational understanding, and show that the root problem turns on the presence of a certain kind of causal web: a web that involves multiple components (both inner and outer) linked by chains of continuous and reciprocal causal influence. There is, however, no compelling route from such facts about causal and temporal complexity to the radical anti- computationalist conclusion. This is because, interactive complexities notwithstanding, the computational approach provides a kind of explanatory understanding that cannot (I suggest) be recreated using the alternative resources of pure Dynamical Systems Theory. In particular, it provides a means of mapping information flow onto causal structure -- a mapping that is crucial to understanding the distinctive kinds of flexibility and control characteristic of truly mindful engagements with the world. Where we confront especially complex interactive causal webs, however, it does indeed become harder to isolate the syntactic vehicles required by the computational approach. Dynamical Systems Theory, I conclude, may play a vital role in recovering such vehicles from the burgeoning mass of real-time interactive complexity</div>
<div id='_893_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAM",this.href,0);return true;' href="http://www.philosophy.ed.ac.uk/staff/clark/pubs/time.pdf">http://www.philosophy.ed.ac.uk/staff/clark/pubs/time.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAM",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0022-362X(199807)95:7&lt;354:TAM&gt;2.0.CO;2-E">http://links.jstor.org/sici?sici=0022-362X(199807)95:7<354:TAM>2.0.CO;2-E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAM",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(199807)95:7&lt;354:TAM&gt;2.0.CO;2-E">http://www.jstor.org/sici?sici=0022-362X(199807)95:7<354:TAM>2.0.CO;2-E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAM",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2564539.pdf">http://www.jstor.org/stable/pdfplus/2564539.pdf</a><br></div></div>
</div><!--entry-->

<div id='_894_entry' class='entry'><span ><span class='name'>Cruz, Joe</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("CRUPEA",this.href,0);return true;' href='http://www.williams.edu/philosophy/fourth_layer/faculty_pages/jcruz/schonbeincomments.pdf'>Psychological explanation and noise in modeling. Comments on Whit Schonbein's "cognition and the power of continuous dynamical systems".</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Psychological%20explanation%20and%20noise%20in%20modeling.%20Comments%20on%20Whit%20Schonbein%27s%20cognition%20and%20the%20power%20of%20continuous%20dynamical%20systems+author%3ACruz&amp;btnG=Search'>Google</a>)</span><div id='_894_abstract' class='extra' style='font-size:12px;'>Abstract: I find myself ambivalent with respect to the line of argument that Schonbein offers. I certainly want to acknowledge and emphasize at the outset that Schonbeinâs discussion has brought to the fore a number of central, compelling and intriguing issues regarding the nature of the dynamical approach to cognition. Though there is much that seems right in this essay, perhaps my view is that the paper invites more questions than it answers. My remarks here then are in the spirit of scouting some of the surrounding terrain in order to see just what Schonbeinâs claim is and what arguments or options may be open to the dynamicist</div>
</div><!--entry-->

<div id='_895_entry' class='entry'><span ><span class='name'>Eiser, J. Richard</span> (1994). <em><span class='pub_name'>Attitudes, Chaos, and the Connectionist Mind.</span></em></span> Cambridge: Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7959520620352587511'>Cited by 67</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Attitudes%2C%20Chaos%2C%20and%20the%20Connectionist%20Mind+author%3AEiser&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_896_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("ELIAAI",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596938'>Attractive and in-discrete: A critique of two putative virtues of the dynamicist theory of mind.</a></span> <span class='pub_name'>Minds And Machines</span> 11 (3):417-426. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5851218891271811115'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Attractive%20and%20in-discrete+author%3AEliasmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_896_links")'>More links</a>)</span><div id='_896_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â I argue that dynamicism does not provide a convincing alternative to currently available cognitive theories. First, I show that the attractor dynamics of dynamicist models are inadequate for accounting for high-level cognition. Second, I argue that dynamicist arguments for the rejection of computation and representation are unsound in light of recent empirical findings. This new evidence provides a basis for questioning the importance of continuity to cognitive function, challenging a central commitment of dynamicism. Coupled with a defense of current connectionist theory, these two critiques lead to the conclusion that dynamicists have failed to achieve their goal of providing a new paradigm for understanding cognition</div>
<div id='_896_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIAAI",this.href,0);return true;' href="http://watarts.uwaterloo.ca/~celiasmi/Papers/ce.press.attractive.mm.html">http://watarts.uwaterloo.ca/~celiasmi/Papers/ce.press.attractive.mm.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIAAI",this.href,0);return true;' href="http://www.springerlink.com/content/w7777h0413p32864/fulltext.pdf">http://www.springerlink.com/content/w7777h0413p32864/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIAAI",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=338891&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=338891&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIAAI",this.href,0);return true;' href="http://www.springerlink.com/index/W7777H0413P32864.pdf">http://www.springerlink.com/index/W7777H0413P32864.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIAAI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000003/00338891">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000003/00338891</a><br></div></div>
</div><!--entry-->

<div id='_897_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("ELICAD-2",this.href,0);return true;' href='http://cogprints.org/325/'>Computation and dynamical models of mind.</a></span> <span class='pub_name'>Minds and Machines</span> 7 (4):531-41. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14213801709099286102'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computation%20and%20dynamical%20models%20of%20mind+author%3AEliasmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_897_links")'>More links</a>)</span><div id='_897_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Van Gelder (1995) has recently spearheaded a movement to challenge the dominance of connectionist and classicist models in cognitive science. The dynamical conception of cognition is van Gelder's replacement for the computation bound paradigms provided by connectionism and classicism. He relies on the Watt governor to fulfill the role of a dynamicist Turing machine and claims that the Motivational Oscillatory Theory (MOT) provides a sound empirical basis for dynamicism. In other words, the Watt governor is to be the theoretical exemplar of the class of systems necessary for cognition and MOT is an empirical instantiation of that class. However, I shall argue that neither the Watt governor nor MOT successfully fulfill these prescribed roles. This failure, along with van Gelder's peculiar use of the concept of computation and his struggle with representationalism, prevent him from providing a convincing alternative to current cognitive theories</div>
<div id='_897_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://cogprints.org/325/ ">http://cogprints.org/325/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000325/">http://cogprints.ecs.soton.ac.uk/archive/00000325/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000325/ ">http://cogprints.ecs.soton.ac.uk/archive/00000325/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596707.596756">http://portal.acm.org/citation.cfm?id=596707.596756</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~celiasmi/Papers/dynamics.mm.html">http://www.arts.uwaterloo.ca/~celiasmi/Papers/dynamics.mm.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~celiasmi/Papers/dynamics.mm.html ">http://www.arts.uwaterloo.ca/~celiasmi/Papers/dynamics.mm.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=316239CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=316239CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:325">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:325</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=316239CI ">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=316239CI </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:325 ">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:325 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.springerlink.com/content/content/u013j75041272360/fulltext.pdf">http://www.springerlink.com/content/content/u013j75041272360/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.springerlink.com/content/u013j75041272360/fulltext.pdf">http://www.springerlink.com/content/u013j75041272360/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=125137&amp;PDF=1 ">http://www.kluweronline.com/article.asp?PIPS=125137&PDF=1 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=125137&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=125137&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.springerlink.com/index/U013J75041272360.pdf ">http://www.springerlink.com/index/U013J75041272360.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.springerlink.com/index/U013J75041272360.pdf">http://www.springerlink.com/index/U013J75041272360.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00125137 ">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00125137 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00125137">http://www.ingentaconnect.com/content/klu/mind/1997/00000007/00000004/00125137</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://cogprints.org/325/1/dynamics.mm.html">http://cogprints.org/325/1/dynamics.mm.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELICAD-2",this.href,0);return true;' href="http://cogprints.org/325/0/dynamics.mm.html">http://cogprints.org/325/0/dynamics.mm.html</a><br></div></div>
</div><!--entry-->

<div id='_898_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("ELIDMA",this.href,0);return true;' href='http://www.arts.uwaterloo.ca/~celiasmi/Papers/vangelderbbs.html'>Dynamical models and Van gelder's dynamicism.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21 (5):639-639. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1061722985095884220'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dynamical%20models%20and%20Van%20gelder%27s%20dynamicism+author%3AEliasmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_898_links")'>More links</a>)</span><div id='_898_abstract' class='extra' style='font-size:12px;'>Abstract: Van Gelder has presented a position which he ties closely to a broad class of models known as dynamical models. While supporting many of his broader claims about the importance of this class (as has been argued by connectionists for quite some time), I note that there are a number of unique characteristics of his brand of dynamicism. I suggest that these characteristics engender difficulties for his view</div>
<div id='_898_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIDMA",this.href,0);return true;' href="http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=30438&amp;jid=BBS&amp;volumeId=21&amp;issueId=05&amp;aid=30437">http://journals.cambridge.org/action/displayFulltext?type=1&fid=30438&jid=BBS&volumeId=21&issueId=05&aid=30437</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIDMA",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X98341734">http://www.journals.cambridge.org/abstract_S0140525X98341734</a><br></div></div>
</div><!--entry-->

<div id='_899_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("ELIMBM",this.href,0);return true;' href='http://www.hss.caltech.edu/~steve/eliasmith.pdf'>Moving beyond metaphors: Understanding the mind for what it is.</a></span> <span class='pub_name'>Journal of Philosophy</span> 100 (10):493-520. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7996168995502401943'>Cited by 21</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Moving%20beyond%20metaphors+author%3AEliasmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_899_links")'>More links</a>)</span>
<div id='_899_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIMBM",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~doneill/cogsci600/Eliasmith.pdf">http://www.arts.uwaterloo.ca/~doneill/cogsci600/Eliasmith.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIMBM",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~raha/CogSci600_web/Readings/eliasmith1.pdf">http://www.arts.uwaterloo.ca/~raha/CogSci600_web/Readings/eliasmith1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIMBM",this.href,0);return true;' href="http://watarts.uwaterloo.ca/~celiasmi/Papers/eliasmith.moving beyond metaphors.jphil.pdf">http://watarts.uwaterloo.ca/~celiasmi/Papers/eliasmith.moving beyond metaphors.jphil.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIMBM",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~celiasmi/Papers/eliasmith.moving beyond metaphors.jphil.pdf">http://www.arts.uwaterloo.ca/~celiasmi/Papers/eliasmith.moving beyond metaphors.jphil.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELIMBM",this.href,0);return true;' href="http://www.journalofphilosophy.org/articles/../issues/100/10/1.pdf">http://www.journalofphilosophy.org/articles/../issues/100/10/1.pdf</a><br></div></div>
</div><!--entry-->

<div id='_900_entry' class='entry'><span ><span class='name'>Eliasmith, Chris</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("ELITTC",this.href,0);return true;' href='http://cogprints.org/324/'>The third contender: A critical examination of the dynamicist theory of cognition.</a></span> <span class='pub_name'>[Journal (Paginated)]</span> 9 (4):441-63. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1576258063024540480'>Cited by 79</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20third%20contender+author%3AEliasmith&amp;btnG=Search'>Google</a> | <a href='javascript:show("_900_links")'>More links</a>)</span><div id='_900_abstract' class='extra' style='font-size:12px;'>Abstract: In a recent series of publications, dynamicist researchers have proposed a new conception of cognitive functioning. This conception is intended to replace the currently dominant theories of connectionism and symbolicism. The dynamicist approach to cognitive modeling employs concepts developed in the mathematical field of dynamical systems theory. They claim that cognitive models should be embedded, low-dimensional, complex, described by coupled differential equations, and non-representational. In this paper I begin with a short description of the dynamicist project and its role as a cognitive theory. Subsequently, I determine the theoretical commitments of dynamicists, critically examine those commitments and discuss current examples of dynamicist models. In conclusion, I determine dynamicism's relation to symbolicism and connectionism and find that the dynamicist goal to establish a new paradigm has yet to be realized</div>
<div id='_900_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://cogprints.org/324/0/thirdcontender.html">http://cogprints.org/324/0/thirdcontender.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000324/">http://cogprints.ecs.soton.ac.uk/archive/00000324/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/03/24/">http://cogprints.soton.ac.uk/documents/disk0/00/00/03/24/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://www.arts.uwaterloo.ca/~celiasmi/Papers/thirdcontender.html">http://www.arts.uwaterloo.ca/~celiasmi/Papers/thirdcontender.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000324/00/thirdcontender.html">http://cogprints.ecs.soton.ac.uk/archive/00000324/00/thirdcontender.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:324">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:324</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793914984~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793914984~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELITTC",this.href,0);return true;' href="http://cogprints.org/324/1/thirdcontender.html">http://cogprints.org/324/1/thirdcontender.html</a><br></div></div>
</div><!--entry-->

<div id='_901_entry' class='entry'><span ><span class='name'>Foss, Jeffrey E.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("FOSITT",this.href,0);return true;' href='http://www.springerlink.com/content/t3r56w7785930446/fulltext.pdf'>Introduction to the epistemology of the brain: Indeterminacy, micro-specificity, chaos, and openness.</a></span> <span class='pub_name'>Topoi</span> 11 (1):45-57. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10287029290698938718'>Cited by 7</a> | <span class='ll' onclick='$("_901_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Introduction%20to%20the%20epistemology%20of%20the%20brain+author%3AFoss&amp;btnG=Search'>Google</a> | <a href='javascript:show("_901_links")'>More links</a>)</span><div id='_901_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the brain as a vector-processing system, and the problems raised by indeterminacy, chaos, and so on. With morals for cognitive science.</div></div><div id='_901_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Given that the mind is the brain, as materialists insist, those who would understand the mind must understand the brain. Assuming that arrays of neural firing frequencies are highly salient aspects of brain information processing (the vector functional account), four hurdles to an understanding of the brain are identified and inspected: indeterminacy, micro-specificity, chaos, and openness</div>
<div id='_901_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FOSITT",this.href,0);return true;' href="http://www.springerlink.com/index/T3R56W7785930446.pdf">http://www.springerlink.com/index/T3R56W7785930446.pdf</a><br></div></div>
</div><!--entry-->

<div id='_902_entry' class='entry'><span ><span class='name'>Freeman, Walter J.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("FRENNO",this.href,0);return true;' href='http://sulcus.berkeley.edu/wjf/CL_DynamicsOfIntention.pdf'>Nonlinear neurodynamics of intentionality.</a></span> <span class='pub_name'>Journal of Mind and Behavior</span> 18 (2-3):291-304. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1347796368073865419'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Nonlinear%20neurodynamics%20of%20intentionality+author%3AFreeman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_902_links")'>More links</a>)</span>
<div id='_902_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRENNO",this.href,0);return true;' href="http://sulcus.berkeley.edu/wjf/CL_DynamicsOfIntention.doc">http://sulcus.berkeley.edu/wjf/CL_DynamicsOfIntention.doc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRENNO",this.href,0);return true;' href="http://lecture.berkeley.edu/wjf/CL_DynamicsOfIntention.doc">http://lecture.berkeley.edu/wjf/CL_DynamicsOfIntention.doc</a><br></div></div>
</div><!--entry-->

<div id='_903_entry' class='entry'><span ><span class='name'>French, Robert M.</span> &amp; <span class='name'>Thomas, Elizabeth</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("FRETDH",this.href,0);return true;' href='http://citeseer.ist.psu.edu/451219.html'>The dynamical hypothesis in cognitive science: A review essay of <em>Mind As Motion</em>.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (1):101-111. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20dynamical%20hypothesis%20in%20cognitive%20science+author%3AFrench&amp;btnG=Search'>Google</a> | <a href='javascript:show("_903_links")'>More links</a>)</span>
<div id='_903_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596903">http://portal.acm.org/citation.cfm?id=596903</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH",this.href,0);return true;' href="http://citeseer.ist.psu.edu/french01dynamical.html">http://citeseer.ist.psu.edu/french01dynamical.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH",this.href,0);return true;' href="http://www.u-bourgogne.fr/LEAD/people/french/mind_as_motion.pdf">http://www.u-bourgogne.fr/LEAD/people/french/mind_as_motion.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH",this.href,0);return true;' href="http://www.springerlink.com/content/content/xv2x648r418194mv/fulltext.pdf">http://www.springerlink.com/content/content/xv2x648r418194mv/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH",this.href,0);return true;' href="http://www.springerlink.com/content/xv2x648r418194mv/fulltext.pdf">http://www.springerlink.com/content/xv2x648r418194mv/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=310383&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=310383&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH",this.href,0);return true;' href="http://www.springerlink.com/index/XV2X648R418194MV.pdf">http://www.springerlink.com/index/XV2X648R418194MV.pdf</a><br></div></div>
</div><!--entry-->

<div id='_904_entry' class='entry'><span ><span class='name'>French, Robert M.</span> &amp; <span class='name'>Thomas, Elizabeth</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("FRETDH-2",this.href,0);return true;' href='http://citeseer.ist.psu.edu/323581.html'>The dynamical hypothesis: One battle behind.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21 (5):640-641. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 4 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20dynamical%20hypothesis+author%3AFrench&amp;btnG=Search'>Google</a> | <a href='javascript:show("_904_links")'>More links</a>)</span><div id='_904_abstract' class='extra' style='font-size:12px;'>Abstract: What new implications does the dynamical hypothesis have for cognitive science? The short answer is: None. The _Behavior and Brain Sciences _target article, âThe dynamical hypothesis in cognitive scienceâ by Tim Van Gelder is basically an attack on traditional symbolic AI and differs very little from prior connectionist criticisms of it. For the past ten years, the connectionist community has been well aware of the necessity of using (and understanding) dynamically evolving, recurrent network models of cognition</div>
<div id='_904_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH-2",this.href,0);return true;' href="http://citeseer.ist.psu.edu/french98dynamical.html">http://citeseer.ist.psu.edu/french98dynamical.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH-2",this.href,0);return true;' href="http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=30498&amp;jid=BBS&amp;volumeId=21&amp;issueId=05&amp;aid=30497">http://journals.cambridge.org/action/displayFulltext?type=1&fid=30498&jid=BBS&volumeId=21&issueId=05&aid=30497</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FRETDH-2",this.href,0);return true;' href="http://journals.cambridge.org/abstract_S0140525X98361737">http://journals.cambridge.org/abstract_S0140525X98361737</a><br></div></div>
</div><!--entry-->

<div id='_905_entry' class='entry'><span ><span class='name'>Garson, James W.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("GARCEA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a793919851~fulltext=713240930'>Chaotic emergence and the language of thought.</a></span> <span class='pub_name'>Philosophical Psychology</span> 11 (3):303-315. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17148957478010855568'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Chaotic%20emergence%20and%20the%20language%20of%20thought+author%3AGarson&amp;btnG=Search'>Google</a>)</span><div id='_905_abstract' class='extra' style='font-size:12px;'>Abstract: The purpose of this paper is to explore the merits of the idea that dynamical systems theory (also known as chaos theory) provides a model of the mind that can vindicate the language of thought (LOT). I investigate the nature of emergent structure in dynamical systems to assess its compatibility with causally efficacious syntactic structure in the brain. I will argue that anyone who is committed to the idea that the brain's functioning depends on emergent features of dynamical systems should have serious reservations about the LOT. First, dynamical systems theory casts doubt on one of the strongest motives for believing in the LOT: principle P, the doctrine that structure found in an effect must also be found in its cause. Second, chaotic emergence is a double-edged sword. Its tendency to cleave the psychological from the neurological undermines foundations for belief in the existence of causally efficacious representations. Overall, a dynamic conception of the brain sways us away from realist conclusions about the causal powers of representations with constituent structure</div>
</div><!--entry-->

<div id='_906_entry' class='entry'><span ><span class='name'>Garson, James W.</span> (1996). Cognition poised at the edge of chaos: A complex alternative to a symbolic mind.</span> <span class='pub_name'>Philosophical Psychology</span> 9 (3):301-22. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=180787199739667679'>Cited by 16</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognition%20poised%20at%20the%20edge%20of%20chaos+author%3AGarson&amp;btnG=Search'>Google</a>)</span><div id='_906_abstract' class='extra' style='font-size:12px;'>Abstract: This paper explores a line of argument against the classical paradigm in cognitive science that is based upon properties of non-linear dynamical systems, especially in their chaotic and near-chaotic behavior. Systems of this kind are capable of generating information-rich macro behavior that could be useful to cognition. I argue that a brain operating at the edge of chaos could generate high-complexity cognition in this way. If this hypothesis is correct, then the symbolic processing methodology in cognitive science faces serious obstacles. A symbolic description of the mind will be extremely difficult, and even if it is achieved to some approximation, there will still be reasons for rejecting the hypothesis that the brain is in fact a symbolic processor</div>
</div><!--entry-->

<div id='_907_entry' class='entry'><span ><span class='name'>Garson, James W.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("GARSIA",this.href,0);return true;' href='http://www.kluweronline.com/article.asp?PIPS=125530&amp;PDF=1'>Syntax in a dynamic brain.</a></span> <span class='pub_name'>Synthese</span> 110 (3):343-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13903713836246511493'>Cited by 8</a> | <span class='ll' onclick='$("_907_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Syntax%20in%20a%20dynamic%20brain+author%3AGarson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_907_links")'>More links</a>)</span><div id='_907_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>There are no good arguments for LOT of the form "The brain needs to do X, and X entails LOT". Considers X = concatenation, logical form, tracking, combinatorial encoding. Either LOT is weakened deeply or is unnecessary.</div></div>
<div id='_907_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GARSIA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/synt/1997/00000110/00000003/00125530">http://www.ingentaconnect.com/content/klu/synt/1997/00000110/00000003/00125530</a><br></div></div>
</div><!--entry-->

<div id='_908_entry' class='entry'><span ><span class='name'>Giunti, Marco</span> (1996). <em><span class='pub_name'>Computers, Dynamical Systems, and the Mind.</span></em></span> Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computers%2C%20Dynamical%20Systems%2C%20and%20the%20Mind+author%3AGiunti&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_909_entry' class='entry'><span ><span class='name'>Giunti, Marco</span> (1995). Dynamic models of cognition.</span> In T. van Gelder &amp; Robert Port (eds.), <em>Mind As Motion</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dynamic%20models%20of%20cognition+author%3AGiunti&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_910_entry' class='entry'><span ><span class='name'>Globus, Gordon G.</span> (1992). Toward a noncomputational cognitive science.</span> <span class='pub_name'>Journal of Cognitive Neuroscience</span> 4:299-310. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Toward%20a%20noncomputational%20cognitive%20science+author%3AGlobus&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_911_entry' class='entry'><span ><span class='name'>Haney, Mitchell R.</span> (1999). Dynamical cognition, soft laws, and moral theorizing.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):227-240. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8820817471206782741'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dynamical%20cognition%2C%20soft%20laws%2C%20and%20moral%20theorizing+author%3AHaney&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_912_entry' class='entry'><span ><span class='name'>Harcum, E. Rae</span> (1991). Behavioral paradigm for a psychological resolution of the free will issue.</span> <span class='pub_name'>Journal of Mind and Behavior</span> 93:93-114. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7061992847208642659'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Behavioral%20paradigm%20for%20a%20psychological%20resolution%20of%20the%20free%20will%20issue+author%3AHarcum&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_913_entry' class='entry'><span ><span class='name'>Hooker, Cliff A.</span> &amp; <span class='name'>Christensen, Wayne D.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("HOOTAN",this.href,0);return true;' href='http://www3.interscience.wiley.com/cgi-bin/fulltext/119119395/PDFSTART'>Towards a new science of the mind: Wide content and the metaphysics of organizational properties in nonlinear dynamic models.</a></span> <span class='pub_name'>Mind and Language</span> 13 (1):98-109. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4626510537412875326'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Towards%20a%20new%20science%20of%20the%20mind+author%3AHooker&amp;btnG=Search'>Google</a> | <a href='javascript:show("_913_links")'>More links</a>)</span>
<div id='_913_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOOTAN",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00067">http://www.blackwell-synergy.com/doi/abs/10.1111/1468-0017.00067</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOOTAN",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1998/00000013/00000001/art00008">http://www.ingentaconnect.com/content/bpl/mila/1998/00000013/00000001/art00008</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOOTAN",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/mila/1998/00000013/00000001/art00067">http://www.ingentaconnect.com/content/bpl/mila/1998/00000013/00000001/art00067</a><br></div></div>
</div><!--entry-->

<div id='_914_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("HORANF",this.href,0);return true;' href='http://www.springerlink.com/content/t0t37187t0861785/fulltext.pdf'>A nonclassical framework for cognitive science.</a></span> <span class='pub_name'>Synthese</span> 101 (3):305-45. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18011481854792227056'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20nonclassical%20framework%20for%20cognitive%20science+author%3AHorgan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_914_links")'>More links</a>)</span><div id='_914_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â David Marr provided a useful framework for theorizing about cognition within classical, AI-style cognitive science, in terms of three levels of description: the levels of (i) cognitive function, (ii) algorithm and (iii) physical implementation. We generalize this framework: (i) cognitive state transitions, (ii) mathematical/functional design and (iii) physical implementation or realization. Specifying the middle, design level to be the theory of dynamical systems yields a nonclassical, alternative framework that suits (but is not committed to) connectionism. We consider how a brain's (or a network's) being a dynamical system might be the key both to its realizing various essential features of cognition â productivity, systematicity, structure-sensitive processing, syntax â and also to a non-classical solution of (frame-type) problems plaguing classical cognitive science</div>
<div id='_914_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORANF",this.href,0);return true;' href="http://www.springerlink.com/index/T0T37187T0861785.pdf">http://www.springerlink.com/index/T0T37187T0861785.pdf</a><br></div></div>
</div><!--entry-->

<div id='_915_entry' class='entry'><span ><span class='name'>Horgan, Terence E.</span> &amp; <span class='name'>Tienson, John L.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("HORCSA",this.href,0);return true;' href='http://www.springerlink.com/content/h86m83605h84710v/fulltext.pdf'>Cognitive systems as dynamic systems.</a></span> <span class='pub_name'>Topoi</span> 11 (1):27-43. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16008801231971207929'>Cited by 16</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognitive%20systems%20as%20dynamic%20systems+author%3AHorgan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_915_links")'>More links</a>)</span>
<div id='_915_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HORCSA",this.href,0);return true;' href="http://www.springerlink.com/index/H86M83605H84710V.pdf">http://www.springerlink.com/index/H86M83605H84710V.pdf</a><br></div></div>
</div><!--entry-->

<div id='_916_entry' class='entry'><span ><span class='name'>Keijzer, Fred A.</span> &amp; <span class='name'>Bem, Sacha</span> (1996). Behavioral systems interpreted as autonomous agents and as coupled dynamical systems: A criticism.</span> <span class='pub_name'>Philosophical Psychology</span> 9 (3):323-46. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6928735480088989085'>Cited by 34</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Behavioral%20systems%20interpreted%20as%20autonomous%20agents%20and%20as%20coupled%20dynamical%20systems+author%3AKeijzer&amp;btnG=Search'>Google</a>)</span><div id='_916_abstract' class='extra' style='font-size:12px;'>Abstract: Cognitive science's basic premises are under attack. In particular, its focus on internal cognitive processes is a target. Intelligence is increasingly interpreted, not as a matter of reclusive thought, but as successful agent-environment interaction. The critics claim that a major reorientation of the field is necessary. However, this will only occur when there is a distinct alternative conceptual framework to replace the old one. Whether or not a serious alternative is provided is not clear. Among the critics there is some consensus, however, that this role could be fulfilled by the concept of a 'behavioral system'. This integrates agent and environment into one encompassing general system. We will discuss two contexts in which the behavioral systems idea is being developed. Autonomous Agents Research is the enterprise of building behavior-based robots. Dynamical Systems Theory provides a mathematical framework well suited for describing the interactions between complex systems. We will conclude that both enterprises provide important contributions to the behavioral systems idea. But neither turns it into a full conceptual alternative which will initiate a major paradigm switch in cognitive science. The concept will need a lot of fleshing out before it can assume that role</div>
</div><!--entry-->

<div id='_917_entry' class='entry'><span ><span class='name'>Mills, Stephen L.</span> (1999). Noncomputable dynamical cognitivism: An eliminativist perspective.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):151-168. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Noncomputable%20dynamical%20cognitivism+author%3AMills&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_918_entry' class='entry'><span ><span class='name'>Morton, Adam</span> (1988). <a rel="nofollow" class='article_title' onclick='trackclick("MORTCO",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(198806)48:3&lt;135:TCOM&gt;2.0.CO;2-G'>The chaology of mind.</a></span> <span class='pub_name'>Analysis</span> 48 (June):135-142. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7034809075212820338'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20chaology%20of%20mind+author%3AMorton&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_919_entry' class='entry'><span ><span class='name'>OâBrien, Gerard</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("OBRDCV",this.href,0);return true;' href='http://www.adelaide.edu.au/philosophy/publications/Commentary_on_Van_Gelder_BBS.pdf '>Digital computers versus dynamical systems: A conflation of distinctions.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21:648-649. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Digital%20computers%20versus%20dynamical%20systems+author%3AO%E2%80%99Brien&amp;btnG=Search'>Google</a> | <a href='javascript:show("_919_links")'>More links</a>)</span><div id='_919_abstract' class='extra' style='font-size:12px;'>Abstract: The distinction at the heart of van Gelderâs target article is one between digital computers and dynamical systems. But this distinction conflates two more fundamental distinctions in cognitive science that should be keep apart. When this conflation is undone, it becomes apparent that the âcomputational hypothesisâ (CH) is not as dominant in contemporary cognitive science as van Gelder contends; nor has the âdynamical hypothesisâ (DH) been neglected</div>
<div id='_919_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRDCV",this.href,0);return true;' href="http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Commentary_on_Van_Gelder_BBS.pdf">http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Commentary_on_Van_Gelder_BBS.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRDCV",this.href,0);return true;' href="http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Commentary_on_Van_Gelder_BBS.pdf ">http://www.arts.adelaide.edu.au/humanities/philosophy/publications/Commentary_on_Van_Gelder_BBS.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("OBRDCV",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X98451732">http://www.journals.cambridge.org/abstract_S0140525X98451732</a><br></div></div>
</div><!--entry-->

<div id='_920_entry' class='entry'><span ><span class='name'>Rietveld, Erik</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("RIETSB",this.href,0);return true;' href='http://tap.sagepub.com/cgi/content/abstract/18/3/341'>The Skillful Body as a Concernful System of Possible  Actions: Phenomena and Neurodynamics.</a></span> <span class='pub_name'>Theory & Psychology</span> 18 (3):341-361. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Skillful%20Body%20as%20a%20Concernful%20System%20of%20Possible%20%20Actions+author%3ARietveld&amp;btnG=Search'>Google</a>)</span><div id='_920_abstract' class='extra' style='font-size:12px;'>Abstract: For Merleau-Ponty,consciousness in skillful coping is a matter of prereflective âI canâ and not explicit âI think that.â The body unifies many domain-specific capacities. There exists a direct link between the perceived possibilities for action in the situation (âaffordancesâ) and the organismâs capacities. From Merleau-Pontyâs descriptions it is clear that in a flow of skillful actions, the leading âI canâ may change from moment to moment without explicit deliberation. How these transitions occur, however, is less clear. Given that Merleau-Ponty suggested that a better understanding of the self-organization of brain and behavior is important, I will re-read his descriptions of skillful coping in the light of recent ideas on neurodynamics. Affective processes play a crucial role in evaluating the motivational significance of objects and contribute to the individualâs prereflective responsiveness to relevant affordances.</div>
</div><!--entry-->

<div id='_921_entry' class='entry'><span ><span class='name'>Robbins, Stephen E.</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("ROBSEA",this.href,0);return true;' href='http://www.stephenerobbins.com/Articles/Cogsys81.pdf'>Semantics, experience and time.</a></span> <span class='pub_name'>Cognitive Systems Research</span> 3 (3):301-337. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16424947390568969460'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Semantics%2C%20experience%20and%20time+author%3ARobbins&amp;btnG=Search'>Google</a> | <a href='javascript:show("_921_links")'>More links</a>)</span>
<div id='_921_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROBSEA",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S1389041702000451">http://linkinghub.elsevier.com/retrieve/pii/S1389041702000451</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROBSEA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/13890417/2002/00000003/00000003/art00045">http://www.ingentaconnect.com/content/els/13890417/2002/00000003/00000003/art00045</a><br></div></div>
</div><!--entry-->

<div id='_922_entry' class='entry'><span ><span class='name'>Rockwell, Teed</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("ROCASA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1055605.1055619'>Attractor spaces as modules: A semi-eliminative reduction of symbolic AI to dynamic systems theory.</a></span> <span class='pub_name'>Minds and Machines</span> 15 (1):23-55. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Attractor%20spaces%20as%20modules+author%3ARockwell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_922_links")'>More links</a>)</span><div id='_922_abstract' class='extra' style='font-size:12px;'>Abstract:  I propose a semi-eliminative reduction of Fodors concept of module to the concept of attractor basin which is used in Cognitive Dynamic Systems Theory (DST). I show how attractor basins perform the same explanatory function as modules in several DST based research program. Attractor basins in some organic dynamic systems have even been able to perform cognitive functions which are equivalent to the If/Then/Else loop in the computer language LISP. I suggest directions for future research programs which could find similar equivalencies between organic dynamic systems and other cognitive functions. This type of research could help us discover how (and/or if) it is possible to use Dynamic Systems Theory to more accurately model the cognitive functions that are now being modeled by subroutines in Symbolic AI computer models. If such a reduction of subroutines to basins of attraction is possible, it could free AI from the limitations that prompted Fodor to say that it was impossible to model certain higher level cognitive functions</div>
<div id='_922_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROCASA",this.href,0);return true;' href="http://www.springerlink.com/content/n6h75482x0qvt016/fulltext.pdf">http://www.springerlink.com/content/n6h75482x0qvt016/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROCASA",this.href,0);return true;' href="http://www.springerlink.com/index/N6H75482X0QVT016.pdf">http://www.springerlink.com/index/N6H75482X0QVT016.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROCASA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000001/00001344">http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000001/00001344</a><br></div></div>
</div><!--entry-->

<div id='_923_entry' class='entry'><span ><span class='name'>Rockwell, Teed</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("ROCRTC",this.href,0);return true;' href='http://users.sfo.com/~mcmf/modreply.html'>Reply to Clark and Van gelder.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reply%20to%20Clark%20and%20Van%20gelder+author%3ARockwell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_923_links")'>More links</a>)</span><div id='_923_abstract' class='extra' style='font-size:12px;'>Abstract: Clark ends his appendix with a description of what he calls "dynamic computationalism", which he describes as an interesting hybrid between DST and GOFAI. My 'horseLISP" example could be described as an example of dynamic computationalism. It is clearly not as eliminativist as Van Gelder's computational governor example, for I am trying to come up with something like identities between computational entities and dynamic ones. Thus unlike other dynamicists, I am not doing what Clark calls "embracing a different vocabulary for the understanding and analysis of brain events". I think we probably can keep much of the computational vocabulary, although the meanings of many of its terms will probably shift as much as the meaning of 'atom' has shifted since Dalton's time. The label of "dynamic computationalism" is perhaps as good a description of my position as any, but I think I would mean something slightly different by it than Clark would. (For the following, please insert the mantra "of course, this is an empirical question" (OCTEQ) every paragraph or so.)</div>
<div id='_923_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROCRTC",this.href,0);return true;' href="http://www.california.com/~mcmf/modreply.html">http://www.california.com/~mcmf/modreply.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROCRTC",this.href,0);return true;' href="http://users.california.com/~mcmf/modreply.html">http://users.california.com/~mcmf/modreply.html</a><br></div></div>
</div><!--entry-->

<div id='_924_entry' class='entry'><span ><span class='name'>Rockwell, Teed</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("ROCTMO",this.href,0);return true;' href='http://users.sfo.com/~mcmf/mod.html'>The modularity of dynamic systems.</a></span> <span class='pub_name'>Colloquia Manilana</span> 6. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5494375928956141605'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20modularity%20of%20dynamic%20systems+author%3ARockwell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_924_links")'>More links</a>)</span><div id='_924_abstract' class='extra' style='font-size:12px;'>Abstract: To some degree, Fodor's claim that Cognitive science divides the mind into modules tells us more about the minds doing the studying than the mind being studied. The knowledge game is played by analyzing an object of study into parts, and then figuring out how those parts are related to each other. This is the method regardless of whether the object being studied is a mind or a solar system. If a module is just another name for a part, then to say that the mind consists of modules is simply to say that it is comprehensible. Fodor comes close to acknowledging this in the following passage</div>
<div id='_924_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROCTMO",this.href,0);return true;' href="http://www.california.com/~mcmf/mod.html">http://www.california.com/~mcmf/mod.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROCTMO",this.href,0);return true;' href="http://users.california.com/~mcmf/mod.html">http://users.california.com/~mcmf/mod.html</a><br></div></div>
</div><!--entry-->

<div id='_925_entry' class='entry'><span ><span class='name'>Schonbein, W.</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("SCHCAT-2",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1055620'>Cognition and the power of continuous dynamical systems.</a></span> <span class='pub_name'>Minds and Machines</span> 15 (1):57-71. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognition%20and%20the%20power%20of%20continuous%20dynamical%20systems+author%3ASchonbein&amp;btnG=Search'>Google</a> | <a href='javascript:show("_925_links")'>More links</a>)</span><div id='_925_abstract' class='extra' style='font-size:12px;'>Abstract:  Traditional approaches to modeling cognitive systems are computational, based on utilizing the standard tools and concepts of the theory of computation. More recently, a number of philosophers have argued that cognition is too subtle or complex for these tools to handle. These philosophers propose an alternative based on dynamical systems theory. Proponents of this view characterize dynamical systems as (i) utilizing continuous rather than discrete mathematics, and, as a result, (ii) being computationally more powerful than traditional computational automata. Indeed, the logical possibility of such super-powerful systems has been demonstrated in the form of analog artificial neural networks. In this paper I consider three arguments against the nomological possibility of these automata. While the first two arguments fail, the third succeeds. In particular, the presence of noise reduces the computational power of analog networks to that of traditional computational automata, and noise is a pervasive feature of information processing in biological systems. Consequently, as an empirical thesis, the proposed dynamical alternative is under-motivated: What is required is an account of how continuously valued systems could be realized in physical systems despite the ubiquity of noise</div>
<div id='_925_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHCAT-2",this.href,0);return true;' href="http://www.springerlink.com/content/xtx321861761117r/fulltext.pdf">http://www.springerlink.com/content/xtx321861761117r/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHCAT-2",this.href,0);return true;' href="http://www.springerlink.com/index/XTX321861761117R.pdf">http://www.springerlink.com/index/XTX321861761117R.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHCAT-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000001/00001345">http://www.ingentaconnect.com/content/klu/mind/2005/00000015/00000001/00001345</a><br></div></div>
</div><!--entry-->

<div id='_926_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("SLOTMA",this.href,0);return true;' href='http://citeseer.ist.psu.edu/35338.html'>The mind as a control system.</a></span> In Christopher Hookway &amp; Donald M. Peterson (eds.), <em>Philosophy and Cognitive Science</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13725734331161747803'>Cited by 66</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20mind%20as%20a%20control%20system+author%3ASloman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_926_links")'>More links</a>)</span>
<div id='_926_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTMA",this.href,0);return true;' href="http://citeseer.ist.psu.edu/sloman93mind.html">http://citeseer.ist.psu.edu/sloman93mind.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTMA",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/cogaff/Aaron.Sloman_Mind.as.controlsystem.ps">http://www.cs.bham.ac.uk/research/cogaff/Aaron.Sloman_Mind.as.controlsystem.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTMA",this.href,0);return true;' href="http://www.cs.bham.ac.uk/~axs/cog_affect/Aaron.Sloman_Mind.as.controlsystem.ps.gz">http://www.cs.bham.ac.uk/~axs/cog_affect/Aaron.Sloman_Mind.as.controlsystem.ps.gz</a><br></div></div>
</div><!--entry-->

<div id='_927_entry' class='entry'><span ><span class='name'>Stark, Herman E.</span> (1999). What the dynamical cognitive scientist said to the epistemologist.</span> <span class='pub_name'>Acta Analytica</span> 22 (22):241-260. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20the%20dynamical%20cognitive%20scientist%20said%20to%20the%20epistemologist+author%3AStark&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_928_entry' class='entry'><span ><span class='name'>Symons, John</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("SYMERA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596723.596944'>Explanation, representation and the dynamical hypothesis.</a></span> <span class='pub_name'>Minds and Machines</span> 11 (4):521-541. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9848454741733056962'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Explanation%2C%20representation%20and%20the%20dynamical%20hypothesis+author%3ASymons&amp;btnG=Search'>Google</a> | <a href='javascript:show("_928_links")'>More links</a>)</span><div id='_928_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper challenges arguments that systematic patterns of intelligent behavior license the claim that representations must play a role in the cognitive system analogous to that played by syntactical structures in a computer program. In place of traditional computational models, I argue that research inspired by Dynamical Systems theory can support an alternative view of representations. My suggestion is that we treat linguistic and representational structures as providing complex multi-dimensional targets for the development of individual brains. This approach acknowledges the indispensability of the intentional or representational idiom in psychological explanation without locating representations in the brains of intelligent agents</div>
<div id='_928_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SYMERA",this.href,0);return true;' href="http://www.springerlink.com/content/u55n058l05q58r53/fulltext.pdf">http://www.springerlink.com/content/u55n058l05q58r53/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SYMERA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=352659&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=352659&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SYMERA",this.href,0);return true;' href="http://www.springerlink.com/index/U55N058L05Q58R53.pdf">http://www.springerlink.com/index/U55N058L05Q58R53.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SYMERA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000004/00352659">http://www.ingentaconnect.com/content/klu/mind/2001/00000011/00000004/00352659</a><br></div></div>
</div><!--entry-->

<div id='_929_entry' class='entry'><span ><span class='name'>Treur, Jan</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("TRESOC",this.href,0);return true;' href='http://www.cs.vu.nl/~wai/Papers/PP04soc.pdf'>States of change: Explaining dynamics by anticipatory state properties.</a></span> <span class='pub_name'>Philosophical Psychology</span> 18 (4):441-471. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16716922270358927380'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=States%20of%20change+author%3ATreur&amp;btnG=Search'>Google</a> | <a href='javascript:show("_929_links")'>More links</a>)</span><div id='_929_abstract' class='extra' style='font-size:12px;'>Abstract: In cognitive science, the dynamical systems theory (DST) has recently been advocated as an approach to cognitive modeling that is better suited to the dynamics of cognitive processes than the symbolic/computational approaches are. Often, the differences between DST and the symbolic/computational approach are emphasized. However, alternatively their commonalities can be analyzed and a unifying framework can be sought. In this paper, the possibility of such a unifying perspective on dynamics is analyzed. The analysis covers dynamics in cognitive disciplines, as well as in physics, mathematics and computer science. The unifying perspective warrants the development of integrated approaches covering both DST aspects and symbolic/computational aspects. The concept of a state-determined system, which is based on the assumption that properties of a given state fully determine the properties of future states, lies at the heart of DST. Taking this assumption as a premise, the explanatory problem of dynamics is analyzed in more detail. The analysis of four cases within different disciplines (cognitive science, physics, mathematics, computer science) shows how in history this perspective led to numerous often used concepts within them. In cognitive science, the concepts desire and intention were introduced, and in classical mechanics the concepts momentum, energy and force. Similarly, in mathematics a number of concepts have been developed to formalize the state-determined system assumption [e.g. derivatives (of different orders) of a function, Taylor approximations]. Furthermore, transition systems - a currently popular format for specification of dynamical systems within computer science - can also be interpreted from this perspective. One of the main contributions of the paper is that the case studies provide a unified view on the explanation of dynamics across the chosen disciplines. All approaches to dynamics analyzed in this paper share the state-determined system assumption and the (explicit or implicit) use of anticipatory state properties. Within cognitive science, realism is one of the problems identified for the symbolic/computational approach - i.e. how do internal states described by symbols relate to the real world in a natural manner. As DST is proposed as an alternative to the symbolic/computational approach, a natural question is whether, for DST, realism of the states can be better guaranteed. As a second main contribution, the paper provides an evaluation of DST compared to the symbolic/computational approach, which shows that, in this respect (i.e. for the realism problem), DST does not provide a better solution than the other approaches. This shows that DST and the symbolic/computational approach not only have the state-determined system assumption and the use of anticipatory state properties in common, but also the realism problem</div>
<div id='_929_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://www.few.vu.nl/~wai/Papers/PP04soc.pdf">http://www.few.vu.nl/~wai/Papers/PP04soc.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://www.cs.vu.nl/~wai/Papers/PP04socprel.pdf">http://www.cs.vu.nl/~wai/Papers/PP04socprel.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://www.phil.uu.nl/preprints/ckipreprints/PREPRINTS/preprint051.pdf">http://www.phil.uu.nl/preprints/ckipreprints/PREPRINTS/preprint051.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a723861123~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a723861123~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/HU51317GJ73622Q1.pdf">http://taylorandfrancis.metapress.com/index/HU51317GJ73622Q1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://www.informaworld.com/index/723861123.pdf">http://www.informaworld.com/index/723861123.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2005/00000018/00000004/art00003">http://www.ingentaconnect.com/content/routledg/cphp/2005/00000018/00000004/art00003</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("TRESOC",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a723861123~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a723861123~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_930_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1997). Connectionism, dynamics, and the philosophy of mind.</span> In Martin Carrier &amp; Peter K. Machamer (eds.), <em>Mindscapes: Philosophy, Science, and the Mind</em>. Pittsburgh University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15566429546900652736'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20dynamics%2C%20and%20the%20philosophy%20of%20mind+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_931_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("VANDDC",this.href,0);return true;' href='http://www.arts.unimelb.edu.au/~tgelder/papers/DHResp.pdf '>Disentangling dynamics, computation, and cognition.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21 (5):654-661. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13430470908038755307'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Disentangling%20dynamics%2C%20computation%2C%20and%20cognition+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_931_links")'>More links</a>)</span><div id='_931_abstract' class='extra' style='font-size:12px;'>Abstract: The nature of the dynamical hypothesis in cognitive science (the DH) is further clarified in responding to various criticisms and objections raised in commentaries. Major topics addressed include the definitions of âdynamical systemâ and âdigital computer;â the DH as Law of Qualitative Structure; the DH as an ontological claim; the multiple-realizability of dynamical models; the level at which the DH is pitched; the nature of dynamics; the role of representations in dynamical cognitive science; the falsifiability of the DH; the extent to which the DH is open; the role of temporal and implementation considerations; and the novelty or importance of the DH. The basic formulation and defense of the DH in the target article survives intact, though some refinements are recommended</div>
<div id='_931_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDDC",this.href,0);return true;' href="http://www.philosophy.unimelb.edu.au/tgelder/papers/DHResp.pdf ">http://www.philosophy.unimelb.edu.au/tgelder/papers/DHResp.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDDC",this.href,0);return true;' href="http://www.phil.canterbury.ac.nz/tom_bestor/e-texts/van Gelder - Dynamtical Hypothesis in Cog Sci Authors Responses.pdf ">http://www.phil.canterbury.ac.nz/tom_bestor/e-texts/van Gelder - Dynamtical Hypothesis in Cog Sci Authors Responses.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDDC",this.href,0);return true;' href="http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=30876&amp;jid=BBS&amp;volumeId=21&amp;issueId=05&amp;aid=30875">http://journals.cambridge.org/action/displayFulltext?type=1&fid=30876&jid=BBS&volumeId=21&issueId=05&aid=30875</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDDC",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X98521735 ">http://www.journals.cambridge.org/abstract_S0140525X98521735 </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDDC",this.href,0);return true;' href="http://journals.cambridge.org/abstract_S0140525X98521735">http://journals.cambridge.org/abstract_S0140525X98521735</a><br></div></div>
</div><!--entry-->

<div id='_932_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("VANDTD",this.href,0);return true;' href='http://citeseer.ist.psu.edu/315733.html'>Defending the dynamic hypothesis.</a></span> In Wolfgang Tschacher &amp; J-P Dauwalder (eds.), <em>Dynamics, Synergetics, Autonomous Agents: Nonlinear Systems Approaches to Cognitive Psychology and Cognitive Science</em>. Singapore: World Scientific. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4049232795597156121'>Cited by 16</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Defending%20the%20dynamic%20hypothesis+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_932_links")'>More links</a>)</span><div id='_932_abstract' class='extra' style='font-size:12px;'>Abstract: Cognitive science has always been dominated by the idea that cognition is _computational _in a rather strong and clear sense. Within the mainstream approach, cognitive agents are taken to be what are variously known as _physical symbol_ _systems, digital computers_, _syntactic engines_, or_ symbol manipulators_. Cognitive operations are taken to consist in the shuffling of symbol tokens according to strict rules (programs). Models of cognition are themselves digital computers, implemented on general purpose electronic machines. The basic mathematical framework for understanding cognition is the theory of discrete computation, and the core theoretical tools for developing and understanding models of cognition are those of computer science</div>
<div id='_932_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDTD",this.href,0);return true;' href="http://citeseer.ist.psu.edu/292698.html">http://citeseer.ist.psu.edu/292698.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDTD",this.href,0);return true;' href="http://citeseer.ist.psu.edu/vangelder98defending.html">http://citeseer.ist.psu.edu/vangelder98defending.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDTD",this.href,0);return true;' href="http://depts.washington.edu/edtech/VanGelder_revisiting.pdf">http://depts.washington.edu/edtech/VanGelder_revisiting.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANDTD",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=BlRAVPwgsMwC&amp;oi=fnd&amp;pg=PA13&amp;ots=weyOd5KZHZ&amp;sig=0xdkpD2AVxZ3VXmohG8YuqJieNg">http://books.google.com/books?hl=en&lr=&id=BlRAVPwgsMwC&oi=fnd&pg=PA13&ots=weyOd5KZHZ&sig=0xdkpD2AVxZ3VXmohG8YuqJieNg</a><br></div></div>
</div><!--entry-->

<div id='_933_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> &amp; <span class='name'>Port, Robert</span> (eds.) (1995). <em><span class='pub_name'>Mind As Motion: Explorations in the Dynamics of Cognition.</span></em></span> MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14323576431528350848'>Cited by 30</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%20As%20Motion+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_934_entry' class='entry'><span ><span class='name'>Van Leeuwen, Marco</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("VANQFT",this.href,0);return true;' href='http://www.springerlink.com/content/700661x15k457732/fulltext.pdf'>Questions for the dynamicist: The use of dynamical systems theory in the philosophy of cognition.</a></span> <span class='pub_name'>Minds and Machines</span> 15 (3-4):271-333. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Questions%20for%20the%20dynamicist+author%3AVan%20Leeuwen&amp;btnG=Search'>Google</a>)</span><div id='_934_abstract' class='extra' style='font-size:12px;'>Abstract: The concepts and powerful mathematical tools of Dynamical Systems Theory (DST) yield illuminating methods of studying cognitive processes, and are even claimed by some to enable us to bridge the notorious explanatory gap separating mind and matter. This article includes an analysis of some of the conceptual and empirical progress Dynamical Systems Theory is claimed to accomodate. While sympathetic to the dynamicist program in principle, this article will attempt to formulate a series of problems the proponents of the approach in question will need to face if they wish to prolong their optimism. The main points to be addressed involve the reductive tendencies inherent in Dynamical Systems Theory, its somewhat muddled position relative to connectionism, the metaphorical nature DST-C exhibits which hinders its explanatory potential, and DST-C's problematic account of causality. Brief discussions of the mathematical and philosophical backgrounds of DST, seminal experimental work and possible adaptations of the theory or alternative suggestions (dynamicist connectionism, neurophenomenology, R&D theory) are included</div>
</div><!--entry-->

<div id='_935_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("VANRTD",this.href,0);return true;' href='http://citeseer.ist.psu.edu/315733.html'>Revisiting the dynamic hypothesis.</a></span> <span class='pub_name'>Preprint</span> 2. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4049232795597156121'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Revisiting%20the%20dynamic%20hypothesis+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_935_links")'>More links</a>)</span><div id='_935_abstract' class='extra' style='font-size:12px;'>Abstract: âThere is a familiar trio of reactions by scientists to a purportedly radical hypothesis: (a) âYou must be our of your mind!â, (b) âWhat else is new? Everybody knows _that_!â, and, laterâif the hypothesis is still standingâ(c) âHmm. You _might _be on to something!â ((Dennett, 1995) p. 283)</div>
<div id='_935_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANRTD",this.href,0);return true;' href="http://depts.washington.edu/edtech/VanGelder_revisiting.pdf">http://depts.washington.edu/edtech/VanGelder_revisiting.pdf</a><br></div></div>
</div><!--entry-->

<div id='_936_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("VANTDH",this.href,0);return true;' href='http://citeseer.ist.psu.edu/303780.html'>The dynamical hypothesis in cognitive science.</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21 (5):615-28. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15871569335594048693'>Cited by 307</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20dynamical%20hypothesis%20in%20cognitive%20science+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_936_links")'>More links</a>)</span><div id='_936_abstract' class='extra' style='font-size:12px;'>Abstract: The dynamical hypothesis is the claim that cognitive agents are dynamical systems. It stands opposed to the dominant computational hypothesis, the claim that cognitive agents are digital computers. This target article articulates the dynamical hypothesis and defends it as an open empirical alternative to the computational hypothesis. Carrying out these objectives requires extensive clarification of the conceptual terrain, with particular focus on the relation of dynamical systems to computers</div>
<div id='_936_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://www.irit.fr/SIGCHI/old/docs/debat/DH.pdf">http://www.irit.fr/SIGCHI/old/docs/debat/DH.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://bbsonline.cup.cam.ac.uk/Preprints/OldArchive/bbs.vangelder.html">http://bbsonline.cup.cam.ac.uk/Preprints/OldArchive/bbs.vangelder.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://www.bbsonline.org/documents/a/00/00/04/68/bbs00000468-00/bbs.vangelder.html">http://www.bbsonline.org/documents/a/00/00/04/68/bbs00000468-00/bbs.vangelder.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=30004&amp;jid=BBS&amp;volumeId=21&amp;issueId=05&amp;aid=30003">http://journals.cambridge.org/action/displayFulltext?type=1&fid=30004&jid=BBS&volumeId=21&issueId=05&aid=30003</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=10097022&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=10097022&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;uid=10097022&amp;cmd=showdetailview&amp;indexed=google">http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&uid=10097022&cmd=showdetailview&indexed=google</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://www.journals.cambridge.org/abstract_S0140525X98001733">http://www.journals.cambridge.org/abstract_S0140525X98001733</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://journals.cambridge.org/abstract_S0140525X98001733">http://journals.cambridge.org/abstract_S0140525X98001733</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://journals.cambridge.org/article_S0140525X98301739">http://journals.cambridge.org/article_S0140525X98301739</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANTDH",this.href,0);return true;' href="http://journals.cambridge.org/article_S0140525X98331738">http://journals.cambridge.org/article_S0140525X98331738</a><br></div></div>
</div><!--entry-->

<div id='_937_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("VANWMC",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iLWO_4Hfgv&amp;sig=GkWQRsEOnDSYzvt2nd7eaEmjCNw'>What might cognition be if not computation?</a></span> <span class='pub_name'>Journal of Philosophy</span> 92 (7):345-81. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5459288819123324454'>Cited by 266</a> | <span class='ll' onclick='$("_937_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20might%20cognition%20be%20if%20not%20computation%3F+author%3Avan%20Gelder&amp;btnG=Search'>Google</a> | <a href='javascript:show("_937_links")'>More links</a>)</span><div id='_937_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Argues for a dynamic-systems conception of the mind that is non-computational and non-representational. Uses an analogy with the Watt steam governor to argue for a new kind of dynamic explanation.</div></div>
<div id='_937_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iLWO_4GjfB&amp;sig=_-hLgEKPrvzRGqiHU3WB-ByPxG4">http://books.google.com/books?hl=en&lr=&id=FEnPpGB6HE0C&oi=fnd&pg=PT158&ots=iLWO_4GjfB&sig=_-hLgEKPrvzRGqiHU3WB-ByPxG4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iK3S02IheD&amp;sig=9bvnduaEm9LGyoZvLb9vrkbzLwc">http://books.google.com/books?hl=en&lr=&id=FEnPpGB6HE0C&oi=fnd&pg=PT158&ots=iK3S02IheD&sig=9bvnduaEm9LGyoZvLb9vrkbzLwc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=FEnPpGB6HE0C&amp;oi=fnd&amp;pg=PT158&amp;ots=iLWOW7Jo9y&amp;sig=nbynhfg_nmoW_oos5qyFfZKaq_w">http://books.google.com/books?hl=en&lr=&id=FEnPpGB6HE0C&oi=fnd&pg=PT158&ots=iLWOW7Jo9y&sig=nbynhfg_nmoW_oos5qyFfZKaq_w</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(199507)92:7&lt;345:WMCBIN&gt;2.0.CO;2-F">http://www.jstor.org/sici?sici=0022-362X(199507)92:7<345:WMCBIN>2.0.CO;2-F</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VANWMC",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2941061.pdf">http://www.jstor.org/stable/pdfplus/2941061.pdf</a><br></div></div>
</div><!--entry-->

<div id='_938_entry' class='entry'><span ><span class='name'>Weiskopf, Daniel A.</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("WEITPO-2",this.href,0);return true;' href='http://phonline.org/paper.php?keynum=351'>The place of time in cognition.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 55 (1):87-105. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17370547602936808783'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20place%20of%20time%20in%20cognition+author%3AWeiskopf&amp;btnG=Search'>Google</a> | <a href='javascript:show("_938_links")'>More links</a>)</span><div id='_938_abstract' class='extra' style='font-size:12px;'>Abstract: models of cognition are essentially incomplete because they fail to capture the temporal properties of mental processing. I present two possible interpretations of the dynamicists' argument from time and show that neither one is successful. The disagreement between dynamicists and symbolic theorists rests not on temporal considerations per se, but on differences over the multiple realizability of cognitive states and the proper explanatory goals of psychology. The negative arguments of dynamicists against symbolic models fail, and it is doubtful whether pursuing dynamicists' explanatory goals will lead to a robust psychological theory. Introduction Elements of the symbolic theory Elements of dynamical systems theory The argument from time 4.1 First interpretation of the argument from time 4.2 Second interpretation of the argument from time Limits of dynamical systems theory</div>
<div id='_938_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEITPO-2",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/55/1/87">http://bjps.oxfordjournals.org/cgi/content/abstract/55/1/87</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEITPO-2",this.href,0);return true;' href="http://bjps.oupjournals.org/cgi/content/abstract/55/1/87">http://bjps.oupjournals.org/cgi/content/abstract/55/1/87</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEITPO-2",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/55/1/87">http://bjps.oxfordjournals.org/cgi/reprint/55/1/87</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEITPO-2",this.href,0);return true;' href="http://www.ingentaconnect.com/searching/Expand?pub=infobike://oup/phisci/2004/00000055/00000001/art00087&amp;unc=">http://www.ingentaconnect.com/searching/Expand?pub=infobike://oup/phisci/2004/00000055/00000001/art00087&unc=</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WEITPO-2",this.href,0);return true;' href="http://www.ingentaconnect.com/content/oup/phisci/2004/00000055/00000001/art00087">http://www.ingentaconnect.com/content/oup/phisci/2004/00000055/00000001/art00087</a><br></div></div>
</div><!--entry-->

<div id='_939_entry' class='entry'><span ><span class='name'>Werning, Markus</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("WERTTD",this.href,0);return true;' href='http://thphil.phil-fak.uni-duesseldorf.de/index.php/filemanager/download/282/syntcog12.pdf'>The temporal dimension of thought: Cortical foundations of predicative representation.</a></span> <span class='pub_name'>Synthese</span> 146 (1-2):203-224. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8825778754844067047'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20temporal%20dimension%20of%20thought+author%3AWerning&amp;btnG=Search'>Google</a> | <a href='javascript:show("_939_links")'>More links</a>)</span><div id='_939_abstract' class='extra' style='font-size:12px;'>Abstract: The paper argues that cognitive states of biological systems are inherently temporal. Three adequacy conditions for neuronal models of representation are vindicated: the compositionality of meaning, the compositionality of content, and the co-variation with content. Classicist and connectionist approaches are discussed and rejected. Based on recent neurobiological data, oscillatory networks are introduced as a third alternative. A mathematical description in a Hilbert space framework is developed. The states of this structure can be regarded as conceptual representations satisfying the three conditions</div>
<div id='_939_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WERTTD",this.href,0);return true;' href="http://service.phil-fak.uni-duesseldorf.de/ezpublish/index.php/filemanager/download/282/syntcog12.pdf">http://service.phil-fak.uni-duesseldorf.de/ezpublish/index.php/filemanager/download/282/syntcog12.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WERTTD",this.href,0);return true;' href="http://www.springerlink.com/content/r522585100067t0p/fulltext.pdf">http://www.springerlink.com/content/r522585100067t0p/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WERTTD",this.href,0);return true;' href="http://www.springerlink.com/index/R522585100067T0P.pdf">http://www.springerlink.com/index/R522585100067T0P.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WERTTD",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/synt/2005/00000146/F0020001/00009089">http://www.ingentaconnect.com/content/klu/synt/2005/00000146/F0020001/00009089</a><br></div></div>
</div><!--entry-->

<div id='_940_entry' class='entry'><span ><span class='name'>Yoshimi, Jeffrey</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("YOSHTO",this.href,0);return true;' href='http://www.springerlink.com/content/193tx62615464j6v/fulltext.pdf'>Husserl's theory of belief and the heideggerean critique.</a></span> <span class='pub_name'>Husserl Studies</span> 25 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Husserl%27s%20theory%20of%20belief%20and%20the%20heideggerean%20critique+author%3AYoshimi&amp;btnG=Search'>Google</a>)</span><div id='_940_abstract' class='extra' style='font-size:12px;'>Abstract: I develop a âtwo-systemsâ interpretation of Husserlâs theory of belief. On this interpretation, Husserl accounts for our sense of the world in terms of (1) a system of embodied horizon meanings and passive synthesis, which is involved in any experience of an object, and (2) a system of active synthesis and sedimentation, which comes on line when we attend to an objectâs properties. I use this account to defend Husserl against several forms of Heideggerean critique. One line of critique, recently elaborated by Taylor Carman, says that Husserl wrongly loads everyday perception with explicit beliefs about things. A second, earlier line of critique, due to Hubert Dreyfus, charges Husserl with thinking of belief on a problematic Artificial Intelligence (AI) model which involves explicit rules applied to discrete symbol structures. I argue that these criticisms are based on a conflation of Husserlâs two systems of belief. The conception of Husserlian phenomenology which emerges is compatible with Heideggerean phenomenology and associated approaches to cognitive science (in particular, dynamical systems theory)</div>
</div><!--entry-->

<div id='_941_entry' class='entry'><span ><span class='name'>Yoshimi, Jeffrey</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("YOSMP",this.href,0);return true;' href='http://www.springerlink.com/content/a22585111621q121/fulltext.pdf'>Mathematizing phenomenology.</a></span> <span class='pub_name'>Phenomenology and the Cognitive Sciences</span> 6 (3). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mathematizing%20phenomenology+author%3AYoshimi&amp;btnG=Search'>Google</a> | <a href='javascript:show("_941_links")'>More links</a>)</span><div id='_941_abstract' class='extra' style='font-size:12px;'>Abstract: Husserl is well known for his critique of the âmathematizing tendenciesâ of modern science, and is particularly emphatic that mathematics and phenomenology are distinct and in some sense incompatible. But Husserl himself uses mathematical methods in phenomenology. In the first half of the paper I give a detailed analysis of this tension, showing how those Husserlian doctrines which seem to speak against application of mathematics to phenomenology do not in fact do so. In the second half of the paper I focus on a particular example of Husserlâs âmathematized phenomenologyâ: his use of concepts from what is today called dynamical systems theory</div>
<div id='_941_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("YOSMP",this.href,0);return true;' href="http://www.springerlink.com/index/A22585111621Q121.pdf">http://www.springerlink.com/index/A22585111621Q121.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("YOSMP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/phen/2007/00000006/00000003/00009052">http://www.ingentaconnect.com/content/klu/phen/2007/00000006/00000003/00009052</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.4e'></a><a name=''></a><span class='myh3'>6.4e The Nature of AI</span></p>

<div id='cat_6.4e' class='cat_content'>
<div id='__new_entries_6.4e__'></div><div id='__new_entry_6.4e__' class='entry'></div>
<div id='_942_entry' class='entry'><span ><span class='name'>Buchanan, Bruce G.</span> (1988). AI as an experimental science.</span> In James H. Fetzer (ed.), <em>Aspects of AI</em>. Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=AI%20as%20an%20experimental%20science+author%3ABuchanan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_943_entry' class='entry'><span ><span class='name'>Bundy, A.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("BUNWKO",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=94267'>What kind of field is AI?</a></span> In Derek Partridge &amp; Y. Wilks (eds.), <em>The Foundations of Artificial Intelligence: A Sourcebook</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10536832271405483476'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20kind%20of%20field%20is%20AI%3F+author%3ABundy&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_944_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1978). AI as philosophy and as psychology.</span> In Martin Ringle (ed.), <em>Philosophical Perspectives on Artificial Intelligence</em>. Humanities Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_944_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=AI%20as%20philosophy%20and%20as%20psychology+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_944_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>AI as detailed armchair psychology and as thought-experimental epistemology. Implications for mind: e.g. a solution to the problem of homuncular regress.</div></div>
</div><!--entry-->

<div id='_945_entry' class='entry'><span ><span class='name'>Glymour, C.</span> (1988). AI is philosophy.</span> In James H. Fetzer (ed.), <em>Aspects of AI</em>. D. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10819127864348867650'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=AI%20is%20philosophy+author%3AGlymour&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_946_entry' class='entry'><span ><span class='name'>Harre, Rom</span> (1990). Vigotsky and artificial intelligence: What could cognitive psychology possibly be about?</span> <span class='pub_name'>Midwest Studies in Philosophy</span> 15:389-399. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Vigotsky%20and%20artificial%20intelligence+author%3AHarre&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_947_entry' class='entry'><span ><span class='name'>Kukla, AndrÃ©</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("KUKIAA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0003-2638(198903)49:2&lt;56:IAAES&gt;2.0.CO;2-C'>Is AI an empirical science?</a></span> <span class='pub_name'>Analysis</span> 49 (March):56-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7226576440615058841'>Cited by 4</a> | <span class='ll' onclick='$("_947_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Is%20AI%20an%20empirical%20science%3F+author%3AKukla&amp;btnG=Search'>Google</a>)</span><div id='_947_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>No, AI is an a priori science that uses empirical methods; its status is similar to that of mathematics.</div></div>
</div><!--entry-->

<div id='_948_entry' class='entry'><span ><span class='name'>Kukla, AndrÃ©</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("KUKMAA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793923186~fulltext=713240930'>Medium AI and experimental science.</a></span> <span class='pub_name'>Philosophical Psychology</span> 7 (4):493-5012. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4476352232819003915'>Cited by 4</a> | <span class='ll' onclick='$("_948_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Medium%20AI%20and%20experimental%20science+author%3AKukla&amp;btnG=Search'>Google</a>)</span><div id='_948_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the status of "medium AI", the study of intelligence in computational systems (not just humans). Contra to many, this is not an empirical science, but a combination of (experimental) mathematics and engineering.</div></div><div id='_948_abstract' class='extra' style='font-size:12px;'>Abstract: It has been claimed that a great deal of AI research is an attempt to discover the empirical laws describing a new type of entity in the worldâthe artificial computing system. I call this enterprise 'medium AI', since it is in some respects stronger than Searle's 'weak AI', and in other respects weaker than 'strong AI'. Bruce Buchanan, among others, conceives of medium AI as an empirical science entirely on a par with psychology or chemistry. I argue that medium AI is not an empirical science at all. Depending on how artificial computing systems are categorized, it is either an a priori science like mathematics, or a branch of engineering</div>
</div><!--entry-->

<div id='_949_entry' class='entry'><span ><span class='name'>McCarthy, John</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("MCCWIA",this.href,0);return true;' href='http://ai.king.net.pl/articles/whatisai.pdf'>What is artificial intelligence?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13349748914876832133'>Cited by 38</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20artificial%20intelligence%3F+author%3AMcCarthy&amp;btnG=Search'>Google</a> | <a href='javascript:show("_949_links")'>More links</a>)</span>
<div id='_949_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCWIA",this.href,0);return true;' href="http://www-formal.stanford.edu/jmc/whatisai.pdf">http://www-formal.stanford.edu/jmc/whatisai.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCWIA",this.href,0);return true;' href="http://airobo.persiangig.com/document/whatisai.pdf">http://airobo.persiangig.com/document/whatisai.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCWIA",this.href,0);return true;' href="http://www.formal.stanford.edu/jmc/whatisai/whatisai.html">http://www.formal.stanford.edu/jmc/whatisai/whatisai.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCWIA",this.href,0);return true;' href="http://www.kurzweilai.net/articles/art0088.html?printable=1">http://www.kurzweilai.net/articles/art0088.html?printable=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCWIA",this.href,0);return true;' href="http://www.fredbf.com/disciplinas/unibratec/dsi/whatisai.pdf">http://www.fredbf.com/disciplinas/unibratec/dsi/whatisai.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCWIA",this.href,0);return true;' href="http://www.inf.furb.br/~jomi/ia/introducao/mccarthy-whatisai.ps">http://www.inf.furb.br/~jomi/ia/introducao/mccarthy-whatisai.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCWIA",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:412">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:412</a><br></div></div>
</div><!--entry-->

<div id='_950_entry' class='entry'><span ><span class='name'>Minsky, Marvin L.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("MINFPT",this.href,0);return true;' href='http://web.media.mit.edu/~minsky/E3/eb3.html'>From pain to suffering.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20pain%20to%20suffering+author%3AMinsky&amp;btnG=Search'>Google</a>)</span><div id='_950_abstract' class='extra' style='font-size:12px;'>Abstract: âGreat pain urges all animals, and has urged them during endless generations, to make the most violent and diversified efforts to escape from the cause of suffering. Even when a limb or other separate part of the body is hurt, we often see a tendency to shake it, as if to shake off the cause, though this may obviously be impossible.â âCharles Darwin[1]</div>
</div><!--entry-->

<div id='_951_entry' class='entry'><span ><span class='name'>Nakashima, H.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("NAKAAC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596713.596829'>AI as complex information processing.</a></span> <span class='pub_name'>Minds and Machines</span> 9 (1):57-80. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9261973348976170722'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=AI%20as%20complex%20information%20processing+author%3ANakashima&amp;btnG=Search'>Google</a> | <a href='javascript:show("_951_links")'>More links</a>)</span><div id='_951_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â In this article, I present a software architecture for intelligent agents. The essence of AI is complex information processing. It is impossible, in principle, to process complex information as a whole. We need some partial processing strategy that is still somehow connected to the whole. We also need flexible processing that can adapt to changes in the environment. One of the candidates for both of these is situated reasoning, which makes use of the fact that an agent is in a situation, so it only processes some of the information â the part that is relevant to that situation. The combination of situated reasoning and context reflection leads to the idea of organic programming, which introduces a new building block of programs called a cell. Cells contain situated programs and the combination of cells is controlled by those programs</div>
<div id='_951_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NAKAAC",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=467235CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=467235CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NAKAAC",this.href,0);return true;' href="http://www.springerlink.com/content/ju27445787217334/fulltext.pdf">http://www.springerlink.com/content/ju27445787217334/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NAKAAC",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=187742&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=187742&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NAKAAC",this.href,0);return true;' href="http://www.springerlink.com/index/JU27445787217334.pdf">http://www.springerlink.com/index/JU27445787217334.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NAKAAC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1998/00000009/00000001/00187742">http://www.ingentaconnect.com/content/klu/mind/1998/00000009/00000001/00187742</a><br></div></div>
</div><!--entry-->

<div id='_952_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("SLOTIO",this.href,0);return true;' href='http://citeseer.ist.psu.edu/445905.html'>The irrelevance of Turing machines to AI.</a></span> In Matthias Scheutz (ed.), <em>Computationalism: New Directions</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2245149707625076202'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20irrelevance%20of%20Turing%20machines%20to%20AI+author%3ASloman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_952_links")'>More links</a>)</span>
<div id='_952_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTIO",this.href,0);return true;' href="http://citeseer.ist.psu.edu/sloman02irrelevance.html">http://citeseer.ist.psu.edu/sloman02irrelevance.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTIO",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/cogaff/sloman.turing.irrelevant.ps">http://www.cs.bham.ac.uk/research/cogaff/sloman.turing.irrelevant.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTIO",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/cogaff/sloman.turing.irrelevant.pdf">http://www.cs.bham.ac.uk/research/cogaff/sloman.turing.irrelevant.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTIO",this.href,0);return true;' href="http://www-lehre.informatik.uni-osnabrueck.de/~yzhao/tcn/sloman.turing.pdf">http://www-lehre.informatik.uni-osnabrueck.de/~yzhao/tcn/sloman.turing.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTIO",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/projects/cogaff/sloman.turing.irrelevant.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/sloman.turing.irrelevant.pdf</a><br></div></div>
</div><!--entry-->

<div id='_953_entry' class='entry'><span ><span class='name'>Sufka, Kenneth J.</span> &amp; <span class='name'>Polger, Thomas W.</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("SUFCTG",this.href,0);return true;' href='http://oz.uc.edu/~polgertw/PolgerSufka-ClosingGapPain.pdf'>Closing the gap on pain.</a></span> In Murat Aydede (ed.), <em>Pain: New Essays on its Nature and the Methodology of its Study</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Closing%20the%20gap%20on%20pain+author%3ASufka&amp;btnG=Search'>Google</a> | <a href='javascript:show("_953_links")'>More links</a>)</span><div id='_953_abstract' class='extra' style='font-size:12px;'>Abstract: A widely accepted theory holds that emotional experiences occur mainly in a part of the human brain called the amygdala. A different theory asserts that color sensation is located in a small subpart of the visual cortex called V4. If these theories are correct, or even approximately correct, then they are remarkable advances toward a scientific explanation of human conscious experience. Yet even understanding the claims of such theoriesâmuch less evaluating themâraises some puzzles. Conscious experience does not present itself as a brain process. Indeed experience seems entirely unlike neural activity. For example, to some people it seems that an exact physical duplicate of you could have different sensations than you do, or could have no sensations at all. If so, then how is it even possible that sensations could turn out to be brain processes?</div>
<div id='_953_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUFCTG",this.href,0);return true;' href="http://oz.uc.edu/~polgertw/PolgerSufka-ClosingGapPain.pdf ">http://oz.uc.edu/~polgertw/PolgerSufka-ClosingGapPain.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SUFCTG",this.href,0);return true;' href="http://homepages.uc.edu/~polgertw/PolgerSufka-ClosingGapPain.pdf">http://homepages.uc.edu/~polgertw/PolgerSufka-ClosingGapPain.pdf</a><br></div></div>
</div><!--entry-->

<div id='_954_entry' class='entry'><span ><span class='name'>Yudkowsky, Eliezer</span> (online). General intelligence and seed AI.</span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=General%20intelligence%20and%20seed%20AI+author%3AYudkowsky&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.4f'></a><a name=''></a><span class='myh3'>6.4f The Frame Problem</span></p>

<div id='cat_6.4f' class='cat_content'>
<div id='__new_entries_6.4f__'></div><div id='__new_entry_6.4f__' class='entry'></div>
<div id='_955_entry' class='entry'><span ><span class='name'>Anselme, Patrick</span> &amp; <span class='name'>French, Robert M.</span> (1999). Interactively converging on context-sensitive representations: A solution to the frame problem.</span> <span class='pub_name'>Revue Internationale de Philosophie</span> 53 (209):365-385. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Interactively%20converging%20on%20context-sensitive%20representations+author%3AAnselme&amp;btnG=Search'>Google</a>)</span><div id='_955_abstract' class='extra' style='font-size:12px;'>Abstract: While we agree that the frame problem, as initially stated by McCarthy and Hayes (1969), is a problem that arises because of the use of representations, we do not accept the anti-representationalist position that the way around the problem is to eliminate representations. We believe that internal representations of the external world are a necessary, perhaps even a defining feature, of higher cognition. We explore the notion of dynamically created context-dependent representations that emerge from a continual interaction between working memory, external input, and long-term memory. We claim that only this kind of representation, necessary for higher cognitive abilities such as counterfactualization, will allow the combinatorial explosion inherent in the frame problem to be avoided</div>
</div><!--entry-->

<div id='_956_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("CLAGAI",this.href,0);return true;' href='http://www.cogs.indiana.edu/andy/GlobalReason.pdf'>Global abductive inference and authoritative sources, or, how search engines can save cognitive science.</a></span> <span class='pub_name'>Cognitive Science Quarterly</span> 2 (2):115-140. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2653633686141603762'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Global%20abductive%20inference%20and%20authoritative%20sources%2C%20or%2C%20how%20search%20engines%20can%20save%20cognitive%20science+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_956_links")'>More links</a>)</span><div id='_956_abstract' class='extra' style='font-size:12px;'>Abstract: Kleinberg (1999) describes a novel procedure for efficient search in a dense hyper-linked environment, such as the world wide web. The procedure exploits information implicit in the links between pages so as to identify patterns of connectivity indicative of âauthorative sourcesâ. At a more general level, the trick is to use this second-order link-structure information to rapidly and cheaply identify the knowledge- structures most likely to be relevant given a specific input. I shall argue that Kleinbergâs procedure is suggestive of a new, viable, and neuroscientifically plausible solution to at least (one incarnation of) the so-called âFrame Problemâ in cognitive science viz the problem of explaining global abductive inference. More accurately, I shall argue that</div>
<div id='_956_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAGAI",this.href,0);return true;' href="http://www.philosophy.ed.ac.uk/staff/clark/pubs/GlobalReason.pdf">http://www.philosophy.ed.ac.uk/staff/clark/pubs/GlobalReason.pdf</a><br></div></div>
</div><!--entry-->

<div id='_957_entry' class='entry'><span ><span class='name'>Crockett, L.</span> (1994). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("CROTTT",this.href,0);return true;' href='http://books.google.com/books?id=sKntHyioe20C&amp;printsec=front_cover'>The Turing Test and the Frame Problem: AI's Mistaken Understanding of Intelligence.</a></span></em></span> Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7606731511007008963'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Turing%20Test%20and%20the%20Frame%20Problem+author%3ACrockett&amp;btnG=Search'>Google</a>)</span><div id='_957_abstract' class='extra' style='font-size:12px;'>Abstract: I have discussed the frame problem and the Turing test at length, but I have not 
attempted to spell out what I think the implications of the frame problem ...</div>
</div><!--entry-->

<div id='_958_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1984). Cognitive wheels: The frame problem of AI.</span> In C. Hookway (ed.), <em>Minds, Machines and Evolution</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17817917090766387784'>Cited by 139</a> | <span class='ll' onclick='$("_958_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognitive%20wheels+author%3ADennett&amp;btnG=Search'>Google</a>)</span><div id='_958_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>General overview.</div></div>
</div><!--entry-->

<div id='_959_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> &amp; <span class='name'>Dreyfus, Stuart E.</span> (1987). How to stop worrying about the frame problem even though it's computationally insoluble.</span> In Zenon W. Pylyshyn (ed.), <em>The Robot's Dilemma</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_959_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20to%20stop%20worrying%20about%20the%20frame%20problem%20even%20though%20it%27s%20computationally%20insoluble+author%3ADreyfus&amp;btnG=Search'>Google</a>)</span><div id='_959_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>FP is an artifact of computational explicitness. Contrast human commonsense know-how, with relevance built in. Comparison to expert/novice distinction.</div></div>
</div><!--entry-->

<div id='_960_entry' class='entry'><span ><span class='name'>Fetzer, James H.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("FETTFP",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=157128.157131'>The frame problem: Artificial intelligence meets David  Hume.</a></span> <span class='pub_name'>International Journal of Expert Systems</span> 3:219-232. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8327187438163299936'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20frame%20problem+author%3AFetzer&amp;btnG=Search'>Google</a> | <a href='javascript:show("_960_links")'>More links</a>)</span>
<div id='_960_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FETTFP",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2737634CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2737634CI</a><br></div></div>
</div><!--entry-->

<div id='_961_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> (1987). Modules, frames, fridgeons, sleeping dogs, and the music of the spheres.</span> In Zenon W. Pylyshyn (ed.), <em>The Robot's Dilemma</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3956744176981895819'>Cited by 56</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modules%2C%20frames%2C%20fridgeons%2C%20sleeping%20dogs%2C%20and%20the%20music%20of%20the%20spheres+author%3AFodor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_962_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> (1989). Modules, frames, fridgeons, sleeping dogs.</span> In <em>Modularity in Knowledge Representation and Natural-Language Understanding</em>. Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modules%2C%20frames%2C%20fridgeons%2C%20sleeping%20dogs+author%3AFodor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_963_entry' class='entry'><span ><span class='name'>Fodor, Jerry A.</span> (1987). Modules, frames, fridgeons.</span> In <em>Modularity In Knowledge Representation And Natural-Language Understanding</em>. Cambridge: Mit Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modules%2C%20frames%2C%20fridgeons+author%3AFodor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_964_entry' class='entry'><span ><span class='name'>Haselager, W. F. G.</span> &amp; <span class='name'>Van Rappard, J. F. H.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("HASCSA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596775'>Connectionism, systematicity, and the frame problem.</a></span> <span class='pub_name'>Minds and Machines</span> 8 (2):161-179. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16434015131078879242'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Connectionism%2C%20systematicity%2C%20and%20the%20frame%20problem+author%3AHaselager&amp;btnG=Search'>Google</a> | <a href='javascript:show("_964_links")'>More links</a>)</span><div id='_964_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper investigates connectionism's potential to solve the frame problem. The frame problem arises in the context of modelling the human ability to see the relevant consequences of events in a situation. It has been claimed to be unsolvable for classical cognitive science, but easily manageable for connectionism. We will focus on a representational approach to the frame problem which advocates the use of intrinsic representations. We argue that although connectionism's distributed representations may look promising from this perspective, doubts can be raised about the potential of distributed representations to allow large amounts of complexly structured information to be adequately encoded and processed. It is questionable whether connectionist models that are claimed to effectively represent structured information can be scaled up to a realistic extent. We conclude that the frame problem provides a difficulty to connectionism that is no less serious than the obstacle it constitutes for classical cognitive science</div>
<div id='_964_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=371129CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=371129CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.springerlink.com/content/um0x474450532866/fulltext.pdf">http://www.springerlink.com/content/um0x474450532866/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=150466&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=150466&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.springerlink.com/index/UM0X474450532866.pdf">http://www.springerlink.com/index/UM0X474450532866.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HASCSA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000002/00150466">http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000002/00150466</a><br></div></div>
</div><!--entry-->

<div id='_965_entry' class='entry'><span ><span class='name'>Haugeland, John</span> (1987). An overview of the frame problem.</span> In Zenon W. Pylyshyn (ed.), <em>The Robot's Dilemma</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11506323741962937826'>Cited by 17</a> | <span class='ll' onclick='$("_965_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=An%20overview%20of%20the%20frame%20problem+author%3AHaugeland&amp;btnG=Search'>Google</a>)</span><div id='_965_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>The FP may be a consequence of the explicit/implicit rep distinction. Use "complicit" reps instead, and changes will be carried along intrinsically.</div></div>
</div><!--entry-->

<div id='_966_entry' class='entry'><span ><span class='name'>Hayes, Patrick</span> (1987). What the frame problem is and isn't.</span> In Zenon W. Pylyshyn (ed.), <em>The Robot's Dilemma</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4512736518038645677'>Cited by 25</a> | <span class='ll' onclick='$("_966_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20the%20frame%20problem%20is%20and%20isn%27t+author%3AHayes&amp;btnG=Search'>Google</a>)</span><div id='_966_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>FP is a relatively narrow problem, Some, e.g. Fodor, wrongly equate FP with the "Generalized AI Problem".</div></div>
</div><!--entry-->

<div id='_967_entry' class='entry'><span ><span class='name'>Hendricks, Scott</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("HENTFP",this.href,0);return true;' href='http://www.clarku.edu/departments/philosophy/faculty/images/hendricks/Hendricks-FrameProblem.pdf'>The frame problem and theories of belief.</a></span> <span class='pub_name'>Philosophical Studies</span> 129 (2):317-33. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20frame%20problem%20and%20theories%20of%20belief+author%3AHendricks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_967_links")'>More links</a>)</span><div id='_967_abstract' class='extra' style='font-size:12px;'>Abstract:  The frame problem is the problem of how we selectively apply relevant knowledge to particular situations in order to generate practical solutions. Some philosophers have thought that the frame problem can be used to rule out, or argue in favor of, a particular theory of belief states. But this is a mistake. Sentential theories of belief are no better or worse off with respect to the frame problem than are alternative theories of belief, most notably, the âmapâ theory of belief</div>
<div id='_967_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HENTFP",this.href,0);return true;' href="http://www.springerlink.com/content/p846610503j81603/fulltext.pdf">http://www.springerlink.com/content/p846610503j81603/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HENTFP",this.href,0);return true;' href="http://www.springerlink.com/index/P846610503J81603.pdf">http://www.springerlink.com/index/P846610503J81603.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HENTFP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/phil/2006/00000129/00000002/00001644">http://www.ingentaconnect.com/content/klu/phil/2006/00000129/00000002/00001644</a><br></div></div>
</div><!--entry-->

<div id='_968_entry' class='entry'><span ><span class='name'>Horgan, Terry</span> &amp; <span class='name'>Timmons, Mark</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("HORWDT",this.href,0);return true;' href='http://www.springerlink.com/content/476672v208k70x64/fulltext.pdf'>What does the frame problem tell us about moral normativity?</a></span> <span class='pub_name'>Ethical Theory and Moral Practice</span> 12 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20does%20the%20frame%20problem%20tell%20us%20about%20moral%20normativity%3F+author%3AHorgan&amp;btnG=Search'>Google</a>)</span><div id='_968_abstract' class='extra' style='font-size:12px;'>Abstract: Within cognitive science, mental processing is often construed as computation over mental representationsâi.e., as the manipulation and transformation of mental representations in accordance with rules of the kind expressible in the form of a computer program. This foundational approach has encountered a long-standing, persistently recalcitrant, problem often called the frame problem; it is sometimes called the relevance problem. In this paper we describe the frame problem and certain of its apparent morals concerning human cognition, and we argue that these morals have significant import regarding both the nature of moral normativity and the human capacity for mastering moral normativity. The morals of the frame problem bode well, we argue, for the claim that moral normativity is not fully systematizable by exceptionless general principles, and for the correlative claim that such systematizability is not required in order for humans to master moral normativity</div>
</div><!--entry-->

<div id='_969_entry' class='entry'><span ><span class='name'>Janlert, Lars-Erik</span> (1987). Modeling change: The frame problem.</span> In Zenon W. Pylyshyn (ed.), <em>The Robot's Dilemma</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10296149929959081440'>Cited by 23</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Modeling%20change+author%3AJanlert&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_970_entry' class='entry'><span ><span class='name'>Korb, Kevin B.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("KORTFP",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=596787'>The frame problem: An AI fairy tale.</a></span> <span class='pub_name'>Minds and Machines</span> 8 (3):317-351. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7223566281251365986'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20frame%20problem+author%3AKorb&amp;btnG=Search'>Google</a> | <a href='javascript:show("_970_links")'>More links</a>)</span><div id='_970_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â I analyze the frame problem and its relation to other epistemological problems for artificial intelligence, such as the problem of induction, the qualification problem and the "general" AI problem. I dispute the claim that extensions to logic (default logic and circumscriptive logic) will ever offer a viable way out of the problem. In the discussion it will become clear that the original frame problem is really a fairy tale: as originally presented, and as tools for its solution are circumscribed by Pat Hayes, the problem is entertaining, but incapable of resolution. The solution to the frame problem becomes available, and even apparent, when we remove artificial restrictions on its treatment and understand the interrelation between the frame problem and the many other problems for artificial epistemology. I present the solution to the frame problem: an adequate theory and method for the machine induction of causal structure. Whereas this solution is clearly satisfactory in principle, and in practice real progress has been made in recent years in its application, its ultimate implementation is in prospect only for future generations of AI researchers</div>
<div id='_970_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KORTFP",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=381462CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=381462CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KORTFP",this.href,0);return true;' href="http://www.springerlink.com/content/q30166435n81x313/fulltext.pdf">http://www.springerlink.com/content/q30166435n81x313/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KORTFP",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=168538&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=168538&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KORTFP",this.href,0);return true;' href="http://www.springerlink.com/index/Q30166435N81X313.pdf">http://www.springerlink.com/index/Q30166435N81X313.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KORTFP",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000003/00168538">http://www.ingentaconnect.com/content/klu/mind/1998/00000008/00000003/00168538</a><br></div></div>
</div><!--entry-->

<div id='_971_entry' class='entry'><span ><span class='name'>Lormand, Eric</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("LORFTF",this.href,0);return true;' href='http://www.springerlink.com/content/r122137p20775140/fulltext.pdf'>Framing the frame problem.</a></span> <span class='pub_name'>Synthese</span> 82 (3):353-74. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3078080606383768713'>Cited by 9</a> | <span class='ll' onclick='$("_971_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Framing%20the%20frame%20problem+author%3ALormand&amp;btnG=Search'>Google</a> | <a href='javascript:show("_971_links")'>More links</a>)</span><div id='_971_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Criticizes Dennett's, Haugeland's and Fodor's construals of the FP.</div></div><div id='_971_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The frame problem is widely reputed among philosophers to be one of the deepest and most difficult problems of cognitive science. This paper discusses three recent attempts to display this problem: Dennett's problem of ignoring obviously irrelevant knowledge, Haugeland's problem of efficiently keeping track of salient side effects, and Fodor's problem of avoiding the use of kooky concepts. In a negative vein, it is argued that these problems bear nothing but a superficial similarity to the frame problem of AI, so that they do not provide reasons to disparage standard attempts to solve it. More positively, it is argued that these problems are easily solved by slight variations on familiar AI themes. Finally, some discussion is devoted to more difficult problems confronting AI</div>
<div id='_971_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LORFTF",this.href,0);return true;' href="http://www.springerlink.com/index/R122137P20775140.pdf">http://www.springerlink.com/index/R122137P20775140.pdf</a><br></div></div>
</div><!--entry-->

<div id='_972_entry' class='entry'><span ><span class='name'>Lormand, Eric</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("LORTFP",this.href,0);return true;' href='http://www-personal.umich.edu/~lormand/phil/cogsci/frame.htm'>The frame problem.</a></span> In Robert A. Wilson &amp; Frank F. Keil (eds.), <em>MIT Encyclopedia of the Cognitive Sciences (MITECS)</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20frame%20problem+author%3ALormand&amp;btnG=Search'>Google</a>)</span><div id='_972_abstract' class='extra' style='font-size:12px;'>Abstract: From its humble origins labeling a technical annoyance for a particular AI formalism, the term "frame problem" has grown to cover issues confronting broader research programs in AI. In philosophy, the term has come to encompass allegedly fundamental, but merely superficially related, objections to computational models of mind in AI and beyond</div>
</div><!--entry-->

<div id='_973_entry' class='entry'><span ><span class='name'>Lormand, Eric</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("LORTHD",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=279932.279940'>The holorobophobe's dilemma.</a></span> In Kenneth M. Ford &amp; Z. Pylylshyn (eds.), <em>The Robot's Dilemma Revisited</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17061348923248933860'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20holorobophobe%27s%20dilemma+author%3ALormand&amp;btnG=Search'>Google</a> | <a href='javascript:show("_973_links")'>More links</a>)</span><div id='_973_abstract' class='extra' style='font-size:12px;'>Abstract: Much research in AI (and cognitive science, more broadly) proceeds on the assumption that there is a difference between being well-informed and being smart. Being well-informed has to do, roughly, with the content of oneâs representations--with their truth and the range of subjects they cover. Being smart, on the other hand, has to do with oneâs ability to process these representations and with packaging them in a form that allows them to be processed efficiently. The main theoretical concern of artificial intelligence research is to solve "process-and-form" problems: problems with finding processes and representational formats that enable us to understand how a computer could be smart</div>
<div id='_973_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LORTHD",this.href,0);return true;' href="http://www-personal.umich.edu/~lormand/phil/cogsci/holorobophobe.htm">http://www-personal.umich.edu/~lormand/phil/cogsci/holorobophobe.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LORTHD",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=FubMrc6I4DQC&amp;oi=fnd&amp;pg=PA61&amp;ots=8FqLfSQJvI&amp;sig=hkiEKXzQKsG9Gm3nxwiIFbbaoPw">http://books.google.com/books?hl=en&lr=&id=FubMrc6I4DQC&oi=fnd&pg=PA61&ots=8FqLfSQJvI&sig=hkiEKXzQKsG9Gm3nxwiIFbbaoPw</a><br></div></div>
</div><!--entry-->

<div id='_974_entry' class='entry'><span ><span class='name'>Maloney, J. Christopher</span> (1988). In praise of narrow minds.</span> In James H. Fetzer (ed.), <em>Aspects of AI</em>. D. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=In%20praise%20of%20narrow%20minds+author%3AMaloney&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_975_entry' class='entry'><span ><span class='name'>McCarthy, John</span> &amp; <span class='name'>Hayes, Patrick</span> (1969). <a rel="nofollow" class='article_title' onclick='trackclick("MCCSPP",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=42642'>Some philosophical problems from the standpoint of artificial intelligence.</a></span> In B. Meltzer &amp; Donald Michie (eds.), <em>Machine Intelligence 4</em>. Edinburgh University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4554557098478437446'>Cited by 1919</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Some%20philosophical%20problems%20from%20the%20standpoint%20of%20artificial%20intelligence+author%3AMcCarthy&amp;btnG=Search'>Google</a> | <a href='javascript:show("_975_links")'>More links</a>)</span>
<div id='_975_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCSPP",this.href,0);return true;' href="http://www-formal.stanford.edu/jmc/mcchay69.pdf">http://www-formal.stanford.edu/jmc/mcchay69.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCSPP",this.href,0);return true;' href="http://www.inf.ufsc.br/~mauro/ine6102/leituras/mcchay69.pdf">http://www.inf.ufsc.br/~mauro/ine6102/leituras/mcchay69.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCSPP",this.href,0);return true;' href="http://www.dfki.uni-sb.de/imedia/lidos/bibtex/GINSBERG_a5141-152.html">http://www.dfki.uni-sb.de/imedia/lidos/bibtex/GINSBERG_a5141-152.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCSPP",this.href,0);return true;' href="http://www.ida.liu.se/ext/brs/A/McCarthy,John/J.McCarthy69A/descrip.adl">http://www.ida.liu.se/ext/brs/A/McCarthy,John/J.McCarthy69A/descrip.adl</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCCSPP",this.href,0);return true;' href="http://www.spatial.maine.edu/~worboys/processes/mccarthy hayes situation calculus.pdf">http://www.spatial.maine.edu/~worboys/processes/mccarthy hayes situation calculus.pdf</a><br></div></div>
</div><!--entry-->

<div id='_976_entry' class='entry'><span ><span class='name'>McDermott, Drew</span> (1987). We've been framed: Or, why AI is innocent of the frame problem.</span> In Zenon W. Pylyshyn (ed.), <em>The Robot's Dilemma</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6209897257094622791'>Cited by 15</a> | <span class='ll' onclick='$("_976_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=We%27ve%20been%20framed+author%3AMcDermott&amp;btnG=Search'>Google</a>)</span><div id='_976_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Solve frame problem by using the sleeping-dog strategy -- keeping things fixed unless there's a reason to suppose otherwise.</div></div>
</div><!--entry-->

<div id='_977_entry' class='entry'><span ><span class='name'>Murphy, Dominic</span> (2001). Folk psychology meets the frame problem.</span> <span class='pub_name'>Studies in History and Philosophy of Modern Physics</span> 32 (3):565-573. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20psychology%20meets%20the%20frame%20problem+author%3AMurphy&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_978_entry' class='entry'><span ><span class='name'>Murphy, D.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("MURFPM-2",this.href,0);return true;' href='http://www.ingentaconnect.com//content/els/13698486/2001/00000032/00000003/art00020'>Folk psychology meets the frame problem - W. F. G. Haselager, cognitive science and folk psychology (london: Sage publications, 1997), X + 165 pp. ISBN 0-761-95425-2 hardback Â£55.00; ISBN 0-761-95426-0 paperback Â£17.99.</a></span> <span class='pub_name'>Studies in History and Philosophy of Science Part C</span> 32 (3):565-573. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Folk%20psychology%20meets%20the%20frame%20problem%20-%20W.%20F.%20G.%20Haselager%2C%20cognitive%20science%20and%20folk%20psychology%20%28london+author%3AMurphy&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_979_entry' class='entry'><span ><span class='name'>Pollock, John L.</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("POLRAC",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0029-4624(199706)31:2&lt;143:RACAPA&gt;2.0.CO;2-A'>Reasoning about change and persistence: A solution to the frame problem.</a></span> <span class='pub_name'>NoÃ»s</span> 31 (2):143-169. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15655806251344696991'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Reasoning%20about%20change%20and%20persistence+author%3APollock&amp;btnG=Search'>Google</a> | <a href='javascript:show("_979_links")'>More links</a>)</span>
<div id='_979_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRAC",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0029-4624(199706)31:2&lt;143:RACAPA&gt;2.0.CO;2-A">http://www.jstor.org/sici?sici=0029-4624(199706)31:2<143:RACAPA>2.0.CO;2-A</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRAC",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/0029-4624.00040">http://www.blackwell-synergy.com/links/doi/10.1111/0029-4624.00040</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRAC",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/0029-4624.00040">http://www.blackwell-synergy.com/doi/abs/10.1111/0029-4624.00040</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRAC",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2216189.pdf">http://www.jstor.org/stable/pdfplus/2216189.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRAC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/nous/1997/00000031/00000002/art00001">http://www.ingentaconnect.com/content/bpl/nous/1997/00000031/00000002/art00001</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRAC",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/nous/1997/00000031/00000002/art00040">http://www.ingentaconnect.com/content/bpl/nous/1997/00000031/00000002/art00040</a><br></div></div>
</div><!--entry-->

<div id='_980_entry' class='entry'><span ><span class='name'>Pylyshyn, Zenon</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("PYLTFP",this.href,0);return true;' href='http://ruccs.rutgers.edu/pub/papers/frame.pdf'>The frame problem blues. Once more, with feeling.</a></span> In K. M. Ford &amp; Z. W. Pylyshyn (eds.), <em>The Robot's Dilemma Revisited: The Frame Problem in Artificial Intelligence</em>. Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20frame%20problem%20blues.%20Once%20more%2C%20with%20feeling+author%3APylyshyn&amp;btnG=Search'>Google</a> | <a href='javascript:show("_980_links")'>More links</a>)</span><div id='_980_abstract' class='extra' style='font-size:12px;'>Abstract: For many of the authors in this volume, this is the second attempt to explore what McCarthy and Hayes (1969) ï¬rst called the âFrame Problemâ. Since the ï¬rst compendium (Pylyshyn, 1987), nicely summarized here by Ronald Loui, there have been several conferences and books on the topic. Their goals range from providing a clariï¬cation of the problem by breaking it down into subproblems (and sometimes declaring the hard subproblems to not be the_ real_ Frame Problem), to providing formal âsolutionsâ to certain aspects of the problem. But more often the message has been that the problem is not solvable except in a piecemeal way in special circumstances by some sort of heuristic approximations. It has sometimes also been said that solving the Frame Problem is not only an unachievable goal, but it is also an unnecessary one since_ humans_ do not solve it either; we simply get along as best we can and deal with the problem of planning in ways that, to use Dennettâs phrase, is âgood enough for government workâ</div>
<div id='_980_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PYLTFP",this.href,0);return true;' href="http://ruccs.rutgers.edu/ftp/pub/papers/frame.pdf">http://ruccs.rutgers.edu/ftp/pub/papers/frame.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PYLTFP",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=279932.279934">http://portal.acm.org/citation.cfm?id=279932.279934</a><br></div></div>
</div><!--entry-->

<div id='_981_entry' class='entry'><span ><span class='name'>Pylyshyn, Zenon W.</span> (ed.) (1987). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("PYLTRD",this.href,0);return true;' href='http://dx.doi.org/10.1336/0893913715'>The Robot's Dilemma.</a></span></em></span> Ablex. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17503757348562885964'>Cited by 148</a> | <span class='ll' onclick='$("_981_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Robot%27s%20Dilemma+author%3APylyshyn&amp;btnG=Search'>Google</a> | <a href='javascript:show("_981_links")'>More links</a>)</span><div id='_981_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lots of papers on the frame problem.</div></div>
<div id='_981_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PYLTRD",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=535989">http://portal.acm.org/citation.cfm?id=535989</a><br></div></div>
</div><!--entry-->

<div id='_982_entry' class='entry'><span ><span class='name'>Shanahan, Murray</span> &amp; <span class='name'>Baars, Bernard J.</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("SHAAGW",this.href,0);return true;' href='http://psyche.cs.monash.edu.au/ASSC8/ps1006.html'>Applying global workspace theory to the frame problem.</a></span> <span class='pub_name'>Cognition</span> 98 (2):157-176. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14365168435422184163'>Cited by 28</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Applying%20global%20workspace%20theory%20to%20the%20frame%20problem+author%3AShanahan&amp;btnG=Search'>Google</a> | <a href='javascript:show("_982_links")'>More links</a>)</span>
<div id='_982_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHAAGW",this.href,0);return true;' href="http://eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ724310">http://eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ724310</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHAAGW",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=16307957&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=16307957&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SHAAGW",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S0010027704002288">http://linkinghub.elsevier.com/retrieve/pii/S0010027704002288</a><br></div></div>
</div><!--entry-->

<div id='_983_entry' class='entry'><span ><span class='name'>Shanahan, Murray</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("SHATFP",this.href,0);return true;' href='http://plato.stanford.edu/entries/frame-problem/'>The frame problem.</a></span> <em>Stanford Encyclopedia of Philosophy</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20frame%20problem+author%3AShanahan&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_984_entry' class='entry'><span ><span class='name'>Sperber, Dan</span> &amp; <span class='name'>Wilson, Deirdre</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("SPEFFP",this.href,0);return true;' href='http://cogprints.org/2029/0/frame.htm'>Fodor's frame problem and relevance theory (reply to chiappe & kukla).</a></span> <span class='pub_name'>[Journal (Paginated)]</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Fodor%27s%20frame%20problem%20and%20relevance%20theory%20%28reply%20to%20chiappe%20%26%20kukla%29+author%3ASperber&amp;btnG=Search'>Google</a> | <a href='javascript:show("_984_links")'>More links</a>)</span><div id='_984_abstract' class='extra' style='font-size:12px;'>Abstract: Chiappe and Kukla argue that relevance theory fails to solve the frame problem as defined by Fodor. They are right. They are wrong, however, to take FodorÂs frame problem too seriously. FodorÂs concerns, on the other hand, even though they are wrongly framed, are worth addressing. We argue that Relevance thoery helps address them</div>
<div id='_984_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPEFFP",this.href,0);return true;' href="http://cogprints.org/2004/1/frame.htm">http://cogprints.org/2004/1/frame.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPEFFP",this.href,0);return true;' href="http://cogprints.org/2029/1/frame.htm">http://cogprints.org/2029/1/frame.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPEFFP",this.href,0);return true;' href="http://cogprints.org/2004/0/frame.htm">http://cogprints.org/2004/0/frame.htm</a><br></div></div>
</div><!--entry-->

<div id='_985_entry' class='entry'><span ><span class='name'>Sprevak, Mark</span>, <a rel="nofollow" class='article_title' onclick='trackclick("SPRTFP",this.href,0);return true;' href='http://people.pwf.cam.ac.uk/mds26/files/Sprevak---Frame%20problem%20and%20prediction.pdf'>The frame problem and the treatment of prediction.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20frame%20problem%20and%20the%20treatment%20of%20prediction+author%3ASprevak&amp;btnG=Search'>Google</a>)</span><div id='_985_abstract' class='extra' style='font-size:12px;'>Abstract: The frame problem is a problem in artificial intelligence that a number of philosophers have claimed has philosophical relevance. The structure of this paper is as follows: (1) An account of the frame problem is given; (2) The frame problem is distinguished from related problems; (3) The main strategies for dealing with the frame problem are outlined; (4) A difference between commonsense reasoning and prediction using a scientific theory is argued for; (5) Some implications for the..</div>
</div><!--entry-->

<div id='_986_entry' class='entry'><span ><span class='name'>Waskan, Jonathan A.</span> (2000). A virtual solution to the frame problem.</span> <span class='pub_name'>Proceedings of the First IEEE-RAS International Conference on Humanoid Robots</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5151999503805315743'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20virtual%20solution%20to%20the%20frame%20problem+author%3AWaskan&amp;btnG=Search'>Google</a>)</span><div id='_986_abstract' class='extra' style='font-size:12px;'>Abstract: </b>We humans often respond effectively when faced with novel circumstances. This is because we are able to predict how particular alterations to the world will play out. Philosophers, psychologists, and computational modelers have long favored an account of this process that takes its inspiration from the truth-preserving powers of formal deduction techniques. There is, however, an alternative hypothesis that is better able to account for the human capacity to predict the consequences worldly alterations. This alternative takes its inspiration from the powers of truth preservation exhibited by scale models and leads to a determinate computational solution to the frame problem</div>
</div><!--entry-->

<div id='_987_entry' class='entry'><span ><span class='name'>Wheeler, Michael</span> (2008). <a rel="nofollow" class='article_title' onclick='trackclick("WHECIC",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a794481656~fulltext=713240930'>Cognition in context: Phenomenology, situated robotics and the frame problem.</a></span> <span class='pub_name'>International Journal of Philosophical Studies</span> 16 (3):323 &#x2013; 349. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cognition%20in%20context+author%3AWheeler&amp;btnG=Search'>Google</a> | <a href='javascript:show("_987_links")'>More links</a>)</span><div id='_987_abstract' class='extra' style='font-size:12px;'>Abstract: The frame problem is the difficulty of explaining how non-magical systems think and act in ways that are adaptively sensitive to context-dependent relevance. Influenced centrally by Heideggerian phenomenology, Hubert Dreyfus has argued that the frame problem is, in part, a consequence of the assumption (made by mainstream cognitive science and artificial intelligence) that intelligent behaviour is representation-guided behaviour. Dreyfus' Heideggerian analysis suggests that the frame problem dissolves if we reject representationalism about intelligence and recognize that human agents realize the property of thrownness (the property of being always already embedded in a context). I argue that this positive proposal is incomplete until we understand exactly how the properties in question may be instantiated in machines like us. So, working within a broadly Heideggerian conceptual framework, I pursue the character of a representation-shunning thrown machine. As part of this analysis, I suggest that the frame problem is, in truth, a two-headed beast. The intra-context frame problem challenges us to say how a purely mechanistic system may achieve appropriate, flexible and fluid action within a context. The inter-context frame problem challenges us to say how a purely mechanistic system may achieve appropriate, flexible and fluid action in worlds in which adaptation to new contexts is open-ended and in which the number of potential contexts is indeterminate. Drawing on the field of situated robotics, I suggest that the intra-context frame problem may be neutralized by systems of special-purpose adaptive couplings, while the inter-context frame problem may be neutralized by systems that exhibit the phenomenon of continuous reciprocal causation. I also defend the view that while continuous reciprocal causation is in conflict with representational explanation, special-purpose adaptive coupling, as well as its associated agential phenomenology, may feature representations. My proposal has been criticized recently by Dreyfus, who accuses me of propagating a cognitivist misreading of Heidegger, one that, because it maintains a role for representation, leads me seriously astray in my handling of the frame problem. I close by responding to Dreyfus' concerns</div>
<div id='_987_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WHECIC",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a794481656~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a794481656~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_988_entry' class='entry'><span ><span class='name'>Wilkerson, William S.</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("WILSTA",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~content=a713690495~fulltext=713240930'>Simulation, theory, and the frame problem: The interpretive moment.</a></span> <span class='pub_name'>Philosophical Psychology</span> 14 (2):141-153. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2310345989505203552'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Simulation%2C%20theory%2C%20and%20the%20frame%20problem+author%3AWilkerson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_988_links")'>More links</a>)</span><div id='_988_abstract' class='extra' style='font-size:12px;'>Abstract: The theory-theory claims that the explanation and prediction of behavior works via the application of a theory, while the simulation theory claims that explanation works by putting ourselves in others' places and noting what we would do. On either account, in order to develop a prediction or explanation of another person's behavior, one first needs to have a characterization of that person's current or recent actions. Simulation requires that I have some grasp of the other person's behavior to project myself upon; whereas theorizing requires a subject matter to theorize about. The frame problem shows that multiple, true characterizations are possible for any behavior or situation. However, only one or a few of these characterizations are relevant to explaining or predicting behavior. Since different characterizations of a behavior lead to different predictions or explanations, much of the work of interpersonal interpretation is done in the process of finding this characterization - that is, prior to either theorizing or simulating. Moreover, finding this characterization involves extensive knowledge of the physical, cultural, and social worlds of the persons involved</div>
<div id='_988_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILSTA",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/2C8FMEEMEUG504KF.pdf">http://taylorandfrancis.metapress.com/index/2C8FMEEMEUG504KF.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILSTA",this.href,0);return true;' href="http://www.informaworld.com/index/2C8FMEEMEUG504KF.pdf">http://www.informaworld.com/index/2C8FMEEMEUG504KF.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILSTA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/routledg/cphp/2001/00000014/00000002/art00001">http://www.ingentaconnect.com/content/routledg/cphp/2001/00000014/00000002/art00001</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILSTA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713690495~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a713690495~fulltext=713240930</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.4g'></a><a name=''></a><span class='myh3'>6.4g AI Methodology</span></p>

<div id='cat_6.4g' class='cat_content'>
<div id='__new_entries_6.4g__'></div><div id='__new_entry_6.4g__' class='entry'></div>
<div id='_989_entry' class='entry'><span ><span class='name'>Bickhard, Mark H.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("BICMAE",this.href,0);return true;' href='http://www.lehigh.edu/~mhb0/motemotion.html'>Motivation and Emotion: An Interactive Process Model.</a></span> In Ralph D. Ellis &amp; Natika Newton (eds.), <em>The Caldron of Consciousness: Motivation, Affect and Self-Organization</em>. John Benjamins. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2878933133127894274'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Motivation%20and%20Emotion+author%3ABickhard&amp;btnG=Search'>Google</a> | <a href='javascript:show("_989_links")'>More links</a>)</span><div id='_989_abstract' class='extra' style='font-size:12px;'>Abstract: In this chapter, I outline dynamic models of motivation and emotion. These turn out not to be autonomous subsystems, but, instead, are deeply integrated in the basic interactive dynamic character of living systems. Motivation is a crucial aspect of particular kinds of interactive systems -- systems for which representation is a sister aspect. Emotion is a special kind of partially reflective interaction process, and yields its own emergent motivational aspects. In addition, the overall model accounts for some of the crucial properties of consciousness</div>
<div id='_989_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BICMAE",this.href,0);return true;' href="http://www.lehigh.edu/~mhb0/motemotion.html ">http://www.lehigh.edu/~mhb0/motemotion.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BICMAE",this.href,0);return true;' href="http://www.lehigh.edu/~mhb0/MotandEmotion.pdf">http://www.lehigh.edu/~mhb0/MotandEmotion.pdf</a><br></div></div>
</div><!--entry-->

<div id='_990_entry' class='entry'><span ><span class='name'>Birnbaum, L.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("BIRRMA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=110289.110292'>Rigor mortis: A response to Nilsson's 'logic and artificial intelligence'.</a></span> <span class='pub_name'>Artificial Intelligence</span> 47:57-78. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8169519747810873722'>Cited by 106</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rigor%20mortis+author%3ABirnbaum&amp;btnG=Search'>Google</a> | <a href='javascript:show("_990_links")'>More links</a>)</span>
<div id='_990_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BIRRMA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2460287CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2460287CI</a><br></div></div>
</div><!--entry-->

<div id='_991_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span>; <span class='name'>French, Robert M.</span> &amp; <span class='name'>Hofstadter, Douglas R.</span> (1992). High-level perception, representation, and analogy: A critique of AI methodology.</span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3419828990541884385'>Cited by 1</a> | <span class='ll' onclick='$("_991_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=High-level%20perception%2C%20representation%2C%20and%20analogy+author%3AChalmers&amp;btnG=Search'>Google</a>)</span><div id='_991_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>AI must integrate perception and cognition in the interest of flexible representation. Current models ignore perception and the development of representation, but this cannot be separated from later cognitive processes.</div></div>
</div><!--entry-->

<div id='_992_entry' class='entry'><span ><span class='name'>Chalmers, David J.</span>; <span class='name'>French, Robert M.</span> &amp; <span class='name'>Hofstadter, Douglas R.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href='http://consc.net/papers/highlevel.pdf'>High-level perception, representation, and analogy:A critique of artificial intelligence methodology.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intellige</span> 4 (3):185 - 211. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9882312320981562757'>Cited by 123</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=High-level%20perception%2C%20representation%2C%20and%20analogy+author%3AChalmers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_992_links")'>More links</a>)</span><div id='_992_abstract' class='extra' style='font-size:12px;'>Abstract: High-level perception--âthe process of making sense of complex data at an abstract, conceptual level--âis fundamental to human cognition. Through high-level perception, chaotic environmen- tal stimuli are organized into the mental representations that are used throughout cognitive pro- cessing. Much work in traditional artificial intelligence has ignored the process of high-level perception, by starting with hand-coded representations. In this paper, we argue that this dis- missal of perceptual processes leads to distorted models of human cognition. We examine some existing artificial-intelligence models--ânotably BACON, a model of scientific discovery, and the Structure-Mapping Engine, a model of analogical thought--âand argue that these are flawed pre- cisely because they downplay the role of high-level perception. Further, we argue that perceptu- al processes cannot be separated from other cognitive processes even in principle, and therefore that traditional artificial-intelligence models cannot be defended by supposing the existence of a --Årepresentation module--ï¿½ that supplies representations ready-made. Finally, we describe a model of high-level perception and analogical thought in which perceptual processing is integrated with analogical mapping, leading to the flexible build-up of representations appropriate to a given context</div>
<div id='_992_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://citeseer.ist.psu.edu/49715.html">http://citeseer.ist.psu.edu/49715.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=175346.175347">http://portal.acm.org/citation.cfm?id=175346.175347</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.u.arizona.edu/~chalmers/papers/highlevel.pdf">http://www.u.arizona.edu/~chalmers/papers/highlevel.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.nbu.bg/cogs/personal/kokinov/COG501/hightlevel.pdf">http://www.nbu.bg/cogs/personal/kokinov/COG501/hightlevel.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2767459CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2767459CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CHAHPR-2",this.href,0);return true;' href="http://www.informaworld.com/index/778787585.pdf">http://www.informaworld.com/index/778787585.pdf</a><br></div></div>
</div><!--entry-->

<div id='_993_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("CLAABM",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1986.tb00096.x'>A biological metaphor.</a></span> <span class='pub_name'>Mind and Language</span> 1:45-64. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17716053236205488374'>Cited by 6</a> | <span class='ll' onclick='$("_993_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20biological%20metaphor+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_993_links")'>More links</a>)</span><div id='_993_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>AI should look at biology.</div></div>
<div id='_993_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAABM",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/119496832/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/119496832/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_994_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("CLATKI",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1468-0017.1987.tb00123.x'>The kludge in the machine.</a></span> <span class='pub_name'>Mind and Language</span> 2:277-300. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14267391638365585509'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20kludge%20in%20the%20machine+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_994_links")'>More links</a>)</span>
<div id='_994_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATKI",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120021149/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120021149/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_995_entry' class='entry'><span ><span class='name'>Colombetti, Giovanna</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("COLEA",this.href,0);return true;' href='http://people.exeter.ac.uk/gc243/index/GC07_EnactiveAppraisal.pdf'>Enactive appraisal.</a></span> <span class='pub_name'>Phenomenology and the Cognitive Sciences</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14012910775635032058'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Enactive%20appraisal+author%3AColombetti&amp;btnG=Search'>Google</a> | <a href='javascript:show("_995_links")'>More links</a>)</span><div id='_995_abstract' class='extra' style='font-size:12px;'>Abstract: Emotion theorists tend to separate âarousalâ and other bodily events such as âactionsâ from the evaluative component of emotion known as âappraisal.â This separation, I argue, implies phenomenologically implausible accounts of emotion elicitation and personhood. As an alternative, I attempt a reconceptualization of the notion of appraisal within the so-called âenactive approach.â I argue that appraisal is constituted by arousal and action, and I show how this view relates to an embodied and affective notion of personhood</div>
<div id='_995_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLEA",this.href,0);return true;' href="http://polorovereto.unitn.it/~colombetti/docs/GC_EnactiveAppraisal06.pdf">http://polorovereto.unitn.it/~colombetti/docs/GC_EnactiveAppraisal06.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLEA",this.href,0);return true;' href="http://polorovereto.unitn.it/~colombetti/docs/GC_EnactiveAppraisal06.pdf ">http://polorovereto.unitn.it/~colombetti/docs/GC_EnactiveAppraisal06.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLEA",this.href,0);return true;' href="http://www.springerlink.com/content/y7543g7p14826726/fulltext.pdf">http://www.springerlink.com/content/y7543g7p14826726/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLEA",this.href,0);return true;' href="http://www.springerlink.com/index/Y7543G7P14826726.pdf">http://www.springerlink.com/index/Y7543G7P14826726.pdf</a><br></div></div>
</div><!--entry-->

<div id='_996_entry' class='entry'><span ><span class='name'>Colombetti, Giovanna</span> &amp; <span class='name'>Thompson, Evan</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("COLTFB",this.href,0);return true;' href='http://individual.utoronto.ca/evant/FeelingBody.pdf'>The feeling body: Towards an enactive approach to emotion.</a></span> In  W. F. Overton,  U. Mueller &amp;  J. Newman (eds.), <em>Body in Mind, Mind in Body: Developmental Perspectives on Embodiment and Consciousness</em>. Erlbaum. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8769394480432127560'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20feeling%20body+author%3AColombetti&amp;btnG=Search'>Google</a> | <a href='javascript:show("_996_links")'>More links</a>)</span><div id='_996_abstract' class='extra' style='font-size:12px;'>Abstract: For many years emotion theory has been characterized by a dichotomy between the head and the body. In the golden years of cognitivism, during the nineteen-sixties and seventies, emotion theory focused on the cognitive antecedents of emotion, the so-called âappraisal processes.â Bodily events were seen largely as byproducts of cognition, and as too unspecific to contribute to the variety of emotion experience. Cognition was conceptualized as an abstract, intellectual, âheadyâ process separate from bodily events. Although current emotion theory has moved beyond this disembodied stance by conceiving of emotions as involving both cognitive processes (perception, attention, and evaluation) and bodily events (arousal, behavior, and facial expressions), the legacy of cognitivism persists in the tendency to treat cognitive and bodily events as separate constituents of emotion. Thus the cognitive aspects of emotion are supposedly distinct and separate from the bodily ones. This separation indicates that cognitivismâs disembodied conception of cognition continues to shape the way emotion theorists conceptualize emotion</div>
<div id='_996_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLTFB",this.href,0);return true;' href="http://individual.utoronto.ca/evant/FeelingBody.pdf ">http://individual.utoronto.ca/evant/FeelingBody.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLTFB",this.href,0);return true;' href="http://people.exeter.ac.uk/gc243/index/GC&amp;ET_FeelingBody.pdf">http://people.exeter.ac.uk/gc243/index/GC&ET_FeelingBody.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COLTFB",this.href,0);return true;' href="http://polorovereto.unitn.it/~colombetti/docs/GC&amp;ET_FeelingBody.pdf">http://polorovereto.unitn.it/~colombetti/docs/GC&ET_FeelingBody.pdf</a><br></div></div>
</div><!--entry-->

<div id='_997_entry' class='entry'><span ><span class='name'>Dascal, M.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("DASWDL",this.href,0);return true;' href='http://www.springerlink.com/content/content/w371m4055304hp68/fulltext.pdf'>Why does language matter to artificial intelligence?</a></span> <span class='pub_name'>Minds and Machines</span> 2 (2):145-174. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6917933906630776411'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20does%20language%20matter%20to%20artificial%20intelligence%3F+author%3ADascal&amp;btnG=Search'>Google</a> | <a href='javascript:show("_997_links")'>More links</a>)</span><div id='_997_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Artificial intelligence, conceived either as an attempt to provide models of human cognition or as the development of programs able to perform intelligent tasks, is primarily interested in theuses of language. It should be concerned, therefore, withpragmatics. But its concern with pragmatics should not be restricted to the narrow, traditional conception of pragmatics as the theory of communication (or of the social uses of language). In addition to that, AI should take into account also the mental uses of language (in reasoning, for example) and the existential dimensions of language as a determiner of the world we (and our computers) live in. In this paper, the relevance of these three branches of pragmatics-sociopragmatics, psychopragmatics, and ontopragmatics-for AI are explored</div>
<div id='_997_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DASWDL",this.href,0);return true;' href="http://www.springerlink.com/content/w371m4055304hp68/fulltext.pdf">http://www.springerlink.com/content/w371m4055304hp68/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DASWDL",this.href,0);return true;' href="http://www.springerlink.com/index/W371M4055304HP68.pdf">http://www.springerlink.com/index/W371M4055304HP68.pdf</a><br></div></div>
</div><!--entry-->

<div id='_998_entry' class='entry'><span ><span class='name'>Dietrich, Eric</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("DIEAAT",this.href,0);return true;' href='http://bingweb.binghamton.edu/~dietrich/Papers/JetaiEditorials/01GalensTyranny.pdf'>AI and the tyranny of Galen, or why evolutionary psychology and cognitive ethology are important to artificial intelligence.</a></span> <span class='pub_name'>Journal of Experimental And Theoretical Artificial Intelligence</span> 6 (4):325-330. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=AI%20and%20the%20tyranny%20of%20Galen%2C%20or%20why%20evolutionary%20psychology%20and%20cognitive%20ethology%20are%20important%20to%20artificial%20intelligence+author%3ADietrich&amp;btnG=Search'>Google</a> | <a href='javascript:show("_998_links")'>More links</a>)</span><div id='_998_abstract' class='extra' style='font-size:12px;'>Abstract: Concern over the nature of AI is, for the tastes many AI scientists, probably overdone. In this they are like all other scientists. Working scientists worry about experiments, data, and theories, not foundational issues such as what their work is really about or whether their discipline is methodologically healthy. However, most scientists arenât in a field that is approximately fifty years old. Even relatively new fields such as nonlinear dynamics or branches of biochemistry are in fact advances in older established sciences and are therefore much more settled. Of course, by stretching things, AI can be said to have a history reaching back t o Charles Babbage, and possibly back beyond that to Leibnitz. However, all of that is best viewed as prelude. AIâs history is punctuated with the invention of the computer (and, if one wants t o stretch our history back to the 1930s, the development of the notion of computation by Turing, Church, and others). Hence, AI really began (or began in earnest) sometime in the late 1940s or early 1950s (some mark the conference a t Dartmouth in the summer of 1957 as the moment of our birth). And since those years we simply have not had time to settle into a routine science attacking reasonably well understood questions (for example, many of the questions some of us regard as supreme are regarded by others as inconsequential or mere excursions)</div>
<div id='_998_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DIEAAT",this.href,0);return true;' href="http://www.informaworld.com/index/777915170.pdf">http://www.informaworld.com/index/777915170.pdf</a><br></div></div>
</div><!--entry-->

<div id='_999_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> (1981). From micro-worlds to knowledge: AI at an impasse.</span> In J. Haugel (ed.), <em>Mind Design</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_999_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20micro-worlds%20to%20knowledge+author%3ADreyfus&amp;btnG=Search'>Google</a>)</span><div id='_999_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Micro-worlds don't test true understanding, and frames and scripts are doomed to leave out too much. Explicit representation can't capture intelligence.</div></div>
</div><!--entry-->

<div id='_1000_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> &amp; <span class='name'>Dreyfus, Stuart E.</span> (1988). Making a mind versus modeling the brain: AI at a crossroads.</span> <span class='pub_name'>Daedalus</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17102900733477037396'>Cited by 6</a> | <span class='ll' onclick='$("_1000_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Making%20a%20mind%20versus%20modeling%20the%20brain+author%3ADreyfus&amp;btnG=Search'>Google</a>)</span><div id='_1000_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>History of AI (boo) and connectionism (qualified hooray). And Husserl/ Heidegger/Wittgenstein. Quite nice.</div></div>
</div><!--entry-->

<div id='_1001_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("DREWHA",this.href,0);return true;' href='http://leidlmair.at/doc/WhyHeideggerianAIFailed.pdf'>Why Heideggerian ai failed and how fixing it would require making it more Heideggerian.</a></span> <span class='pub_name'>Philosophical Psychology</span> 20 (2):247 &ndash; 268. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20Heideggerian%20ai%20failed%20and%20how%20fixing%20it%20would%20require%20making%20it%20more%20Heideggerian+author%3ADreyfus&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1001_links")'>More links</a>)</span>
<div id='_1001_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREWHA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~content=a777583844~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~content=a777583844~fulltext=713240930</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREWHA",this.href,0);return true;' href="http://www.informaworld.com/index/777583844.pdf">http://www.informaworld.com/index/777583844.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREWHA",this.href,0);return true;' href="http://www.informaworld.com/smpp/./ftinterface~db=all~content=a777583844~fulltext=713240930">http://www.informaworld.com/smpp/./ftinterface~db=all~content=a777583844~fulltext=713240930</a><br></div></div>
</div><!--entry-->

<div id='_1002_entry' class='entry'><span ><span class='name'>Elster, Jon</span> (1996). <a rel="nofollow" class='article_title' onclick='trackclick("ELSRT",this.href,0);return true;' href='http://www.geocities.com/hmelberg/elster/AR96RATE.HTM '>Rationality and the emotions.</a></span> <span class='pub_name'>Economic Journal</span> 106:1386-97. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2092630431198874519'>Cited by 63</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rationality%20and%20the%20emotions+author%3AElster&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1002_links")'>More links</a>)</span><div id='_1002_abstract' class='extra' style='font-size:12px;'>Abstract: In an earlier paper (Elster, 1989 a), I discussed the relation between rationality and social norms. Although I did mention the role of the emotions in sustaining social norms, I did not focus explicitly on the relation between rationality and the emotions. That relation is the main topic of the present paper, with social norms in a subsidiary part</div>
<div id='_1002_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELSRT",this.href,0);return true;' href="http://ideas.repec.org/a/ecj/econjl/v106y1996i438p1386-97.html">http://ideas.repec.org/a/ecj/econjl/v106y1996i438p1386-97.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELSRT",this.href,0);return true;' href="http://culturalheritage.ceistorvergata.it/virtual_library/Art. - Rationality and emotions - J. ELSTER.pdf">http://culturalheritage.ceistorvergata.it/virtual_library/Art. - Rationality and emotions - J. ELSTER.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELSRT",this.href,0);return true;' href="http://orton.catie.ac.cr/cgi-bin/wxis.exe/?IsisScript=IDEA.xis&amp;method=post&amp;formato=2&amp;cantidad=1&amp;expresion=mfn=001739">http://orton.catie.ac.cr/cgi-bin/wxis.exe/?IsisScript=IDEA.xis&method=post&formato=2&cantidad=1&expresion=mfn=001739</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ELSRT",this.href,0);return true;' href="http://links.jstor.org/sici?sici=0013-0133(199609)106:438&lt;1386:RATE&gt;2.0.CO;2-T">http://links.jstor.org/sici?sici=0013-0133(199609)106:438<1386:RATE>2.0.CO;2-T</a><br></div></div>
</div><!--entry-->

<div id='_1003_entry' class='entry'><span ><span class='name'>Flach, P. A.</span> (ed.) (1991). <em><span class='pub_name'>Future Directions in Artificial Intelligence.</span></em></span> New York: Elsevier Science. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13866261909957160021'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Future%20Directions%20in%20Artificial%20Intelligence+author%3AFlach&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1004_entry' class='entry'><span ><span class='name'>Fulda, Joseph S.</span> (2006). A Plea for Automated Language-to-Logical-Form Converters.</span> <span class='pub_name'>RASK: Internationalt tidsskrift for sprog og kommuinkation</span> 24 (--):87-102. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20Plea%20for%20Automated%20Language-to-Logical-Form%20Converters+author%3AFulda&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1005_entry' class='entry'><span ><span class='name'>Griffiths, Paul E.</span> &amp; <span class='name'>Scarantino, Andrea</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("GRIEIT",this.href,0);return true;' href='http://philsci-archive.pitt.edu/archive/00002448/'>Emotions in the Wild: The Situated Perspective on Emotion.</a></span> In P. Robbins &amp; Murat Aydede (eds.), <em>The Cambridge Handbook of Situated Cognition</em>. Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5822688324034855825'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Emotions%20in%20the%20Wild+author%3AGriffiths&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1005_links")'>More links</a>)</span><div id='_1005_abstract' class='extra' style='font-size:12px;'>Abstract: Paul E Griffiths Biohumanities Project University of Queensland St Lucia 4072 Australia paul.griffiths@uq.edu.au</div>
<div id='_1005_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GRIEIT",this.href,0);return true;' href="http://philsci-archive.pitt.edu/archive/00002448/ ">http://philsci-archive.pitt.edu/archive/00002448/ </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GRIEIT",this.href,0);return true;' href="http://www.uq.edu.au/biohumanities/webpdfs/EmotionsintheWild.PDF">http://www.uq.edu.au/biohumanities/webpdfs/EmotionsintheWild.PDF</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GRIEIT",this.href,0);return true;' href="http://www.uq.edu.au/biohumanities/webpdfs/EmotionsintheWild.PDF ">http://www.uq.edu.au/biohumanities/webpdfs/EmotionsintheWild.PDF </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GRIEIT",this.href,0);return true;' href="http://paul.representinggenes.org/webpdfs/Griff.Scara.IP.EmotionsWild.pdf">http://paul.representinggenes.org/webpdfs/Griff.Scara.IP.EmotionsWild.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GRIEIT",this.href,0);return true;' href="http://philsci-archive.pitt.edu/archive/00002448/01/Emotions_in_the_Wild.PDF">http://philsci-archive.pitt.edu/archive/00002448/01/Emotions_in_the_Wild.PDF</a><br></div></div>
</div><!--entry-->

<div id='_1006_entry' class='entry'><span ><span class='name'>Hadley, Robert F.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("HADTMU",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=103531'>The many uses of 'belief' in AI.</a></span> <span class='pub_name'>Minds and Machines</span> 1 (1):55-74. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15841794301800825820'>Cited by 2</a> | <span class='ll' onclick='$("_1006_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20many%20uses%20of%20%27belief%27%20in%20AI+author%3AHadley&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1006_links")'>More links</a>)</span><div id='_1006_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Various AI approaches to belief: syntactic, propositional/meaning-based, information, tractability, discoverability, and degree of confidence.</div></div><div id='_1006_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Within AI and the cognitively related disciplines, there exist a multiplicity of uses of belief. On the face of it, these differing uses reflect differing views about the nature of an objective phenomenon called belief. In this paper I distinguish six distinct ways in which belief is used in AI. I shall argue that not all these uses reflect a difference of opinion about an objective feature of reality. Rather, in some cases, the differing uses reflect differing concerns with special AI applications. In other cases, however, genuine differences exist about the nature of what we pre-theoretically call belief. To an extent the multiplicity of opinions about, and uses of belief, echoes the discrepant motivations of AI researchers. The relevance of this discussion for cognitive scientists and philosophers arises from the fact that (a) many regard theoretical research within AI as a branch of cognitive science, and (b) even if theoretical AI is not cognitive science, trends within AI influence theories developed within cognitive science. It should be beneficial, therefore, to unravel the distinct uses and motivations surrounding belief, in order to discover which usages merely reflect differing pragmatic concerns, and which usages genuinely reflect divergent views about reality</div>
<div id='_1006_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADTMU",this.href,0);return true;' href="http://www.springerlink.com/content/qm781236u5642248/fulltext.pdf">http://www.springerlink.com/content/qm781236u5642248/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HADTMU",this.href,0);return true;' href="http://www.springerlink.com/index/QM781236U5642248.pdf">http://www.springerlink.com/index/QM781236U5642248.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1007_entry' class='entry'><span ><span class='name'>Haugeland, John</span> (1979). <a rel="nofollow" class='article_title' onclick='trackclick("HAUUNL",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0022-362X(197911)76:11&lt;619:UNL&gt;2.0.CO;2-E'>Understanding natural language.</a></span> <span class='pub_name'>Journal of Philosophy</span> 76 (November):619-32. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9149910691590378772'>Cited by 12</a> | <span class='ll' onclick='$("_1007_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Understanding%20natural%20language+author%3AHaugeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1007_links")'>More links</a>)</span><div id='_1007_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>AI will need holism: interpretational, common-sense, situational, existential.</div></div>
<div id='_1007_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUUNL",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0022-362X(197911)76:11&lt;619:UNL&gt;2.0.CO;2-E">http://www.jstor.org/sici?sici=0022-362X(197911)76:11<619:UNL>2.0.CO;2-E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUUNL",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2025695.pdf">http://www.jstor.org/stable/pdfplus/2025695.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1008_entry' class='entry'><span ><span class='name'>Kirsh, David</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("KIRFOA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=110289.110290'>Foundations of AI: The big issues.</a></span> <span class='pub_name'>Artificial Intelligence</span> 47:3-30. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7164306103535127500'>Cited by 46</a> | <span class='ll' onclick='$("_1008_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Foundations%20of%20AI+author%3AKirsh&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1008_links")'>More links</a>)</span><div id='_1008_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Identifying the dividing lines: pre-eminence of knowledge, embodiment, language-like kinematics, role of learning, uniformity of architecture.</div></div><div id='_1008_abstract' class='extra' style='font-size:12px;'>Abstract: The objective of research in the foundations of Al is to explore such basic questions as: What is a theory in Al? What are the most abstract assumptions underlying the competing visions of intelligence? What are the basic arguments for and against each assumption? In this essay I discuss five foundational issues: (1) Core Al is the study of conceptualization and should begin with knowledge level theories. (2) Cognition can be studied as a disembodied process without solving the symbol grounding problem. (3) Cognition is nicely described in propositional terms. (4) We can study cognition separately from learning. (5) There is a single architecture underlying virtually all cognition. I explain what each of these implies and present arguments from both outside and inside Al why each has been seen as right or wrong.</div>
<div id='_1008_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KIRFOA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2460285CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2460285CI</a><br></div></div>
</div><!--entry-->

<div id='_1009_entry' class='entry'><span ><span class='name'>Kobsa, Alfred</span> (1987). What is explained by AI models.</span> In <em>Artificial Intelligence</em>. St Martin's Press. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20explained%20by%20AI%20models+author%3AKobsa&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1010_entry' class='entry'><span ><span class='name'>Labuschagne, Willem A.</span> &amp; <span class='name'>Heidema, Johannes</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("LABNAA",this.href,0);return true;' href='http://www.ajol.info/viewarticle.php?id=24184'>Natural and artificial cognition: On the proper place of reason.</a></span> <span class='pub_name'>South African Journal of Philosophy</span> 24 (2):137-149. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4814810960436081042'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Natural%20and%20artificial%20cognition+author%3ALabuschagne&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1010_links")'>More links</a>)</span>
<div id='_1010_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LABNAA",this.href,0);return true;' href="http://www.ajol.info/viewarticle.php?jid=211&amp;id=24184">http://www.ajol.info/viewarticle.php?jid=211&id=24184</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LABNAA",this.href,0);return true;' href="http://www.cs.otago.ac.nz/homepages/willem/publications/SAJP paper.rtf">http://www.cs.otago.ac.nz/homepages/willem/publications/SAJP paper.rtf</a><br></div></div>
</div><!--entry-->

<div id='_1011_entry' class='entry'><span ><span class='name'>Marr, David</span> (1977). <a rel="nofollow" class='article_title' onclick='trackclick("MARAIA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?doid=889233'>Artificial intelligence: A personal view.</a></span> <span class='pub_name'>Artificial Intelligence</span> 9 (September):37-48. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11106376545732944870'>Cited by 131</a> | <span class='ll' onclick='$("_1011_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence+author%3AMarr&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1011_links")'>More links</a>)</span><div id='_1011_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>AI usually comes up with Type 2 (algorithmic) theories, when Type 1 (info processing) theories might be more useful -- at least if they exist.</div></div>
<div id='_1011_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MARAIA",this.href,0);return true;' href="https://dspace.mit.edu/handle/1721.1/5776?mode=simple">https://dspace.mit.edu/handle/1721.1/5776?mode=simple</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MARAIA",this.href,0);return true;' href="http://www.inf.ed.ac.uk/teaching/modules/irm/marr.ps.gz">http://www.inf.ed.ac.uk/teaching/modules/irm/marr.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MARAIA",this.href,0);return true;' href="http://www.inf.ed.ac.uk/teaching/courses/irm/marr.ps.gz">http://www.inf.ed.ac.uk/teaching/courses/irm/marr.ps.gz</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MARAIA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=G0lJqbM15gsC&amp;oi=fnd&amp;pg=PA37&amp;ots=fpIHwpf-A3&amp;sig=TFXshtTLSQeKKpJCvrg1gvOCbDg">http://books.google.com/books?hl=en&lr=&id=G0lJqbM15gsC&oi=fnd&pg=PA37&ots=fpIHwpf-A3&sig=TFXshtTLSQeKKpJCvrg1gvOCbDg</a><br></div></div>
</div><!--entry-->

<div id='_1012_entry' class='entry'><span ><span class='name'>McDermott, Drew</span> (1987). <a rel="nofollow" class='article_title' onclick='trackclick("MCDACO",this.href,0);return true;' href='http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-8640.1987.tb00183.x'>A critique of pure reason.</a></span> <span class='pub_name'>Computational Intelligence</span> 3:151-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3509655737288407662'>Cited by 141</a> | <span class='ll' onclick='$("_1012_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20critique%20of%20pure%20reason+author%3AMcDermott&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1012_links")'>More links</a>)</span><div id='_1012_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Criticism of logicism (i.e. reliance on deduction) in AI.</div></div>
<div id='_1012_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MCDACO",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/120022352/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/120022352/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_1013_entry' class='entry'><span ><span class='name'>McDermott, Drew</span> (1981). <a rel="nofollow" class='article_title' onclick='trackclick("MCDAIM",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1045340'>Artificial intelligence meets natural stupidity.</a></span> In J. Haugel (ed.), <em>Mind Design</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9958132641893744738'>Cited by 99</a> | <span class='ll' onclick='$("_1013_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence%20meets%20natural%20stupidity+author%3AMcDermott&amp;btnG=Search'>Google</a>)</span><div id='_1013_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Problems in AI methodology: wishful mnemonics, oversimplifying natural language concepts, and never implementing programs. Entertaining.</div></div>
</div><!--entry-->

<div id='_1014_entry' class='entry'><span ><span class='name'>Nilsson, Neil</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("NILLAA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=110289.110291'>Logic and artificial intelligence.</a></span> <span class='pub_name'>Artificial Intelligence</span> 47:31-56. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9401772059034127811'>Cited by 123</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Logic%20and%20artificial%20intelligence+author%3ANilsson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1014_links")'>More links</a>)</span>
<div id='_1014_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NILLAA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2460286CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2460286CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("NILLAA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=gHmayvQUS-0C&amp;oi=fnd&amp;pg=PA31&amp;ots=Ncnpqvy7wH&amp;sig=6iT-5H55h1UY0sB27skFDMVYdDc">http://books.google.com/books?hl=en&lr=&id=gHmayvQUS-0C&oi=fnd&pg=PA31&ots=Ncnpqvy7wH&sig=6iT-5H55h1UY0sB27skFDMVYdDc</a><br></div></div>
</div><!--entry-->

<div id='_1015_entry' class='entry'><span ><span class='name'>Partridge, Derek</span> &amp; <span class='name'>Wilks, Y.</span> (eds.) (1990). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("PARTFO",this.href,0);return true;' href='http://books.google.com/books?id=bFTWIEEQ6OkC&amp;printsec=front_cover'>The Foundations of Artificial Intelligence: A Sourcebook.</a></span></em></span> Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=458160127038394361'>Cited by 19</a> | <span class='ll' onclick='$("_1015_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Foundations%20of%20Artificial%20Intelligence+author%3APartridge&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1015_links")'>More links</a>)</span><div id='_1015_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Lots of papers on various aspects of AI methodology. Quite thorough.</div></div><div id='_1015_abstract' class='extra' style='font-size:12px;'>Abstract: This outstanding collection is designed to address the fundamental issues and principles underlying the task of Artificial Intelligence.</div>
<div id='_1015_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PARTFO",this.href,0);return true;' href="http://dannyreviews.com/h/The_Foundations_of_Artificial_Intelligence.html">http://dannyreviews.com/h/The_Foundations_of_Artificial_Intelligence.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PARTFO",this.href,0);return true;' href="http://www.anatomy.usyd.edu.au/danny/book-reviews/h/The_Foundations_of_Artificial_Intelligence.html">http://www.anatomy.usyd.edu.au/danny/book-reviews/h/The_Foundations_of_Artificial_Intelligence.html</a><br></div></div>
</div><!--entry-->

<div id='_1016_entry' class='entry'><span ><span class='name'>Petersen, Stephen</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("PETFCL",this.href,0);return true;' href='http://stevepetersen.net/professional/petersen-function-emotions.pdf'>Functions, creatures, learning, emotion.</a></span> <span class='pub_name'>Hudlicka and Canamero</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15671526128741230051'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Functions%2C%20creatures%2C%20learning%2C%20emotion+author%3APetersen&amp;btnG=Search'>Google</a>)</span><div id='_1016_abstract' class='extra' style='font-size:12px;'>Abstract: I propose a conceptual framework for emotions according to which they
are best understood as the feedback mechanism a creature possesses in
virtue of its function to learn.  More specifically, emotions can be
neatly modeled as a measure of harmony in a certain kind of constraint
satisfaction problem.  This measure can be used as error for weight
adjustment (learning) in an unsupervised connectionist network.</div>
</div><!--entry-->

<div id='_1017_entry' class='entry'><span ><span class='name'>Preston, Beth</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("PREHAA",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0031-8205(199303)53:1&lt;43:HAAI&gt;2.0.CO;2-M'>Heidegger and artificial intelligence.</a></span> <span class='pub_name'>Philosophy and Phenomenological Research</span> 53 (1):43-69. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2424536454893105455'>Cited by 4</a> | <span class='ll' onclick='$("_1017_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Heidegger%20and%20artificial%20intelligence+author%3APreston&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1017_links")'>More links</a>)</span><div id='_1017_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>On the non-represented background to everyday activity, and environmental interaction in cognition. Criticizes cognitivism, connectionism, looks at Agre/Chapman/Brooks, ethology, anthropology for support.</div></div>
<div id='_1017_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PREHAA",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0031-8205(199303)53:1&lt;43:HAAI&gt;2.0.CO;2-M">http://www.jstor.org/sici?sici=0031-8205(199303)53:1<43:HAAI>2.0.CO;2-M</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PREHAA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2108053.pdf">http://www.jstor.org/stable/pdfplus/2108053.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1018_entry' class='entry'><span ><span class='name'>Pylyshyn, Zenon W.</span> (1979). Complexity and the study of artificial and human intelligence.</span> In Martin Ringle (ed.), <em>Philosophical Perspectives in Artificial Intelligence</em>. Humanities Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=4632712992923740566'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Complexity%20and%20the%20study%20of%20artificial%20and%20human%20intelligence+author%3APylyshyn&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1019_entry' class='entry'><span ><span class='name'>Ringle, Martin</span> (ed.) (1979). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("RINPPI",this.href,0);return true;' href='http://orton.catie.ac.cr/cgi-bin/wxis.exe/?IsisScript=SIBE01.xis&amp;method=post&amp;formato=2&amp;cantidad=1&amp;expresion=mfn=010089'>Philosophical Perspectives in Artificial Intelligence.</a></span></em></span> Humanities Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17988994762318597810'>Cited by 5</a> | <span class='ll' onclick='$("_1019_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophical%20Perspectives%20in%20Artificial%20Intelligence+author%3ARingle&amp;btnG=Search'>Google</a>)</span><div id='_1019_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>10 papers on philosophy of AI, psychology and knowledge representation.</div></div>
</div><!--entry-->

<div id='_1020_entry' class='entry'><span ><span class='name'>Robinson, William S.</span> (1991). Rationalism, expertise, and the dreyfuses' critique of AI research.</span> <span class='pub_name'>Southern Journal of Philosophy</span> 29:271-90. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_1020_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rationalism%2C%20expertise%2C%20and%20the%20dreyfuses%27%20critique%20of%20AI%20research+author%3ARobinson&amp;btnG=Search'>Google</a>)</span><div id='_1020_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Defending limited rationalism: i.e. a theory of intelligence below the conceptual level but above the neuronal level.</div></div>
</div><!--entry-->

<div id='_1021_entry' class='entry'><span ><span class='name'>Shaffer, Michael J.</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("SHADTI",this.href,0);return true;' href='http://www.springerlink.com/content/n207320965536802/fulltext.pdf'>Decision theory, intelligent planning and counterfactuals.</a></span> <span class='pub_name'>Minds and Machines</span> 19 (1):61-92. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Decision%20theory%2C%20intelligent%20planning%20and%20counterfactuals+author%3AShaffer&amp;btnG=Search'>Google</a>)</span><div id='_1021_abstract' class='extra' style='font-size:12px;'>Abstract: The ontology of decision theory has been subject to considerable debate in the past, and discussion of just how we ought to view decision problems has revealed more than one interesting problem, as well as suggested some novel modifications of classical decision theory. In this paper it will be argued that Bayesian, or evidential, decision-theoretic characterizations of decision situations fail to adequately account for knowledge concerning the causal connections between acts, states, and outcomes in decision situations, and so they are incomplete. Second, it will be argues that when we attempt to incorporate the knowledge of such causal connections into Bayesian decision theory, a substantial technical problem arises for which there is no currently available solution that does not suffer from some damning objection or other. From a broader perspective, this then throws into question the use of decision theory as a model of human or machine planning</div>
</div><!--entry-->

<div id='_1022_entry' class='entry'><span ><span class='name'>Sticklen, J.</span> (1989). <a rel="nofollow" class='article_title' onclick='trackclick("STIPAA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=104905.104906'>Problem-solving architectures at the knowledge level.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 1:233-247. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16879532615758022816'>Cited by 19</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Problem-solving%20architectures%20at%20the%20knowledge%20level+author%3ASticklen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1022_links")'>More links</a>)</span>
<div id='_1022_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STIPAA",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=2213245CI">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=2213245CI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("STIPAA",this.href,0);return true;' href="http://www.informaworld.com/index/777585783.pdf">http://www.informaworld.com/index/777585783.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1023_entry' class='entry'><span ><span class='name'>Stone, Matthew</span>, <a rel="nofollow" class='article_title' onclick='trackclick("STOAIT-2",this.href,0);return true;' href='http://www.cs.rutgers.edu/~mdstone/pubs/whatis.pdf'>Agents in the real world.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Agents%20in%20the%20real%20world+author%3AStone&amp;btnG=Search'>Google</a>)</span><div id='_1023_abstract' class='extra' style='font-size:12px;'>Abstract: The mid-twentieth century saw the introduction of a new general model of processes, COMPUTATION, with the work of scientists such as Turing, Chomsky, Newell and Simon.1 This model so revolutionized the intellectual world that the dominant scientific programs of the dayâspearheaded by such eminent scientists as Hilbert, Bloomfield and Skinnerâare today remembered as much for the way computation exposed their stark limitations as for their positive contributions.2 Ever since, the field of Artificial Intelligence (AI) has defined itself as the subfield of computer science dedicated to the understanding of intelligent entities as computational processes. Now, drawing on fifty years of results of increasing breadth and applicability, we can also characterize AI research as a concrete practice: an ENGINEER-</div>
</div><!--entry-->
</div>
<p><a name='.6.4h'></a><a name=''></a><span class='myh3'>6.4h Robotics</span></p>

<div id='cat_6.4h' class='cat_content'>
<div id='__new_entries_6.4h__'></div><div id='__new_entry_6.4h__' class='entry'></div>
<div id='_1024_entry' class='entry'><span ><span class='name'>Beavers, Anthony F.</span>, <a rel="nofollow" class='article_title' onclick='trackclick("BEABAA-2",this.href,0);return true;' href='http://faculty.evansville.edu/tb2/PDFs/Robot Ethics - APPE.pdf'>Between angels and animals: The question of robot ethics, or is Kantian moral agency desirable?</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Between%20angels%20and%20animals+author%3ABeavers&amp;btnG=Search'>Google</a>)</span><div id='_1024_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper, I examine a variety of agents that appear in Kantian ethics in order to determine which would be necessary to make a robot a genuine moral agent. However, building such an agent would require that we structure into a robotâs behavioral repertoire the possibility for immoral behavior, for only then can the moral law, according to Kant, manifest itself as an ought, a prerequisite for being able to hold an agent morally accountable for its actions. Since building a moral robot requires the possibility of immoral behavior, I go on to argue that we cannot morally want robots to be genuine moral agents, but only beings that simulate moral behavior. Finally, I raise but do not answer the question that if morality requires us to want robots that are not genuine moral agents, why should we want something different in the case of human beings</div>
</div><!--entry-->

<div id='_1025_entry' class='entry'><span ><span class='name'>Breazeal, C.</span> &amp; <span class='name'>Brooks, Rodney</span> (2004). Robot emotions: A functional perspective.</span> In J. Fellous (ed.), <em>Who Needs Emotions</em>. Oxford University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robot%20emotions+author%3ABreazeal&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1026_entry' class='entry'><span ><span class='name'>Brooks, Rodney A.</span> &amp; <span class='name'>Stein, Lynn Andrea</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("BROBBF",this.href,0);return true;' href='http://citeseer.ist.psu.edu/99913.html'>Building brains for bodies.</a></span> <span class='pub_name'>Autonomous Robotics</span> 1 (1):7-25. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15645465904268815390'>Cited by 281</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Building%20brains%20for%20bodies+author%3ABrooks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1026_links")'>More links</a>)</span><div id='_1026_abstract' class='extra' style='font-size:12px;'>Abstract: We describe a project to capitalize on newly available levels of computational resources in order to understand human cognition. We are building an integrated physical system including vision, sound input and output, and dextrous manipulation, all controlled by a continuously operating large scale parallel MIMD computer. The resulting system will learn to "think" by building on its bodily experiences to accomplish progressively more abstract tasks. Past experience suggests that in attempting to build such an integrated system we will have to fundamentally change the way artificial intelligence, cognitive science, linguistics, and philosophy think about the organization of intelligence. We expect to be able to better reconcile the theories that will be developed with current work in neuroscience</div>
<div id='_1026_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="https://dspace.mit.edu/handle/1721.1/5948">https://dspace.mit.edu/handle/1721.1/5948</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://www.ai.mit.edu/people/brooks/papers/brains.pdf">http://www.ai.mit.edu/people/brooks/papers/brains.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://people.csail.mit.edu/people/brooks/papers/brains.pdf">http://people.csail.mit.edu/people/brooks/papers/brains.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://www.aisland.org/cki20/media/handouts/frederic_zolnet.doc">http://www.aisland.org/cki20/media/handouts/frederic_zolnet.doc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://wexler.free.fr/library/files/brooks (1994) building brains for bodies.pdf">http://wexler.free.fr/library/files/brooks (1994) building brains for bodies.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://www.ece.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/building-braind-brooks.pdf">http://www.ece.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/building-braind-brooks.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://stinet.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA270531">http://stinet.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA270531</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=200163015253CE&amp;recid=A9432374AH">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=200163015253CE&recid=A9432374AH</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROBBF",this.href,0);return true;' href="http://www.springerlink.com/index/QW4834246H1K5537.pdf">http://www.springerlink.com/index/QW4834246H1K5537.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1027_entry' class='entry'><span ><span class='name'>Brooks, Rodney</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("BROCFC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=116517.116566'>Challenges for Complete Creature Architectures.</a></span> In Jean-Arcady Meyer &amp; Stewart W. Wilson (eds.), <em>From Animals to Animats: Proceedings of The First International Conference on Simulation of Adaptive Behavior (Complex Adaptive Systems)</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6993612131747681171'>Cited by 71</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Challenges%20for%20Complete%20Creature%20Architectures+author%3ABrooks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1027_links")'>More links</a>)</span><div id='_1027_abstract' class='extra' style='font-size:12px;'>Abstract: boundaries. It is impossible to do good science without having an appreciation for the problems and concepts in the other levels of abstraction (at least in the direction from biology towards physics), but there are whole sets of tools, methods of analysis, theories and explanations within each discipline which do not cross those boundaries</div>
<div id='_1027_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROCFC",this.href,0);return true;' href="http://citeseer.ist.psu.edu/brooks90challenges.html">http://citeseer.ist.psu.edu/brooks90challenges.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROCFC",this.href,0);return true;' href="http://people.csail.mit.edu/brooks/papers/challenges.pdf">http://people.csail.mit.edu/brooks/papers/challenges.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROCFC",this.href,0);return true;' href="http://www.cs.helsinki.fi/u/jphuttun/histo/source/challenges.pdf">http://www.cs.helsinki.fi/u/jphuttun/histo/source/challenges.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROCFC",this.href,0);return true;' href="http://www.valentiniweb.com/Piermo/robotica/doc/Brooks/challenges.pdf">http://www.valentiniweb.com/Piermo/robotica/doc/Brooks/challenges.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROCFC",this.href,0);return true;' href="http://hebb.cis.uoguelph.ca/~dastacey/Robotics/Brooks/Brookschallenges.ps">http://hebb.cis.uoguelph.ca/~dastacey/Robotics/Brooks/Brookschallenges.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROCFC",this.href,0);return true;' href="http://www.ee.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/brooks-challenges.pdf">http://www.ee.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/brooks-challenges.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROCFC",this.href,0);return true;' href="http://www.ece.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/brooks-challenges.pdf">http://www.ece.pdx.edu/~mperkows/ML_LAB/Giant_Hexapod/brooks-challenges.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1028_entry' class='entry'><span ><span class='name'>Brooks, Rodney A.</span>; <span class='name'>Breazeal, Cynthia</span>; <span class='name'>Marjanovic, Matthew</span>; <span class='name'>Scassellati, Brian</span> &amp; <span class='name'>Williamson, Matthew</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("BROTCP",this.href,0);return true;' href='http://citeseer.ist.psu.edu/brooks99cog.html'>The cog project: Building a humanoid robot.</a></span> <span class='pub_name'>Lecture Notes in Computer Science</span> 1562:52-87. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3247805867096522308'>Cited by 302</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20cog%20project+author%3ABrooks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1028_links")'>More links</a>)</span><div id='_1028_abstract' class='extra' style='font-size:12px;'>Abstract: To explore issues of developmental structure, physical em- bodiment, integration of multiple sensory and motor systems, and social interaction, we have constructed an upper-torso humanoid robot called Cog. The robot has twenty-one degrees of freedom and a variety of sen- sory systems, including visual, auditory, vestibular, kinesthetic, and tac- tile senses. This chapter gives a background on the methodology that we have used in our investigations, highlights the research issues that have been raised during this project, and provides a summary of both the current state of the project and our long-term goals. We report on a variety of implemented visual-motor routines (smooth-pursuit track- ing, saccades, binocular vergence, and vestibular-ocular and opto-kinetic re?exes), orientation behaviors, motor control techniques, and social be- haviors (pointing to a visual target, recognizing joint attention through face and eye ?nding, imitation of head nods, and regulating interaction through expressive feedback). We further outline a number of areas for future research that will be necessary to build a complete embodied sys- tem</div>
<div id='_1028_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://www.cs.yale.edu/homes/scaz/papers/springer-final-cog.pdf">http://www.cs.yale.edu/homes/scaz/papers/springer-final-cog.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://groups.csail.mit.edu/lbr/hrg/1998/springer-final-cog.pdf">http://groups.csail.mit.edu/lbr/hrg/1998/springer-final-cog.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://cs-www.cs.yale.edu/homes/scaz/papers/springer-final-cog.pdf">http://cs-www.cs.yale.edu/homes/scaz/papers/springer-final-cog.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://www.cc.gatech.edu/classes/AY2003/cs4803b_spring/readings/brooks99cog.pdf">http://www.cc.gatech.edu/classes/AY2003/cs4803b_spring/readings/brooks99cog.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://www.ee.pdx.edu/~mperkows/CLASS_ROBOTICS/FEBR26-2004/Humanoids/cog-project-brooks99cog.pdf">http://www.ee.pdx.edu/~mperkows/CLASS_ROBOTICS/FEBR26-2004/Humanoids/cog-project-brooks99cog.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="https://longway.dell11.com/03http-14777.cq.zq1.Wx6/jevrWg1G/NAe/wei/fooJ--/springer-final-cog.pdf">https://longway.dell11.com/03http-14777.cq.zq1.Wx6/jevrWg1G/NAe/wei/fooJ--/springer-final-cog.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=B0JrZ7nJGWAC&amp;oi=fnd&amp;pg=PA52&amp;ots=93oWiQzUcJ&amp;sig=e5kkWmVDS2-6Fa5ty-n0_WWIjfE">http://books.google.com/books?hl=en&lr=&id=B0JrZ7nJGWAC&oi=fnd&pg=PA52&ots=93oWiQzUcJ&sig=e5kkWmVDS2-6Fa5ty-n0_WWIjfE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://www.springerlink.com/index/q0ly9uyvwaddmdxj.pdf">http://www.springerlink.com/index/q0ly9uyvwaddmdxj.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTCP",this.href,0);return true;' href="http://www.springerlink.com/index/Q0LY9UYVWADDMDXJ.pdf">http://www.springerlink.com/index/Q0LY9UYVWADDMDXJ.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1029_entry' class='entry'><span ><span class='name'>Bryson, Joanna J.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("BRYTAS",this.href,0);return true;' href='http://www.cs.bath.ac.uk/~jjb/ftp/MindsMachines06.pdf'>The attentional spotlight (dennett and the cog project).</a></span> <span class='pub_name'>Minds and Machines</span> 16 (1):21-28. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20attentional%20spotlight%20%28dennett%20and%20the%20cog%20project%29+author%3ABryson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1029_links")'>More links</a>)</span>
<div id='_1029_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BRYTAS",this.href,0);return true;' href="http://www.springerlink.com/index/B32K3HT479101W80.pdf">http://www.springerlink.com/index/B32K3HT479101W80.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1030_entry' class='entry'><span ><span class='name'>Cardon, Alain</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("CARACA",this.href,0);return true;' href='http://www.elet.polimi.it/upload/gini/robot/docs/consciousness.pdf'>Artificial consciousness, artificial emotions, and autonomous robots.</a></span> <span class='pub_name'>Cognitive Processing</span> 7 (4):245-267. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20consciousness%2C%20artificial%20emotions%2C%20and%20autonomous%20robots+author%3ACardon&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1030_links")'>More links</a>)</span>
<div id='_1030_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CARACA",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=17016730&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=17016730&dopt=Citation</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CARACA",this.href,0);return true;' href="http://www.springerlink.com/index/T03M83873362716L.pdf">http://www.springerlink.com/index/T03M83873362716L.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CARACA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/10339/2006/00000007/00000004/00000154">http://www.ingentaconnect.com/content/klu/10339/2006/00000007/00000004/00000154</a><br></div></div>
</div><!--entry-->

<div id='_1031_entry' class='entry'><span ><span class='name'>Chella, Antonio</span> (2007). Towards robot conscious perception.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Towards%20robot%20conscious%20perception+author%3AChella&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1032_entry' class='entry'><span ><span class='name'>Clancey, William</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("CLAHSC",this.href,0);return true;' href='http://cogprints.soton.ac.uk/documents/disk0/00/00/04/46/cog00000446-00/135.htm'>How situated cognition is different from situated robotics.</a></span> In Luc Steels &amp; Rodney Brooks (eds.), <em>The "Artificial Life" Route to "Artificial Intelligence": Building Situated Embodied Agents</em>. Hillsdale, NJ: Lawrence Erlbaum Associates. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20situated%20cognition%20is%20different%20from%20situated%20robotics+author%3AClancey&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1033_entry' class='entry'><span ><span class='name'>Clark, Andy</span> &amp; <span class='name'>Grush, Rick</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("CLATAC",this.href,0);return true;' href='http://isab.org/journal/adap7_1.php'>Towards a cognitive robotics.</a></span> <span class='pub_name'>Adaptive Behavior</span> 7 (1):5-16. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12673516903959994460'>Cited by 73</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Towards%20a%20cognitive%20robotics+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1033_links")'>More links</a>)</span><div id='_1033_abstract' class='extra' style='font-size:12px;'>Abstract: There is a definite challenge in the air regarding the pivotal notion of internal representation. This challenge is explicit in, e.g., van Gelder, 1995; Beer, 1995; Thelen & Smith, 1994; Wheeler, 1994; and elsewhere. We think it is a challenge that can be met and that (importantly) can be met by arguing from within a general framework that accepts many of the basic premises of the work (in new robotics and in dynamical systems theory) that motivates such scepticism in the first place. Our strategy will be as follows. We begin (Section 1) by offering an account (an example and something close to a definition) of what we shall term Minimal Robust Representationalism (MRR). Sections 2 & 3 address some likely worries and questions about this notion. We end (Section 4) by making explicit the conditions under which, on our account, a science (e.g., robot- ics) may claim to be addressing cognitive phenomena</div>
<div id='_1033_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://www.isab.org/journal/adap7_1.php ">http://www.isab.org/journal/adap7_1.php </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=312918">http://portal.acm.org/citation.cfm?id=312918</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://mind.ucsd.edu/papers/cogrob/cogrob.pdf">http://mind.ucsd.edu/papers/cogrob/cogrob.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="https://www.era.lib.ed.ac.uk/handle/1842/1297">https://www.era.lib.ed.ac.uk/handle/1842/1297</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://mind.ucsd.edu/papers/cogrob/cogrob.pdf ">http://mind.ucsd.edu/papers/cogrob/cogrob.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://www.denizyuret.com/ref/clark_andy/cogrob.ps">http://www.denizyuret.com/ref/clark_andy/cogrob.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://www.cogs.indiana.edu/andy/tacrfinalw-Grush.pdf">http://www.cogs.indiana.edu/andy/tacrfinalw-Grush.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://www.cogs.indiana.edu/andy/tacrfinalw-Grush.pdf ">http://www.cogs.indiana.edu/andy/tacrfinalw-Grush.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://mind.ucsd.edu/papers/cogrob/cogrobhtml/cogrob-text.html">http://mind.ucsd.edu/papers/cogrob/cogrobhtml/cogrob-text.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://mind.ucsd.edu/papers/cogrob/cogrobhtml/cogrob-text.html ">http://mind.ucsd.edu/papers/cogrob/cogrobhtml/cogrob-text.html </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://www.philosophy.ed.ac.uk/staff/clark/pubs/tacrfinalw-Grush.pdf">http://www.philosophy.ed.ac.uk/staff/clark/pubs/tacrfinalw-Grush.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://www.philosophy.ed.ac.uk/staff/clark/pubs/tacrfinalw-Grush.pdf ">http://www.philosophy.ed.ac.uk/staff/clark/pubs/tacrfinalw-Grush.pdf </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://wexler.free.fr/library/files/clark (1999) towards a cognitive robotics.pdf">http://wexler.free.fr/library/files/clark (1999) towards a cognitive robotics.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLATAC",this.href,0);return true;' href="http://adb.sagepub.com/cgi/content/abstract/7/1/5">http://adb.sagepub.com/cgi/content/abstract/7/1/5</a><br></div></div>
</div><!--entry-->

<div id='_1034_entry' class='entry'><span ><span class='name'>Dautenhahn, Kerstin</span>; <span class='name'>Ogden, Bernard</span>; <span class='name'>Quick, Tom</span> &amp; <span class='name'>Ziemke, Tom</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("DAUFET",this.href,0);return true;' href='http://homepages.feis.herts.ac.uk/~comqkd/CSR2002.pdf'>From embodied to socially embedded agents: Implications for interaction-aware robots.</a></span> <span class='pub_name'>Cognitive Systems Research</span> 3 (1):397-427. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 50 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20embodied%20to%20socially%20embedded%20agents+author%3ADautenhahn&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1034_links")'>More links</a>)</span>
<div id='_1034_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAUFET",this.href,0);return true;' href="http://linkinghub.elsevier.com/retrieve/pii/S1389041702000505">http://linkinghub.elsevier.com/retrieve/pii/S1389041702000505</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DAUFET",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/13890417/2002/00000003/00000003/art00050">http://www.ingentaconnect.com/content/els/13890417/2002/00000003/00000003/art00050</a><br></div></div>
</div><!--entry-->

<div id='_1035_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (ms). <a rel="nofollow" class='article_title' onclick='trackclick("DENCAA",this.href,0);return true;' href='http://cogprints.org/248/'>Cog as a thought experiment.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17803849104570670995'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cog%20as%20a%20thought%20experiment+author%3ADennett&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1035_links")'>More links</a>)</span><div id='_1035_abstract' class='extra' style='font-size:12px;'>Abstract: In her presentation at the Monte VeritÃ  workshop, Maja Mataric showed us a videotape of her robots cruising together through the lab, and remarked, aptly: "They're flocking, but that's not what they think they're doing." This is a vivid instance of a phenomenon that lies at the heart of all the research I learned about at Monte VeritÃ : the execution of surprisingly successful "cognitive" behaviors by systems that did not explicitly represent, and did not need to explicitly represent, what they were doing. How "high" in the intuitive scale of cognitive sophistication can such unwitting prowess reach? All the way, apparently, since I want to echo Maja's observation with one of my own: "These roboticists are doing philosophy, but that's not what they think they're doing." It is possible, then, even to do philosophy--that most intellectual of activities--without realizing that that is what you are doing. It is even possible to do it well, for this is a good, new way of addressing antique philosophical puzzles</div>
<div id='_1035_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCAA",this.href,0);return true;' href="http://ase.tufts.edu/cogstud/papers/cogthogt.htm">http://ase.tufts.edu/cogstud/papers/cogthogt.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCAA",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000248/">http://cogprints.ecs.soton.ac.uk/archive/00000248/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCAA",this.href,0);return true;' href="http://cogprints.soton.ac.uk/documents/disk0/00/00/02/48/">http://cogprints.soton.ac.uk/documents/disk0/00/00/02/48/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCAA",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:248">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:248</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCAA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/els/09218890/1997/00000020/00000002/art80709">http://www.ingentaconnect.com/content/els/09218890/1997/00000020/00000002/art80709</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCAA",this.href,0);return true;' href="http://cogprints.org/248/1/cogthogt.htm">http://cogprints.org/248/1/cogthogt.htm</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DENCAA",this.href,0);return true;' href="http://cogprints.org/248/0/cogthogt.htm">http://cogprints.org/248/0/cogthogt.htm</a><br></div></div>
</div><!--entry-->

<div id='_1036_entry' class='entry'><span ><span class='name'>Dennett, Daniel C.</span> (1995). Cog: Steps toward consciousness in robots.</span> In Thomas Metzinger (ed.), <em>Conscious Experience</em>. Ferdinand Schoningh. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11129656156924373964'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Cog+author%3ADennett&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1037_entry' class='entry'><span ><span class='name'>Elton, Matthew</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("ELTRAR",this.href,0);return true;' href='http://www.abdn.ac.uk/philosophy/endsandmeans/vol1no2/elton.shtml'>Robots and rights: The ethical demands of artificial agents.</a></span> <span class='pub_name'>Ends and Means</span> 1 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15100386754950956165'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots%20and%20rights+author%3AElton&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1038_entry' class='entry'><span ><span class='name'>Gips, James</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("GIPTTE",this.href,0);return true;' href='http://cs.bc.edu/~gips/EthicalRobot.pdf'>Toward the ethical robot.</a></span> In Kenneth M. Ford, C. Glymour &amp; Patrick Hayes (eds.), <em>Android Epistemology</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 19 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Toward%20the%20ethical%20robot+author%3AGips&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1038_links")'>More links</a>)</span>
<div id='_1038_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GIPTTE",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=216375">http://portal.acm.org/citation.cfm?id=216375</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("GIPTTE",this.href,0);return true;' href="http://www.roboethics.org/site/modules/mydownloads/download/references/Gips_EthicalRobot.pdf">http://www.roboethics.org/site/modules/mydownloads/download/references/Gips_EthicalRobot.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1039_entry' class='entry'><span ><span class='name'>Hesslow, Germund</span> &amp; <span class='name'>Jirenhed, D-A.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("HESTIW",this.href,0);return true;' href='http://www.ingentaconnect.com//content/imp/jcs/2007/00000014/00000007/art00006'>The inner world of a simple robot.</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 14 (7):85-96. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20inner%20world%20of%20a%20simple%20robot+author%3AHesslow&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1039_links")'>More links</a>)</span><div id='_1039_abstract' class='extra' style='font-size:12px;'>Abstract: The purpose of the paper is to discuss whether a particular robot can be said to have an 'inner world', something that can be taken to be a critical feature of consciousness. It has previously been argued that the mechanism underlying the appearance of an inner world in humans is an ability of our brains to simulate behaviour and perception. A robot has previously been designed in which perception can be simulated. A prima facie case can be made that this robot has an inner world in the same sense as humans. Various objections to this claim are discussed in the paper and it is concluded that the robot, although extremely simple, can easily be improved without adding any new principles, so that ascribing an inner world to it becomes intuitively reasonable</div>
<div id='_1039_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HESTIW",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00006">http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00006</a><br></div></div>
</div><!--entry-->

<div id='_1040_entry' class='entry'><span ><span class='name'>Holland, Owen</span> &amp; <span class='name'>Goodman, Russell B.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("HOLRWI",this.href,0);return true;' href='http://www.rodgoodman.ws/pdf/RG.Paper.JA46.pdf'>Robots with internal models: A route to machine consciousness?</a></span> <span class='pub_name'>Journal of Consciousness Studies</span> 10 (4):77-109. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12246066617239933326'>Cited by 20</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots%20with%20internal%20models+author%3AHolland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1040_links")'>More links</a>)</span>
<div id='_1040_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOLRWI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1348">http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1348</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HOLRWI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1342">http://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1342</a><br></div></div>
</div><!--entry-->

<div id='_1041_entry' class='entry'><span ><span class='name'>Holland, Owen</span>; <span class='name'>Knight, Rob</span> &amp; <span class='name'>Newcombe, Richard</span> (2007). The role of the self process in embodied machine consciousness.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20role%20of%20the%20self%20process%20in%20embodied%20machine%20consciousness+author%3AHolland&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1042_entry' class='entry'><span ><span class='name'>Ishiguro, Hiroshi</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("ISHASC",this.href,0);return true;' href='http://taylorandfrancis.metapress.com/index/H2865440G7N30431.pdf'>Android science: Conscious and subconscious recognition.</a></span> <span class='pub_name'>Connection Science</span> 18 (4):319-332. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2816075044224823321'>Cited by 14</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Android%20science+author%3AIshiguro&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1042_links")'>More links</a>)</span>
<div id='_1042_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ISHASC",this.href,0);return true;' href="http://www.informaworld.com/index/758709863.pdf">http://www.informaworld.com/index/758709863.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1043_entry' class='entry'><span ><span class='name'>Kitamura, T.</span>; <span class='name'>Tahara, T.</span> &amp; <span class='name'>Asami, K.</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("KITHCA",this.href,0);return true;' href='http://www.kluweronline.com/article.asp?PIPS=vsp_01691864_v14n4_s2&amp;PDF=1'>How can a robot have consciousness?</a></span> <span class='pub_name'>Advanced Robotics</span> 14:263-275. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18412629451153931468'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20can%20a%20robot%20have%20consciousness%3F+author%3AKitamura&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1043_links")'>More links</a>)</span>
<div id='_1043_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KITHCA",this.href,0);return true;' href="http://www.springerlink.com/index/P64723468651LH49.pdf">http://www.springerlink.com/index/P64723468651LH49.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KITHCA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/vsp/arb/2000/00000014/00000004/art00002">http://www.ingentaconnect.com/content/vsp/arb/2000/00000014/00000004/art00002</a><br></div></div>
</div><!--entry-->

<div id='_1044_entry' class='entry'><span ><span class='name'>Kitamura, T.</span> (2002). What is the self of a robot? On a consciousness architecture for a mobile robot as a model of human consciousness.</span> In Kunio Yasue, Marj Jibu &amp; Tarcisio Della Senta (eds.), <em>No Matter, Never Mind</em>. John Benjamins. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20the%20self%20of%20a%20robot%3F%20On%20a%20consciousness%20architecture%20for%20a%20mobile%20robot%20as%20a%20model%20of%20human%20consciousness+author%3AKitamura&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1045_entry' class='entry'><span ><span class='name'>Korienek, Gene</span> &amp; <span class='name'>Uzgalis, William L.</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("KORAR",this.href,0);return true;' href='http://www.ingentaconnect.com/content/bpl/meta/2002/00000033/F0020001/art00218'>Adaptable robots.</a></span> <span class='pub_name'>Metaphilosophy</span> 33 (1-2):83-97. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5977387623988556108'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Adaptable%20robots+author%3AKorienek&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1046_entry' class='entry'><span ><span class='name'>Lacey, Nicola</span> &amp; <span class='name'>Lee, M.</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("LACTEF",this.href,0);return true;' href='http://cadair.aber.ac.uk/dspace/handle/2160/109'>The epistemological foundations of artificial agents.</a></span> <span class='pub_name'>Minds and Machines</span> 13 (3):339-365. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1700236438061634441'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20epistemological%20foundations%20of%20artificial%20agents+author%3ALacey&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1046_links")'>More links</a>)</span><div id='_1046_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â A situated agent is one which operates within an environment. In most cases, the environment in which the agent exists will be more complex than the agent itself. This means that an agent, human or artificial, which wishes to carry out non-trivial operations in its environment must use techniques which allow an unbounded world to be represented within a cognitively bounded agent. We present a brief description of some important theories within the fields of epistemology and metaphysics. We then discuss ways in which philosophical problems of scepticism are related to the problems faced by knowledge representation. We suggest that some of the methods that philosophers have developed to address the problems of epistemology may be relevant to the problems of representing knowledge within artificial agents</div>
<div id='_1046_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LACTEF",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=781081.781090">http://portal.acm.org/citation.cfm?id=781081.781090</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LACTEF",this.href,0);return true;' href="http://www.springerlink.com/content/g6g408r7457k4u21/fulltext.pdf">http://www.springerlink.com/content/g6g408r7457k4u21/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LACTEF",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5118862&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5118862&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LACTEF",this.href,0);return true;' href="http://www.springerlink.com/index/G6G408R7457K4U21.pdf">http://www.springerlink.com/index/G6G408R7457K4U21.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LACTEF",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000003/05118862">http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000003/05118862</a><br></div></div>
</div><!--entry-->

<div id='_1047_entry' class='entry'><span ><span class='name'>Menant, Christophe</span> (2005). <a rel="nofollow" class='article_title' onclick='trackclick("MENIAM",this.href,0);return true;' href='http://cogprints.org/4531/'>Information and meaning in life, humans and robots (2005).</a></span> <span class='pub_name'>Proceedings of FIS2005 by MDPI, Basel, Switzerland</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Information%20and%20meaning%20in%20life%2C%20humans%20and%20robots%20%282005%29+author%3AMenant&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1047_links")'>More links</a>)</span><div id='_1047_abstract' class='extra' style='font-size:12px;'>Abstract: Information and meaning exist around us and within ourselves, and the same information can correspond to different meanings. This is true for humans and animals, and is becoming true for robots. We propose here an overview of this subject by using a systemic tool related to meaning generation that has already been published (C. Menant, Entropy 2003). The Meaning Generator System (MGS) is a system submitted to a constraint that generates a meaningful information when it receives an incident information that has a relation with the constraint. The content of the meaningful information is explicited, and its function is to trigger an action that will be used to satisfy the constraint of the system. The MGS has been introduced in the case of basic life submitted to a &quot;stay alive&quot; constraint. We propose here to see how the usage of the MGS can be extended to more complex living systems, to humans and to robots by introducing new types of constraints, and integrating the MGS into higher level systems. The application of the MGS to humans is partly based on a scenario relative to the evolution of body self-awareness toward self-consciousness that has already been presented (C. Menant, Biosemiotics 2003, and TSC 2004). The application of the MGS to robots is based on the definition of the MGS applied to robots functionality, taking into account the origins of the constraints. We conclude with a summary of this overview and with themes that can be linked to this systemic approach on meaning generation</div>
<div id='_1047_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENIAM",this.href,0);return true;' href="http://www.mdpi.org/fis2005/F.45.paper.pdf">http://www.mdpi.org/fis2005/F.45.paper.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENIAM",this.href,0);return true;' href="http://www.mdpi.net/fis2005/F.45.paper.pdf">http://www.mdpi.net/fis2005/F.45.paper.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MENIAM",this.href,0);return true;' href="http://cogprints.org/4531/1/F.45.paper.pdf">http://cogprints.org/4531/1/F.45.paper.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1048_entry' class='entry'><span ><span class='name'>Minsky, Marvin L.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("MINWRI",this.href,0);return true;' href='http://web.media.mit.edu/~minsky/papers/sciam.inherit.txt'>Will robots inherit the earth?</a></span> <span class='pub_name'>Scientific American</span> (Oct). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14398289996230717174'>Cited by 37</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Will%20robots%20inherit%20the%20earth%3F+author%3AMinsky&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1048_links")'>More links</a>)</span><div id='_1048_abstract' class='extra' style='font-size:12px;'>Abstract: Everyone wants wisdom and wealth. Nevertheless, our health often gives out before we achieve them. To lengthen our lives, and improve our minds, in the future we will need to change our our bodies and brains. To that end, we first must consider how normal Darwinian evolution brought us to where we are. Then we must imagine ways in which future replacements for worn body parts might solve most problems of failing health. We must then invent strategies to augment our brains and gain greater wisdom. Eventually we will entirely replace our brains -- using nanotechnology. Once delivered from the limitations of biology, we will be able to decide the length of our lives--with the option of immortality-- and choose among other, unimagined capabilities as well</div>
<div id='_1048_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWRI",this.href,0);return true;' href="http://www.media.mit.edu/~minsky/papers/sciam.inherit.txt">http://www.media.mit.edu/~minsky/papers/sciam.inherit.txt</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWRI",this.href,0);return true;' href="http://www.media.mit.edu/~minsky/papers/sciam.inherit.html">http://www.media.mit.edu/~minsky/papers/sciam.inherit.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWRI",this.href,0);return true;' href="http://web.media.mit.edu/~minsky/papers/sciam.inherit.html">http://web.media.mit.edu/~minsky/papers/sciam.inherit.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINWRI",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=7939559&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=7939559&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_1049_entry' class='entry'><span ><span class='name'>Moravec, Hans</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("MORBRM",this.href,0);return true;' href='http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1995/Kunstforum.html'>Bodies, robots, minds.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Bodies%2C%20robots%2C%20minds+author%3AMoravec&amp;btnG=Search'>Google</a>)</span><div id='_1049_abstract' class='extra' style='font-size:12px;'>Abstract: Serious attempts to build thinking machines began after the second world war. One line of research, called Cybernetics, used electronic circuitry imitating nervous systems to make machines that learned to recognize simple patterns, and turtle-like robots that found their way to recharging plugs. A different approach, named Artificial Intelligence, harnessed the arithmetic power of post-war computers to abstract reasoning, and by the 1960s made computers prove theorems in logic and geometry, solve calculus problems and play good games of checkers. At the end of the 1960s, research groups at MIT and Stanford attached television cameras and robot arms to their computers, so "thinking" programs could begin to collect information directly from the real world</div>
</div><!--entry-->

<div id='_1050_entry' class='entry'><span ><span class='name'>Moravec, Hans</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("MORR",this.href,0);return true;' href='http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2003/robotics.eb.2003.html'>Robotics.</a></span> <em>Encyclopaedia Britannica Online</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robotics+author%3AMoravec&amp;btnG=Search'>Google</a>)</span><div id='_1050_abstract' class='extra' style='font-size:12px;'>Abstract: the development of machines with motor, perceptual and cognitive skills once found only in animals and humans. The field parallels and has adopted developments from several areas, among them mechanization, automation and artificial intelligence, but adds its own gripping myth, of complete artificial mechanical human beings. Ancient images and figurines depicting animals and humans can be interpreted as steps towards this vision, as can mechanical automata from classical times on. The pace accelerated rapidly in the twentieth century with the development of electronic sensing and amplification that permitted automata to sense and react as well as merely perform. By the late twentieth century automata controlled by computers could also think and remember</div>
</div><!--entry-->

<div id='_1051_entry' class='entry'><span ><span class='name'>Moravec, Hans</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("MORRIH",this.href,0);return true;' href='http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1995/RobotMind.talk.html'>Robots inherit human minds.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots%20inherit%20human%20minds+author%3AMoravec&amp;btnG=Search'>Google</a>)</span><div id='_1051_abstract' class='extra' style='font-size:12px;'>Abstract: Our first tools, sticks and stones, were very different from ourselves. But many tools now resemble us, in function or form, and they are beginning to have minds. A loose parallel with our own evolution suggests how they may develop in future. Computerless industrial machinery exhibits the behavioral flexibility of single-celled organisms. Today's best computer-controlled robots are like the simpler invertebrates. A thousand-fold increase in computer power in this decade should make possible machines with reptile-like sensory and motor competence. Growing computer power over the next half century will allow robots that learn like mammals, model their world like primates and eventually reason like humans. Depending on your point of view, humanity will then have produced a worthy successor, or transcended inherited limitations and transformed itself into something quite new. No longer limited by the slow pace of human learning and even slower biological evolution, intelligent machinery will conduct its affairs on an ever faster, ever smaller scale, until coarse physical nature has been converted to fine-grained purposeful thought</div>
</div><!--entry-->

<div id='_1052_entry' class='entry'><span ><span class='name'>Moravec, Hans</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("MORTAO-2",this.href,0);return true;' href='http://www.ri.cmu.edu/pubs/pub_1810.html'>The age of robots.</a></span> In Max More (ed.), <em>Extro 1, Proceedings of the First Extropy Institute Conference on TransHumanist Thought</em>. Extropy Institute. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20age%20of%20robots+author%3AMoravec&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1052_links")'>More links</a>)</span><div id='_1052_abstract' class='extra' style='font-size:12px;'>Abstract: _Our artifacts are getting smarter, and a loose parallel with the evolution of animal intelligence suggests one future course_ _for them. Computerless industrial machinery exhibits the behavioral flexibility of single-celled organisms. Today's best_ _computer-controlled robots are like the simpler invertebrates. A thousand-fold increase in computer power in this decade_ _should make possible machines with reptile-like sensory and motor competence. Properly configured, such robots could_ _do in the physical world what personal computers now do in the world of data--act on our behalf as literal-minded_ _slaves. Growing computer power over the next half-century will allow this reptile stage will be surpassed, in stages_ _producing robots that learn like mammals, model their world like primates and eventually reason like humans._ _Depending on your point of view, humanity will then have produced a worthy successor, or transcended inherited_ _limitations and transformed itself into something quite new. No longer limited by the slow pace of human learning and_ _even slower biological evolution, intelligent machinery will conduct its affairs on an ever faster, ever smaller scale, until_ _coarse physical nature has been converted to fine-grained purposeful thought._</div>
<div id='_1052_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MORTAO-2",this.href,0);return true;' href="http://www.ri.cmu.edu/pubs/pub_1810_text.html">http://www.ri.cmu.edu/pubs/pub_1810_text.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MORTAO-2",this.href,0);return true;' href="http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html">http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html</a><br></div></div>
</div><!--entry-->

<div id='_1053_entry' class='entry'><span ><span class='name'>Parisi, Domenico</span> (2007). Mental robotics.</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mental%20robotics+author%3AParisi&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1054_entry' class='entry'><span ><span class='name'>Petersen, Stephen</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("PETTEO",this.href,0);return true;' href='http://stevepetersen.net/professional/petersen-robot-servitude.pdf'>The ethics of robot servitude.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 19 (1):43-54. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20ethics%20of%20robot%20servitude+author%3APetersen&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1054_links")'>More links</a>)</span><div id='_1054_abstract' class='extra' style='font-size:12px;'>Abstract: Assume we could someday create artificial creatures with
intelligence comparable to our own.  Could it be ethical use them as
unpaid labor?  There is very little philosophical literature on this
topic, but the consensus so far has been that such robot servitude
would merely be a new form of slavery.  Against this consensus I
defend the permissibility of robot servitude, and in particular the
controversial case of designing robots so that they want to
serve (more or less particular) human ends.  A typical objection to
this case draws an analogy to the genetic engineering of humans: if
designing eager robot servants is permissible, it should also be
permissible to design eager human servants.  Few ethical views can
easily explain even the wrongness of such human engineering, however,
and those few explanations that are available break the analogy with
engineering robots.  The case turns out to be illustrative of
profound problems in the field of population ethics.</div>
<div id='_1054_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PETTEO",this.href,0);return true;' href="http://stevepetersen.net/professional/petersen-robot-servitude-slides.pdf">http://stevepetersen.net/professional/petersen-robot-servitude-slides.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PETTEO",this.href,0);return true;' href="http://stevepetersen.net/styleless/professional/petersen-robot-servitude.pdf">http://stevepetersen.net/styleless/professional/petersen-robot-servitude.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PETTEO",this.href,0);return true;' href="http://journalsonline.tandf.co.uk/smpp/content~content=a770959968~db=all~jumptype=rss">http://journalsonline.tandf.co.uk/smpp/content~content=a770959968~db=all~jumptype=rss</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PETTEO",this.href,0);return true;' href="http://taylorandfrancis.metapress.com/index/V14W2MT8346M88N1.pdf">http://taylorandfrancis.metapress.com/index/V14W2MT8346M88N1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PETTEO",this.href,0);return true;' href="http://www.informaworld.com/index/V14W2MT8346M88N1.pdf">http://www.informaworld.com/index/V14W2MT8346M88N1.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1055_entry' class='entry'><span ><span class='name'>Schmidt, C. T. A.</span> &amp; <span class='name'>Kraemer, F.</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("SCHRDA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1145469'>Robots, Dennett and the autonomous: A terminological investigation.</a></span> <span class='pub_name'>Minds and Machines</span> 16 (1):73-80. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8786395255237914272'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Robots%2C%20Dennett%20and%20the%20autonomous+author%3ASchmidt&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1055_links")'>More links</a>)</span><div id='_1055_abstract' class='extra' style='font-size:12px;'>Abstract:  In the present enterprise we take a look at the meaning of Autonomy, how the word has been employed and some of the consequences of its use in the sciences of the artificial. Could and should robots really be autonomous entities? Over and beyond this, we use concepts from the philosophy of mind to spur on enquiry into the very essence of human autonomy. We believe our initiative, as does Dennett's life-long research, sheds light upon the problems of robot design with respect to their relation with humans</div>
<div id='_1055_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHRDA",this.href,0);return true;' href="http://www.springerlink.com/content/j20034x2925vk488/fulltext.pdf">http://www.springerlink.com/content/j20034x2925vk488/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHRDA",this.href,0);return true;' href="http://www.springerlink.com/index/J20034X2925VK488.pdf">http://www.springerlink.com/index/J20034X2925VK488.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1056_entry' class='entry'><span ><span class='name'>Torrance, Steve</span> (1994). The mentality of robots, II.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 68 (68):229-262. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20mentality%20of%20robots%2C%20II+author%3ATorrance&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1057_entry' class='entry'><span ><span class='name'>Young, R. A.</span> (1994). The mentality of robots, I.</span> <span class='pub_name'>Proceedings of the Aristotelian Society</span> 68 (68):199-227. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20mentality%20of%20robots%2C%20I+author%3AYoung&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1058_entry' class='entry'><span ><span class='name'>Ziemke, Tom</span> (2007). What's life got to do with it?</span> In Antonio Chella &amp; Riccardo Manzotti (eds.), <em>Artificial Consciousness</em>. Imprint Academic. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%27s%20life%20got%20to%20do%20with%20it%3F+author%3AZiemke&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->
</div>
<p><a name='.6.5'></a><a name=''></a><span class='myh2'>6.5 Computationalism</span> <p style='font-size:smaller;display:inline;'>18 / 160 entries displayed</p></p>

<div id='cat_6.5' class='cat_content'>
<div id='__new_entries_6.5__'></div><div id='__new_entry_6.5__' class='entry'></div>
<div id='_1059_entry' class='entry'><span ><span class='name'>Balogh, 1Imre</span>; <span class='name'>Beakley, Brian</span>; <span class='name'>Churchland, Paul</span>; <span class='name'>Gorman, Michael</span>; <span class='name'>Harnad, Stevan</span>; <span class='name'>Mertz, David</span>; <span class='name'>Pattee, H. H.</span>; <span class='name'>Ramsey, William</span>; <span class='name'>Ringen, John</span>; <span class='name'>Schwarz, Georg</span>; <span class='name'>Slator, Brian</span>; <span class='name'>Strudler, Alan</span> &amp; <span class='name'>Wallis, Charles</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("BALRTC",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a794260843~fulltext=713240930'>Responses to 'computationalism'.</a></span> <span class='pub_name'>Social Epistemology</span> 4 (2):155 â 199. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Responses%20to%20%27computationalism%27+author%3ABalogh&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1060_entry' class='entry'><span ><span class='name'>Bechtel, William</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("BECDVC",this.href,0);return true;' href='http://journals.cambridge.org/action/displayFulltext?type=1&amp;fid=30074&amp;jid=BBS&amp;volumeId=21&amp;issueId=05&amp;aid=30073'>Dynamicists versus computationalists: Whither mechanists?</a></span> <span class='pub_name'>Behavioral and Brain Sciences</span> 21 (5):629-629. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Dynamicists%20versus%20computationalists+author%3ABechtel&amp;btnG=Search'>Google</a>)</span><div id='_1060_abstract' class='extra' style='font-size:12px;'>Abstract: Van Gelder's characterization of the differences between the dynamical and computational hypotheses, in terms of the contrast between change versus state and geometry versus structure, suggests that the dynamical approach is also at odds with classical mechanism. Dynamical and mechanistic approaches are in fact allies: mechanism can identify components whose properties define the variables that are related in dynamical analyses</div>
</div><!--entry-->

<div id='_1061_entry' class='entry'><span ><span class='name'>Cordeschi, Roberto</span>; <span class='name'>Frixione, M.</span>; <span class='name'>Cordeschi, Roberto</span> &amp; <span class='name'>Frixione, M.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("CORCUA",this.href,0);return true;' href='http://w3.uniroma1.it/cordeschi/PDF/CordFrixChap3FIN_2.pdf'>Computationalism under attack.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computationalism%20under%20attack+author%3ACordeschi&amp;btnG=Search'>Google</a>)</span><div id='_1061_abstract' class='extra' style='font-size:12px;'>Abstract:  in M. Marraffa, M. De Caro and F. Ferretti (eds.), Cartographies of the Mind: Philosophy and Psychology in Intersection, Springer, Berlin-Heidelberg, 2007, pp. 37-49. PDF</div>
</div><!--entry-->

<div id='_1062_entry' class='entry'><span ><span class='name'>Dyer, Michael G.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("DYEIAC",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=95646.95657'>Intentionality and computationalism: Minds, machines, Searle and Harnad.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 2:303-19. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7595359163004966126'>Cited by 23</a> | <span class='ll' onclick='$("_1062_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intentionality%20and%20computationalism+author%3ADyer&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1062_links")'>More links</a>)</span><div id='_1062_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Reply to Searle/Harnad: systems reply, level confusions, etc.</div></div>
<div id='_1062_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DYEIAC",this.href,0);return true;' href="http://www.informaworld.com/index/777957609.pdf">http://www.informaworld.com/index/777957609.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1063_entry' class='entry'><span ><span class='name'>Glennan, Stuart S.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("GLECAT",this.href,0);return true;' href='http://www.informaworld.com/smpp/./ftinterface~db=all~content=a793922298~fulltext=713240930'>Computationalism and the problem of other minds.</a></span> <span class='pub_name'>Philosophical Psychology</span> 8 (4):375-88. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computationalism%20and%20the%20problem%20of%20other%20minds+author%3AGlennan&amp;btnG=Search'>Google</a>)</span><div id='_1063_abstract' class='extra' style='font-size:12px;'>Abstract: In this paper I discuss Searle's claim that the computational properties of a system could never cause a system to be conscious. In the first section of the paper I argue that Searle is correct that, even if a system both behaves in a way that is characteristic of conscious agents (like ourselves) and has a computational structure similar to those agents, one cannot be certain that that system is conscious. On the other hand, I suggest that Searle's intuition that it is âempirically absurdâ that such a system could be conscious is unfounded. In the second section I show that Searle's attempt to show that a system's computational states could not possibly cause it to be conscious is based upon an erroneous distinction between computational and physical properties. On the basis of these two arguments, I conclude that, supposing that the behavior of conscious agents can be explained in terms of their computational properties, we have good reason to suppose that a system having computational properties similar to such agents is also conscious</div>
</div><!--entry-->

<div id='_1064_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("HAUODR",this.href,0);return true;' href='http://www.wutsamada.com/work/ordinary.htm'>Ordinary devices: Reply to Bringsjord's <em>Clarifying the Logic of Anti-Computationalism: Reply to Hauser</em>.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (1):115-117. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Ordinary%20devices+author%3AHauser&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1064_links")'>More links</a>)</span><div id='_1064_abstract' class='extra' style='font-size:12px;'>Abstract: What Robots Can and Can't Be (hereinafter Robots) is, as Selmer Bringsjord says "intended to be a collection of formal-arguments-that-border-on-proofs for the proposition that in all worlds, at all times, machines can't be minds" (Bringsjord, forthcoming). In his (1994) "PrÃ©cis of What Robots Can and Can't Be" Bringsjord styles certain of these arguments as proceeding "repeatedly . . . through instantiations of" the "simple schema"</div>
<div id='_1064_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUODR",this.href,0);return true;' href="http://www.wutsamada.com/work/ordinary.htm ">http://www.wutsamada.com/work/ordinary.htm </a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUODR",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=596715.596855">http://portal.acm.org/citation.cfm?id=596715.596855</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUODR",this.href,0);return true;' href="http://www.springerlink.com/content/content/h874662818vp4p8x/fulltext.pdf">http://www.springerlink.com/content/content/h874662818vp4p8x/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUODR",this.href,0);return true;' href="http://www.springerlink.com/content/h874662818vp4p8x/fulltext.pdf">http://www.springerlink.com/content/h874662818vp4p8x/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUODR",this.href,0);return true;' href="http://www.springerlink.com/index/H874662818VP4P8X.pdf">http://www.springerlink.com/index/H874662818VP4P8X.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1065_entry' class='entry'><span ><span class='name'>Kazez, J. R.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("KAZCAT",this.href,0);return true;' href='http://www.springerlink.com/content/p4g1m447g1814507/fulltext.pdf'>Computationalism and the causal role of content.</a></span> <span class='pub_name'>Philosophical Studies</span> 75 (3):231-60. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6583559809215592986'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computationalism%20and%20the%20causal%20role%20of%20content+author%3AKazez&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1065_links")'>More links</a>)</span>
<div id='_1065_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("KAZCAT",this.href,0);return true;' href="http://www.springerlink.com/index/P4G1M447G1814507.pdf">http://www.springerlink.com/index/P4G1M447G1814507.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1066_entry' class='entry'><span ><span class='name'>Laforte, Geoffrey</span>; <span class='name'>Hayes, Pat</span> &amp; <span class='name'>Ford, Kenneth M.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("LAFWGT",this.href,0);return true;' href='http://www.cs.uwf.edu/~glaforte/papers/whyGodel.ps'>Why Godel's theorem cannot refute computationalism: A reply to Penrose.</a></span> <span class='pub_name'>Artificial Intelligence</span> 104. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Why%20Godel%27s%20theorem%20cannot%20refute%20computationalism+author%3ALaforte&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1067_entry' class='entry'><span ><span class='name'>Longinotti, David</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("LONCAT-2",this.href,0);return true;' href='http://www.springerlink.com/content/v74x49651v665017/fulltext.pdf'>Computationalism and the locality principle.</a></span> <span class='pub_name'>Minds and Machines</span> 19 (4):495-506. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computationalism%20and%20the%20locality%20principle+author%3ALonginotti&amp;btnG=Search'>Google</a>)</span><div id='_1067_abstract' class='extra' style='font-size:12px;'>Abstract: Computationalism, a specie of functionalism, posits that a mental state like pain is realized by a âcoreâ computational state within a particular causal network of such states. This entails that what is realized by the core state is contingent on events remote in space and time, which puts computationalism at odds with the locality principle of physics. If computationalism is amended to respect locality, then it posits that a type of phenomenal experience is determined by a single type of computational state. But a computational state, considered by itself, is of no determinate typeâit has no particular symbolic content, since it could be embedded in any of an infinite number of algorithms. Hence, if locality is respected, then the type of experience that is realized by a computational state, or whether any experience at all is realized, is under-determined by the computational nature of the state. Accordingly, Blockâs absent and inverted qualia arguments against functionalism find support in the locality principle of physics. If computationalism denies locality to avoid this problem, then it cannot be considered a physicalist theory since it would entail a commitment to phenomena, like teleological causation and action-at-a-distance, that have long been rejected by modern science. The remaining theoretical alternative is to accept the locality principle for macro events and deny that formal, computational operations are sufficient to realize a phenomenal mental state</div>
</div><!--entry-->

<div id='_1068_entry' class='entry'><span ><span class='name'>Luna, Laureano</span> &amp; <span class='name'>Small, Christopher</span> (2009). Intentionality and Computationalism. A Diagonal Argument.</span> <span class='pub_name'>Mind and Matter</span> 7 (1):81-90. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Intentionality%20and%20Computationalism.%20A%20Diagonal%20Argument.+author%3ALuna&amp;btnG=Search'>Google</a>)</span><div id='_1068_abstract' class='extra' style='font-size:12px;'>Abstract: Computationalism is the claim that all possible thoughts are computations, i.e. executions of algorithms. The aim of the paper is to show that if intentionality is semantically clear, in a way defined in the paper, then computationalism must be false. Using a convenient version of the phenomenological relation of intentionality and a diagonalization device inspired by Thomson's theorem of 1962, we show there exists a thought that canno be a computation.</div>
</div><!--entry-->

<div id='_1069_entry' class='entry'><span ><span class='name'>Lyngzeidetson, Albert E.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("LYNMPD",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(199003)41:1&lt;121:MPDPAA&gt;2.0.CO;2-E'>Massively parallel distributed processing and a computationalist foundation for cognitive science.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 41 (March):121-127. <span style='font-size:smaller'>&nbsp;&nbsp;(<span class='ll' onclick='$("_1069_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Massively%20parallel%20distributed%20processing%20and%20a%20computationalist%20foundation%20for%20cognitive%20science+author%3ALyngzeidetson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1069_links")'>More links</a>)</span><div id='_1069_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A Connection Machine might escape the Lucas argument. Bizarre.</div></div>
<div id='_1069_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(199003)41:1&lt;121:MPDPAA&gt;2.0.CO;2-E">http://www.jstor.org/sici?sici=0007-0882(199003)41:1<121:MPDPAA>2.0.CO;2-E</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/41/1/121">http://bjps.oxfordjournals.org/cgi/content/abstract/41/1/121</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/41/1/121">http://bjps.oxfordjournals.org/cgi/reprint/41/1/121</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("LYNMPD",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/688006.pdf">http://www.jstor.org/stable/pdfplus/688006.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1070_entry' class='entry'><span ><span class='name'>Piccinini, Gualtiero</span> (2009). <a rel="nofollow" class='article_title' onclick='trackclick("PICCIT",this.href,0);return true;' href='http://www.umsl.edu/~piccininig/Computationalism_in_the_Philosophy_of_Mind.pdf'>Computationalism in the philosophy of mind.</a></span> <span class='pub_name'>Philosophy Compass</span> 4 (3):515-532. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computationalism%20in%20the%20philosophy%20of%20mind+author%3APiccinini&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1070_links")'>More links</a>)</span><div id='_1070_abstract' class='extra' style='font-size:12px;'>Abstract: Computationalism has been the mainstream view of cognition for decades. There are periodic reports of its demise, but they are greatly exaggerated. This essay surveys some recent literature on computationalism and reaches the following conclusions. Computationalism is a family of theories about the mechanisms of cognition. The main relevant evidence for testing computational theories comes from neuroscience, though psychology and AI are relevant too. Computationalism comes in many versions, which continue to guide competing research programs in philosophy of mind as well as psychology and neuroscience. Although our understanding of computationalism has deepened in recent years, much work in this area remains to be done</div>
<div id='_1070_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICCIT",this.href,0);return true;' href="http://www3.interscience.wiley.com/cgi-bin/fulltext/122301402/PDFSTART">http://www3.interscience.wiley.com/cgi-bin/fulltext/122301402/PDFSTART</a><br></div></div>
</div><!--entry-->

<div id='_1071_entry' class='entry'><span ><span class='name'>Piccinini, Gualtiero</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("PICCTC",this.href,0);return true;' href='http://www.umsl.edu/~piccininig/Computationalism_Church-Turing_Thesis_Church-Turing_Fallacy.pdf'>Computationalism, the churchâturing thesis, and the churchâturing fallacy.</a></span> <span class='pub_name'>Synthese</span> 154 (1):97-120. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computationalism%2C%20the%20church%E2%80%93turing%20thesis%2C%20and%20the%20church%E2%80%93turing%20fallacy+author%3APiccinini&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1071_links")'>More links</a>)</span><div id='_1071_abstract' class='extra' style='font-size:12px;'>Abstract: The ChurchâTuring Thesis (CTT) is often employed in arguments for computationalism. I scrutinize the most prominent of such arguments in light of recent work on CTT and argue that they are unsound. Although CTT does nothing to support computationalism, it is not irrelevant to it. By eliminating misunderstandings about the relationship between CTT and computationalism, we deepen our appreciation of computationalism as an empirical hypothesis.</div>
<div id='_1071_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PICCTC",this.href,0);return true;' href="http://www.springerlink.com/content/u2914611854801u1/fulltext.pdf">http://www.springerlink.com/content/u2914611854801u1/fulltext.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1072_entry' class='entry'><span ><span class='name'>Rescorla, Michael</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("RESCTA",this.href,0);return true;' href='http://www.philosophy.ucsb.edu/people/profiles/faculty/cvs/papers/church2.pdf'>Church's Thesis and the Conceptual Analysis of Computability.</a></span> <span class='pub_name'>Notre Dame Journal of Formal Logic</span> 48 (2):253-280. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Church%27s%20Thesis%20and%20the%20Conceptual%20Analysis%20of%20Computability+author%3ARescorla&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1072_links")'>More links</a>)</span><div id='_1072_abstract' class='extra' style='font-size:12px;'>Abstract: Church's thesis asserts that a number-theoretic function is intuitively computable if and only if it is recursive. A related thesis asserts that Turing's work yields a conceptual analysis of the intuitive notion of numerical computability. I endorse Church's thesis, but I argue against the related thesis. I argue that purported conceptual analyses based upon Turing's work involve a subtle but persistent circularity. Turing machines manipulate syntactic entities. To specify which number-theoretic function a Turing machine computes, we must correlate these syntactic entities with numbers. I argue that, in providing this correlation, we must demand that the correlation itself be computable. Otherwise, the Turing machine will compute uncomputable functions. But if we presuppose the intuitive notion of a computable relation between syntactic entities and numbers, then our analysis of computability is circular.</div>
<div id='_1072_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RESCTA",this.href,0);return true;' href="http://www.projecteuclid.org/DPubS?verb=Display&amp;version=1.0&amp;service=UI&amp;handle=euclid.ndjfl/1179323267&amp;page=record">http://www.projecteuclid.org/DPubS?verb=Display&version=1.0&service=UI&handle=euclid.ndjfl/1179323267&page=record</a><br></div></div>
</div><!--entry-->

<div id='_1073_entry' class='entry'><span ><span class='name'>Rey, Georges</span> (1994). Wittgenstein, computationalism, and qualia.</span> In Roberto Casati, B. Smith &amp; Stephen L. White (eds.), <em>Philosophy and the Cognitive Sciences</em>. Holder-Pichler-Tempsky. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13965155349452516646'>Cited by 3</a> | <span class='ll' onclick='$("_1073_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Wittgenstein%2C%20computationalism%2C%20and%20qualia+author%3ARey&amp;btnG=Search'>Google</a>)</span><div id='_1073_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Computational functionalism about qualia is compatible with Wittgenstein's views. It makes sense of the points about "dividing through" my private objects, for example. With remarks on spectrum inversions.</div></div>
</div><!--entry-->

<div id='_1074_entry' class='entry'><span ><span class='name'>Robinson, William S.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("ROBBSA",this.href,0);return true;' href='http://www.springerlink.com/content/l075451262856x7g/fulltext.pdf'>Brain symbols and computationalist explanation.</a></span> <span class='pub_name'>Minds and Machines</span> 5 (1):25-44. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9286180813998858138'>Cited by 4</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Brain%20symbols%20and%20computationalist%20explanation+author%3ARobinson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1074_links")'>More links</a>)</span><div id='_1074_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Computationalist theories of mind require brain symbols, that is, neural events that represent kinds or instances of kinds. Standard models of computation require multiple inscriptions of symbols with the same representational content. The satisfaction of two conditions makes it easy to see how this requirement is met in computers, but we have no reason to think that these conditions are satisfied in the brain. Thus, if we wish to give computationalist explanations of human cognition, without committing ourselvesa priori to a strong and unsupported claim in neuroscience, we must first either explain how we can provide multiple brain symbols with the same content, or explain how we can abandon standard models of computation. It is argued that both of these alternatives require us to explain the execution of complex tasks that have a cognition-like structure. Circularity or regress are thus threatened, unless noncomputationalist principles can provide the required explanations. But in the latter case, we do not know that noncomputationalist principles might not bear most of the weight of explaining cognition. Four possible types of computationalist theory are discussed; none appears to provide a promising solution to the problem. Thus, despite known difficulties in noncomputationalist investigations, we have every reason to pursue the search for noncomputationalist principles in cognitive theory</div>
<div id='_1074_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ROBBSA",this.href,0);return true;' href="http://www.springerlink.com/index/L075451262856X7G.pdf">http://www.springerlink.com/index/L075451262856X7G.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1075_entry' class='entry'><span ><span class='name'>Waskan, Jonathan</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("WASAVT",this.href,0);return true;' href='http://www.springerlink.com/content/248275486ug14731/fulltext.pdf'>A vehicular theory of corporeal qualia (a gift to computationalists).</a></span> <span class='pub_name'>Philosophical Studies</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20vehicular%20theory%20of%20corporeal%20qualia%20%28a%20gift%20to%20computationalists%29+author%3AWaskan&amp;btnG=Search'>Google</a>)</span><div id='_1075_abstract' class='extra' style='font-size:12px;'>Abstract: I have argued elsewhere that non-sentential representations that are the close kin of scale models can be, and often are, realized by computational processes. I will attempt here to weaken any resistance to this claim that happens to issue from those who favor an across-the-board computational theory of cognitive activity. I will argue that embracing the idea that certain computers harbor nonsentential models gives proponents of the computational theory of cognition the means to resolve the conspicuous disconnect between the sentential character of the data structures they posit and the nonsentential qualitative character of our perceptual experiences of corporeal (i.e., spatial, kinematic, and dynamic) properties. Along the way, I will question the viability of some externalist remedies for this disconnect, and I will explain why the computational theory put forward here falls quite clearly beyond the useful bounds of the Chinese-Room argument</div>
</div><!--entry-->

<div id='_1076_entry' class='entry'><span ><span class='name'>Wilson, Robert A.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("WILWC",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0026-4423(199407)2:103:411&lt;351:WC&gt;2.0.CO;2-T'>Wide computationalism.</a></span> <span class='pub_name'>Mind</span> 103 (411):351-72. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3995937787312855519'>Cited by 39</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Wide%20computationalism+author%3AWilson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1076_links")'>More links</a>)</span>
<div id='_1076_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILWC",this.href,0);return true;' href="http://mind.oxfordjournals.org/cgi/reprint/103/411/351">http://mind.oxfordjournals.org/cgi/reprint/103/411/351</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WILWC",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2253744.pdf">http://www.jstor.org/stable/pdfplus/2253744.pdf</a><br></div></div>
</div><!--entry-->
</div>
<p><a name='.6.6'></a><a name=''></a><span class='myh2'>6.6 Philosophy of AI, Miscellaneous</span></p>

<div id='cat_6.6' class='cat_content'>
<div id='__new_entries_6.6__'></div><div id='__new_entry_6.6__' class='entry'></div>
<div id='_1077_entry' class='entry'><span ><span class='name'>Akman, Varol</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("AKMITT",this.href,0);return true;' href='http://cogprints.org/961/00/intro.ps'>Introduction to the special issue on philosophical foundations of artificial intelligence.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 12 (3):247-250. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 2 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Introduction%20to%20the%20special%20issue%20on%20philosophical%20foundations%20of%20artificial%20intelligence+author%3AAkman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1077_links")'>More links</a>)</span><div id='_1077_abstract' class='extra' style='font-size:12px;'>Abstract: This is the guest editor's introduction to a JETAI special issue on philosophical foundations of AI</div>
<div id='_1077_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/346061.html">http://citeseer.ist.psu.edu/346061.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000961/">http://cogprints.ecs.soton.ac.uk/archive/00000961/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://citeseer.ist.psu.edu/akman00introduction.html">http://citeseer.ist.psu.edu/akman00introduction.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://www.cs.bilkent.edu.tr/~akman/jour-papers/jetai/jetai2000.pdf">http://www.cs.bilkent.edu.tr/~akman/jour-papers/jetai/jetai2000.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:961">http://citebase.eprints.org/cgi-bin/citations?archiveID=oai:cogprints.soton.ac.uk:961</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://www.informaworld.com/index/K7H3RFR1N065UAU2.pdf">http://www.informaworld.com/index/K7H3RFR1N065UAU2.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://www.ingentaconnect.com/content/tandf/teta/2000/00000012/00000003/art00001">http://www.ingentaconnect.com/content/tandf/teta/2000/00000012/00000003/art00001</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://cogprints.org/961/2/intro.ps">http://cogprints.org/961/2/intro.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("AKMITT",this.href,0);return true;' href="http://cogprints.org/961/0/intro.ps">http://cogprints.org/961/0/intro.ps</a><br></div></div>
</div><!--entry-->

<div id='_1078_entry' class='entry'><span ><span class='name'>Alai, Mario</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("ALAASD",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=954516'>A.I., Scientific discovery and realism.</a></span> <span class='pub_name'>Minds and Machines</span> 14 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3873877998890580553'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A.I.%2C%20Scientific%20discovery%20and%20realism+author%3AAlai&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1078_links")'>More links</a>)</span><div id='_1078_abstract' class='extra' style='font-size:12px;'>Abstract: Epistemologists have debated at length whether scientific discovery is a rational and logical process. If it is, according to the Artificial Intelligence hypothesis, it should be possible to write computer programs able to discover laws or theories; and if such programs were written, this would definitely prove the existence of a logic of discovery. Attempts in this direction, however, have been unsuccessful: the programs written by Simon's group, indeed, infer famous laws of physics and chemistry; but having found no new law, they cannot properly be considered discovery machines. The programs written in the Turing tradition, instead, produced new and useful empirical generalization, but no theoretical discovery, thus failing to prove the logical character of the most significant kind of discoveries. A new cognitivist and connectionist approach by Holland, Holyoak, Nisbett and Thagard, looks more promising. Reflection on their proposals helps to understand the complex character of discovery processes, the abandonment of belief in the logic of discovery by logical positivists, and the necessity of a realist interpretation of scientific research</div>
<div id='_1078_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALAASD",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/510/mm-alai.pdf">http://www.cse.buffalo.edu/~rapaport/510/mm-alai.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALAASD",this.href,0);return true;' href="http://www.springerlink.com/content/u078803u28817475/fulltext.pdf">http://www.springerlink.com/content/u078803u28817475/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALAASD",this.href,0);return true;' href="http://www.springerlink.com/index/U078803U28817475.pdf">http://www.springerlink.com/index/U078803U28817475.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("ALAASD",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000001/05142090">http://www.ingentaconnect.com/content/klu/mind/2004/00000014/00000001/05142090</a><br></div></div>
</div><!--entry-->

<div id='_1079_entry' class='entry'><span ><span class='name'>Apter, Michael J.</span> (1970). <em><span class='pub_name'>The Computer Simulation Of Behaviour.</span></em></span> Hutchinson. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2318800455132801250'>Cited by 18</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Computer%20Simulation%20Of%20Behaviour+author%3AApter&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1080_entry' class='entry'><span ><span class='name'>Barbour, Ian G.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("BARNAI",this.href,0);return true;' href='http://www3.interscience.wiley.com/cgi-bin/fulltext/119079399/PDFSTART'>Neuroscience, artificial intelligence, and human nature: Theological and philosophical reflections.</a></span> In <em>Neuroscience and the Person: Scientific Perspectives on Divine Action</em>. Notre Dame: University Notre Dame Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1219797344815066811'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Neuroscience%2C%20artificial%20intelligence%2C%20and%20human%20nature+author%3ABarbour&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1080_links")'>More links</a>)</span>
<div id='_1080_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BARNAI",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/0591-2385.00222">http://www.blackwell-synergy.com/doi/abs/10.1111/0591-2385.00222</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BARNAI",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/zygo/1999/00000034/00000003/art00222">http://www.ingentaconnect.com/content/bpl/zygo/1999/00000034/00000003/art00222</a><br></div></div>
</div><!--entry-->

<div id='_1081_entry' class='entry'><span ><span class='name'>Baum, Eric B.</span> (2004). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("BAUWIT",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=995059'>What Is Thought?</a></span></em></span> Cambridge MA: Bradford Book/MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=18416398144585216949'>Cited by 33</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20Is%20Thought%3F+author%3ABaum&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1081_links")'>More links</a>)</span>
<div id='_1081_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BAUWIT",this.href,0);return true;' href="http://www.reiters.com/index.cgi?ISBN=0262025485&amp;f=p">http://www.reiters.com/index.cgi?ISBN=0262025485&f=p</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BAUWIT",this.href,0);return true;' href="http://mentalhelp.net/books/books.php?type=de&amp;id=2226">http://mentalhelp.net/books/books.php?type=de&id=2226</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BAUWIT",this.href,0);return true;' href="http://www.markus-enzenberger.de/compgo_biblio/books/what-is-thought.html">http://www.markus-enzenberger.de/compgo_biblio/books/what-is-thought.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BAUWIT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=TPh8uUFiM0QC&amp;oi=fnd&amp;pg=RA1-PR11&amp;sig=0oGe6jMGAotxDkTeK0Hq7OsKo5o">http://books.google.com/books?hl=en&lr=&id=TPh8uUFiM0QC&oi=fnd&pg=RA1-PR11&sig=0oGe6jMGAotxDkTeK0Hq7OsKo5o</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BAUWIT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=TPh8uUFiM0QC&amp;oi=fnd&amp;pg=PR11&amp;ots=Qm4pU75R0M&amp;sig=yoAV8PwnJuCYCm_o1yuHXWsro7Q">http://books.google.com/books?hl=en&lr=&id=TPh8uUFiM0QC&oi=fnd&pg=PR11&ots=Qm4pU75R0M&sig=yoAV8PwnJuCYCm_o1yuHXWsro7Q</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BAUWIT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=TPh8uUFiM0QC&amp;oi=fnd&amp;pg=PR11&amp;ots=Qm3sS78_-K&amp;sig=M13fepJ_m6oWkmKf9nvKwdUMdBs">http://books.google.com/books?hl=en&lr=&id=TPh8uUFiM0QC&oi=fnd&pg=PR11&ots=Qm3sS78_-K&sig=M13fepJ_m6oWkmKf9nvKwdUMdBs</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BAUWIT",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=TPh8uUFiM0QC&amp;oi=fnd&amp;pg=RA1-PR11&amp;ots=Qm3sS78_-K&amp;sig=LVr9z-CZ4xm_ltubPIHNCUdfzhk">http://books.google.com/books?hl=en&lr=&id=TPh8uUFiM0QC&oi=fnd&pg=RA1-PR11&ots=Qm3sS78_-K&sig=LVr9z-CZ4xm_ltubPIHNCUdfzhk</a><br></div></div>
</div><!--entry-->

<div id='_1082_entry' class='entry'><span ><span class='name'>Beavers, Anthony F.</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("BEAPAA",this.href,0);return true;' href='http://faculty.evansville.edu/tb2/PDFs/PhenomAI.pdf'>Phenomenology and artificial intelligence.</a></span> <span class='pub_name'>Metaphilosophy</span> 33 (1-2):70-82. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5548444727775949730'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Phenomenology%20and%20artificial%20intelligence+author%3ABeavers&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1082_links")'>More links</a>)</span><div id='_1082_abstract' class='extra' style='font-size:12px;'>Abstract:  In CyberPhilosophy: The Intersection of Philosophy and Computing, edited by James H. Moor and Terrell Ward Bynum (Oxford, UK: Blackwell, 2002), 66-77. Also in Metaphilosophy 33.1/2 (2002): 70-82</div>
<div id='_1082_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BEAPAA",this.href,0);return true;' href="http://www.blackwell-synergy.com/links/doi/10.1111/1467-9973.00217/abs/">http://www.blackwell-synergy.com/links/doi/10.1111/1467-9973.00217/abs/</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BEAPAA",this.href,0);return true;' href="http://www.blackwell-synergy.com/doi/abs/10.1111/1467-9973.00217">http://www.blackwell-synergy.com/doi/abs/10.1111/1467-9973.00217</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BEAPAA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/bpl/meta/2002/00000033/F0020001/art00217">http://www.ingentaconnect.com/content/bpl/meta/2002/00000033/F0020001/art00217</a><br></div></div>
</div><!--entry-->

<div id='_1083_entry' class='entry'><span ><span class='name'>Bergadano, F.</span> (1993). <a rel="nofollow" class='article_title' onclick='trackclick("BERMLA",this.href,0);return true;' href='http://www.springerlink.com/content/content/w67627184tv71rk6/fulltext.pdf'>Machine learning and the foundations of inductive inference.</a></span> <span class='pub_name'>Minds and Machines</span> 3 (1):31-51. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20learning%20and%20the%20foundations%20of%20inductive%20inference+author%3ABergadano&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1083_links")'>More links</a>)</span><div id='_1083_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The problem of valid induction could be stated as follows: are we justified in accepting a given hypothesis on the basis of observations that frequently confirm it? The present paper argues that this question is relevant for the understanding of Machine Learning, but insufficient. Recent research in inductive reasoning has prompted another, more fundamental question: there is not just one given rule to be tested, there are a large number of possible rules, and many of these are somehow confirmed by the data â how are we to restrict the space of inductive hypotheses and choose effectively some rules that will probably perform well on future examples? We analyze if and how this problem is approached in standard accounts of induction and show the difficulties that are present. Finally, we suggest that the explanation-based learning approach and related methods of knowledge intensive induction could be, if not a solution, at least a tool for solving some of these problems</div>
<div id='_1083_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERMLA",this.href,0);return true;' href="http://www.springerlink.com/content/w67627184tv71rk6/fulltext.pdf">http://www.springerlink.com/content/w67627184tv71rk6/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BERMLA",this.href,0);return true;' href="http://www.springerlink.com/index/W67627184TV71RK6.pdf">http://www.springerlink.com/index/W67627184TV71RK6.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1084_entry' class='entry'><span ><span class='name'>Boden, Margaret A.</span> (1978). <a rel="nofollow" class='article_title' onclick='trackclick("BODAIA",this.href,0);return true;' href='http://www.springerlink.com/content/t68361277t087206/fulltext.pdf'>Artificial intelligence and Piagetian theory.</a></span> <span class='pub_name'>Synthese</span> 38 (July):389-414. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=2228153014233542920'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence%20and%20Piagetian%20theory+author%3ABoden&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1084_links")'>More links</a>)</span>
<div id='_1084_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BODAIA",this.href,0);return true;' href="http://www.springerlink.com/index/T68361277T087206.pdf">http://www.springerlink.com/index/T68361277T087206.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1085_entry' class='entry'><span ><span class='name'>Boden, Margaret A.</span> (1989). <em><span class='pub_name'>Artificial Intelligence In Psychology: Interdisciplinary Essays.</span></em></span> Cambridge: Mit Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1396907972450135920'>Cited by 15</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Intelligence%20In%20Psychology+author%3ABoden&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1086_entry' class='entry'><span ><span class='name'>Boden, Margaret A.</span> (1973). <a rel="nofollow" class='article_title' onclick='trackclick("BODHAI",this.href,0);return true;' href='http://bjps.oxfordjournals.org/cgi/reprint/24/1/61'>How artificial is artificial intelligence?</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 24 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20artificial%20is%20artificial%20intelligence%3F+author%3ABoden&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1087_entry' class='entry'><span ><span class='name'>Born, Rainer P.</span> (ed.) (1987). <em><span class='pub_name'>Artificial Intelligence: The Case Against.</span></em></span> St Martin's Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17942968763635978772'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Intelligence+author%3ABorn&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1088_entry' class='entry'><span ><span class='name'>Bostrom, Nick</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("BOSHLB",this.href,0);return true;' href='http://www.nickbostrom.com/superintelligence.html'>How long before superintelligence?</a></span> <span class='pub_name'>International Journal of Futures Studies</span> 2. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8938306286483768875'>Cited by 22</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20long%20before%20superintelligence%3F+author%3ABostrom&amp;btnG=Search'>Google</a>)</span><div id='_1088_abstract' class='extra' style='font-size:12px;'>Abstract: _This paper outlines the case for believing that we will have superhuman artificial intelligence_ _within the first third of the next century. It looks at different estimates of the processing power of_ _the human brain; how long it will take until computer hardware achieve a similar performance;_ _ways of creating the software through bottom-up approaches like the one used by biological_ _brains; how difficult it will be for neuroscience figure out enough about how brains work to_ _make this approach work; and how fast we can expect superintelligence to be developed once_ _there is human-level artificial intelligence._</div>
</div><!--entry-->

<div id='_1089_entry' class='entry'><span ><span class='name'>Bostrom, Nick</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("BOSTTF",this.href,0);return true;' href='http://transhumanism.org/index.php/WTA/faq/'>The transhumanist FAQ.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15261533166448038188'>Cited by 14</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20transhumanist%20FAQ+author%3ABostrom&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1089_links")'>More links</a>)</span>
<div id='_1089_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BOSTTF",this.href,0);return true;' href="http://www.transhumanism.org/resources/faq.html">http://www.transhumanism.org/resources/faq.html</a><br></div></div>
</div><!--entry-->

<div id='_1090_entry' class='entry'><span ><span class='name'>Brooks, Rodney</span> (2001). <a rel="nofollow" class='article_title' onclick='trackclick("BROTRB-2",this.href,0);return true;' href='http://adsabs.harvard.edu/abs/2001Natur.409..409B'>The relationship between matter and life.</a></span> <span class='pub_name'>Nature</span> 409 (6818):409-411. <span style='font-size:smaller'>&nbsp;&nbsp;(Cited by 65 | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20relationship%20between%20matter%20and%20life+author%3ABrooks&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1090_links")'>More links</a>)</span><div id='_1090_abstract' class='extra' style='font-size:12px;'>Abstract: Researchers in artificial intelligence (AI) Mooreâs law states that computational complexity of the models is still far below that and artificial life (Alife) are interested resources for a fixed price roughly double of any living system. New experiments in evo- in understanding the properties of liv- every 18 months. From about 1975 into the lution simulate spatially isolated populations ing organisms so that they can build artificial early 1990s all the gains of Mooreâs law went to investigate speciation. Over the past few systems that exhibit these properties for into the changeover from the centralized years, new directions have emerged in AI<sup>5</sup>, in useful purposes. AI researchers are interest- mainframe to the individual computer on attempts to implement artificial creatures in ed mostly in perception, cognition and your desk, accommodating a vastly simulated or physical environments. generation of action (Box 1), whereas Alife increased number of users. The amount of Often called the behaviour-based focuses on evolution, reproduction, computing power available to the individual approach, this new mode of thought involves morphogenesis and metabolism (Box 2). scientist did not change that much, although the connection of perception to action with Neither of these disciplines is a conventional the price came down by a factor of a little in the way of intervening representa- science; rather, they are a mixture of science thousand. But since the early 1990s, all of tional systems. Rather than relying on and engineering. Despite, or perhaps Mooreâs law has gone into increasing the per- search, this approach relies on the correct because of, this hybrid structure, both disci- formance of the workstation itself. short, fast connections being present plines have been very successful and our And both AI and Alife have benefited from between sensory and motor modules. world is full of their products. this shift. Behaviour-based approaches began with Every time we use a computer we use Increased computer power has enabled insect models, but more recently they have algorithms and techniques developed by AI search-based AI to push ahead with been extended to humanoid robots<sup>6</sup> â researchers.</div>
<div id='_1090_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTRB-2",this.href,0);return true;' href="http://www.nature.com/nature/journal/v409/n6818/full/409409a0.html">http://www.nature.com/nature/journal/v409/n6818/full/409409a0.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("BROTRB-2",this.href,0);return true;' href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;list_uids=11201756&amp;dopt=Citation">http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=11201756&dopt=Citation</a><br></div></div>
</div><!--entry-->

<div id='_1091_entry' class='entry'><span ><span class='name'>Button, Graham</span>; <span class='name'>Coulter, Jeff</span>; <span class='name'>Lee, John R. E.</span> &amp; <span class='name'>Sharrock, Wes</span> (1995). <em><span class='pub_name'>Computers, Minds, and Conduct.</span></em></span> Polity Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14509778517310438804'>Cited by 54</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computers%2C%20Minds%2C%20and%20Conduct+author%3AButton&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1092_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (2002). Artificial intelligence.</span> In Stephen P. Stich &amp; Ted A. Warfield (eds.), <em>Blackwell Guide to Philosophy of Mind</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence+author%3AClark&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1093_entry' class='entry'><span ><span class='name'>Clark, Andy</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("CLAAIA",this.href,0);return true;' href='http://www.cogs.indiana.edu/andy/AIandFacesofReason.pdf'>Artificial intelligence and the many faces of reason.</a></span> In Stephen P. Stich &amp; Ted A. Warfield (eds.), <em>The Blackwell Guide to Philosophy of Mind</em>. Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=9643468857536010902'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence%20and%20the%20many%20faces%20of%20reason+author%3AClark&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1093_links")'>More links</a>)</span><div id='_1093_abstract' class='extra' style='font-size:12px;'>Abstract: wide variety of things. It covers the capacity to carry out deductive inferences, to make</div>
<div id='_1093_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAAIA",this.href,0);return true;' href="http://www.philosophy.ed.ac.uk/staff/clark/pubs/AIandFacesofReason.pdf">http://www.philosophy.ed.ac.uk/staff/clark/pubs/AIandFacesofReason.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CLAAIA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oI8lWo-dasIC&amp;oi=fnd&amp;pg=PA309&amp;ots=YXROBOGM7A&amp;sig=a69b_8ZipUXmv8jfu6-lWPxYp4U">http://books.google.com/books?hl=en&lr=&id=oI8lWo-dasIC&oi=fnd&pg=PA309&ots=YXROBOGM7A&sig=a69b_8ZipUXmv8jfu6-lWPxYp4U</a><br></div></div>
</div><!--entry-->

<div id='_1094_entry' class='entry'><span ><span class='name'>Copeland, B. Jack</span> (1995). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("COPAIA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=530166'>Artificial Intelligence: A Philosophical Introduction.</a></span></em></span> Cambridge: Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12582843766812094638'>Cited by 77</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Intelligence+author%3ACopeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1094_links")'>More links</a>)</span>
<div id='_1094_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPAIA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=PVDNf9MUygIC&amp;oi=fnd&amp;pg=PR9&amp;sig=4U5JFzAZ_uapDXPy03SDTNiW3j0">http://books.google.com/books?hl=en&lr=&id=PVDNf9MUygIC&oi=fnd&pg=PR9&sig=4U5JFzAZ_uapDXPy03SDTNiW3j0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPAIA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=PVDNf9MUygIC&amp;oi=fnd&amp;pg=PR5&amp;ots=GSKvY9Q1u7&amp;sig=RyCTIUvUlJbSuSqUcDtLDJN2IKc">http://books.google.com/books?hl=en&lr=&id=PVDNf9MUygIC&oi=fnd&pg=PR5&ots=GSKvY9Q1u7&sig=RyCTIUvUlJbSuSqUcDtLDJN2IKc</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPAIA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=PVDNf9MUygIC&amp;oi=fnd&amp;pg=PR5&amp;ots=GSLsX9O2x1&amp;sig=gF3b31Zdq8wGkfR-3EzPZuAZcRE">http://books.google.com/books?hl=en&lr=&id=PVDNf9MUygIC&oi=fnd&pg=PR5&ots=GSLsX9O2x1&sig=gF3b31Zdq8wGkfR-3EzPZuAZcRE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("COPAIA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=PVDNf9MUygIC&amp;oi=fnd&amp;pg=PR9&amp;ots=GSKvY9Q1u7&amp;sig=QMC-cA7DK8sTMPuYT4j0Nsq8Hto">http://books.google.com/books?hl=en&lr=&id=PVDNf9MUygIC&oi=fnd&pg=PR9&ots=GSKvY9Q1u7&sig=QMC-cA7DK8sTMPuYT4j0Nsq8Hto</a><br></div></div>
</div><!--entry-->

<div id='_1095_entry' class='entry'><span ><span class='name'>Cordeschi, Roberto</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("CORATF",this.href,0);return true;' href='http://w3.uniroma1.it/cordeschi/PDF/AAI 07.pdf'>AI turns fifty: Revisiting its origins.</a></span> <span class='pub_name'>Applied Artificial Intelligence</span> 21:259-279. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5438000853859914210'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=AI%20turns%20fifty+author%3ACordeschi&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1095_links")'>More links</a>)</span><div id='_1095_abstract' class='extra' style='font-size:12px;'>Abstract: Applied Artificial Intelligence, 21, 2007, pp. 259-279</div>
<div id='_1095_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CORATF",this.href,0);return true;' href="http://www.informaworld.com/index/778482823.pdf">http://www.informaworld.com/index/778482823.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1096_entry' class='entry'><span ><span class='name'>Cordeschi, Roberto</span> (2006). <a rel="nofollow" class='article_title' onclick='trackclick("CORSIA",this.href,0);return true;' href='http://w3.uniroma1.it/cordeschi/PDF/Cordeschi Springer chapter.pdf'>Searching in a Maze, in search of knowledge: Issues in early artificial intelligence.</a></span> In O. Stock &amp; M. Schaerf (eds.), <em>Lecture Notes In Computer Science</em>. Springer-Verlag. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Searching%20in%20a%20Maze%2C%20in%20search%20of%20knowledge+author%3ACordeschi&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1096_links")'>More links</a>)</span><div id='_1096_abstract' class='extra' style='font-size:12px;'>Abstract:  Lecture Notes in Artificial Intelligence, vol. 4155, Springer, Berlin-Heidelberg, 2006, pp. 1-23. PDF</div>
<div id='_1096_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("CORSIA",this.href,0);return true;' href="http://www.springerlink.com/index/k151241455035325.pdf">http://www.springerlink.com/index/k151241455035325.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1097_entry' class='entry'><span ><span class='name'>Crosson, Frederick J.</span> (ed.) (1967). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("CROPAC",this.href,0);return true;' href='http://www.questia.com/PM.qst?a=o&amp;docId=72413973'>Philosophy And Cybernetics.</a></span></em></span> Notre Dame: University of Notre Dame Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10613892358786179105'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophy%20And%20Cybernetics+author%3ACrosson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1098_entry' class='entry'><span ><span class='name'>Culbertson, James T.</span> (1963). <em><span class='pub_name'>The Minds Of Robots: Sense Data, Memory Images, And Behavior In Conscious Automata.</span></em></span> Urbana: University Of Illinois Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12805159775297977441'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Minds%20Of%20Robots+author%3ACulbertson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1099_entry' class='entry'><span ><span class='name'>Cummins, Robert E.</span> (ed.) (1991). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("CUMPAA",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=xnd6J2H_Hi4C&amp;oi=fnd&amp;pg=RA2-PA8&amp;sig=ko71PHsanVkskC5bGxzxDXbLICY'>Philosophy and AI.</a></span></em></span> Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8372177967392781482'>Cited by 6</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophy%20and%20AI+author%3ACummins&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1100_entry' class='entry'><span ><span class='name'>Dahlbom, B.</span> (1995). Mind is artificial.</span> In B. Dahlbom (ed.), <em>Dennett and His Critics</em>. Cambridge: Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13691861343927974789'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%20is%20artificial+author%3ADahlbom&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1101_entry' class='entry'><span ><span class='name'>Dreyfus, Hubert L.</span> (1985). <a rel="nofollow" class='article_title' onclick='trackclick("DREFST",this.href,0);return true;' href='http://socrates.berkeley.edu/~hdreyfus/html/paper_socrates.html'>From socrates to expert systems: The limits and dangers of calculative rationality.</a></span> In Carl Mitcham &amp; Alois Huning (eds.), <em>Philosophy and Technology II: Information Technology and Computers in Theory and Practice</em>. Reidel. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5455694581470941821'>Cited by 26</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=From%20socrates%20to%20expert%20systems+author%3ADreyfus&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1101_links")'>More links</a>)</span><div id='_1101_abstract' class='extra' style='font-size:12px;'>Abstract: Actual AI research began auspiciously around 1955 with Allen Newell and Herbert Simon's work at the RAND Corporation. Newell and Simon proved that computers could do more than calculate. They demonstrated that computers were physical symbol systems whose symbols could be made to stand for anything, including features of the real world, and whose programs could be used as rules for relating these features. In this way computers could be used to simulate certain important aspects intelligence. Thus the information-processing model of the mind was born. But, looking back over these fifty years, it seems that theoretical AI with its promise of a robot like HAL appears to be a perfect example of what Imre Lakatos has called a "degenerating research program"</div>
<div id='_1101_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREFST",this.href,0);return true;' href="http://ist-socrates.berkeley.edu/~hdreyfus/html/paper_socrates.html">http://ist-socrates.berkeley.edu/~hdreyfus/html/paper_socrates.html</a><br></div></div>
</div><!--entry-->

<div id='_1102_entry' class='entry'><span ><span class='name'>Drescher, Gary L.</span> (1991). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("DREMMA-2",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=113149'>Made-Up Minds: A Constructivist Approach to Artificial Intelligence.</a></span></em></span> Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10846917001494468972'>Cited by 244</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Made-Up%20Minds+author%3ADrescher&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1102_links")'>More links</a>)</span>
<div id='_1102_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREMMA-2",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=SERIES9797.113149">http://portal.acm.org/citation.cfm?id=SERIES9797.113149</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREMMA-2",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=jYsEzeKHLNUC&amp;oi=fnd&amp;pg=PP13&amp;sig=_ohd54z5t1p8mkp-rhSDpR4rm94">http://books.google.com/books?hl=en&lr=&id=jYsEzeKHLNUC&oi=fnd&pg=PP13&sig=_ohd54z5t1p8mkp-rhSDpR4rm94</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREMMA-2",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=jYsEzeKHLNUC&amp;oi=fnd&amp;pg=PP13&amp;ots=IPMEZ_QevW&amp;sig=SHx5OAD7blCUzbDEiR6GolRpyWg">http://books.google.com/books?hl=en&lr=&id=jYsEzeKHLNUC&oi=fnd&pg=PP13&ots=IPMEZ_QevW&sig=SHx5OAD7blCUzbDEiR6GolRpyWg</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREMMA-2",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=jYsEzeKHLNUC&amp;oi=fnd&amp;pg=PP13&amp;ots=IPMDYXSgpU&amp;sig=ZKziQKs5aXz52ImGfHTiJEf04Jk">http://books.google.com/books?hl=en&lr=&id=jYsEzeKHLNUC&oi=fnd&pg=PP13&ots=IPMDYXSgpU&sig=ZKziQKs5aXz52ImGfHTiJEf04Jk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DREMMA-2",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=jYsEzeKHLNUC&amp;oi=fnd&amp;pg=PP13&amp;ots=IPLG1VPlvX&amp;sig=8dzEHHgqm0WTkRm4QEOtVvsj2EI">http://books.google.com/books?hl=en&lr=&id=jYsEzeKHLNUC&oi=fnd&pg=PP13&ots=IPLG1VPlvX&sig=8dzEHHgqm0WTkRm4QEOtVvsj2EI</a><br></div></div>
</div><!--entry-->

<div id='_1103_entry' class='entry'><span ><span class='name'>Dresher, B. Elan</span> &amp; <span class='name'>Hornstein, Norbert</span> (1976). <a rel="nofollow" class='article_title' onclick='trackclick("DREOSS",this.href,0);return true;' href='http://eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ161384'>On some supposed contributions of artificial intelligence to the scientific study of language.</a></span> <span class='pub_name'>Cognition</span> 4 (December):321-398. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=8210495274742027371'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20some%20supposed%20contributions%20of%20artificial%20intelligence%20to%20the%20scientific%20study%20of%20language+author%3ADresher&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1104_entry' class='entry'><span ><span class='name'>Duch, WÅodzisÅaw</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("DUCWIC",this.href,0);return true;' href='http://cogprints.org/5358/'>What is computational intelligence and where is it going?</a></span> In Wlodzislaw Duch &amp; Jacek Mandziuk (eds.), <em>Challenges for Computational Intelligence</em>. Springer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=What%20is%20computational%20intelligence%20and%20where%20is%20it%20going%3F+author%3ADuch&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1104_links")'>More links</a>)</span><div id='_1104_abstract' class='extra' style='font-size:12px;'>Abstract: What is Computational Intelligence (CI) and what are its relations with Artificial Intelligence (AI)? A brief survey of the scope of CI journals and books with ``computational intelligence'' in their title shows that at present it is an umbrella for three core technologies (neural, fuzzy and evolutionary), their applications, and selected fashionable pattern recognition methods. At present CI has no comprehensive foundations and is more a bag of tricks than a solid branch of science. The change of focus from methods to challenging problems is advocated, with CI defined as a part of computer and engineering sciences devoted to solution of non-algoritmizable problems. In this view AI is a part of CI focused on problems related to higher cognitive functions, while the rest of the CI community works on problems related to perception and control, or lower cognitive functions. Grand challenges on both sides of this spectrum are addressed</div>
<div id='_1104_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("DUCWIC",this.href,0);return true;' href="http://www.springerlink.com/index/k275703555734407.pdf">http://www.springerlink.com/index/k275703555734407.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1105_entry' class='entry'><span ><span class='name'>Epstein, Susan L.</span> (1992). <a rel="nofollow" class='article_title' onclick='trackclick("EPSTRO",this.href,0);return true;' href='http://www.cs.hunter.cuny.edu/~epstein/papers/mm_92.ps'>The role of memory and concepts in learning.</a></span> <span class='pub_name'>Minds and Machines</span> 2 (3). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10420620660488975818'>Cited by 10</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20role%20of%20memory%20and%20concepts%20in%20learning+author%3AEpstein&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1105_links")'>More links</a>)</span><div id='_1105_abstract' class='extra' style='font-size:12px;'>Abstract: The extent to which concepts, memory, and planning are necessary to the simulation of intelligent behavior is a fundamental philosophical issue in Artificial Intelligence. An active and productive segement of the AI community has taken the position that multiple low-level agents, properly organized, can account for high-level behavior. Empirical research on these questions with fully operational systems has been restricted to mobile robots that do simple tasks. This paper recounts experiments with Hoyle, a system in a cerebral, rather than a physical, domain. The program learns to perform well and quickly, often outpacing its human creators at two-person, perfect information board games. Hoyle demonstrates that a surprising amount of intelligent behavior can be treated as if it were situation-determined, that often planning is unnecessary, and that the memory required to support this learning is minimal. Concepts, however, are crucial to this reactive program's ability to learn and perform</div>
<div id='_1105_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EPSTRO",this.href,0);return true;' href="http://www.springerlink.com/content/q764210h47533476/fulltext.pdf">http://www.springerlink.com/content/q764210h47533476/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("EPSTRO",this.href,0);return true;' href="http://www.springerlink.com/index/Q764210H47533476.pdf">http://www.springerlink.com/index/Q764210H47533476.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1106_entry' class='entry'><span ><span class='name'>Fetzer, James H.</span> (1990). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("FETAII",this.href,0);return true;' href='http://books.google.com/books?id=bdHIZ1m98j4C&amp;printsec=front_cover'>Artificial Intelligence: Its Scope and Limits.</a></span></em></span> Kluwer. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5042957729903468633'>Cited by 35</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Intelligence+author%3AFetzer&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1106_links")'>More links</a>)</span>
<div id='_1106_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FETAII",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=533526">http://portal.acm.org/citation.cfm?id=533526</a><br></div></div>
</div><!--entry-->

<div id='_1107_entry' class='entry'><span ><span class='name'>Franchi, Stefano</span> &amp; <span class='name'>Guzeldere, Guven</span> (1995). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("FRACOT",this.href,0);return true;' href='http://www.stanford.edu/group/SHR/4-2/text/toc.html'>Constructions of the Mind: Artificial Intelligence and the Humanities.</a></span></em></span> Stanford Humanities Review. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Constructions%20of%20the%20Mind+author%3AFranchi&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1108_entry' class='entry'><span ><span class='name'>Froese, Tom</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("FROOTR",this.href,0);return true;' href='http://cogprints.org/5778/1/Froese2007.pdf'>On the role of AI in the ongoing paradigm shift within the cognitive sciences.</a></span> In M. Lungarella (ed.), <em>50 Years of AI</em>. Springer-Verlag. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=On%20the%20role%20of%20AI%20in%20the%20ongoing%20paradigm%20shift%20within%20the%20cognitive%20sciences+author%3AFroese&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1108_links")'>More links</a>)</span><div id='_1108_abstract' class='extra' style='font-size:12px;'>Abstract: This paper supports the view that the ongoing shift from orthodox to embodied-embedded cognitive science has been significantly influenced by the experimental results generated by AI research. Recently, there has also been a noticeable shift toward enactivism, a paradigm which radicalizes the embodied-embedded approach by placing autonomous agency and lived subjectivity at the heart of cognitive science. Some first steps toward a clarification of the relationship of AI to this further shift are outlined. It is concluded that the success of enactivism in establishing itself as a mainstream cognitive science research program will depend less on progress made in AI research and more on the development of a phenomenological pragmatics</div>
<div id='_1108_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("FROOTR",this.href,0);return true;' href="http://froese.files.wordpress.com/2007/06/on-the-role-of-ai-in-the-ongoing-paradigm-shift.pdf">http://froese.files.wordpress.com/2007/06/on-the-role-of-ai-in-the-ongoing-paradigm-shift.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1109_entry' class='entry'><span ><span class='name'>Hall, John Storrs</span> (forthcoming). <a rel="nofollow" class='article_title' onclick='trackclick("HALSAA",this.href,0);return true;' href='http://www.springerlink.com/content/0n70u4l8q7235840/fulltext.pdf'>Self-improving AI: An analysis.</a></span> <span class='pub_name'>Minds and Machines</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Self-improving%20AI+author%3AHall&amp;btnG=Search'>Google</a>)</span><div id='_1109_abstract' class='extra' style='font-size:12px;'>Abstract:  Self-improvement was one of the aspects of AI proposed for study in the 1956 Dartmouth conference. Turing proposed a âchild machineâ which could be taught in the human manner to attain adult human-level intelligence. In latter days, the contention that an AI system could be built to learn and improve itself indefinitely has acquired the label of the bootstrap fallacy. Attempts in AI to implement such a system have met with consistent failure for half a century. Technological optimists, however, have maintained that a such system is possible, producing, if implemented, a feedback loop that would lead to a rapid exponential increase in intelligence. We examine the arguments for both positions and draw some conclusions</div>
</div><!--entry-->

<div id='_1110_entry' class='entry'><span ><span class='name'>Haugeland, John</span> (1985). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HAUAIT",this.href,0);return true;' href='http://books.google.com/books?id=zLFSPdIuqKsC&amp;printsec=front_cover'>Artificial Intelligence: The Very Idea.</a></span></em></span> Cambridge: Mit Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15327454879512919257'>Cited by 404</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Intelligence+author%3AHaugeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1110_links")'>More links</a>)</span><div id='_1110_abstract' class='extra' style='font-size:12px;'>Abstract: The idea that human thinking and machine computing are &quot;radically the same&quot; provides the central theme for this marvelously lucid and witty book on...</div>
<div id='_1110_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUAIT",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?doid=4694">http://portal.acm.org/citation.cfm?doid=4694</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUAIT",this.href,0);return true;' href="http://www.reiters.com/index.cgi?ISBN=0262580950&amp;f=p">http://www.reiters.com/index.cgi?ISBN=0262580950&f=p</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUAIT",this.href,0);return true;' href="http://www.cs.bilkent.edu.tr/~akman/book-revs/sigart/sigart1998.pdf">http://www.cs.bilkent.edu.tr/~akman/book-revs/sigart/sigart1998.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1111_entry' class='entry'><span ><span class='name'>Haugeland, John</span> (ed.) (1981). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HAUMD",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=42462'>Mind Design.</a></span></em></span> MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=58389722615649726'>Cited by 122</a> | <span class='ll' onclick='$("_1111_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%20Design+author%3AHaugeland&amp;btnG=Search'>Google</a>)</span><div id='_1111_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>12 papers on the foundations of AI and cognitive science.</div></div>
</div><!--entry-->

<div id='_1112_entry' class='entry'><span ><span class='name'>Haugeland, John</span> (ed.) (1997). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HAUMDI",this.href,0);return true;' href='http://books.google.com/books?id=TIC1mzIQZMIC&amp;printsec=front_cover'>Mind Design II: Philosophy, Psychology, Artificial Intelligence.</a></span></em></span> Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6215975871688007480'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Mind%20Design%20II+author%3AHaugeland&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1112_links")'>More links</a>)</span><div id='_1112_abstract' class='extra' style='font-size:12px;'>Abstract: Contributors: Rodney A. Brooks, Paul M. Churchland, Andy Clark, Daniel C. Dennett, Hubert L. Dreyfus, Jerry A. Fodor, Joseph Garon, John Haugeland, Marvin...</div>
<div id='_1112_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUMDI",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=548831">http://portal.acm.org/citation.cfm?id=548831</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAUMDI",this.href,0);return true;' href="http://cogprints.ecs.soton.ac.uk/archive/00000539/00/md2.ps">http://cogprints.ecs.soton.ac.uk/archive/00000539/00/md2.ps</a><br></div></div>
</div><!--entry-->

<div id='_1113_entry' class='entry'><span ><span class='name'>Hayes, Patrick J.</span>; <span class='name'>Ford, Kenneth M.</span> &amp; <span class='name'>Adams-Webber, J. R.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("HAYHRA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=161071.161073'>Human reasoning about artificial intelligence.</a></span> <span class='pub_name'>Journal of Experimental and Theoretical Artificial Intelligence</span> 4:247-63. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13021694606277770121'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Human%20reasoning%20about%20artificial%20intelligence+author%3AHayes&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1113_links")'>More links</a>)</span>
<div id='_1113_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("HAYHRA",this.href,0);return true;' href="http://www.informaworld.com/index/777592360.pdf">http://www.informaworld.com/index/777592360.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1114_entry' class='entry'><span ><span class='name'>Hookway, Christopher</span> (ed.) (1984). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("HOOMMA",this.href,0);return true;' href='http://orton.catie.ac.cr/cgi-bin/wxis.exe/?IsisScript=LIBRO.xis&amp;method=post&amp;formato=2&amp;cantidad=1&amp;expresion=mfn=005009'>Minds, Machines And Evolution.</a></span></em></span> Cambridge: Cambridge University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14650036352033186534'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%2C%20Machines%20And%20Evolution+author%3AHookway&amp;btnG=Search'>Google</a>)</span><div id='_1114_abstract' class='extra' style='font-size:12px;'>Abstract: This is a volume of original essays written by philosophers and scientists and dealing with philosophical questions arising from work in evolutionary biology and artificial intelligence. In recent years both of these areas have been the focus for attempts to provide a scientific, model of a wide range of human capacities - most prominently perhaps in sociobiology and cognitive psychology. The book therefore examines a number of issues related to the search for a 'naturalistic' or scientific account of human experience and behaviour. Some of the essays deal with the application of such models to particular behaviour, stressing the problems raised by consciousness, and the information to be derived from the differing capacities of animals and people; others consider more general questions about the logic of the explanations provided by these kinds of approach. The volume continues the informal series stemming from meetings sponsored by the Thyssen Foundation</div>
</div><!--entry-->

<div id='_1115_entry' class='entry'><span ><span class='name'>Jaki, Stanley L.</span> (1969). <em><span class='pub_name'>Brain, Mind And Computers.</span></em></span> Herder & Herder. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=14317373698214360771'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Brain%2C%20Mind%20And%20Computers+author%3AJaki&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1116_entry' class='entry'><span ><span class='name'>Keeley, Brian L.</span> (1994). <a rel="nofollow" class='article_title' onclick='trackclick("KEEATG",this.href,0);return true;' href='http://mugwump.pitzer.edu/~bkeeley/work/PUBS/agr/AGR_pap.htm'>Against the global replacement: On the application of the philosophy of artificial intelligence to artificial life.</a></span> In C.G. Langton (ed.), <em>Artificial Life III: Proceedings of the Workshop on Artificial Life</em>. Reading, Mass: Addison-Wesley. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11477817309522360491'>Cited by 11</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Against%20the%20global%20replacement+author%3AKeeley&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1117_entry' class='entry'><span ><span class='name'>Krellenstein, Marc F.</span> (1987). A reply to parallel computation and the mind-body problem.</span> <span class='pub_name'>Cognitive Science</span> 11:155-7. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7122297930704377683'>Cited by 3</a> | <span class='ll' onclick='$("_1117_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20reply%20to%20parallel%20computation%20and%20the%20mind-body%20problem+author%3AKrellenstein&amp;btnG=Search'>Google</a>)</span><div id='_1117_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Thagard 1986 is wrong: speed and the like make no fundamental difference. With Thagard's reply: it makes a difference in practice, if not in principle.</div></div>
</div><!--entry-->

<div id='_1118_entry' class='entry'><span ><span class='name'>McDermott, Drew</span> (1997). <a rel="nofollow" class='article_title' onclick='trackclick("MCDHII",this.href,0);return true;' href='http://www.nyu.edu/gsas/dept/philo/courses/mindsandmachines/Papers/mcdermott.html'>How intelligent is deep blue?</a></span> <span class='pub_name'>New York Times (May)</span> 14. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1245997611848172782'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=How%20intelligent%20is%20deep%20blue%3F+author%3AMcDermott&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1119_entry' class='entry'><span ><span class='name'>Minsky, Marvin L.</span> (1986). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("MINTSO",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=22939'>The Society Of Mind.</a></span></em></span> Simon & Schuster. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10492785087636788215'>Cited by 2409</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Society%20Of%20Mind+author%3AMinsky&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1119_links")'>More links</a>)</span>
<div id='_1119_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("MINTSO",this.href,0);return true;' href="http://www.reiters.com/index.cgi?ISBN=0671657135&amp;f=p">http://www.reiters.com/index.cgi?ISBN=0671657135&f=p</a><br></div></div>
</div><!--entry-->

<div id='_1120_entry' class='entry'><span ><span class='name'>Moor, James H.</span> (1998). <a rel="nofollow" class='article_title' onclick='trackclick("MOOAAI",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=oXmTuWBOn_AC&amp;oi=fnd&amp;pg=PA213&amp;dq=Assessing+artificial+intelligence+and+its+critics+Moor&amp;ots=OZPA1z-yT5&amp;sig=a6eYl_HWeuk8dLdeuTCxo56KhSs'>Assessing artificial intelligence and its critics.</a></span> In T.W. Bynum &amp;  Moor. J. (eds.), <em>The Digital Phoenix</em>. Cambridge: Blackwell. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5562603257312843646'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Assessing%20artificial%20intelligence%20and%20its%20critics+author%3AMoor&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1121_entry' class='entry'><span ><span class='name'>Moody, Todd C.</span> (1993). <em><span class='pub_name'>Philosophy and Artificial Intelligence.</span></em></span> Prentice-Hall. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7446974367781058661'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophy%20and%20Artificial%20Intelligence+author%3AMoody&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1122_entry' class='entry'><span ><span class='name'>Neumaier, Otto</span> (1987). A Wittgensteinian view of artificial intelligence.</span> In <em>Artificial Intelligence</em>. St Martin's Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13525177540903672490'>Cited by 1</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20Wittgensteinian%20view%20of%20artificial%20intelligence+author%3ANeumaier&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1123_entry' class='entry'><span ><span class='name'>Pollock, John</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("POLOAC",this.href,0);return true;' href='http://oscarhome.soc-sci.arizona.edu/ftp/MANUAL/manual1.ps'>Oscar: A cognitive architecture for intelligent agents.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Oscar+author%3APollock&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1123_links")'>More links</a>)</span><div id='_1123_abstract' class='extra' style='font-size:12px;'>Abstract:  The âgrand problemâ of AI has always been to build artificial agents of human-level intelligence, capable of operating in environments of real-world complexity. OSCAR is a cognitive architecture for such agents, implemented in LISP. OSCAR is based on my extensive work in philosophy concerning both epistemology and rational decision making. This paper provides a detailed overview of OSCAR. The main conclusions are that such agents must be capablew of operating against a background of pervasive ignorance, because the real world is too complex for them to know more than a small fraction of what is true. This is handled by giving the agent the power to reason defeasibily. The OSCAR system of defeasible reasoning is sketched. It is argued that if epistemic cognition must be defeasible, planning must also be done defeasibly, and the best way to do that is to reason defeasibly about plans. A sketch is given about how this might work</div>
<div id='_1123_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLOAC",this.href,0);return true;' href="http://oscarhome.soc-sci.arizona.edu/ftp/PAPERS/OSCAR architecture.pdf">http://oscarhome.soc-sci.arizona.edu/ftp/PAPERS/OSCAR architecture.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1124_entry' class='entry'><span ><span class='name'>Pollock, John L.</span> (1990). <a rel="nofollow" class='article_title' onclick='trackclick("POLPAA",this.href,0);return true;' href='http://www.jstor.org/sici?sici=1520-8583(1990)4&lt;461:PAAI&gt;2.0.CO;2-B'>Philosophy and artificial intelligence.</a></span> <span class='pub_name'>Philosophical Perspectives</span> 4:461-498. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophy%20and%20artificial%20intelligence+author%3APollock&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1124_links")'>More links</a>)</span>
<div id='_1124_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLPAA",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/2214201.pdf">http://www.jstor.org/stable/pdfplus/2214201.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1125_entry' class='entry'><span ><span class='name'>Pollock, John L.</span> (1999). <a rel="nofollow" class='article_title' onclick='trackclick("POLRCI",this.href,0);return true;' href='http://citeseer.ist.psu.edu/519649.html'>Rational cognition in Oscar.</a></span> <span class='pub_name'>Agent Theories</span>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12989177505104534650'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rational%20cognition%20in%20Oscar+author%3APollock&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1125_links")'>More links</a>)</span><div id='_1125_abstract' class='extra' style='font-size:12px;'>Abstract: Stuart Russell [14] describes rational agents as --Åthose that do the right thing--ï¿½. The problem of designing a rational agent then becomes the problem of figuring out what the right thing is. There are two approaches to the latter problem, depending upon the kind of agent we want to build. On the one hand, anthropomorphic agents are those that can help human beings rather directly in their intellectual endeavors. These endeavors consist of decision making and data processing. An agent that can help humans in these enterprises must make decisions and draw conclusions that are rational by human standards of rationality. Anthropomorphic agents can be contrasted with goal-oriented agents --â those that can carry out certain narrowly-defined tasks in the world. Here the objective is to get the job done, and it makes little difference how the agent achieves its design goal</div>
<div id='_1125_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRCI",this.href,0);return true;' href="http://citeseer.ist.psu.edu/246569.html">http://citeseer.ist.psu.edu/246569.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRCI",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=749598">http://portal.acm.org/citation.cfm?id=749598</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRCI",this.href,0);return true;' href="http://oscarhome.soc-sci.arizona.edu/ftp/PAPERS/Rational Cognition in OSCAR.ps">http://oscarhome.soc-sci.arizona.edu/ftp/PAPERS/Rational Cognition in OSCAR.ps</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRCI",this.href,0);return true;' href="http://oscarhome.soc-sci.arizona.edu/ftp/OSCAR-web-page/PAPERS/Rational-Cognition-in-OSCAR.pdf">http://oscarhome.soc-sci.arizona.edu/ftp/OSCAR-web-page/PAPERS/Rational-Cognition-in-OSCAR.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRCI",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=pxKPVyzPFEMC&amp;oi=fnd&amp;pg=PA71&amp;ots=RQ2LB5zx9I&amp;sig=evRmQuZSv9eq2Wxij231iMjAfzA">http://books.google.com/books?hl=en&lr=&id=pxKPVyzPFEMC&oi=fnd&pg=PA71&ots=RQ2LB5zx9I&sig=evRmQuZSv9eq2Wxij231iMjAfzA</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("POLRCI",this.href,0);return true;' href="http://www.springerlink.com/index/a7r273h735877q41.pdf">http://www.springerlink.com/index/a7r273h735877q41.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1126_entry' class='entry'><span ><span class='name'>Pollock, John L.</span> (2000). Rationality in philosophy and artificial intelligence.</span> In <em>The Proceedings of the Twentieth World Congress of Philosophy, Volume 9: Philosophy of Mind</em>. Charlottesville: Philosophy Doc Ctr. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rationality%20in%20philosophy%20and%20artificial%20intelligence+author%3APollock&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1127_entry' class='entry'><span ><span class='name'>Pollock, John L.</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("POLTOP",this.href,0);return true;' href='http://oscarhome.soc-sci.arizona.edu/ftp/OSCAR-web-page/oscar.html'>The Oscar project.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Oscar%20project+author%3APollock&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1128_entry' class='entry'><span ><span class='name'>Preston, Beth</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("PREAA",this.href,0);return true;' href='http://www.springerlink.com/content/n6j5022705t2r86x/fulltext.pdf'>Anthropocentrism, and the evolution of 'intelligence'.</a></span> <span class='pub_name'>Minds and Machines</span> 1 (3):259-277. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=15347617618741449138'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Anthropocentrism%2C%20and%20the%20evolution%20of%20%27intelligence%27+author%3APreston&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1128_links")'>More links</a>)</span><div id='_1128_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â Intuitive conceptions guide practice, but practice reciprocally reshapes intuition. The intuitive conception of intelligence in AI was originally highly anthropocentric. However, the internal dynamics of AI research have resulted in a divergence from anthropocentric concerns. In particular, the increasing emphasis on commonsense knowledge and peripheral intelligence (perception and movement) in effect constitutes an incipient reorientation of intuitions about the nature of intelligence in a non-anthropocentric direction. I argue that this conceptual shift undermines Joseph Weizenbaum's claim that the project of artificial intelligence is inherently dehumanizing</div>
<div id='_1128_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PREAA",this.href,0);return true;' href="http://www.springerlink.com/index/N6J5022705T2R86X.pdf">http://www.springerlink.com/index/N6J5022705T2R86X.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1129_entry' class='entry'><span ><span class='name'>Puccetti, Roland</span> (1974). <a rel="nofollow" class='article_title' onclick='trackclick("PUCPRI",this.href,0);return true;' href='http://links.jstor.org/sici?sici=0007-0882(197406)25:2&lt;137:PRICAT&gt;2.0.CO;2-T'>Pattern recognition in computers and the human brain:: With special application to chess playing machines.</a></span> <span class='pub_name'>British Journal for the Philosophy of Science</span> 25 (2):137-154. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10338400754404720710'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Pattern%20recognition%20in%20computers%20and%20the%20human%20brain+author%3APuccetti&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1129_links")'>More links</a>)</span><div id='_1129_abstract' class='extra' style='font-size:12px;'>Abstract: 1 Matching Templates and Feature Analysers. 2 Modes of Perception in Left and Right Cerebral Hemispheres. 3 Identification and Recognition. 4 Chess Plying Machines</div>
<div id='_1129_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUCPRI",this.href,0);return true;' href="http://www.jstor.org/sici?sici=0007-0882(197406)25:2&lt;137:PRICAT&gt;2.0.CO;2-T">http://www.jstor.org/sici?sici=0007-0882(197406)25:2<137:PRICAT>2.0.CO;2-T</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUCPRI",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/content/abstract/25/2/137">http://bjps.oxfordjournals.org/cgi/content/abstract/25/2/137</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUCPRI",this.href,0);return true;' href="http://bjps.oxfordjournals.org/cgi/reprint/25/2/137">http://bjps.oxfordjournals.org/cgi/reprint/25/2/137</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("PUCPRI",this.href,0);return true;' href="http://www.jstor.org/stable/pdfplus/686818.pdf">http://www.jstor.org/stable/pdfplus/686818.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1130_entry' class='entry'><span ><span class='name'>Robinson, William S.</span> (1992). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("ROBCMA",this.href,0);return true;' href='http://www.lavoisier.fr/notice/frOGO3SO6X2XSXAR.html'>Computers, Minds, and Robots.</a></span></em></span> Temple University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7512699379303316720'>Cited by 8</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Computers%2C%20Minds%2C%20and%20Robots+author%3ARobinson&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1131_entry' class='entry'><span ><span class='name'>Russell, S.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("RUSILB",this.href,0);return true;' href='http://www.springerlink.com/content/q5162t97787411g7/fulltext.pdf'>Inductive learning by machines.</a></span> <span class='pub_name'>Philosophical Studies</span> 64 (October):37-64. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=11295252905319491442'>Cited by 6</a> | <span class='ll' onclick='$("_1131_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Inductive%20learning%20by%20machines+author%3ARussell&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1131_links")'>More links</a>)</span><div id='_1131_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A nice paper on the relationship between techniques of theory formation from machine learning and philosophical problems of induction and knowledge.</div></div>
<div id='_1131_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("RUSILB",this.href,0);return true;' href="http://www.springerlink.com/index/Q5162T97787411G7.pdf">http://www.springerlink.com/index/Q5162T97787411G7.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1132_entry' class='entry'><span ><span class='name'>Rychlak, Joseph F.</span> (1991). <em><span class='pub_name'>Artificial Intelligence and Human Reason: A Teleological Critique.</span></em></span> Columbia University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=10996580810497686462'>Cited by 13</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Intelligence%20and%20Human%20Reason+author%3ARychlak&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1133_entry' class='entry'><span ><span class='name'>Schiaffonati, Viola</span> (2003). <a rel="nofollow" class='article_title' onclick='trackclick("SCHAFF",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=947737.947758'>A framework for the foundation of the philosophy of artificial intelligence.</a></span> <span class='pub_name'>Minds and Machines</span> 13 (4):537-552. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=A%20framework%20for%20the%20foundation%20of%20the%20philosophy%20of%20artificial%20intelligence+author%3ASchiaffonati&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1133_links")'>More links</a>)</span><div id='_1133_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â The peculiarity of the relationship between philosophy and Artificial Intelligence (AI) has been evidenced since the advent of AI. This paper aims to put the basis of an extended and well founded philosophy of AI: it delineates a multi-layered general framework to which different contributions in the field may be traced back. The core point is to underline how in the same scenario both the role of philosophy on AI and role of AI on philosophy must be considered. Moreover, this framework is revised and extended in the light of the consideration of a type of multiagent system devoted to afford the issue of scientific discovery both from a conceptual and from a practical point of view</div>
<div id='_1133_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHAFF",this.href,0);return true;' href="http://www.cse.buffalo.edu/~rapaport/Papers/Papers.by.Others/mm.viola.pdf">http://www.cse.buffalo.edu/~rapaport/Papers/Papers.by.Others/mm.viola.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHAFF",this.href,0);return true;' href="http://www.springerlink.com/content/tun11774g3434j44/fulltext.pdf">http://www.springerlink.com/content/tun11774g3434j44/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHAFF",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5142084&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5142084&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHAFF",this.href,0);return true;' href="http://www.springerlink.com/index/TUN11774G3434J44.pdf">http://www.springerlink.com/index/TUN11774G3434J44.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SCHAFF",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000004/05142084">http://www.ingentaconnect.com/content/klu/mind/2003/00000013/00000004/05142084</a><br></div></div>
</div><!--entry-->

<div id='_1134_entry' class='entry'><span ><span class='name'>Simon, Herbert A.</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("SIMMAM",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=216042'>Machine as mind.</a></span> In <em>Android Epistemology</em>. Cambridge: MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=1277897401660273657'>Cited by 9</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Machine%20as%20mind+author%3ASimon&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1134_links")'>More links</a>)</span>
<div id='_1134_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SIMMAM",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=216350.216358">http://portal.acm.org/citation.cfm?id=216350.216358</a><br></div></div>
</div><!--entry-->

<div id='_1135_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> (1978). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("SLOTCR",this.href,0);return true;' href='http://www.cs.bham.ac.uk/research/projects/cogaff/crp/'>The Computer Revolution in Philosophy: Philosophy Science and Models of Mind.</a></span></em></span> Harvester. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7269468384742713263'>Cited by 87</a> | <span class='ll' onclick='$("_1135_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Computer%20Revolution%20in%20Philosophy+author%3ASloman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1135_links")'>More links</a>)</span><div id='_1135_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>All about how the computer should change the way we think about the mind.</div></div><div id='_1135_abstract' class='extra' style='font-size:12px;'>Abstract: Since 1991 the author has been Professor of Artificial Intelligence and Cognitive Science in the School of Computer Science at the University of Birmingham, UK</div>
<div id='_1135_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTCR",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/projects/cogaff/crp/crp.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/crp/crp.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTCR",this.href,0);return true;' href="http://www.cs.bham.ac.uk/research/projects/cogaff/crp/titlepage.pdf">http://www.cs.bham.ac.uk/research/projects/cogaff/crp/titlepage.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTCR",this.href,0);return true;' href="http://www.ams.org/bull/1980-02-02/S0273-0979-1980-14750-3/home.html">http://www.ams.org/bull/1980-02-02/S0273-0979-1980-14750-3/home.html</a><br></div></div>
</div><!--entry-->

<div id='_1136_entry' class='entry'><span ><span class='name'>Sloman, Aaron</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("SLOTIO-2",this.href,0);return true;' href='http://books.google.com/books?hl=en&amp;lr=&amp;id=Y59zyNWnNfYC&amp;oi=fnd&amp;pg=PA87&amp;ots=BHZ5DmbOPb&amp;sig=xqJcA6FDwc1qKb0WY_uWGIg05PA'>The irrelevance of Turing machines to artificial intelligence.</a></span> In Matthias Scheutz (ed.), <em>Computationalism: New Directions</em>. MIT Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=13005649647608594555'>Cited by 18</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20irrelevance%20of%20Turing%20machines%20to%20artificial%20intelligence+author%3ASloman&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1136_links")'>More links</a>)</span>
<div id='_1136_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SLOTIO-2",this.href,0);return true;' href="http://lib.org.by/_djvu/Cs_Computer science/CsAi_AI, knowledge/Scheutz M. (ed.) Computationalism (MIT, 2002)(223s).pdf#page=101">http://lib.org.by/_djvu/Cs_Computer science/CsAi_AI, knowledge/Scheutz M. (ed.) Computationalism (MIT, 2002)(223s).pdf#page=101</a><br></div></div>
</div><!--entry-->

<div id='_1137_entry' class='entry'><span ><span class='name'>Sluckin, W.</span> (1954). <em><span class='pub_name'>Minds And Machines.</span></em></span> London,: Penguin,. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5256122154587744718'>Cited by 16</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Minds%20And%20Machines+author%3ASluckin&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1138_entry' class='entry'><span ><span class='name'>Sparrow, Robert</span> (2002). <a rel="nofollow" class='article_title' onclick='trackclick("SPATMO",this.href,0);return true;' href='http://eprints.unimelb.edu.au/archive/00000138/'>The March of the robot dogs.</a></span> <span class='pub_name'>Ethics and Information Technology</span> 4 (4):305-318. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=6396759246477223133'>Cited by 3</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20March%20of%20the%20robot%20dogs+author%3ASparrow&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1138_links")'>More links</a>)</span><div id='_1138_abstract' class='extra' style='font-size:12px;'>Abstract: The Centre for Applied Philosophy and Public Ethics (CAPPE) was established in 2000 as a Special Research Centre in applied philosophy funded by the Australian Research Council. It has combined the complementary strengths of two existing centres specialising in applied philosophy, namely the Centre for Philosophy and Public Issues (CPPI) at the University of Melbourne and the Centre for Professional and Applied Ethics at Charles Sturt University. It operates as a unified centre with two divisions: in Melbourne at the University of Melbourne and in Canberra at Charles Sturt University. The Director of CAPPE and the head of the Canberra node is Professor Seumas Miller. Professor C.A.J. (Tony) Coady is the Deputy Director of CAPPE and the head of the Melbourne node</div>
<div id='_1138_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://www.cs.pitt.edu/~bigrigg/cs1590/sparrow.pdf">http://www.cs.pitt.edu/~bigrigg/cs1590/sparrow.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://www.cs.cmu.edu/~social/reading/Sparrow1.pdf">http://www.cs.cmu.edu/~social/reading/Sparrow1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=607976.607992">http://portal.acm.org/citation.cfm?id=607976.607992</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://www-2.cs.cmu.edu/~social/reading/Sparrow1.pdf">http://www-2.cs.cmu.edu/~social/reading/Sparrow1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://eprints.infodiv.unimelb.edu.au/archive/00000138">http://eprints.infodiv.unimelb.edu.au/archive/00000138</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://eprints.unimelb.edu.au/archive/00000138/01/Sparrow1.pdf">http://eprints.unimelb.edu.au/archive/00000138/01/Sparrow1.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://www.springerlink.com/content/lu2520h1307q6772/fulltext.pdf">http://www.springerlink.com/content/lu2520h1307q6772/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://www.kluweronline.com/article.asp?PIPS=5111338&amp;PDF=1">http://www.kluweronline.com/article.asp?PIPS=5111338&PDF=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://www.springerlink.com/index/LU2520H1307Q6772.pdf">http://www.springerlink.com/index/LU2520H1307Q6772.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("SPATMO",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/etin/2002/00000004/00000004/05111338">http://www.ingentaconnect.com/content/klu/etin/2002/00000004/00000004/05111338</a><br></div></div>
</div><!--entry-->

<div id='_1139_entry' class='entry'><span ><span class='name'>Storrs Hall, J.</span> (2006). Nano-enabled AI: Some philosophical issues.</span> <span class='pub_name'>International Journal of Applied Philosophy</span> 20 (2):247-261. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Nano-enabled%20AI+author%3AStorrs%20Hall&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1140_entry' class='entry'><span ><span class='name'>Thagard, Paul R.</span> (1991). <a rel="nofollow" class='article_title' onclick='trackclick("THAPAC",this.href,0);return true;' href='http://www.springerlink.com/content/r8426372x18u8666/fulltext.pdf'>Philosophical and computational models of explanation.</a></span> <span class='pub_name'>Philosophical Studies</span> 64 (October):87-104. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17440184935281873623'>Cited by 4</a> | <span class='ll' onclick='$("_1140_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophical%20and%20computational%20models%20of%20explanation+author%3AThagard&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1140_links")'>More links</a>)</span><div id='_1140_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>A comparison of philosophical and AI approaches to explanation: deductive, statistical, schematic, analogical, causal, and linguistic.</div></div>
<div id='_1140_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THAPAC",this.href,0);return true;' href="http://www.springerlink.com/index/R8426372X18U8666.pdf">http://www.springerlink.com/index/R8426372X18U8666.pdf</a><br></div></div>
</div><!--entry-->

<div id='_1141_entry' class='entry'><span ><span class='name'>Thagard, Paul R.</span> (1990). Philosophy and machine learning.</span> <span class='pub_name'>Canadian Journal of Philosophy</span> 20 (2):261-76. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7679333225957884668'>Cited by 2</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Philosophy%20and%20machine%20learning+author%3AThagard&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1142_entry' class='entry'><span ><span class='name'>Thagard, Paul R.</span> (1986). <a rel="nofollow" class='article_title' onclick='trackclick("THAPCA",this.href,0);return true;' href='http://www.leaonline.com/doi/abs/10.1207/s15516709cog1003_3'>Parallel computation and the mind-body problem.</a></span> <span class='pub_name'>Cognitive Science</span> 10:301-18. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=7382857641496033305'>Cited by 28</a> | <span class='ll' onclick='$("_1142_notes").show()'>Annotation</span> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Parallel%20computation%20and%20the%20mind-body%20problem+author%3AThagard&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1142_links")'>More links</a>)</span><div id='_1142_notes' class='extra' style='display:none;font-size:smaller'><br><br><div>Parallelism does make a difference. Some somewhat anti-functionalist points.</div></div>
<div id='_1142_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THAPCA",this.href,0);return true;' href="http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog1003_3">http://www.leaonline.com/doi/pdfplus/10.1207/s15516709cog1003_3</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THAPCA",this.href,0);return true;' href="http://www.cogsci.rpi.edu/CSJarchive/1986v10/i03/p0301p0318/MAIN.PDF">http://www.cogsci.rpi.edu/CSJarchive/1986v10/i03/p0301p0318/MAIN.PDF</a><br></div></div>
</div><!--entry-->

<div id='_1143_entry' class='entry'><span ><span class='name'>ThÃ³risson, Kristinn R.</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("THRIAS",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=1285561.1285575'>Integrated A.I. Systems.</a></span> <span class='pub_name'>Minds and Machines</span> 17 (1). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Integrated%20A.I.%20Systems+author%3ATh%C3%B3risson&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1143_links")'>More links</a>)</span><div id='_1143_abstract' class='extra' style='font-size:12px;'>Abstract: The broad range of capabilities exhibited by humans and animals is achieved through a large set of heterogeneous, tightly integrated cognitive mechanisms. To move artificial systems closer to such general-purpose intelligence we cannot avoid replicating some subsetâquite possibly a substantial portionâof this large set. Progress in this direction requires that systems integration be taken more seriously as a fundamental research problem. In this paper I make the argument that intelligence must be studied holistically. I present key issues that must be addressed in the area of integration and propose solutions for speeding up rate of progress towards more powerful, integrated A.I. systems, including (a) tools for building large, complex architectures, (b) a design methodology for building realtime A.I. systems and (c) methods for facilitating code sharing at the community level</div>
<div id='_1143_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THRIAS",this.href,0);return true;' href="http://www.springerlink.com/content/y04485h9j3u8x431/fulltext.pdf">http://www.springerlink.com/content/y04485h9j3u8x431/fulltext.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THRIAS",this.href,0);return true;' href="http://www.springerlink.com/index/Y04485H9J3U8X431.pdf">http://www.springerlink.com/index/Y04485H9J3U8X431.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("THRIAS",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/mind/2007/00000017/00000001/00009055">http://www.ingentaconnect.com/content/klu/mind/2007/00000017/00000001/00009055</a><br></div></div>
</div><!--entry-->

<div id='_1144_entry' class='entry'><span ><span class='name'>Torrance, Steven</span> (ed.) (1984). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("TORTMA",this.href,0);return true;' href='http://www.osti.gov/energycitations/product.biblio.jsp?osti_id=6486571'>The Mind And The Machine: Philosophical Aspects Of Artificial Intelligence.</a></span></em></span> Chichester: Horwood. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=3453329014739846927'>Cited by 12</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Mind%20And%20The%20Machine+author%3ATorrance&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1145_entry' class='entry'><span ><span class='name'>Hauser, Larry</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("UNKAI",this.href,0);return true;' href='http://www.iep.utm.edu/a/art-inte.htm'>Artificial intelligence.</a></span> <em>Internet Encyclopedia of Philosophy</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20intelligence+author%3AHauser&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1146_entry' class='entry'><span ><span class='name'>van Gelder, Tim</span> (1998). Into the deep blue yonder.</span> <span class='pub_name'>Quadrant</span> 42:33-39. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Into%20the%20deep%20blue%20yonder+author%3Avan%20Gelder&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1147_entry' class='entry'><span ><span class='name'>Vinge, Vernor</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("VINTTS",this.href,0);return true;' href='http://wholeearth.com/ArticleBin/111-3.pdf'>The technological singularity.</a></span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=5611128554145293913'>Cited by 43</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20technological%20singularity+author%3AVinge&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1147_links")'>More links</a>)</span>
<div id='_1147_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://wholeearthmag.com/ArticleBin/111-3.pdf">http://wholeearthmag.com/ArticleBin/111-3.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://adsabs.harvard.edu/abs/1993vise.nasa...11V">http://adsabs.harvard.edu/abs/1993vise.nasa...11V</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.aleph.se/Trans/Global/Singularity/sing.html">http://www.aleph.se/Trans/Global/Singularity/sing.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.cs.ucsd.edu/users/goguen/misc/singularity.html">http://www.cs.ucsd.edu/users/goguen/misc/singularity.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.kurzweilai.net/articles/art0092.html?printable=1">http://www.kurzweilai.net/articles/art0092.html?printable=1</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VINTTS",this.href,0);return true;' href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=N9427359AH">http://www.csa.com/partners/viewrecord.php?requester=gs&collection=TRD&recid=N9427359AH</a><br></div></div>
</div><!--entry-->

<div id='_1148_entry' class='entry'><span ><span class='name'>von Neumann, John</span> (1958). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("VONTCA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=578873'>The Computer And The Brain.</a></span></em></span> New Haven: Yale University Press. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=16113676055383442682'>Cited by 404</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20Computer%20And%20The%20Brain+author%3Avon%20Neumann&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1148_links")'>More links</a>)</span>
<div id='_1148_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://portal.acm.org/citation.cfm?id=SERIES11430.578873">http://portal.acm.org/citation.cfm?id=SERIES11430.578873</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXdyE8188M&amp;sig=LVA9RlYQZeZ2It9LlalNsee3B78">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXdyE8188M&sig=LVA9RlYQZeZ2It9LlalNsee3B78</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXduBe4gaK&amp;sig=fZ-lKPYBhJvagjc0WfC7SkhZtMI">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXduBe4gaK&sig=fZ-lKPYBhJvagjc0WfC7SkhZtMI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jWmsAd-7aM&amp;sig=56GHMjh9AJa4TqJQ5IIruU8Ms1A">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jWmsAd-7aM&sig=56GHMjh9AJa4TqJQ5IIruU8Ms1A</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXdtzd4cbP&amp;sig=DHwS67V-SvzbAjm9NYDHA37tI74">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXdtzd4cbP&sig=DHwS67V-SvzbAjm9NYDHA37tI74</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jWmwD9-dcN&amp;sig=qUd4y-uRsBLh74twJozMyaVGh5o">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jWmwD9-dcN&sig=qUd4y-uRsBLh74twJozMyaVGh5o</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXdwzg_daI&amp;sig=ajWucxc5XPSwz6ajjtHei3f7i3I">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXdwzg_daI&sig=ajWucxc5XPSwz6ajjtHei3f7i3I</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXdsDd-8bN&amp;sig=uivfQKg6zUhWLgzUFPiEKaIX8yI">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXdsDd-8bN&sig=uivfQKg6zUhWLgzUFPiEKaIX8yI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jWlvIe475J&amp;sig=cYOMqvd1VWngQ_rqASDW0msA8-o">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jWlvIe475J&sig=cYOMqvd1VWngQ_rqASDW0msA8-o</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXdtFe-dbN&amp;sig=zrqTa_c5ThZ0ILmi6bcolSjcSqk">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXdtFe-dbN&sig=zrqTa_c5ThZ0ILmi6bcolSjcSqk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXdwFg384L&amp;sig=x6eHrPSvrSXSqDzB4FT2iiFJ-YE">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXdwFg384L&sig=x6eHrPSvrSXSqDzB4FT2iiFJ-YE</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jWmtBf194J&amp;sig=xwPyDaNBqwNBeV8bJB_qBXeByXk">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jWmtBf194J&sig=xwPyDaNBqwNBeV8bJB_qBXeByXk</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("VONTCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Q30MqJjRv1gC&amp;oi=fnd&amp;pg=PR23&amp;ots=jXduHf185I&amp;sig=QHaMpf285hOXWmgcp-4jobJ-6uk">http://books.google.com/books?hl=en&lr=&id=Q30MqJjRv1gC&oi=fnd&pg=PR23&ots=jXduHf185I&sig=QHaMpf285hOXWmgcp-4jobJ-6uk</a><br></div></div>
</div><!--entry-->

<div id='_1149_entry' class='entry'><span ><span class='name'>Wagman, Morton</span> (1991). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("WAGAIA",this.href,0);return true;' href='http://dx.doi.org/10.1336/0275936155'>Artificial Intelligence and Human Cognition.</a></span></em></span> New York: Praeger. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17166636508487366863'>Cited by 7</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Artificial%20Intelligence%20and%20Human%20Cognition+author%3AWagman&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1150_entry' class='entry'><span ><span class='name'>Warnick, Barbara</span> (2004). <a rel="nofollow" class='article_title' onclick='trackclick("WARRAA",this.href,0);return true;' href='http://www.kluweronline.com/article.asp?PIPS=5139657&amp;PDF=1'>Rehabilitating AI: Argument loci and the case for artificial intelligence.</a></span> <span class='pub_name'>Argumentation</span> 18 (2):149-170. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Rehabilitating%20AI+author%3AWarnick&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1150_links")'>More links</a>)</span>
<div id='_1150_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WARRAA",this.href,0);return true;' href="http://www.springerlink.com/index/N808L6965581N152.pdf">http://www.springerlink.com/index/N808L6965581N152.pdf</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WARRAA",this.href,0);return true;' href="http://www.ingentaconnect.com/content/klu/argu/2004/00000018/00000002/05139657">http://www.ingentaconnect.com/content/klu/argu/2004/00000018/00000002/05139657</a><br></div></div>
</div><!--entry-->

<div id='_1151_entry' class='entry'><span ><span class='name'>Winograd, Terry</span> &amp; <span class='name'>Flores, Fernando</span> (1987). <em><span class='pub_name'><a rel="nofollow" class='article_title' onclick='trackclick("WINUCA",this.href,0);return true;' href='http://portal.acm.org/citation.cfm?id=576359&amp;dl='>Understanding Computers and Cognition.</a></span></em></span> Addison-Wesley. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=12981026026682883877'>Cited by 3155</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Understanding%20Computers%20and%20Cognition+author%3AWinograd&amp;btnG=Search'>Google</a> | <a href='javascript:show("_1151_links")'>More links</a>)</span>
<div id='_1151_links' style='display:none'><div class='extra'>Additional links for this entry:<br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pAQntmVd&amp;sig=29nUZ6v7NBR3_MW1f2iethnpq-Y">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pAQntmVd&sig=29nUZ6v7NBR3_MW1f2iethnpq-Y</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pxWlqqNk&amp;sig=OVMXPUQmKwV5M0sXy_jUirMqKr8">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pxWlqqNk&sig=OVMXPUQmKwV5M0sXy_jUirMqKr8</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pxQkvlVf&amp;sig=SPH_8y6W5R44eAZVF_KecsPTmFM">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pxQkvlVf&sig=SPH_8y6W5R44eAZVF_KecsPTmFM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pAWontOj&amp;sig=8bI0ORjPQdC0CyIgtYGGbyJ-KNM">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pAWontOj&sig=8bI0ORjPQdC0CyIgtYGGbyJ-KNM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pwOjwoOk&amp;sig=CJEWYsI8caWVRQdXVOd5b7NNd4o">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pwOjwoOk&sig=CJEWYsI8caWVRQdXVOd5b7NNd4o</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pzOmpqSb&amp;sig=BIXmzPS0q90udE7PaQF4k2VjFt0">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pzOmpqSb&sig=BIXmzPS0q90udE7PaQF4k2VjFt0</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pBSorqWj&amp;sig=BpZ1d0eOup2x3OzmNXXBmncf2gI">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pBSorqWj&sig=BpZ1d0eOup2x3OzmNXXBmncf2gI</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2_yzTovsQi&amp;sig=BGrPq-xVKWkg6CPTjGbXnOwLRzM">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2_yzTovsQi&sig=BGrPq-xVKWkg6CPTjGbXnOwLRzM</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2_yzRoupNh&amp;sig=W-GRjaar6j6QRFjlhVFDGngIzPY">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2_yzRoupNh&sig=W-GRjaar6j6QRFjlhVFDGngIzPY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pwUkqsRh&amp;sig=epUTB--1d3IJz9QsgxQtp2A9OYo">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pwUkqsRh&sig=epUTB--1d3IJz9QsgxQtp2A9OYo</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2_yzOlpuUg&amp;sig=1iSm6bCFzZPx_UR0p8uKW74EKw4">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2_yzOlpuUg&sig=1iSm6bCFzZPx_UR0p8uKW74EKw4</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pySlvmUb&amp;sig=2GK_DpBxmYL5ydVp294DhQiIXoY">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pySlvmUb&sig=2GK_DpBxmYL5ydVp294DhQiIXoY</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pvSjquUi&amp;sig=HgphXvbH7gfKxMVAXukzAAf05gQ">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pvSjquUi&sig=HgphXvbH7gfKxMVAXukzAAf05gQ</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=PR11&amp;ots=2-pzUmusWc&amp;sig=KZQ_QBXaLCBwwbmLJkZwbLH37-c">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=PR11&ots=2-pzUmusWc&sig=KZQ_QBXaLCBwwbmLJkZwbLH37-c</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=RA1-PR11&amp;ots=2_yvPlpoNf&amp;sig=KApvVKf8mZ9A3wab70l9zlF6C5A">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=RA1-PR11&ots=2_yvPlpoNf&sig=KApvVKf8mZ9A3wab70l9zlF6C5A</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=RA1-PR11&amp;ots=2_xyXmtmQb&amp;sig=99bcvKGbsQX85xJLVbqUhjybzFA">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=RA1-PR11&ots=2_xyXmtmQb&sig=99bcvKGbsQX85xJLVbqUhjybzFA</a><br><a rel="nofollow" style='font-size:smaller' onclick='trackclick("WINUCA",this.href,0);return true;' href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2sRC8vcDYNEC&amp;oi=fnd&amp;pg=RA1-PR11&amp;ots=2_ywQhspPj&amp;sig=qNJ48zOzeAWCzVK9IHHlHSx6qYE">http://books.google.com/books?hl=en&lr=&id=2sRC8vcDYNEC&oi=fnd&pg=RA1-PR11&ots=2_ywQhspPj&sig=qNJ48zOzeAWCzVK9IHHlHSx6qYE</a><br></div></div>
</div><!--entry-->

<div id='_1152_entry' class='entry'><span ><span class='name'>Yudkowsky, Eliezer</span> (online). Creating friendly AI.</span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&lr=&cites=17311904247319211443'>Cited by 5</a> | <a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Creating%20friendly%20AI+author%3AYudkowsky&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1153_entry' class='entry'><span ><span class='name'>Yudkowsky, Eliezer</span> (online). Staring into the singularity.</span> <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Staring%20into%20the%20singularity+author%3AYudkowsky&amp;btnG=Search'>Google</a>)</span><div id='_1153_abstract' class='extra' style='font-size:12px;'>Abstract: 1: The End of History 2: The Beyondness of the Singularity 2.1: The Definition of Smartness 2.2: Perceptual Transcends 2.3: Great Big Numbers 2.4: Smarter Than We Are 3: Sooner Than You Think 4: Uploading 5: The Interim Meaning of Life 6: Getting to the Singularity</div>
</div><!--entry-->
</div>
<p><a name='.6.6a'></a><a name=''></a><span class='myh3'>6.6a Philosophy of AI, General Works</span></p>

<div id='cat_6.6a' class='cat_content'>
<div id='__new_entries_6.6a__'></div><div id='__new_entry_6.6a__' class='entry'></div></div>
<p><a name='.6.6b'></a><a name=''></a><span class='myh3'>6.6b Philosophy of AI, Misc</span></p>

<div id='cat_6.6b' class='cat_content'>
<div id='__new_entries_6.6b__'></div><div id='__new_entry_6.6b__' class='entry'></div>
<div id='_1154_entry' class='entry'><span ><span class='name'>Adam, Alison</span> (2000). <a rel="nofollow" class='article_title' onclick='trackclick("ADADTS",this.href,0);return true;' href='http://www.springerlink.com/content/qnk553h7861v2107/fulltext.pdf'>Deleting the subject: A feminist reading of epistemology in artificial intelligence.</a></span> <span class='pub_name'>Minds and Machines</span> 10 (2). <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Deleting%20the%20subject+author%3AAdam&amp;btnG=Search'>Google</a>)</span><div id='_1154_abstract' class='extra' style='font-size:12px;'>Abstract: Â Â This paper argues that AI follows classical versions of epistemology in assuming that the identity of the knowing subject is not important. In other words this serves to `delete the subject''. This disguises an implicit hierarchy of knowers involved in the representation of knowledge in AI which privileges the perspective of those who design and build the systems over alternative perspectives. The privileged position reflects Western, professional masculinity. Alternative perspectives, denied a voice, belong to less powerful groups including women. Feminist epistemology can be used to approach this from new directions, in particular, to show how women''s knowledge may be left out of consideration by AI''s focus on masculine subjects. The paper uncovers the tacitly assumed Western professional male subjects in two flagship AI systems, Cyc and Soar</div>
</div><!--entry-->

<div id='_1155_entry' class='entry'><span ><span class='name'>Kirsh, David</span> (1995). <a rel="nofollow" class='article_title' onclick='trackclick("KIRTIU",this.href,0);return true;' href='http://adrenaline.ucsd.edu/kirsh/articles/space/intelligent_useof_space.pdf'>The intelligent use of space.</a></span> <span class='pub_name'>Artificial Intelligence</span> 73:31-68. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=The%20intelligent%20use%20of%20space+author%3AKirsh&amp;btnG=Search'>Google</a>)</span><div id='_1155_abstract' class='extra' style='font-size:12px;'>Abstract: The objective of this essay is to provide the beginning of a principled classification of some of the ways space is intelligently used. Studies of planning have typically focused on the temporal ordering of action, leaving as unaddressed questions of where to lay down instruments, ingredients, work-in-progress, and the like. But, in having a body, we are spatially located creatures: we must always be facing some direction, have only certain objects in view, be within reach of certain others. How we manage the spatial arrangement of items around us is not an afterthought: it is an integral part of the way we think, plan, and behave. The proposed classification has three main categories: spatial arrangements that simplify choice; spatial arrangements that simplify perception; and spatial dynamics that simplify internal computation. The data for such a classification is drawn from videos of cooking, assembly and packing, everyday observations in supermarkets, workshops and playrooms, and experimental studies of subjects playing Tetris, the computer game. This study, therefore, focuses on interactive processes in the medium and short term: on how agents set up their workplace for particular tasks, and how they continuously manage that workplace.</div>
</div><!--entry-->

<div id='_1156_entry' class='entry'><span ><span class='name'>Muntean, Ioan</span> &amp; <span class='name'>Wright, Cory D.</span> (2007). Autonomy, allostasic mechanisms, and AI: a biomimetic perspective.</span> <span class='pub_name'>Pragmatics and Cognition</span> 15:489â513. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Autonomy%2C%20allostasic%20mechanisms%2C%20and%20AI+author%3AMuntean&amp;btnG=Search'>Google</a>)</span><div id='_1156_abstract' class='extra' style='font-size:12px;'>Abstract: We argue that the concepts of mechanism and autonomy appear to be antagonistic when autonomy is conflated with agency. Once these concepts are disentangled, it becomes clearer how autonomy emerges from complex forms of control. Subsequently, current biomimetic strategies tend to focus on homeostatic regulatory systems; we propose that research in AI and robotics would do well to incorporate biomimetic strategies that instead invoke models of allostatic mechanisms as a way of understanding how to enhance autonomy in artificial systems.</div>
</div><!--entry-->

<div id='_1157_entry' class='entry'><span ><span class='name'>Penco, Carlo</span> (online). <a rel="nofollow" class='article_title' onclick='trackclick("PENETB",this.href,0);return true;' href='http://www.dif.unige.it/epi/hp/penco/pub/exp.htm'>Expressing the Background.</a></span> <em>Icelandic Philosophical Association (talks)</em>. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Expressing%20the%20Background+author%3APenco&amp;btnG=Search'>Google</a>)</span>
</div><!--entry-->

<div id='_1158_entry' class='entry'><span ><span class='name'>Silva, Porfirio</span> &amp; <span class='name'>U. Lima, Pedro</span> (2007). <a rel="nofollow" class='article_title' onclick='trackclick("SILIR",this.href,0);return true;' href='http://www.springerlink.com/content/jv82627127585321/fulltext.pdf'>Institutional Robotics.</a></span> In F. Almeida e Costa et al  (ed.), <em>Advances in Artificial Life. ECAL 2007</em>. Springer-Verlag. <span style='font-size:smaller'>&nbsp;&nbsp;(<a href='http://www.google.com/scholar?hl=en&amp;lr=&amp;q=Institutional%20Robotics+author%3ASilva&amp;btnG=Search'>Google</a>)</span><div id='_1158_abstract' class='extra' style='font-size:12px;'>Abstract: Pioneer approaches to Artificial Intelligence have traditionally
neglected, in a chronological sequence, the agent body, the world
where the agent is situated, and the other agents. With the advent of
Collective Robotics approaches, important progresses were made toward
embodying and situating the agents, together with the introduction of
collective intelligence. However, the currently used models of social environments are still rather poor, jeopardizing the attempts of developing
truly intelligent robot teams. In this paper, we propose a roadmap for
a new approach to the design of multi-robot systems, mainly inspired
by concepts from Institutional Economics, an alternative to mainstream
neoclassical economic theory. Our approach intends to sophisticate the
design of robot collectives by adding, to the currently popular emergentist
view, the concepts of physically and socially bounded autonomy of
cognitive agents, uncoupled interaction among them and deliberately set
up coordination devices.</div>
</div><!--entry-->
</div>


<br><br><br>
<br>
<div class="footer">
Use of this site is subject to <a rel="nofollow" href="http://philpapers.org/help/terms.html">terms &amp; conditions</a>.<br>
(c) David Chalmers and David Bourget 2007-2009<br>
<a href=http://deluxe-menu.com/>Javascript Menu by Deluxe-Menu.com</a><br>
</div>

<script type="text/javascript">
// Google analytics
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-6029851-2");
pageTracker._trackPageview();
</script>


++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.cs.yale.edu/>====================
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="refresh" content="0; url=http://cpsc.yale.edu/">
<meta name="robots" content="noindex">
</head>

<body>

<div style="text-align:center">
  <h1>Yale Computer Science has moved</h1>
<h2>Please bookmark our new URL</h2>
  <a href="http://cpsc.yale.edu/">http://cpsc.yale.edu</a> 
  <p>If you are not automatically redirected to the new site in a few
seconds, please click on the link above.</p>
</div>

</body>
</html>
++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://www.ai.uga.edu/>====================
<!DOCTYPE HTML>
<html><!-- InstanceBegin template="/Templates/index.dwt" codeOutsideHTMLIsLocked="false" -->
<head>
<script type="text/javascript" src="js/libraries/jquery.js"></script>
<script type="text/javascript" src="js/slider.js"></script>
<script type="text/javascript" src="js/simple-menu.js"></script>

<!-- script for photo slider on home page -->
<script type="text/javascript">
$(document).ready(function(){
		$('#slider').s3Slider({
			timeOut:6000
			}); 
		});
function MM_preloadImages() { //v3.0
  var d=document; if(d.images){ if(!d.MM_p) d.MM_p=new Array();
    var i,j=d.MM_p.length,a=MM_preloadImages.arguments; for(i=0; i<a.length; i++)
    if (a[i].indexOf("#")!=0){ d.MM_p[j]=new Image; d.MM_p[j++].src=a[i];}}
}

function MM_swapImgRestore() { //v3.0
  var i,x,a=document.MM_sr; for(i=0;a&&i<a.length&&(x=a[i])&&x.oSrc;i++) x.src=x.oSrc;
}

function MM_findObj(n, d) { //v4.01
  var p,i,x;  if(!d) d=document; if((p=n.indexOf("?"))>0&&parent.frames.length) {
    d=parent.frames[n.substring(p+1)].document; n=n.substring(0,p);}
  if(!(x=d[n])&&d.all) x=d.all[n]; for (i=0;!x&&i<d.forms.length;i++) x=d.forms[i][n];
  for(i=0;!x&&d.layers&&i<d.layers.length;i++) x=MM_findObj(n,d.layers[i].document);
  if(!x && d.getElementById) x=d.getElementById(n); return x;
}

function MM_swapImage() {  //v3.0
  var i,j=0,x,a=MM_swapImage.arguments; document.MM_sr=new Array; for(i=0;i<(a.length-2);i+=3)
   if ((x=MM_findObj(a[i]))!=null){document.MM_sr[j++]=x; if(!x.oSrc) x.oSrc=x.src; x.src=a[i+2];}
}
</script>

<link href="css/styles.css" rel="stylesheet" type="text/css" media="screen" /> 
<link href="css/print.css" rel="stylesheet" type="text/css" media="print" /> 
<link href="css/slider.css" rel="stylesheet" type="text/css" media="screen" /> 
<link href="css/simple-menu.css" rel="stylesheet" type="text/css" media="screen">

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Type" content="cache" />
<meta http-equiv="robots" content="INDEX,FOLLOW" />
<meta http-equiv="keywords" content="Artificial Intelligence, AI, UGA, University of Georgia" />
<meta http-equiv="description" content="Aritificial Intelligence, University of Georgia" />
<!-- InstanceBeginEditable name="doctitle" -->
<title>Institute for Artificial Intelligence University of Georgia</title>
<!-- InstanceEndEditable -->
<!-- InstanceBeginEditable name="head" -->
<!-- InstanceEndEditable -->
</head>

<body>
<div id="outer">
<div id="wrapper">

<!-- The menu at the very top of the screen -->
<div id="topmenu">
    <ul>
    <li><a href="http://ugamail.uga.edu/" target="_blank">UGA Mail</a></li>
    <li><a href="https://employee.uga.edu/FacStaff/index.jsp" target="_blank">Faculty/Staff Services</a></li>
    <li><a href="http://www.libs.uga.edu/" target="_blank">UGA Libraries</a></li>
    <li><a href="http://news.uga.edu/" target="_blank">UGA News</a></li>
    <li><a href="Driving_Dir.html" target="_blank">AI Driving Directions</a></li>
    <li><a href="http://www.grad.uga.edu/" target="_blank">Graduate School</a></li>
    </ul>
</div> 

<!-- The IAI logo and name --> 
<div id="banner"><a href="index.html"><img src="images/banner.png" /></a></div>

<!-- The primary menu for the site --> 
<div id="topnav" class="wrap">
	<ul id="nav">
		<li><a href="#">Degree Programs</a>
			<ul>
				<li><a href="Prospective_students.html">Prospective Students</a>
				<li><a href="MS_in_AI.html">MS Program Details</a></li>
				<li><a href="Application.html">MS Program Admissions</a></li>
				<li><a href="Course_Requirements.html">MS Course Requirement</a></li>
				<li><a href="AB_in_CogSci.html">AB in Cognitive Science</a></li>
			</ul>			
		</li>
		<li><a href="#">People</a>
			<ul>
				<li><a href="Faculty.html">Faculty</a></li> 
				<li><a href="Current_Students.html">Current Students</a></li>
				<li><a href="Fellows.html">Fellows</a></li>
				<li><a href="Industrial.html">Industrial Partners</a></li>
                         
			</ul>
		</li>
		<li><a href="#">Resources</a>
			<ul>
				<li><a href="Oral_thesis.html">Theses and Oral Exam</a></li>
				<li><a href="IAI_related_sites.html">IAI Related Sites</a></li>
   				<li><a href="important_links.html">Important Links</a></li>
				<li><a href="International_Students.html">International Students</a></li>
			</ul>
        </li>    
		<li><a href="TechnicalSupport.html">Technical Support</a></li>
		<li><a href="News.html">News</a></li>
		<li><a href="Support.html">Support IAI</a></li>
	</ul>
</div>


<!-- InstanceBeginEditable name="EditRegion3" -->
    <div id="slider">
      <ul id="sliderContent">
        <li class="sliderImage"> <img src="images/dpotter.jpg" /> <span class="top"><strong>Dr. Don Potter</strong> <br />
         Director of the Institute for Artificial Intelligence<br />Professor of Computer Science<br />Research interests:<br /> Knowledge-based systems<br />Genetic algorithms<br />Expert database systems<br />Advanced information system design
 <br />
          </span> </li>
        <li class="sliderImage"> <img src="images/Congzhou.jpg" /> <span class="top"><strong>Dr. Michael Covington</strong> <br />
          Senior Research Scientist <br />Adjunct Professor of Computer Science<br />
Member of the Linguistics and Engineering Faculties<br />
Associate Director of Artificial Intelligence
          </span> </li>
                  <li class="sliderImage"> <img src="images/doshi3.jpg" /> <span class="top"><strong>Dr. Prashant Doshi</strong> <br />
          Associate Professor of Computer Science <br />
          Faculty member of Artificial Intelligence<br />
          Director of THINC lab<br />
          Research interests:  <br />
          Multiagent systems with a focus on interactive <br />decision theory, game theory, and application to robotics<br />
          </span> </li>
           <li class="sliderImage"> <img src="images/Bill.jpg" /> <span class="top"><strong>Dr. Bill Hollingsworth</strong> <br />
          Ph.D., Computer Science at Univerisity of Cambridge <br />
           </span> </li>
            <li class="sliderImage"> <img src="images/Electro.jpg" /> <span class="top"><strong>Electronics</strong> <br />The AI Microelectronics Lab is equipped for digital and <br />analog circuit design, microcontroller programming, and  <br />robot construction and testing.

          <br />
           </span> </li>

        <li class="sliderImage"> <img src="images/StudyAtAI.JPG" /> <span class="top"><strong>Study at the IAI</strong> <br />
        At the IAI, you will find a culture of curiosity and mutual support that gives our students strong relationships with <br />both faculty and other students. This yields <br /> massive learning opportunities in and out of the  <br />classroom.
           <br />
          </span> </li>
        <li class="sliderImage"> <img src="images/Robot.JPG" /> <span class="top"><strong>Robotics Class</strong> <br />
         Introduction to Robotics provides a focus on autonomous mobile robots, especially: cognitive behavior, and motion.  Cognitive behavior addresses problem solving using  <br />sensory inputs and desired goals.  Motion deals with  <br />various aspects of movement.  Projects are carried out  <br />using a variety of robotics kits.


 <br />
          </span> </li>
                <li class="sliderImage"> <img src="images/CovingtonTeachingNLP.jpg" /> <span class="top"><strong>Natural Language Processing </strong><br />
                This is a technical course in computer processing and understanding of human languages. Topics include morphological analysis, part-of-speech tagging, parsing, unification-based grammar, and formal semantics.

           <br />
           </span> </li>
       

        <div class="clear sliderImage"></div>
      </ul>
    </div>
    <div id="content">
      <h1>Using computers to model and extend the human mind</h1>
      <p>The University of Georgia has always seen cognitive science as an interdisciplinary field where <a href="http://www.cs.uga.edu/" target="_blank">computer science</a> intersects with <a href="http://www.phil.uga.edu/" target="_blank">philosophy</a>, <a href="http://www.uga.edu/psychology/" target="_blank">psychology</a>, <a href="http://www.linguistics.uga.edu/" target="_blank">linguistics</a>, <a href="http://www.engr.uga.edu/" target="_blank">engineering</a> and other fields.This comprises both classical <strong>artificial intelligence,</strong> which focuses on getting computers to behave intelligently, and newer approaches to <strong>cognitive computing</strong>, where the computer is seen as an extension rather than a model of the human mind. </p>
      <p>The Institute for Artificial Intelligence  is an interdepartmental research and instructional unit within the <a href="http://www.franklin.uga.edu/" target="_blank">Franklin College of Arts and Sciences</a> of the <a href="http://www.uga.edu/" target="_blank">University of Georgia</a>. Strengths include logic programming, expert systems, neural nets, genetic algorithms, natural language processing and computational psycholinguistics.The Institute for Artificial Intelligence houses two degree programs, the Master of Science program in Artificial Intelligence and the bachelor's degree program in Cognitive Science. Affliliated with the Institute are over 75 people hailing from over 10 different countries. We pride ourselves on the diversity of our program student body and the ability of our program to allow for the pursuit of personal research interests. </p>
      <p align="center"><a href="Application.html">Apply to our Master's Degree Program</a></p>
    </div>
    <!-- InstanceEndEditable -->
 
<div id="footer">
	<!-- markup as was BEFORE richtext
	<span id="leftfoot">
		<a href="../Contact.html">Contact us </a> <br/>
		Institute for Artificial Intelligence<br/>
		University of Georgia<br/>
		Boyd GSRC, Room 111<br/>
		Athens, GA 30602-7415<br/>
		Phone: (706) 542-0358<br/>
		Fax: (706) 542-8864<br/>
	</span>
    -->
    <span itemscope itemtype="http://schema.org/LocalBusiness" id="leftfoot">
        <a href="Contact.html">Contact us </a> <br/>
        <span itemprop="name">Institute for Artificial Intelligence<br/>
            University of Georgia</span><br/>
        <span itemprop="address" itemscope itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">Boyd GSRC, Room 111</span><br/>
        <span itemprop="addressLocality">Athens</span>, 
        <span itemprop="addressRegion">GA</span> 
        <span itemprop="postalCode">30602-7415</span>
        <meta itemprop="addressCountry" content="USA"></span><br/>
        Phone: 
        <span itemprop="telephone">(706) 542-0358</span><br/>
        Fax: (706) 542-8864<br/>
        <meta itemprop="url" content="http://www.ai.uga.edu">
            <span itemprop="location" itemscope itemtype="http://schema.org/Place">
                <span itemprop="geo" itemscope itemtype="http://schema.org/GeoCoordinates">
                    <meta itemprop="latitude" content="33.946057"/>
                    <meta itemprop="longitude" content="-83.374557"/>
                </span>
            </span>
	</span>
	<span id="rightfoot">
		<a href="http://www.uga.edu/" target="_blank"> The University of Georgia</a><br/>
		<a href="http://www.uga.edu/" target="_blank">is an equal opportunity/affirmative action employer</a>.<br/>
	</span><br/>  
</div>

</div>
</div>
</body>
<!-- InstanceEnd --></html>++++++++++++++++++++<Over>++++++++++++++++++++
====================<http://cogsci.uwaterloo.ca/>====================
<HTML>  
<HEAD>
  <META NAME="GENERATOR" CONTENT="Adobe PageMill 3.0 Mac">
  <TITLE>Computational Epistemology Lab Home Page</TITLE>
</HEAD>
<BODY BGCOLOR="#ffffff">

<H1><A HREF="http://www.uwaterloo.ca/"><IMG SRC="Icons/uw%20logo.gif"
WIDTH="134" HEIGHT="91" ALIGN="LEFT" BORDER="0" NATURALSIZEFLAG="3"></A></H1>

<h1><font color="#3300CC">Computational Epistemology Laboratory</font></h1>
<h4 ALIGN=left>&nbsp;</h4>
<p align="left">The <A HREF="http://cogsci.uwaterloo.ca/index.html">Computational 
  Epistemology Lab</A> (<B>CEL</B>), headed by Professor <A HREF="http://watarts.uwaterloo.ca/%7Epthagard/Biographies/pault.html">Paul 
  Thagard </A>of the <A HREF="http://watarts.uwaterloo.ca/PHIL/index.html">Department 
  of Philo</A><A HREF="http://watarts.uwaterloo.ca/PHIL/index.html">sophy</A>, 
  the <A HREF="http://www.uwaterloo.ca/">University of Waterloo</A>, is a facility 
for research into Cognitive Science and related areas of Philosophy. </p>
<p align="left">See<a href="http://watarts.uwaterloo.ca/%7Epthagard/Biographies/pault.html"> 
  Paul Thagard's website</a> for his biography, publications, and courses.</p>
<p align="left">See below for information on <a href="#anchor650765">cognitive 
  science</a>, <a href="#software">software</a>, and <a href="#bibs">bibliographies.</a>. 
</p>
<HR ALIGN=LEFT>
<H2><A NAME="anchor650765"></A>Cognitive Science sites</H2>
<H3>Cognitive Science at the University of Waterloo</H3>
<UL>
  <LI><A HREF="http://www.arts.uwaterloo.ca/InterDis/cogsci/index.htm">General 
    information</A> 
  <LI><a href="http://ugradcalendar.uwaterloo.ca/page/ARTS-Cognitive-Science-Option">Undergraduate option 
    - calendar information, 2010-2011</a>
  <LI><A HREF="http://philosophy.uwaterloo.ca/CogSci/grad/diplomareqs.html">Graduate 
    diploma in Cognitive Science</A> 
  <LI><A HREF="http://cogsci.uwaterloo.ca/Movies/ChrisTalks.mov">Cognitive science 
    forum - Prof. Chris Eliasmith (Quicktime movie</A><A
  HREF="http://cogsci.uwaterloo.ca/Movies/ChriTalks%2Cmov">)</A> 
  <LI><A HREF="http://watarts.uwaterloo.ca/~pthagard/cogscifaculty.html">Cognitive Science faculty at the University of Waterloo</A> 
</UL>
<H3>Other interesting sites</H3>
<MENU> 
<LI><A HREF="http://cogsci.uwaterloo.ca/courses/resources.html">Cognitive science 
  resources</A>
<LI><a href="http://plato.stanford.edu/entries/cognitive-science/">Introduction to Cognitive Science</a> </MENU>
<P>
<HR ALIGN=LEFT SIZE="5">
<H2><A NAME="software"></A>Software</H2>
<P><A HREF="http://cogsci.uwaterloo.ca/CoherenceCode/COHERE/COHERE.instructions.html">COHERE 
  </A>(LISP code in HTML format), including ACME, DECO, ECHO,</P>
<P> IMP, and HOTCO.</P>
<P><A HREF="http://cogsci.uwaterloo.ca/CoherenceCode/PI.html">PI</A> (LISP code 
  from 1987, in HTML).</P>
<DL>
  <DT><A HREF="/JavaECHO/jecho.html">JavaECHO</A> (Java version) 
  <DD>Source code for Java version of ECHO. 
  <DT><A HREF="/CoherenceCode/MacECHO.sit.hqx">MacECHO</A> (LISP version) 
  <DD>Macintosh ECHO system software (228 K) in binhexed StuffIt format. 
  <DT><A HREF="/CoherenceCode/MacECHO-c.sit.hqx">MacECHO</A> (C version) 
  <DD>Macintosh ECHO system software (448 K) in binhexed Stuffit format. 
  <DT><A HREF="/CoherenceCode/DECO.sit.hqx">DECO</A> (LISP version) 
  <DD>DECO system software (108 K) in binhexed Stuffit format. 
  <DT><A HREF="http://zooid.org/%7Etforcdivad/diva/diva.html">DIVA</A> (Java 3D 
    program for dynamic visual analogies). 
  <DT><A HREF="http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/neural/systems/thnet/0.html">THNET</A> 
    (original LISP versions of ACME and ARCS). 
  <DD>&nbsp; 
</DL>
<P>
<HR ALIGN=LEFT WIDTH="75%">
<h2><a name="bibs"></a>Bibliographies </h2>
<p align="left"><a href="Bibliographies/cogsci.bib.html">Cognitive Science bibliography.</a></p>
<P><a href="courses/Phil256/glossary.html">Cognitive Science glossary.</a></P>
<hr>
<P><a href="mailto:pthagard@uwaterloo.ca">Please email comments.</a> </P> </P>
<a href="http://cogsci.uwaterloo.ca/Biographies/pault.html">Paul Thagard's 
  home page</a>
<ADDRESS>
Last updated, Dec. 22, 2010
</ADDRESS>
</BODY>
</HTML>
++++++++++++++++++++<Over>++++++++++++++++++++
